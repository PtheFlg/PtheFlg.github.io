<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>JIT即时编译器</title>
    <url>/2022/06/02/JIT/</url>
    <content><![CDATA[<p>最早我们说运行时数据区的时候有一张图，就是runtime的构造，里面有PC，堆，栈，方法区，本地方法栈啥的，还有一个东西，叫JIT编译产物 CodeCache，这时啥玩意？我们这里就来介绍一下JIT是啥东西。</p>
<span id="more"></span>

<h1 id="1-JIT-即时编译器"><a href="#1-JIT-即时编译器" class="headerlink" title="1. JIT 即时编译器"></a>1. JIT 即时编译器</h1><p>首先明确几个概念：</p>
<ul>
<li><p>Java 运行在 JVM上，JVM 类似 物理机，二者都有指令，比如物理机有 汇编 机器码 JVM 就有JVM指令。</p>
</li>
<li><p>Java 是半解释半编译语言</p>
</li>
<li><p>这个编译，分为两部分：</p>
<ul>
<li><p>前端编译：javac 编译代码变成 class 文件</p>
</li>
<li><p>后端编译: JIT 编译代码为 计算机认识的指令</p>
</li>
</ul>
</li>
<li><p>翻译，指的是 JVM 通过 PC寄存器，逐条执行class文件里面的指令</p>
</li>
<li><p>JIT 是即时编译器，也就是在程序运行时编译，是否编译取决于热点探测，这个后面会说到。</p>
</li>
</ul>
<h1 id="2-Java代码的执行分类"><a href="#2-Java代码的执行分类" class="headerlink" title="2. Java代码的执行分类"></a>2. Java代码的执行分类</h1><p>如下图：</p>
<p><img src="/images/runtime/JIT.png"></p>
<p><img src="/images/runtime/JIT2.png" alt="jit2"></p>
<p>上图两个就是Java编译的方式。</p>
<p>途中，黄色的路线：程序源码一直到抽象语法树，都是javac 给我们处理， 目的是生成线性的指令集合，然后 要么是 JVM直接翻译运行，要么就是 JIT 编译成机器码 运行。</p>
<p>即时编译：</p>
<p>就是JIT编译完以后，机器码存起来了，如果再次调用这个方法，他就会直接去找机器码运行。</p>
<h1 id="3-HotSpot-采用的方式"><a href="#3-HotSpot-采用的方式" class="headerlink" title="3. HotSpot 采用的方式"></a>3. HotSpot 采用的方式</h1><p>HotSpot 是两种方式都在使用，在运行时 即时编译和翻译是同步进行，二者协调进行。</p>
<p>即时编译的好处就是一次编译，以后运行速度快，但是编译也耗费时间。</p>
<p>翻译的好处就是不需要翻译，直接运行。</p>
<p>当虚拟机启动时，翻译器会首先工作，省去编译的时间，然后随着时间的推移， 即时编译器开始起作用，将一些有价值的代码编译成机器指令，提高速度。</p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>生产环境中，热机能承受的负载大于冷机，如果项目体量大，流量大，那么吧一个项目部署到一个JVM刚刚启动的机器上，可能导致宕机。</p>
<h1 id="4-细说JIT"><a href="#4-细说JIT" class="headerlink" title="4. 细说JIT"></a>4. 细说JIT</h1><ul>
<li><p>java 语言的 “编译期” 其实是一段不确定的操作过程，因为他有三种情况：</p>
</li>
<li><p>既可能指的是前端编译 也就是 javac 编译，把java文件转化为class文件</p>
</li>
<li><p>也可能是后端编译，将JVM指令转化为机器码</p>
</li>
<li><p>还有可能是静态提前编译器(AOT 编辑器， Ahead Of Time Compiler) 直接吧 Java 编译成机器码</p>
</li>
</ul>
<p>问题来了，前面提到，Hotspot 虚拟机是 编译和翻译同时进行的，</p>
<p>那么jvm如何选择哪些编译哪些翻译？就用到了下面的东西</p>
<h1 id="5-热点代码及探测方法"><a href="#5-热点代码及探测方法" class="headerlink" title="5. 热点代码及探测方法"></a>5. 热点代码及探测方法</h1><p>是否需要启动JIT去编译代码取决于这个代码的执行频率，如果执行频率高，则启动JIT进行编译，同时JIT对其进行 <em>深度优化</em> ，然后编译成机器码，那么这部分执行频率高的代码，也叫做 <em>热点代码</em> 。</p>
<ul>
<li><p>一个被多起的方法，或者是一个方法题内循环册数比较大多的循环体，都可以称为 <em>热点代码</em> 。因为这个过程发生在方法执行过程中，所以这个方法也成为 <em>栈上替换</em> 简称 OSR(On Stack Replacement)</p>
</li>
<li><p>那么一个代码被执行多少次就算是热点代码了？这主要依赖<em>热点探测功能</em>。</p>
</li>
<li><p>Hotspot 的热点探测方式是基于计数器的热点探测</p>
</li>
<li><p>采用计数器，Hotspot VM 将给每一个方法都建立2个不同的计数器，分别是：</p>
<ul>
<li><p>方法调用计数器：统计方法调用次数</p>
</li>
<li><p>回边计数器：统计循环体执行的循环次数</p>
</li>
</ul>
</li>
<li><p>阈值：VM 的client模式下是 1500次，server 模式下 10000 次</p>
<blockquote>
<p>即便我们的是PC，个人电脑，但是VM也是server 模式，</p>
<p>可以 <code>java --version</code> 看一看.</p>
</blockquote>
</li>
<li><p>这个阈值可以通过 <code>-XX:CompileThreshold</code> 来人为设定。</p>
</li>
<li><p>超过阈值，就会提交编译请求，然后JIT编译，最后的编译结果，也就是机器指令，他会存在方法区里面，我们之前也说过 方法区里面有JIT的代码缓存 <em>CodeCache</em> 。</p>
</li>
</ul>
<p>具体流程如下图：</p>
<p><img src="/images/runtime/JIT3.png" alt="jit3"></p>
<hr>
<h2 id="热度衰减"><a href="#热度衰减" class="headerlink" title="热度衰减"></a>热度衰减</h2><ul>
<li><p>如果不做任何设置，方法调用计数器记录的并不是一个绝对的次数，而是一个相对的频率，也就是一段时间内的调用次数，如果超过了这个一段时间，方法的调用次数还不足以提交便已请求，那么调用计数器的值就会减半，这个过程称为程序计数器的<strong>热度衰减</strong>，这段时间叫<strong>半衰期</strong>。</p>
</li>
<li><p>热度衰减是 JVM在垃圾回收的时候顺便进行的行为，可以通过参数 <code>-XX:-UseCounterDecay</code> 来关闭热度衰减，这个时候，调用计数器记录的就是一个绝对的调用次数，只要运行时间够长，绝大多数的方法都可以被编译。</p>
</li>
<li><p>可以通过 <code>-XX:CounterHalfLifeTime</code>来设置半衰期时间，单位是秒。</p>
</li>
</ul>
<h1 id="6-JVM-关于JIT的参数"><a href="#6-JVM-关于JIT的参数" class="headerlink" title="6. JVM 关于JIT的参数"></a>6. JVM 关于JIT的参数</h1><ul>
<li><p><code>-Xint</code> 代码全部解释执行，也可以 java -Xint –version 我们会看到 interpreted mod，也就是解释执行</p>
</li>
<li><p><code>-Xcomp</code> 代码全部编译执行，同理上面，看到 compile mode 编译执行</p>
</li>
<li><p><code>-Xmixed</code> 代码混合执行，一边翻译一边编译。</p>
</li>
</ul>
<h1 id="7-JVM模式"><a href="#7-JVM模式" class="headerlink" title="7. JVM模式"></a>7. JVM模式</h1><p>我们之前说过，JVM分为两种模式：client 模式 和 server 模式，client 模式里面调用计数器阈值是1500 次 server 是 10000次，同事JIT也分为两种，一个 Client Compiler(简称C1)，一个 Server Compiler (简称C2)如何修改这两种模式：</p>
<ul>
<li><p><code>-client</code> 开启 client 模式，使用C1，优化比较简单，耗时短，达到最快的编译速度。</p>
</li>
<li><p><code>-server</code> 开启 server模式，使用C2，64位电脑是支持server模式的，同时默认开启，server模式优化的更深一点，所以得到的机器码比client 更快，但是编译时间更长。</p>
</li>
</ul>
<h1 id="8-扩展：AOT提前编译器"><a href="#8-扩展：AOT提前编译器" class="headerlink" title="8. 扩展：AOT提前编译器"></a>8. 扩展：AOT提前编译器</h1><p>AOT 提前编译器，不同于即时编译器是运行时编译，他是在运行之前编译。</p>
<p>jdk9 引入了实验性的 aot编译工具 jaotc，将java 类文件直接编译成机器码，存放到生成的代码共享库中。</p>
<p>具体流程：.java -&gt; .class — jaotc —&gt; .os</p>
<p>好处就是第一次运行快了，坏处就是降低了 Java 链接过程的动态性，破坏了 java 一次编译到处运行的原则。</p>
<h1 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h1><p>可以看出这一章东西倒不是很多，比较简单，就是一些简单的概念，了解我觉得就行了。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>JS-this指向问题</title>
    <url>/2022/10/16/JS-this%E6%8C%87%E5%90%91%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>之前的JS一直就学了个皮毛，this问题倒是也不咋碰到所以不咋重视，结果这次做项目发现this我是一点也不懂，所以就百度了好久，总结了一下 JS 里面的this到底是个啥。</p>
<span id="more"></span>

<blockquote>
<p>create by P-F on 2022&#x2F;10&#x2F;16</p>
</blockquote>
<h1 id="1-function-作为对象"><a href="#1-function-作为对象" class="headerlink" title="1. function 作为对象"></a>1. function 作为对象</h1><p>JS 里面的 function 与其说是函数，不如说是我们理解的方法，Java 里面的方法中的 this 就是指向的当前类的实例化对象，JS 的 function 也一样，在 function 作为普通方法调用的时候，function 内的 this 指向的就是当前 function 所在的对象。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> user = &#123;</span><br><span class="line">    <span class="attr">name</span>: <span class="string">&quot;jack&quot;</span>,</span><br><span class="line">    <span class="attr">age</span>: <span class="number">20</span>,</span><br><span class="line">    <span class="attr">hello</span>: <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`hello, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.name&#125;</span>, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.age&#125;</span> years old`</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面这个例子中，this 就指向的是当前 hello 方法的所属对象 user，所以就可以使用 <code>this.name</code> 这种的来访问对象的成员。</p>
<h1 id="2-function-作为函数"><a href="#2-function-作为函数" class="headerlink" title="2. function 作为函数"></a>2. function 作为函数</h1><p>如果说 function 没有在对象内，而是直接放在了上下文中，比如直接放在了 script 标签内，那么 function 的 this 其实也同理指向了 function 的所属对象，但是这个时候 function 的所属对象就变成了 function 的上下文。</p>
<p>举个例子：如果 function 直接放在了 script 标签内，那么就可以理解成这个对象是当前页面 window 对象的方法，所以 function 的 this 就会指向 window，那如果在 nodejs 环境中，function 直接写在文件内，那么 this 就指向了 nodejs 中的上下文对象 <code>global</code>。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    <span class="keyword">function</span> <span class="title function_">a</span>(<span class="params"></span>) &#123;<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)&#125;</span><br><span class="line">    <span class="title function_">a</span>()</span><br><span class="line"></span><br><span class="line">    &lt;!-- <span class="variable language_">window</span>&#123;...&#125; --&gt;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// nodejs:</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">a</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">a</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Object [global]...</span></span><br></pre></td></tr></table></figure>

<h1 id="3-this-不可继承"><a href="#3-this-不可继承" class="headerlink" title="3. this 不可继承"></a>3. this 不可继承</h1><p>如果出现了嵌套函数，那内层函数的 this 又变成谁了？</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;</span><br><span class="line">    <span class="attr">a</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">b</span>: <span class="number">20</span>,</span><br><span class="line"></span><br><span class="line">    <span class="attr">foo</span>: <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> c = <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="title function_">c</span>()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">obj.<span class="title function_">foo</span>()</span><br></pre></td></tr></table></figure>

<p>这里分析一下：外层的 foo 方法是 obj 对象的方法，所以 foo 方法内的 this 肯定是指向了 obj，这个没毛病，但是里面的 c 函数也是指向了 obj 么？结果显示并非，内层函数的 this 仍然是 window，似乎也好理解，因为 c 函数虽然在obj 对象的方法内部，但是本身并不属于某个对象，所以 this 还是 window。</p>
<p>那怎么改才能让内层的函数可以访问 obj？</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;</span><br><span class="line">    <span class="attr">self</span>: <span class="variable language_">this</span>,</span><br><span class="line"></span><br><span class="line">    <span class="attr">foo</span>: <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        (<span class="keyword">function</span>(<span class="params"></span>)&#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(self)</span><br><span class="line">        &#125;)()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">obj.<span class="title function_">foo</span>()</span><br></pre></td></tr></table></figure>

<p>这样就可以了。</p>
<h1 id="4-function-作为构造函数"><a href="#4-function-作为构造函数" class="headerlink" title="4. function 作为构造函数"></a>4. function 作为构造函数</h1><p>这里就涉及到了 JS 面向对象的内容了，面向对象还涉及到 JS 的原型和原型链，以后会详细看的，目前还不会。只是大致说一下：function 可以作为构造函数，使用 new 关键字可以创建对象，看下面的例子：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">Person</span>(<span class="params">name, age</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="attr">name</span>: name, <span class="attr">age</span>: age&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> p = <span class="title class_">Person</span>(<span class="string">&#x27;jack&#x27;</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">User</span>(<span class="params">name, age</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里的 this 不代表 window 了，而是代表当前要构造的对象 &#123;  &#125;</span></span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">name</span> = name</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">age</span> = age</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">hello</span> = <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`hello, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.name&#125;</span>, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.age&#125;</span> years old`</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> u = <span class="keyword">new</span> <span class="title class_">User</span>(<span class="string">&#x27;jack&#x27;</span>, <span class="number">20</span>)</span><br><span class="line">u.<span class="title function_">hello</span>()</span><br></pre></td></tr></table></figure>

<p>上面的例子里面，第一个 Person 方法，也可以创建一个对象，但是略有点麻烦，那么就可以使用下面这种办法：使用 new 关键字来创建对象。</p>
<p>new 后面跟一个函数，然后函数会被当做构造函数执行，作为构造函数时，函数内的 this 就代表我要构造出来的这个对象。</p>
<h1 id="5-箭头函数的this"><a href="#5-箭头函数的this" class="headerlink" title="5. 箭头函数的this"></a>5. 箭头函数的this</h1><p>而箭头函数中，this 又是另一番镜像。箭头函数中的 this 只是一个普通的变量，没错，就是一个普通的变量。根据函数作用域，当函数内访问变量时，会在函数声明的地方找这个变量，如果找不到，就会从声明位置往上找，比如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">a</span>(<span class="params"></span>)&#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">b</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> a = <span class="number">20</span></span><br><span class="line">    <span class="title function_">a</span>()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">b</span>()</span><br></pre></td></tr></table></figure>

<p>这里会打印 10，为啥？因为 b 函数内调用 a 函数，a 函数要找 a 变量，从 a 的声明位置开始找，a 函数内没有，则往外找，也就找到了全局里面的 <code>let a = 10</code>。</p>
<p>同理，调用一个箭头函数，对于箭头函数来说 this 就是一个普通变量，他会根据上面的原则去找这个 this 到底是个啥，比如：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">let</span> a = <span class="keyword">function</span>(<span class="params"></span>) &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>) &#125;</span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">let</span> <span class="title function_">b</span> = (<span class="params"></span>) =&gt; &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>) &#125;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="title function_">a</span>()</span></span><br><span class="line"><span class="language-javascript">    <span class="title function_">b</span>()</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>这俩输出的 this 全是 window，为啥？因为在 script 标签内，this 就是 window，a 函数看作是 window 的方法，所以 a 的 this 是 window，但是 b 不一样，b 函数里面找 this，没找到，就去 b 的上层作用域里面找，也就是 script 标签内，结果发现了 script 标签内有 this，还是 window，所以 b 打印 this 也是 window。</p>
<p>这里虽然俩 this 都是 window，但意义是不一样的，在 nodejs 环境：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = <span class="keyword">function</span>(<span class="params"></span>) &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>) &#125;</span><br><span class="line"><span class="keyword">let</span> <span class="title function_">b</span> = (<span class="params"></span>) =&gt; &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>) &#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">a</span>()</span><br><span class="line"><span class="title function_">b</span>()</span><br></pre></td></tr></table></figure>

<p>这回就不一样了，a 出来的 this 是 global，而 b 的 this 就是 { }，因为 nodejs 中，函数的看做是 global 的方法，但是这个 global 可不是这个 js 文件的作用域，一个 js 文件里面默认就有一个对象 this &#x3D; {}，所以调用 b 函数找 this 就找到了 { }。</p>
<p>一句这个特性，我们就可以优化上面提到的 this 继承问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;</span><br><span class="line">    <span class="attr">a</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="title function_">foo</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="title function_">c</span> = (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="variable language_">this</span>.<span class="property">a</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="title function_">c</span>()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">obj.<span class="title function_">foo</span>()</span><br></pre></td></tr></table></figure>

<p>这次就可以正常让内层函数正确的访问到外层方法的 this 对象，原因也很简单，c 函数调用时，碰到了 this，但是不知道这个 this 是啥声明里面也没有，就跑到 c 的上层作用域也就是 foo 方法内去找 this，结果在 foo 里面找到了 this 也就是 obj 对象，所以就可以正确访问 obj 了。</p>
]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>OPTIONS请求BUG</title>
    <url>/2022/08/12/OPTIONS%E8%AF%B7%E6%B1%82BUG/</url>
    <content><![CDATA[<p>第一次做 Go 的项目，结果写 vue 前端的时候用的是 axios ，报错，一添加 header 就报错，这是为啥呢？</p>
<span id="more"></span>

<h1 id="1-症状"><a href="#1-症状" class="headerlink" title="1. 症状"></a>1. 症状</h1><p>什么个情况呢？我们 axios 设置了个请求拦截器，然后在拦截器里面设置请求头，把 token 放到 Authorization 请求头上：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">axios.<span class="property">interceptors</span>.<span class="property">request</span>.<span class="title function_">use</span>(<span class="function"><span class="params">config</span> =&gt;</span> &#123;</span><br><span class="line">    config.<span class="property">headers</span>[<span class="string">&quot;Authorization&quot;</span>] = <span class="title function_">getToken</span>()</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<p>结果，这个请求就死活发不出去了，依次会发两个请求，第一次是 OPTIONS 第二次是 POST，但是无一例外报错，而且 chrome 浏览器贼傻逼，不告诉原因，就告诉我 NET:ERR。</p>
<p>一开始我以为是我拦截器的问题，然后今天没有使用拦截器，使用原始axios发了个请求，嘿，您猜怎么着，照样发不出去，然后定位错误，发现是 headers 的问题，只要我的 headers 带上 Authorization，那这请求铁定发布出去。都给我整麻了。</p>
<p>这次事故持续了近3个小时，期间崩溃了10次嚎啕大哭了9次晕厥了8次。</p>
<h1 id="2-定位"><a href="#2-定位" class="headerlink" title="2. 定位"></a>2. 定位</h1><p>发了两个请求，第一次是 OPTIONS，第二次才是 POST，所以初步认为这个 BUG 应该和 OPTIONS 这个请求有关系，所以我在服务端自己写了一个 OPTIONS 请求的处理器，直接给他返回字符串，嘿，您猜怎么着，即便如此，这个 OPTIONS 还是报错。</p>
<p>然后我打开了 firefox 浏览器，嘿，firefox 还是厚道，告诉我这么一串：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">CORS 预检响应的 &#x27;Access-Control-Allow-Headers&#x27;，不允许使用头 &#x27;contenttype&#x27;</span><br></pre></td></tr></table></figure>

<p>WTF? 火狐告诉我我这个请求头不允许？虽然这个请求头不是 Authorization 而是我写错的 contentType，但是还是给我提供了思路，很可能这个 Authorization 请求头是因为某种原因被 Ban 了。那么是出于什么原因？很可能就和这个 OPTIONS 有关。</p>
<p>所以我再次推测，可能是第一次 OPTIONS 请求询问了服务器，我下次的 POST 可以带哪些请求头啊？结果服务器告诉我：反正不能是 Authorization，结果下次 POST 请求，我带上 Authorization 就挂了。</p>
<h1 id="3-解决"><a href="#3-解决" class="headerlink" title="3. 解决"></a>3. 解决</h1><p>既然推测是这么回事，就得解决一下，因为我的服务器是 Beego 写的，所以我就查了一下 beego 解决 OPTIONS 请求的办法，真就查到了：</p>
<p><a href="https://cloud.tencent.com/developer/article/1719610">beego 解决 options</a></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> success = []<span class="type">byte</span>(<span class="string">&quot;SUPPORT OPTIONS&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> corsFunc = <span class="function"><span class="keyword">func</span><span class="params">(ctx *context.Context)</span></span> &#123;</span><br><span class="line">    origin := ctx.Input.Header(<span class="string">&quot;Origin&quot;</span>)</span><br><span class="line">    ctx.Output.Header(<span class="string">&quot;Access-Control-Allow-Methods&quot;</span>, <span class="string">&quot;OPTIONS,DELETE,POST,GET,PUT,PATCH&quot;</span>)</span><br><span class="line">    ctx.Output.Header(<span class="string">&quot;Access-Control-Max-Age&quot;</span>, <span class="string">&quot;3600&quot;</span>)</span><br><span class="line">    ctx.Output.Header(<span class="string">&quot;Access-Control-Allow-Headers&quot;</span>, <span class="string">&quot;X-Custom-Header,accept,Content-Type,Authorization&quot;</span>)</span><br><span class="line">    ctx.Output.Header(<span class="string">&quot;Access-Control-Allow-Credentials&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    ctx.Output.Header(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, origin)</span><br><span class="line">    <span class="keyword">if</span> ctx.Input.Method() == http.MethodOptions &#123;</span><br><span class="line">        <span class="comment">// options请求，返回200</span></span><br><span class="line">        ctx.Output.SetStatus(http.StatusOK)</span><br><span class="line">        _ = ctx.Output.Body(success)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">    beego.InsertFilter(<span class="string">&quot;/*&quot;</span>, beego.BeforeRouter, corsFunc)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后我把这一段扔到了项目里，再试，嘿，真就行了。然后我再做了个测试，我把里面 Access-Control-Allow-Headers 里面的 Authorization 去掉了，然后再请求，果然，出现了以前的问题。</p>
<h1 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h1><p>很好，这么个恶心我好几个小时的 BUG 就这么被解决了，但是有这么个问题，为什么 axios 会发送一个 options 请求？我又去网上查了一下，查到个博客，这里直接复制：</p>
<p><a href="https://www.jianshu.com/p/9e52ca6b8818">axios 的 options请求</a></p>
<p><strong>简单请求</strong></p>
<p>满足下面两个条件的请求是简单请求：</p>
<p><strong>请求方式是以下三种之一：</strong> </p>
<ul>
<li>HEAD </li>
<li>GET </li>
<li>POST</li>
</ul>
<p><strong>HTTP的头信息不超出以下几种字段：</strong></p>
<ul>
<li>Accept </li>
<li>Accept-Language </li>
<li>Content-Language </li>
<li>Last-Event-ID </li>
<li>Content-Type</li>
</ul>
<p><strong>但是Content-Type的值，只限于三个值：</strong></p>
<ul>
<li>application&#x2F;x-www-form-urlencoded</li>
<li>multipart&#x2F;form-data</li>
<li>text&#x2F;plain</li>
</ul>
<p><strong>复杂请求</strong></p>
<p>非简单请求就是复杂请求。</p>
<p>复杂请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为“预检”请求（preflight）。预检请求为OPTIONS请求，用于向服务器请求权限信息。预检请求被成功响应后，才会发出真实请求，携带真实数据。</p>
<p>axios默认请求就是application&#x2F;json,所以不需要自己加上头部（不需要在config中加headers），所以总是会发出options请求的，看看是不是配置的时候加了不必要的headers配置项。<br>另外，如果真的需要预检，后台也需要进行设置，允许options请求。</p>
<p>作者：LinkLiKang<br>链接：<a href="https://www.jianshu.com/p/9e52ca6b8818">https://www.jianshu.com/p/9e52ca6b8818</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>嗯哼，就这么回事，这个 BUG 就算过去了。</p>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>02.操作系统</title>
    <url>/2023/06/30/OS-02-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>操作系统</p>
<span id="more"></span>

<h1 id="1-操作系统运行机制"><a href="#1-操作系统运行机制" class="headerlink" title="1. 操作系统运行机制"></a>1. 操作系统运行机制</h1><h2 id="1-1-两种程序"><a href="#1-1-两种程序" class="headerlink" title="1.1 两种程序"></a>1.1 两种程序</h2><p>两种程序分为：应用程序和内核程序。</p>
<p>应用程序很好理解，就是跑在OS上的程序，比如QQ，微信，程序猿开发的一些程序等等。而开发操作系统的开发人员，开发的就是内核程序，很多的内核程序组成了操作系统内核，或者简称内核（Kernel），内核是OS最重要最核心的部分，也是最接近硬件的部分，甚至可以说一个OS只需要内核就够了，比如 Docker，一个 Linux 容器可以只包含了 Linux 内核。</p>
<h2 id="1-2-两种指令"><a href="#1-2-两种指令" class="headerlink" title="1.2 两种指令"></a>1.2 两种指令</h2><p>首先明确一个概念，指令指的是CPU执行的二进制的那一串一串的玩意，详细的可以在计算机组成原理里面学到，而我们执行的那些 cd ls 啥的都是我们之前说的命令接口。</p>
<p>CPU有一些比较牛逼的指令比如清空内存这类的，这类功能肯定不是谁想用谁就用的，只能是OS的管理者——操作系统内核才有资格执行这种指令。所以CPU就分了两种指令：特权指令和非特权指令。普通应用程序只能使用“非特权指令”，比如加减指令这些。而更危险的特权指令只能由内核程序来发送。</p>
<p>但是CPU只负责一条一条的执行指令，CPU出厂的时候就已经定好了特权指令，他确实可以分辨特权指令，但是他怎么知道这个指令是内核发来的还是应用程序发来的？</p>
<h2 id="1-3-CPU-两种状态"><a href="#1-3-CPU-两种状态" class="headerlink" title="1.3 CPU 两种状态"></a>1.3 CPU 两种状态</h2><p>CPU有两种状态，“内核态” 与 “用户态”，用户态时，CPU只能执行非特权指令，内核态时，CPU就可以执行特权指令了。</p>
<p>同时，CPU里面有一个寄存器叫 <strong>程序状态字寄存器（PSW）</strong>，其中又个二进制位，1表示当前时内核态，0表示用户态。</p>
<p>两种状态还有个别名：内核态 &#x3D; 核心态 &#x3D; 管态； 用户态 &#x3D; 目态。</p>
<h2 id="1-4-CPU状态切换"><a href="#1-4-CPU状态切换" class="headerlink" title="1.4 CPU状态切换"></a>1.4 CPU状态切换</h2><p>流程如下：</p>
<ul>
<li>刚开机时，CPU状态是内核态，操作系统的内核程序先上CPU运行</li>
<li>开完机以后，内核程序会向CPU发送一条特权指令，将PSW从1改成0，进而变成用户态，操作系统就会让出CPU的使用权。</li>
<li>然后就可以执行其他的应用程序。</li>
<li>假设，这个应用程序被黑了，被植入了一条特权指令，CPU读取到这个特权指令后，检查PSW发现自己是用户态，不能执行该指令，就引发一个<strong>中断信号</strong>。</li>
<li>CPU检测到中断信号后，会立即变成<strong>核心态</strong>，并停止运行当前的应用程序，转而运行处理中断信号的内核程序。也就是<strong>中断</strong>会使操作系统重新夺回CPU的控制权。</li>
<li>操作系统处理完了中断时间后，再将CPU使用权交给别的应用程序。</li>
</ul>
<p>两种状态切换：</p>
<ul>
<li>内核态-&gt;用户态：执行一条特权指令即可，操作系统会让出CPU使用权</li>
<li>用户态-&gt;内核态：由“中断”引发，硬件自动完成变态过程，触发中断信号以为着操作系统将强行夺回CPU的使用权。</li>
</ul>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p>一张图：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616163352.png" alt="image.png"></p>
<h1 id="2-中断和异常"><a href="#2-中断和异常" class="headerlink" title="2. 中断和异常"></a>2. 中断和异常</h1><h2 id="2-1-中断的作用"><a href="#2-1-中断的作用" class="headerlink" title="2.1 中断的作用"></a>2.1 中断的作用</h2><p>上面就说过了，操作系统内核程序是整个操作系统的管理者，在合适的情况下，操作系统会将CPU使用权让给应用程序，“中断”则是<strong>让操作系统内核夺回CPU使用权</strong>的唯一途径。</p>
<p>如果没有“中断”机制，CPU就会一直运行一个程序，还怎么并发？</p>
<h2 id="2-2-中断的分类"><a href="#2-2-中断的分类" class="headerlink" title="2.2 中断的分类"></a>2.2 中断的分类</h2><p>分为两类：内中断和外中断。</p>
<p><strong>内中断</strong></p>
<p>上面说的黑客例子就是一个内中断，CPU在用户态接收了一个特权指令进而引发内中断。CPU如果执行的指令是非法的，或者指令的某些参数是非法的，比如除以0，就会引发内中断。</p>
<p>另一种情况就是，我们的应用程序要调用操作系统的一些功能，就需要发送一条特殊的指令——<strong>陷入指令</strong>，意味着应用程序主动将CPU控制权还给操作系统内核，让操作系统帮我干一些事儿。陷入指令也会引发内中断。当然需要注意的是，陷入指令并不是特权指令。</p>
<p><strong>外中断</strong></p>
<p>中断和CPU当前的指令没有关系，中断信号来源于CPU<strong>外部</strong>。比如时钟中断，这个东西就是实现了CPU时间片轮转。现在有两个程序A和B，程序A执行了50ms了，时钟一看差不多该转了，就会给CPU发送一个始终中断信号，然后CPU就会切换到内核态执行时钟中断的内核程序，这个内核程序就可以让CPU待会去执行程序B而非程序A。</p>
<p>其他的比如IO设备，打印机。打印完成后打印机就会发送一个中断信号，这个来源于CPU外部，也属于外中断。</p>
<p>用一张图来说明：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616165006.png" alt="image.png"></p>
<p>这里可以看到，异常也就是内中断，而如果我们直接说中断，大部分情况下说的都是外中断。</p>
<h2 id="2-3-中断机制的基本原理"><a href="#2-3-中断机制的基本原理" class="headerlink" title="2.3 中断机制的基本原理"></a>2.3 中断机制的基本原理</h2><p>不同的中断信号，需要不同的中断处理程序来处理，比如时钟中断，就得用相应的处理程序去进行时间片轮转。当CPU检测到中断信号后，会根据中断信号的类型去查询“中断向量表”，以此来找到相应的中断处理程序在内存中的存放位置。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616165337.png" alt="image.png"></p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616165425.png" alt="image.png"></p>
<h1 id="3-系统调用"><a href="#3-系统调用" class="headerlink" title="3. 系统调用"></a>3. 系统调用</h1><h2 id="3-1-什么是系统调用"><a href="#3-1-什么是系统调用" class="headerlink" title="3.1 什么是系统调用"></a>3.1 什么是系统调用</h2><p>我们之前说过：操作系统向上提供了一些简单易用的服务。主要包括命令接口和程序接口。其中程序接口由一组系统调用组成。</p>
<p>”系统调用“是操作系统提供给应用程序使用的接口，可以理解为一种可供应用程序调用的特殊函数，<strong>应用程序可以通过系统调用来请求获得操作系统内核的服务</strong>。</p>
<p>编程语言的库函数和系统调用的区别：系统调用向上层提供服务，让上层程序可以请求内核服务，这个上层程序有可能就是库函数，很多库函数就使用了系统调用，然后进行封装，让我们调用的更加方便。</p>
<p>但是并不是所有的库函数都用了系统调用，比如C语言的 abs 函数就没用，其他的一些比如创建一个新文件这类的函数，肯定就会用到系统调用。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616170342.png" alt="image.png"></p>
<h2 id="3-2-系统调用重要性"><a href="#3-2-系统调用重要性" class="headerlink" title="3.2 系统调用重要性"></a>3.2 系统调用重要性</h2><p>这么个场景：用 WPS 和 office 同时打印论文，如果两个进程都可以直接调用IO设备，并发的使用打印机，那么两个论文就会混在一起了。</p>
<p>所以，将这类共享资源交给操作系统内核进行统一管理，并向上提供“系统调用”，用户进程想要使用打印机，只能通过系统调用向操作系统内核发出请求，然后内核再对哥哥请求进行协调处理，该阻塞阻塞。</p>
<h2 id="3-3-什么功能要用到系统调用"><a href="#3-3-什么功能要用到系统调用" class="headerlink" title="3.3 什么功能要用到系统调用"></a>3.3 什么功能要用到系统调用</h2><p>很简单，凡是与共享资源有关的操作（存储分配、IO操作、文件管理），都必须通过系统调用的方式向操作系统内核提出服务请求，由操作系统内核代为完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616170934.png" alt="image.png"></p>
<h2 id="3-4-系统调用过程"><a href="#3-4-系统调用过程" class="headerlink" title="3.4 系统调用过程"></a>3.4 系统调用过程</h2><p>这个就很有意思了，假设我们的C语言要开辟一个新进程：</p>
<ul>
<li>首先，向CPU发送一条指令，将fork存到CPU的寄存器中</li>
<li>然后，再向CPU发送一条指令，将具体的参数存到寄存器中</li>
<li>发送陷入指令（trap），CPU一看trap指令就会发生内中断，然后调用处理trap的内核程序，这个内核程序就会将寄存器中存的参数取出来，一看，奥，你要执行fork，然后具体参数是多少多少，然后内核程序给你执行</li>
<li>执行完了以后，回到用户态。</li>
</ul>
<p>需要注意的是，陷入指令是用户态执行的，然后立即引发一个内中断，CPU进入内核态；发送系统调用请求是在用户态，而对系统调用的相应处理是在核心态下进行。</p>
<p>顺带：陷入指令 &#x3D; trap 指令 &#x3D; 访管指令</p>
<h2 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616171751.png" alt="image.png"></p>
<h1 id="4-操作系统体系结构"><a href="#4-操作系统体系结构" class="headerlink" title="4. 操作系统体系结构"></a>4. 操作系统体系结构</h1><h2 id="4-1-内核结构"><a href="#4-1-内核结构" class="headerlink" title="4.1 内核结构"></a>4.1 内核结构</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616172203.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616172333.png" alt="image.png"><br>上面的三种东西，时钟，中断，原语，这三个东西和硬件最为紧密，是一定要放在内核中的。但是下面三个 进程、存储器、设备，不会直接涉及到硬件，所以有些操作系统并不会将他们放到内核中。</p>
<p>这就引出两种操作系统设计方法；</p>
<ul>
<li>将所有内容包含在内核中，包括 进程、寄存器、设备管理，就叫大内核。</li>
<li>只保留时钟，中断，原语等核心功能，这种设计就叫微内核。</li>
</ul>
<p>微内核情况下，核心功能跑在内核态，其他的进程管理、寄存器管理、设备管理就会跑在用户态。</p>
<h2 id="4-2-两种内核的区别"><a href="#4-2-两种内核的区别" class="headerlink" title="4.2 两种内核的区别"></a>4.2 两种内核的区别</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616172949.png" alt="image.png"></p>
<p>主要就是变态这块有点区别，剩下的没啥。</p>
<h2 id="4-3-大小内核总结"><a href="#4-3-大小内核总结" class="headerlink" title="4.3 大小内核总结"></a>4.3 大小内核总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616173054.png" alt="image.png"></p>
<h2 id="4-4-分层结构"><a href="#4-4-分层结构" class="headerlink" title="4.4 分层结构"></a>4.4 分层结构</h2><p>这个和Java的什么三层架构很像，操作系统分为多个层，每层可单向调用更低一层提供接口：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616175224.png" alt="image.png"></p>
<p>好处就是易于调试，而且想要在两层之间加一层的话也是比较简单的。</p>
<p>但是缺点就是，层与层的划分有的时候并不明确，比如进程管理和内存管理，两种功能相互调用，在分层结构中就比较难办。同时，A层不能直接调用D层，而是需要依次向下传递调用，效率会比较慢。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616175454.png" alt="image.png"></p>
<h2 id="4-5-模块化结构"><a href="#4-5-模块化结构" class="headerlink" title="4.5 模块化结构"></a>4.5 模块化结构</h2><p>将操作系统按照功能划分为若干个具有一定独立性的模块。每个模块具有某方面的管理功能，并会定好个模块之间的接口，使各模块之间能通过接口进行通信。还可以进一步将各模块细分为若干个具有一定功能的自模块，同样也规定好各自模块之间的接口。将这种设计方法称为模块-接口法：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616175731.png" alt="image.png"><br>这里面内核包括主模块和加载模块，主模块包含最主要的功能，没有主模块没法启动，加载模块非必需，可以按照需求动态添加。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616180219.png" alt="image.png"></p>
<h2 id="4-6-大小内核"><a href="#4-6-大小内核" class="headerlink" title="4.6 大小内核"></a>4.6 大小内核</h2><p>这个就是之前重点在说的，直接看图就行了：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616180256.png" alt="image.png"></p>
<h2 id="4-7-外核"><a href="#4-7-外核" class="headerlink" title="4.7 外核"></a>4.7 外核</h2><p>一般情况下，OS给用户分配的都是虚拟的资源，比如虚拟的内存空间，我们看到的内存是连续的，但其实在物理上压根不是连续的。外存就是跳过了虚拟这一步，外存讲究不虚拟，不抽象，直接调用硬件资源给你，让资源管理更加灵活，同时外核也负责保证这些硬件资源的安全。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616180900.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616180834.png" alt="image.png"></p>
<h1 id="5-操作系统引导"><a href="#5-操作系统引导" class="headerlink" title="5. 操作系统引导"></a>5. 操作系统引导</h1><p>简单说就是怎么开机，我们买回来一块硬盘，装在电脑上，然后分完区，将系统装在C盘上，磁盘就会出现一个东西叫主引导记录：里面记录的磁盘的引导程序和磁盘的分区表。</p>
<p>同时电脑的内存分为两类：RAM和ROM，ROM断电后是不会消失的，然后我们来看看电脑是怎么开机的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616181654.png" alt="image.png"></p>
<ul>
<li>通电以后，CPU开始工作，CPU执行ROM中的引导程序，主要就是自检，同时指示CPU将磁盘中的主引导记录导入内存</li>
<li>CPU开始执行磁盘引导程序，磁盘引导程序会根据分区表去判断C盘的位置，然后就可以将C盘的第一部分数据读入内存，也就是引导记录PBR</li>
<li>这个PBR本质上也是个程序，CPU执行这个PBR，就会找到C盘根目录中的启动管理程序，然后这个程序负责初始化操作系统。</li>
</ul>
<h1 id="6-虚拟机"><a href="#6-虚拟机" class="headerlink" title="6. 虚拟机"></a>6. 虚拟机</h1><p>虚拟机：使用虚拟化技术，将一台物理机器虚拟化为堕胎虚拟机起，每个虚拟机起都可以独立运行一个操作系统。</p>
<p>同义术语：虚拟机管理程序&#x2F;虚拟机监控程序&#x2F;Virtual Machine Monitor（VMM）&#x2F; Hypervisor</p>
<h2 id="6-1-第一类虚拟机"><a href="#6-1-第一类虚拟机" class="headerlink" title="6.1 第一类虚拟机"></a>6.1 第一类虚拟机</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616183023.png" alt="image.png"></p>
<p>虚拟机管理程序直接运行在硬件上，然后将硬件资源分配给上层的各个虚拟机。但是这里有个问题，虚拟机以为自己是真实的机器，所以他们也会有虚拟的内核态，就会向真实CPU发送特权指令，但是整个虚拟机其实都是真实机的用户态，怎么办？</p>
<p>简单，VMM会截获虚拟机发送过来的特权指令，然后将特权指令进行等价转化，让虚拟机以为自己的特权指令执行成功。</p>
<h2 id="6-2-第二类虚拟机"><a href="#6-2-第二类虚拟机" class="headerlink" title="6.2 第二类虚拟机"></a>6.2 第二类虚拟机</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616183342.png" alt="image.png"></p>
<h2 id="6-3-两类虚拟机区别"><a href="#6-3-两类虚拟机区别" class="headerlink" title="6.3 两类虚拟机区别"></a>6.3 两类虚拟机区别</h2><p>直接看图吧，没啥说的了：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616184114.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>JVM-类加载子系统</title>
    <url>/2022/05/22/JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>从这里开始正式开始JVM，首先我们要对类加载有一个大致的认识。类加载子系统 就是将 类 从磁盘中读取到 内存中的一个东西，包括 加载 链接 初始化 三个阶段。</p>
<span id="more"></span>

<h1 id="1-类加载三阶段"><a href="#1-类加载三阶段" class="headerlink" title="1. 类加载三阶段"></a>1. 类加载三阶段</h1><h2 id="1-1-加载"><a href="#1-1-加载" class="headerlink" title="1.1 加载"></a>1.1 加载</h2><ol>
<li><p>通过一个类的全限定命名，获取这个类的二进制流。</p>
<blockquote>
<p>class 文件来源：<br>Class文件；applet 网络；计算生成也就是动态代理；JSP；压缩文件(jar war)。。。</p>
</blockquote>
</li>
<li><p>将字节流代表的静态存储结构转化为方法区的运行时数据结构。</p>
</li>
<li><p>在内存中生成代表这个类的反射(java.lang.Class)，作为方法区这个类的各种数据访问入口。</p>
</li>
</ol>
<h2 id="1-2-链接"><a href="#1-2-链接" class="headerlink" title="1.2 链接"></a>1.2 链接</h2><h3 id="1-2-1-验证-verify"><a href="#1-2-1-验证-verify" class="headerlink" title="1.2.1 验证 verify"></a>1.2.1 验证 verify</h3><p>保证加载类的字节流包含的数据符合规范，不会危害到JVM。<br>主要验证：文件格式 元数据 字节码 符号引用</p>
<blockquote>
<p>这里举个例子，Java 的字节码文件有一个规范，二进制都以 CA FE BA BE 开头</p>
</blockquote>
<h3 id="1-2-2-准备阶段"><a href="#1-2-2-准备阶段" class="headerlink" title="1.2.2 准备阶段"></a>1.2.2 准备阶段</h3><p>给 类变量设置初始值为零值，仅限于类变量，也就是 static,不包含 final static，因为 final 的零值在编译的时候就已经分配了。</p>
<h3 id="1-2-3-解析"><a href="#1-2-3-解析" class="headerlink" title="1.2.3 解析"></a>1.2.3 解析</h3><p>常量池中的符号引用改为直接引用,举个例子，我们就写一个类里面有一个主方法，他就需要加载一大堆类，其实就是 lang 底下的各种类，总不能说都放到out目录下，所以就需要引用他们。</p>
<p>详细的以后细说，这里大致了解一下。</p>
<h2 id="1-3-初始化阶段"><a href="#1-3-初始化阶段" class="headerlink" title="1.3 初始化阶段"></a>1.3 初始化阶段</h2><ol>
<li><p>调用类的 clinit 方法，这个方法会把 所有对 static 成员的赋值操作收集起来，<br>写成一个方法 clinit(按顺序，按顺序，按顺序)，对 static 进行重新赋值</p>
<blockquote>
<p>这里举一个例子：<br> static{num &#x3D; 20;} private static int num &#x3D; 10;<br>首先因为链接阶段的 prepare，num 在初始化前就是 0，所以在初始化的时候，按照顺序生成 clinit，也就是先 num &#x3D; 20，再 num &#x3D; 10，所以最后，num &#x3D;&#x3D; 10 </p>
</blockquote>
</li>
<li><p>如果说 我们的类 里面没有 static，那么就不存在 clinit</p>
</li>
<li><p>clinit 不同于 构造函数，clinit 在 构造之前执行，在JVM 的角度，构造函数 是 &lt;init&gt;() 方法，在 &lt;clinit&gt;() 之后。</p>
</li>
<li><p>子类执行 clinint 之前，必须执行 超类 的 clinit</p>
</li>
<li><p>JVM 保证多线程下 clinit 方法被枷锁</p>
</li>
</ol>
<h1 id="2-类加载器"><a href="#2-类加载器" class="headerlink" title="2. 类加载器"></a>2. 类加载器</h1><h2 id="2-1-概括"><a href="#2-1-概括" class="headerlink" title="2.1 概括"></a>2.1 概括</h2><p>JVM 支持两种类加载器：</p>
<ul>
<li><p>引导类加载器 Bootstrap ClassLoader</p>
</li>
<li><p>自定义类加载器 User-defined Class Loader</p>
<blockquote>
<p>这个自定义类加载器不是说我们自己写的，而是只要派生了抽象类ClassLoader的，<br>都叫自定义类加载器。</p>
</blockquote>
</li>
</ul>
<p>必须注意的是，Bootstrap ClassLoader 并没有继承 ClassLoader，它使用 C 实现的。</p>
<p>各个类加载器之间是包含关系，不是上下级，更不是继承。</p>
<pre><code>                  BootstrapClassLoader
                           |
                  ExtensionClassLoader
                           |
                    SystemClassLoader
                           |
              |------------+-----------|                      
     User-def ClassLoader     User-def ClassLoader
             ...                      ...
</code></pre>
<p>我们可以通过代码来验证这种关系：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回 sun.misc.Launcher$AppClassLoader 表明得到了 SystemClassLoader</span></span><br><span class="line"><span class="type">ClassLoader</span> <span class="variable">sysLoader</span> <span class="operator">=</span> ClassLoader.getSystemClassLoader();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回 sun.misc.Launcher$ExtClassLoader 表明ExtClassLoader包含 SystemClassLoader</span></span><br><span class="line"><span class="type">ClassLoader</span> <span class="variable">extLoader</span> <span class="operator">=</span> sysLoader.getParent();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无法得到 ExtClassLoader 的parent，因为他的上层 BootstrapClassLoader 不是Java写的。返回null</span></span><br><span class="line"><span class="type">ClassLoader</span> <span class="variable">bootLoader</span> <span class="operator">=</span> extLoader.getParent();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义类的类加载器，返回 AppClassLoader，也就是系统类加载器加载自定义类。</span></span><br><span class="line"><span class="type">ClassLoader</span> <span class="variable">myClassLoader</span> <span class="operator">=</span> MyClass.class.getClassLoader();</span><br><span class="line"></span><br><span class="line"><span class="comment">// String 由引导类加载器加载，返回 null 所以 Java 的核心类都被引导加载器加载</span></span><br><span class="line"><span class="type">ClassLoader</span> <span class="variable">stringLoader</span> <span class="operator">=</span> String.class.getClassLoader();</span><br></pre></td></tr></table></figure>

<h2 id="2-2-JVM自带的类加载器"><a href="#2-2-JVM自带的类加载器" class="headerlink" title="2.2 JVM自带的类加载器"></a>2.2 JVM自带的类加载器</h2><h3 id="2-2-1-启动类加载器"><a href="#2-2-1-启动类加载器" class="headerlink" title="2.2.1 启动类加载器"></a>2.2.1 启动类加载器</h3><p>也叫引导类加载器 BootstrapClassLoader</p>
<ul>
<li><p>用 C&#x2F;C++ 实现，嵌套在JVM内部</p>
</li>
<li><p>用来加载Java核心类库</p>
<blockquote>
<p>JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar resources.jar 或者<br>sun.boot.class.path 下的内容，用于提供JVM自身需要的类</p>
</blockquote>
</li>
<li><p>并没有继承ClassLoader，没有父加载器</p>
</li>
<li><p>加载扩展类和应用程序类加载器(ExtClassLoader &amp; AppClassLoader)，并制定他们的父加载器</p>
</li>
<li><p>出于安全考虑，只加载包名开头是 java javax sun 的类。</p>
</li>
</ul>
<h3 id="2-2-2-扩展类加载器"><a href="#2-2-2-扩展类加载器" class="headerlink" title="2.2.2 扩展类加载器"></a>2.2.2 扩展类加载器</h3><ul>
<li><p>用 Java 编写</p>
</li>
<li><p>派生于 ClassLoader，sun.misc.Launcher$ExtClassLoader</p>
</li>
<li><p>父加载器是 启动类加载器</p>
</li>
<li><p>从 java.ext.dirs系统属性指定的目录中加载，或者 加载 jre&#x2F;lib&#x2F;ext 下的类库。</p>
<blockquote>
<p>如果用户写的 jar文件放在这里，也被他加载。</p>
</blockquote>
</li>
</ul>
<h3 id="2-2-3-应用程序加载器"><a href="#2-2-3-应用程序加载器" class="headerlink" title="2.2.3 应用程序加载器"></a>2.2.3 应用程序加载器</h3><ul>
<li>Java 编写</li>
<li>派生于 ClassLoader， sun.misc.Launcher$AppClassLoader 实现</li>
<li>父加载器是 扩展类加载器</li>
<li>家在环境变量 classpath或系统属性 java.class.path目录下的类库</li>
<li>程序默认的类加载器，Java 应用程序都被他加载</li>
<li>调用 ClassLoader.getSystemClassLoader() 可以得到</li>
</ul>
<h3 id="2-2-4-自定义类加载"><a href="#2-2-4-自定义类加载" class="headerlink" title="2.2.4 自定义类加载"></a>2.2.4 自定义类加载</h3><ul>
<li>一般来说，类加载几乎都是上面三个 类加载器加载的，情况特殊我们可以用自己的。</li>
<li>什么时候需要自定义：<ul>
<li>隔离加载类 比如框架之间用 Jar包，为了相互不冲突，自定义类加载器</li>
<li>修改类的加载方式</li>
<li>扩展加载源，比如我们可以从数据库中加载</li>
<li>防止源码泄露，先对源码进行加密，然后自定义类加载器进行解密。</li>
</ul>
</li>
<li>如何自定义类加载器，以后再说，大致需要实现 继承 ClassLoader 重写 findClass</li>
</ul>
<h2 id="2-3-关于-ClassLoader"><a href="#2-3-关于-ClassLoader" class="headerlink" title="2.3 关于 ClassLoader"></a>2.3 关于 ClassLoader</h2><p>是一个抽象类，我们以后自己要实现类加载器的话可以继承这个类来实现一些我们自己的功能。</p>
<h1 id="3-双亲委派机制"><a href="#3-双亲委派机制" class="headerlink" title="3. 双亲委派机制"></a>3. 双亲委派机制</h1><p>一个类加载器接收到类加载请求后，并不会立马进行加载，而是把加载请求传给父加载器（虽然说父加载器，但是一直说 三个类加载器之间没有继承关系），然后一直递归，一直往上，最终给了 引导类加载器。如果父加载器可以完成加载，则返回结果，如果不能，再传回子加载器</p>
<p>举个例子：</p>
<p>加载我们的自定义类 User，首先AppClassLoader 收到加载请求，将请求发给ExtClassLoader，然后ExtClassLoader 再发给BootstrapClassLoader，BootstrapClassLoader 一看，我只负责加载 java javax 等，你这个 pri.entity.User 我不负责，将请求发回 ExtClassLoader，ext 也不管，则返回App，最终App进行加载。</p>
<p>再举个栗子：</p>
<p>我们自定义一个 java.lang.String，然后在别的地方 <code>String str = new String();</code> 那么加载的是哪个类，是我们自定义的，还是Java 的。根据这个机制，这个请求最终发给了 BootstrapClassLoader，那么很显然就会加载 系统的 String,而不是我们自己的String，因为我们自己的 String 需要 AppClassLoader 加载。</p>
<p>然后我们在我们自己的 String 里面定义main 方法，可不可3以运行？显然不行，因为执行main方法需要先进性类加载，直接加载 系统的 String。系统的String 很显然没有main</p>
<h2 id="3-1-优势"><a href="#3-1-优势" class="headerlink" title="3.1 优势"></a>3.1 优势</h2><ul>
<li>避免类的重复加载。</li>
<li>保护核心api不被破坏，比如上面的例子</li>
</ul>
<h2 id="3-2-如何判断两个Class-相同"><a href="#3-2-如何判断两个Class-相同" class="headerlink" title="3.2 如何判断两个Class 相同"></a>3.2 如何判断两个Class 相同</h2><ul>
<li>全限定命名一样</li>
<li>所用的类加载器一样</li>
</ul>
<h2 id="3-3-Java加载类的两种方式"><a href="#3-3-Java加载类的两种方式" class="headerlink" title="3.3 Java加载类的两种方式"></a>3.3 Java加载类的两种方式</h2><p>Java加载类就是两种方式：主动加载和被加载，下面是主动加载</p>
<ul>
<li>创建实例</li>
<li>访问静态变量或者赋值</li>
<li>调用静态方法</li>
<li>反射，比如 Class.forName()</li>
<li>初始化一个类的子类</li>
<li>Java虚拟机启动时被标明为启动类的类</li>
<li>JDK7开始的同台语言支持，不知道啥意思</li>
</ul>
<p>除此之外，全是被动加载，被动加载不会进行初始化。我们上面说过，类加载经理加载链接初始化，只有主动加载一个类，这个类才会经历初始化过程，否则不会经历。那么不会初始化会导致什么后果？以后再说。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>04.线程</title>
    <url>/2023/06/30/OS-04-%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<p>线程</p>
<span id="more"></span>

<h1 id="1-什么是线程"><a href="#1-什么是线程" class="headerlink" title="1. 什么是线程"></a>1. 什么是线程</h1><p>有的进程可能需要“同时”做很多事情，而传统的进程只能穿性的执行一系列程序。为此引入了“线程”，来增加并发度。可以吧线程理解成“轻量级进程”</p>
<p>传统的进程是程序执行流的最小单位，引入线程后，线程成为了程序执行流的最小单位，线程是一个基本的CPU执行单元，进程内的各个线程也可以并发，从而进一步提高了系统并发度。</p>
<h1 id="2-线程带来的变化"><a href="#2-线程带来的变化" class="headerlink" title="2. 线程带来的变化"></a>2. 线程带来的变化</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618093531.png" alt="image.png"></p>
<p>这里再提一句，这个进程运行环境在上一章专门说过，也就是CPU里面寄存器那些东西，这些东西需要保存到PCB中，切换进程就需要将当前进程的环境保存到PCB，然后将下一个进程的PCB数据读入，开销会比较大。</p>
<h1 id="3-线程的属性"><a href="#3-线程的属性" class="headerlink" title="3. 线程的属性"></a>3. 线程的属性</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618093825.png" alt="image.png"></p>
<h1 id="4-线程的实现方式"><a href="#4-线程的实现方式" class="headerlink" title="4. 线程的实现方式"></a>4. 线程的实现方式</h1><h2 id="4-1-用户级线程"><a href="#4-1-用户级线程" class="headerlink" title="4.1 用户级线程"></a>4.1 用户级线程</h2><p>早起的操作系统（比如 Unix）只支持进程不支持线程。当时的“线程”是由线程库实现的。比如说我们要写一个程序，这个程序要同时处理文字聊天，视频，文件传输，我们就可以在代码层面这么写：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span>(i == <span class="number">0</span>) &#123; 文字聊天 &#125;</span><br><span class="line">		<span class="keyword">if</span>(i == <span class="number">1</span>) &#123; 视频 &#125;</span><br><span class="line">		<span class="keyword">if</span>(i == <span class="number">2</span>) &#123; 文件传输 &#125;</span><br><span class="line">		i = (i + <span class="number">1</span>) % <span class="number">3</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码我们就简单实现了三个线程，很多编程语言提供了强大的线程库，可以实现线程的创建、销毁、调度等功能。</p>
<p>说明几个问题：</p>
<ul>
<li>线程的管理工作由用户来完成，操作系统感知不到线程的存在</li>
<li>线程切换不需要CPU变态，因为进程没变</li>
</ul>
<p>这种线程的实现在用户空间即可完成，不需要CPU切换到核心态，所以管理的系统开销小，效率高。但是从代码角度看，如果一个线程被阻塞，整个程序都会被阻塞，并发度不高。同时因为CPU感知不到线程，多个线程不可以在多核处理机上并行运行。</p>
<h2 id="4-2-内核级线程"><a href="#4-2-内核级线程" class="headerlink" title="4.2 内核级线程"></a>4.2 内核级线程</h2><p>这种就是操作系统层面上支持线程，线程的管理工作如线程调度、切换等由操作系统内核完成，所以内核级线程的切换必须要在核心态下才能完成。</p>
<p>和进程类似，操作系统会为每个内核级线程创建相应的TCB（Thread Control Block），通过对TCB来管理线程。“内核级线程”就是“从操作系统内核角度能看到的线程”。</p>
<p>这么做的优点就是当一个线程被阻塞后，别的线程还可以继续执行，并发能力强，而且多个线程就可以被分配到多个处理机上并行执行。而缺点就是一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理成本高。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618095730.png" alt="image.png"></p>
<h1 id="5-多线程模型"><a href="#5-多线程模型" class="headerlink" title="5. 多线程模型"></a>5. 多线程模型</h1><p>如果将用户线程和内核线程结合起来，将用户线程映射到内核线程上，就会有下面这么三种多线程模型。</p>
<h2 id="5-1-一对一模型"><a href="#5-1-一对一模型" class="headerlink" title="5.1 一对一模型"></a>5.1 一对一模型</h2><p>每个用户线程映射到一个内核线程。每个用户进程有与用户线程同数量的内核线程。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618100033.png" alt="image.png"></p>
<p>当一个线程被阻塞后，别的线程还可以继续运行，并发能力强。多线程可以在多核处理机上并行。但是一个用户进程占用多个内核线程，线程管理开销大。</p>
<h2 id="5-2-多对一模型"><a href="#5-2-多对一模型" class="headerlink" title="5.2 多对一模型"></a>5.2 多对一模型</h2><p>多个用户及线程映射到一个内核级线程。且一个进程只分配一个内核级线程。这个东西就是退化回去了，优点和之前一样，线程转换不需要切换到核心态，线程管理开销小。但是线程一旦被阻塞整个进程就会被阻塞，并发度不高。多个线程也不能在多核处理机上并行。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618100426.png" alt="image.png"></p>
<p>切记：<font color='red'> 操作系统只“看得见”内核级线程，因此只有内核线程才是处理机分配的单位。</font></p>
<h2 id="5-3-多对多模型"><a href="#5-3-多对多模型" class="headerlink" title="5.3 多对多模型"></a>5.3 多对多模型</h2><p>N个用户线程映射到M个内核线程上（N&gt;M）。每个用户进程对应M个内核线程。克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核线程，开销太大的缺点。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618100601.png" alt="image.png"></p>
<p>这里用户线程和核心线程的关系：</p>
<ul>
<li>用户线程是“代码逻辑”的载体</li>
<li>内核线程是”运行机会“的载体</li>
</ul>
<p>一端代码逻辑只有获得了运行机会才能被CPU执行。比如三个功能，视频聊天，文字聊天，文件传输，其中视频聊天比较占用资源，就可以给视频聊天的用户线程单独分配一个核心线程，然后文字聊天和文件传输共用另一个核心线程。</p>
<h1 id="6-线程的状态与转换"><a href="#6-线程的状态与转换" class="headerlink" title="6. 线程的状态与转换"></a>6. 线程的状态与转换</h1><p>这个就十分的简单了，和前面的进程几乎是一毛一样，我们只需要着重关注三个状态：就绪、运行、阻塞。线程首先进入就绪状态然后等待CPU分配时间片，然后运行，时间片用完以后就会返回就绪状态。如果在运行的时候等待某件事，就会进入阻塞，等待结束返回就绪态。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618101420.png" alt="image.png"></p>
<h1 id="7-线程的组织与控制"><a href="#7-线程的组织与控制" class="headerlink" title="7. 线程的组织与控制"></a>7. 线程的组织与控制</h1><p>这个和进程也是很类似，操作系统为了管理线程就会为每个线程创建一个TCB线程控制块：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618101912.png" alt="image.png"></p>
<p>这里只说两个东西：</p>
<ul>
<li>其他寄存器：这个东西和之前的进程运行状态类似，就是CPU在执行这个线程的时候寄存器的值</li>
<li>堆栈指针：这个玩意如果学过JVM的话就好理解了，就是指向虚拟机栈的指针，然后这个栈用来记录函数调用情况。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>01.操作系统基础概念</title>
    <url>/2023/06/30/OS-01-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer" />

<p>操作系统基础概念</p>
<span id="more"></span>

<h1 id="1-操作系统的定义"><a href="#1-操作系统的定义" class="headerlink" title="1. 操作系统的定义"></a>1. 操作系统的定义</h1><p>操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理的组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的借口和环境；她是计算机系统中最基本的系统软件。</p>
<h1 id="2-操作系统的功能和目标"><a href="#2-操作系统的功能和目标" class="headerlink" title="2. 操作系统的功能和目标"></a>2. 操作系统的功能和目标</h1><h2 id="2-1-向上层提供方便易用的服务"><a href="#2-1-向上层提供方便易用的服务" class="headerlink" title="2.1 向上层提供方便易用的服务"></a>2.1 向上层提供方便易用的服务</h2><p>操作系统的主要功能和目标就是向上层提供方便易用的服务，这里用qq视频为例：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616151323.png" alt="image.png"></p>
<p>总体如下：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616152019.png" alt="image.png"><br>这里稍微解释一下联机命令接口和脱机命令接口。</p>
<ul>
<li>联机命令接口就是我说一句系统做一句，其实就是我直接输入的类似 ls 的这种指令。</li>
<li>脱机命令接口就是批处理指令，一大堆命令写的指令集。<br>程序接口就是程序里面用的，比如C语言的printf，底层就掉用了很多操作系统提供的接口，这种就是程序接口。<br>然后命令接口和程序接口也可以统称为用户接口。</li>
</ul>
<h2 id="2-2-作为最接近硬件的层次"><a href="#2-2-作为最接近硬件的层次" class="headerlink" title="2.2 作为最接近硬件的层次"></a>2.2 作为最接近硬件的层次</h2><p>这个也好理解，操作系统离硬件最近，可以拓展硬件的功能，比如可以在操作系统的层面上实现虚拟机。</p>
<h1 id="3-操作系统的特征"><a href="#3-操作系统的特征" class="headerlink" title="3. 操作系统的特征"></a>3. 操作系统的特征</h1><h2 id="3-1-并发"><a href="#3-1-并发" class="headerlink" title="3.1 并发"></a>3.1 并发</h2><p>这个非常熟悉了，宏观上是同时发生的，但是微观上是交替发生的。对应的是并行，并行就是在同一时间确实是同时发生的。</p>
<p>而在操作系统的层面上来说，并发性指的是计算机系统中“同时”运行着多个程序，这些程序宏观上是同时运行的，而围观上是交替运行的。操作系统就是伴随着“多道程序技术”而出现的。因此，操作系统和程序并发是一起诞生的。</p>
<p>并发性是操作系统一个最基本的特性。</p>
<h2 id="3-2-共享"><a href="#3-2-共享" class="headerlink" title="3.2 共享"></a>3.2 共享</h2><p>共享就是资源共享，指系统中的资源可供内容中的多个并罚执行的进程共同使用。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616153156.png" alt="image.png"></p>
<p>这里所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问的，也就是分时共享。</p>
<h2 id="3-3-并发和共享的关系"><a href="#3-3-并发和共享的关系" class="headerlink" title="3.3 并发和共享的关系"></a>3.3 并发和共享的关系</h2><p>并发性指同时存在着多个运行着的程序<br>共享性指系统中的资源可供能存中的多个并罚执行的进程共同使用。</p>
<p>这里举个例子：qq和微信同时发送文件，qq发送文件A，微信发送文件B。qq和微信两个进程并发执行，如果失去了并发性，则系统中只有一个程序正在运行，则共享性失去了意义。两个进程共享的访问硬盘资源，如果失去了共享性，则qq和微信不能同时访问磁盘，则无法并发。</p>
<p>所以并发性和共享性互为<strong>存在条件</strong>。</p>
<h2 id="3-4-虚拟"><a href="#3-4-虚拟" class="headerlink" title="3.4 虚拟"></a>3.4 虚拟</h2><p>这个东西有个概念就行了，往后会重点说，大致就是，我的电脑只有4g内存，我打开一个gta5就用了4g内存，但是我还可以同时打开其他的软件，难道内存不会爆么？这里就涉及虚拟存储器技术的“空分复用技术”。</p>
<p>再比如，一个单核CPU的计算机，但是用户可以打开很多软件，为啥？这里队赢了虚拟处理器技术，更详细的就是“时分复用技术”，微观上处理剂在各个微笑的时间段内加集体的为各个进程服务。</p>
<p>显然，如果失去了并发性，虚拟性也就没有意义了。</p>
<h2 id="3-5-异步"><a href="#3-5-异步" class="headerlink" title="3.5 异步"></a>3.5 异步</h2><p>在多道程序环境中，允许多个程序并发执行，但是由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是异步性，其实说白了就是阻塞，学Java并发的时候很清楚了。</p>
<h2 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616154733.png" alt="image.png"></p>
<p>并发和共享互为存在条件，没有并发和共享，就谈不上虚拟和异步，所以并发和共享是操作系统的两个最基本的特征。</p>
<h1 id="4-OS的发展和分类"><a href="#4-OS的发展和分类" class="headerlink" title="4. OS的发展和分类"></a>4. OS的发展和分类</h1><h2 id="4-1-手工操作阶段"><a href="#4-1-手工操作阶段" class="headerlink" title="4.1 手工操作阶段"></a>4.1 手工操作阶段</h2><p>这个玩意很反人类，就是最早的纸带，程序员把程序通过打孔的方式写到纸带上，然后把纸带给计算机，计算机计算后将结果大打回到纸带上，然后程序猿再去研究纸带。</p>
<p>这种方式最主要就是资源利用率差，程序猿研究纸带就很浪费时间，而计算机计算又非常快。而且同一时间只有一个程序猿可以使用计算机，总的来说就是资源利用率极低。</p>
<h2 id="4-2-单道批处理系统"><a href="#4-2-单道批处理系统" class="headerlink" title="4.2 单道批处理系统"></a>4.2 单道批处理系统</h2><p>一定程度上解决了上面的问题，程序猿把自己的纸带一块交给一个叫外围机的机器，这个机器会把所有的纸带数据录入到磁带上，然后将磁带交给计算机进行计算，再将结果返回给磁带。</p>
<p>好处就是磁带的读写速度比纸带快很多，计算机的利用率就上来了。但是速度仍然很差，一段时间内只有一个程序在运行。</p>
<h2 id="4-3-多道批处理系统"><a href="#4-3-多道批处理系统" class="headerlink" title="4.3 多道批处理系统"></a>4.3 多道批处理系统</h2><p>这里操作系统就真正的诞生了，计算机可以从内容（也就是磁带）中读取多道程序，然后并发的执行，将结果返回给磁带，优点就是多道程序并发执行，共享计算机资源。资源利用率大幅提高，CPU和其他资源更能保持“忙碌”状态，系统吞吐量增大。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616155831.png" alt="image.png"></p>
<h2 id="4-4-分时操作系统"><a href="#4-4-分时操作系统" class="headerlink" title="4.4 分时操作系统"></a>4.4 分时操作系统</h2><p>这里就有了时间片，计算机以时间片为单位轮流为各个用户&#x2F;作业进行服务，各个用户可以通过终端与计算机交互。</p>
<p>主要优点：用户请求可以即时被响应，解决了人机交互的问题。允许多个用户同时使用一台计算机，并且用户对计算机的操作相互独立，感受不到别人的存在。</p>
<p>主要缺点：不能及时处理一些紧急的任务。</p>
<h2 id="4-5-实时操作系统"><a href="#4-5-实时操作系统" class="headerlink" title="4.5 实时操作系统"></a>4.5 实时操作系统</h2><p>这种可以优先响应一些紧急任务，某些紧急任务不需要时间片排队。在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在<strong>严格的时限内处理完事件</strong>。实施操作系统的主要特点是<strong>及时性和可靠性</strong>。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616160422.png" alt="image.png"></p>
<h2 id="4-6-其他操作系统"><a href="#4-6-其他操作系统" class="headerlink" title="4.6 其他操作系统"></a>4.6 其他操作系统</h2><p>这里看看图就行了，不多说。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230616160520.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>05.调度</title>
    <url>/2023/06/30/OS-05-%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<p>调度</p>
<span id="more"></span>

<h1 id="1-调度概念"><a href="#1-调度概念" class="headerlink" title="1. 调度概念"></a>1. 调度概念</h1><p>有一堆任务要处理，但是由于资源有限，这些事情没法同时处理。这就需要确定<strong>某种规则</strong>来决定处理这些任务的顺序，这就是”调度“研究的问题。</p>
<h1 id="2-调度三层次"><a href="#2-调度三层次" class="headerlink" title="2. 调度三层次"></a>2. 调度三层次</h1><h2 id="2-1-高级调度"><a href="#2-1-高级调度" class="headerlink" title="2.1 高级调度"></a>2.1 高级调度</h2><p>也叫作业调度，作业就是一个具体的任务，用户向系统提交一个作业 约等于 用户让操作系统启动一个程序（来处理一个具体的任务），这个时候这个程序还在磁盘里面呢。所以高级调度是从磁盘到内存的调度。</p>
<p>我们要启动好几个程序，就需要将这些程序放入内存，但有的时候内存空间有限，无法放入内存。所以高级调度就是：按照一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。每个作业只调入一次，调出一次。作业调入时会创建PCB，调出时会撤销PCB。</p>
<h2 id="2-2-低级调度"><a href="#2-2-低级调度" class="headerlink" title="2.2 低级调度"></a>2.2 低级调度</h2><p>也就是进程调度或者叫处理机调度：按照某种策略从就绪队列中选取一个进程，将处理机分配给他。也就是我们之前说的进程的时间片轮转。</p>
<p>进程调度时操作系统中<strong>最基本的一种调度</strong>，在一般的操作系统中都必须配置进程调度，而且进程调度的频率很高，一般几十毫秒一次。</p>
<h2 id="2-3-中级调度"><a href="#2-3-中级调度" class="headerlink" title="2.3 中级调度"></a>2.3 中级调度</h2><p>也叫内存调度，内存不够时，可以将某些进程的数据调出外存。等内存空闲或者进程需要运行时再重新调入内存。</p>
<p>暂时调到外存等待的进程状态为挂起状态。被挂起的进程PCB会被组织成挂起队列。</p>
<p>所以总的来说，中级调度就是按照某种策略决定将哪个处于挂起状态的进程重新调入内存。同样是磁盘到内存。</p>
<h2 id="2-4-七状态模型"><a href="#2-4-七状态模型" class="headerlink" title="2.4 七状态模型"></a>2.4 七状态模型</h2><p>之前我们说的进程状态是5个，开始、结束、就绪、运行、阻塞。现在有了挂起，那么就可以多两种状态：就绪挂起和阻塞挂起。</p>
<ul>
<li>就绪挂起：进程本来是就绪态，但是被挂起了，那就变成就绪挂起，有的时候运行态的进程发现内存没有地方了，也会直接被设为就绪挂起。</li>
<li>阻塞挂起：好理解，就是阻塞的时候内存不够了，这个进程被挂起，就会进入阻塞挂起，阻塞挂起不能直接回到就绪，当阻塞结束时，他会先变为就绪挂起，然后再回到就绪态。</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618103739.png" alt="image.png"></p>
<p>这种408可能不会考。</p>
<h2 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618103931.png" alt="image.png"><br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618104043.png" alt="image.png"></p>
<h1 id="3-进程调度的时机"><a href="#3-进程调度的时机" class="headerlink" title="3. 进程调度的时机"></a>3. 进程调度的时机</h1><p>注意，这里可是叫进程调度，也就是对应前面的低级调度。</p>
<p>进程调度的时机就是什么时候可以进行进程调度，什么时候不能进行调度。</p>
<h2 id="3-1-可以进程调度"><a href="#3-1-可以进程调度" class="headerlink" title="3.1 可以进程调度"></a>3.1 可以进程调度</h2><p>两种情况可以进行进程调度：</p>
<ul>
<li>当前运行的进程主动放弃处理机：进程正常终止，或者运行过程中发成异常，或者进程正在等待某事发生阻塞。</li>
<li>当前运行的进程被动放弃处理机：时间片到了，有更紧急的事儿需要处理（比如IO中断），或者有更高优先级的进程进入就绪队列。</li>
</ul>
<h2 id="3-2-不能进程调度"><a href="#3-2-不能进程调度" class="headerlink" title="3.2 不能进程调度"></a>3.2 不能进程调度</h2><ul>
<li>处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难做到在处理中断的过程中进行进程切换</li>
<li>进程在<font color = 'red'>操作系统内核程序临界区</font>中</li>
<li>在原子操作过程中，比如原语。原子操作需要一气呵成，中间不能调度。</li>
</ul>
<h2 id="3-3-临界区"><a href="#3-3-临界区" class="headerlink" title="3.3 临界区"></a>3.3 临界区</h2><p>前面说到了操作系统内核临界区，这里解释一下：</p>
<p>首先说一下临界资源：一个时间段内只允许一个进程使用的资源。各个进程需要互斥地访问临界资源。临界区：访问临界资源的那段代码。</p>
<p>内核程序临界区一般是用来访问某种内核数据结构的，比如进程的就绪队列。根据我学JUC和MySQL 的经验，比如进程要操作就绪队列，就绪队列就属于临界资源，那么操作队列的这段代码就是临界区，为了实现互斥效果，操作队列之前就会给队列上锁，但是这个锁不能老上着啊，一直持有锁不释放很有可能发生BUG，所以这个时候就不能进程调度，而是让当前进程赶紧用完队列赶紧释放锁。</p>
<p>但是还有一种情况，就是程序处在普通临界区，比如程序正在操作打印机，这个时候是没事的。</p>
<h1 id="4-进程调度的方式"><a href="#4-进程调度的方式" class="headerlink" title="4. 进程调度的方式"></a>4. 进程调度的方式</h1><h2 id="4-1-非剥夺调度方式"><a href="#4-1-非剥夺调度方式" class="headerlink" title="4.1 非剥夺调度方式"></a>4.1 非剥夺调度方式</h2><p>也叫非抢占方式。只允许进程主动放弃处理机。在运行过程中即使有更近剖的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动阻塞。</p>
<p>这种方式开销小，但是无法及时执行紧急任务。</p>
<h2 id="4-2-剥夺调度方式"><a href="#4-2-剥夺调度方式" class="headerlink" title="4.2 剥夺调度方式"></a>4.2 剥夺调度方式</h2><p>也叫抢占方式。当一个进程正在处理机上时，如果有一个更重要或者更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要的进程。</p>
<p>可以优先处理更紧急的进程，也可以让各个进程按照时间片轮流执行。适合于分时操作系统和实时操作系统。</p>
<h1 id="5-进程的切换与过程"><a href="#5-进程的切换与过程" class="headerlink" title="5. 进程的切换与过程"></a>5. 进程的切换与过程</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618110321.png" alt="image.png"></p>
<h1 id="6-调度器-x2F-调度程序"><a href="#6-调度器-x2F-调度程序" class="headerlink" title="6. 调度器&#x2F;调度程序"></a>6. 调度器&#x2F;调度程序</h1><p>调度器或者说调度程序（Scheduler）就是具体执行调度的东西，调度器来执行进程从就绪态到运行态的转变。具体调度程序需要决定：</p>
<ul>
<li>让谁来运行：调度算法</li>
<li>运行多长时间：时间片大小</li>
</ul>
<p>而我们之前说的调度时机，其实就是什么事件会出发”调度程序“：</p>
<ul>
<li>创建新进程</li>
<li>进程推出</li>
<li>运行进程阻塞</li>
<li>IO中断发生（可能唤醒某些阻塞的进程）</li>
<li>非抢占式调度策略，只有运行进程发生阻塞或者退出才会触发调度程序工作</li>
<li>抢占式调度策略，每个时钟中断或K个时钟中断会触发调度程序工作</li>
</ul>
<p>对于不支持内核线程的操作系统，调度程序的处理对象就是进程。而对于支持内核线程的操作系统，调度程序的处理对象就是内核线程。因为线程是调度的基本单位。</p>
<h1 id="7-闲逛进程"><a href="#7-闲逛进程" class="headerlink" title="7. 闲逛进程"></a>7. 闲逛进程</h1><p>调度程序的备胎，如果没有其他就绪进程的话，就会运行闲逛进程（Idle）。</p>
<p>Idle 的特性：</p>
<ul>
<li>优先级最低：单反有一个就绪的进程都不会运行他</li>
<li>可以是0地址指令，占一个完整的指令周期（指令周期末尾例行检查中断）：就是说这个指令不需要访问CPU啥的</li>
<li>能耗低</li>
</ul>
<h1 id="8-评价调度算法的指标"><a href="#8-评价调度算法的指标" class="headerlink" title="8. 评价调度算法的指标"></a>8. 评价调度算法的指标</h1><h2 id="8-1-CPU利用率"><a href="#8-1-CPU利用率" class="headerlink" title="8.1 CPU利用率"></a>8.1 CPU利用率</h2><p>$$<br>CPU利用率&#x3D;\frac{CPU忙碌时间}{总时间}<br>$$</p>
<p>考研的时候往往会考察多道程序并发执行的情况，可以用“甘特图”来辅助计算。</p>
<h2 id="8-2-系统吞吐量"><a href="#8-2-系统吞吐量" class="headerlink" title="8.2 系统吞吐量"></a>8.2 系统吞吐量</h2><p>指的就是单位时间内完成作业的数量。</p>
<p>$$<br>所以吞吐量&#x3D;\frac{总共完成了多少道作业}{总共花了多少时间}<br>$$</p>
<h2 id="8-3-周转时间"><a href="#8-3-周转时间" class="headerlink" title="8.3 周转时间"></a>8.3 周转时间</h2><p>指的是作业被提交给系统开始，到作业完成为止的这段时间间隔。包括四个部分：</p>
<ul>
<li>作业在外存后备队列上等待作业调度（高级调度）的时间</li>
<li>进程在就绪队列上等待进程调度（低级调度）的时间</li>
<li>进程在CPU上执行的时间</li>
<li>进程等待IO操作完成的时间。</li>
</ul>
<p>后面三项在作业整个处理过程中可能发生多次。</p>
<p>$$<br>周转时间 &#x3D; {作业完成时间} - {作业提交时间}<br>$$</p>
<p>$$<br>平均周转时间 &#x3D; \frac{各作业周转时间和}{作业数}<br>$$</p>
<p>两个作业虽然周转时间相同，但是实际运行时间可能不同，导致的感受也不同，所以又提出了带权周转时间：</p>
<p>$$<br>带权周转时间 &#x3D; \frac{作业周转时间}{作业实际运行时间} &#x3D; \frac{作业完成时间 - 作业提交时间}{作业实际运行时间}<br>$$</p>
<p>带权周转时间必然 &gt;&#x3D; 1，带权周转时间和周转时间都是越小越好。</p>
<p>然后还有一个平均带权周转时间，就是各个作业带权周转时间的和除以作业数，不说了。</p>
<h2 id="8-4-等待时间"><a href="#8-4-等待时间" class="headerlink" title="8.4 等待时间"></a>8.4 等待时间</h2><p>指的是进程&#x2F;作业处于等待处理机状态时间之和，等待时间越长，用户满意度越低。</p>
<p>对于进程来说，等待时间就是指进程建立后等待被服务的时间之和，在等待IO完成的期间其实进程也是被服务的，所以不计入等待时间（也就是说打印机工作的时间不算）。</p>
<p>对于作业来说，不仅要考虑建立进程后等待的时间，还要加上作业在外存后备队列中等待的时间。</p>
<p>一个作业总共需要被CPU服务多久，被IO设备服务多久一般是确定不变的，因此调度算法其实只会影响作业&#x2F;进程的等待时间。</p>
<p>$$<br>等待时间 &#x3D; 周转时间 - 运行时间（如果使用了IO设备，还需要减去IO设备使用时间）<br>$$</p>
<h2 id="8-5-响应时间"><a href="#8-5-响应时间" class="headerlink" title="8.5 响应时间"></a>8.5 响应时间</h2><p>指的就是用户提交请求到首次产生响应所需要的时间。</p>
<h2 id="8-6-总结"><a href="#8-6-总结" class="headerlink" title="8.6 总结"></a>8.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618145437.png" alt="image.png"></p>
<h1 id="9-调度算法"><a href="#9-调度算法" class="headerlink" title="9. 调度算法"></a>9. 调度算法</h1><h2 id="9-1-先来先服务"><a href="#9-1-先来先服务" class="headerlink" title="9.1 先来先服务"></a>9.1 先来先服务</h2><p>很好理解，就是越先来的进程越先被服务。一般也就是按照时间顺序依次往后执行。核心思想就是“公平”，且属于非抢占式调度算法，除非任务主动放弃或者阻塞，不会强制让任务下线。用于作业调度时，考虑哪个作业先到达后备队列；用于进程调度时，考虑哪个进程先到达就绪队列。</p>
<p>优点：公平、算法实现简单</p>
<p>缺点：排在长作业后面的短作业需要等待很长时间，从指标来看就是带权周转时间非常长，这个体验就是非常不好了。</p>
<p>这种算法不会导致饥饿，所以任务都会有序的被服务。</p>
<h2 id="9-2-短作业优先"><a href="#9-2-短作业优先" class="headerlink" title="9.2 短作业优先"></a>9.2 短作业优先</h2><p>追求最少的平均等待时间，最少的平均周转时间、最少的平均带权周转时间。算法规则就是：最短的作业&#x2F;进程优先得到服务（最短指的是要求服务时间最短）。既可以用于作业调度，也可以用在进程调度。用于进程调度时称为“短进程优先（SPF）算法”。</p>
<p>优点就是“最短的”平均等待时间、平均周转时间。</p>
<p>缺点：不太公平。对短作业有利，对长作业不利。可能产生饥饿现象。另外，作业&#x2F;进程的运行时间是由用户提供的，并已定真实，不一定能做到真正的短作业优先</p>
<p>然而短作业优先又分两种：抢占式和非抢占式：</p>
<h3 id="9-2-1-非抢占式短作业优先"><a href="#9-2-1-非抢占式短作业优先" class="headerlink" title="9.2.1 非抢占式短作业优先"></a>9.2.1 非抢占式短作业优先</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618151318.png" alt="image.png"></p>
<h3 id="9-2-2-抢占式短作业优先"><a href="#9-2-2-抢占式短作业优先" class="headerlink" title="9.2.2 抢占式短作业优先"></a>9.2.2 抢占式短作业优先</h3><p>这种算法也叫“最短剩余时间优先算法（SRNT）”，每次一个任务来了以后，他就会根据任务的剩余时间来重新调度。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618151344.png"></p>
<h3 id="9-2-3-细节"><a href="#9-2-3-细节" class="headerlink" title="9.2.3 细节"></a>9.2.3 细节</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618151642.png" alt="image.png"></p>
<h2 id="9-3-高响应比优先"><a href="#9-3-高响应比优先" class="headerlink" title="9.3 高响应比优先"></a>9.3 高响应比优先</h2><p>是一种非抢占式的算法，就是每次要重新调度的时候，我都看看谁等的时间长了而且活比较简单，优先让这类作业先上处理机。因此也不会饥饿。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618152410.png" alt="image.png"></p>
<h2 id="9-4-总结"><a href="#9-4-总结" class="headerlink" title="9.4 总结"></a>9.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618152556.png" alt="image.png"></p>
<h2 id="9-5-时间片轮转"><a href="#9-5-时间片轮转" class="headerlink" title="9.5 时间片轮转"></a>9.5 时间片轮转</h2><p>比较常用的算法，只用于进程调度，伴随着分时操作系统引入的一种算法。所以这种算法更注重响应时间。</p>
<p>如果时间片设置太大，使得每个进程都可以在一个时间片内完成，则算法就会退化成先来先服务算法，并且会增大进程响应时间。另一方面，如果进程切换过于频繁，就会导致系统会花费大量的时间来处理进程切换，从而导致进程执行的时间比例减少。一般来说，进程开销占比不少过1%。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618153559.png" alt="image.png"></p>
<p>这里说一下算法规则：任务一定是按照顺序进入就绪队列中，所以调度的时候也是按顺序进行调度。如果时间片内任务没做完，则重新放回队列末尾。如果同一时间又有新任务加入，时间片也用完了旧任务要回队，我们默认旧任务排在新任务后面。</p>
<h2 id="9-6-优先级调度算法"><a href="#9-6-优先级调度算法" class="headerlink" title="9.6 优先级调度算法"></a>9.6 优先级调度算法</h2><p>就是说每个任务来的时候都会有个优先数代表着优先级（优先级越高可不一定优先数越大，分情况讨论），每次调度都会选择最高优先级的任务先上处理机。</p>
<p>同样有抢占式的和非抢占式的，非抢占式的好理解，抢占式的就是每次就绪队列发生变化都要重新调度一下，看看有没有新的任务优先级更高，就优先执行哪个。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618154812.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618154718.png" alt="image.png"></p>
<h2 id="9-7-多级反馈队列调度算法"><a href="#9-7-多级反馈队列调度算法" class="headerlink" title="9.7 多级反馈队列调度算法"></a>9.7 多级反馈队列调度算法</h2><p>这个算法可就优点复杂了。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618155507.png" alt="image.png"><br>看图看不懂，来上个例子：</p>
<p>现在有三个任务：</p>
<table>
<thead>
<tr>
<th>进程</th>
<th>到达时间</th>
<th>运行时间</th>
</tr>
</thead>
<tbody><tr>
<td>P1</td>
<td>0</td>
<td>8</td>
</tr>
<tr>
<td>P2</td>
<td>1</td>
<td>4</td>
</tr>
<tr>
<td>P3</td>
<td>5</td>
<td>1</td>
</tr>
</tbody></table>
<p>多级反馈队列会提供多个队列，每个队列有自己的时间片，优先级越高的队列对应的时间片越低：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618160550.png" alt="image.png"></p>
<p>当P1进入，因为是先到达，所以首先进入一级队列，对应的时间片是1，所以执行1个时间，执行完以后，由于时间片没有被打断切P1没有完成，P1就会进入第二级队列，同时，P2来了，就会先进入一级队列。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618160746.png" alt="image.png"></p>
<p>然后操作系统会优先执行优先级高的队列，所以就会优先执行一级队列中的P2，同样是执行一个时间，然后和P1一样进入二级队列。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618160913.png" alt="image.png"></p>
<p>然后二级队列就会按照顺序执行P1，P1同样没有被打断而且没有执行完，那么P1就会进入三级队列，之后继续执行P2任务。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618161034.png" alt="image.png"></p>
<p>P2执行了一个时间时，P3来了，这个时候就会重新调度，相当于P2执行被打断，如果执行被打断，就不会流向下一级队列，而是会重新返回当前队列等待执行。同时P3进入一级队列。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618161214.png" alt="image.png"></p>
<p>操作系统又会优先执行高优先级队列，所以优先执行P3，P3执行完以后执行P2，P2执行了二个时间后执行完成，不会进入三级队列。最后执行P1，因为是最低级队列，即便是时间片内没有执行完，也会重新回到当前队列重新执行。</p>
<h2 id="9-8-总结"><a href="#9-8-总结" class="headerlink" title="9.8 总结"></a>9.8 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618155620.png" alt="image.png"></p>
<h2 id="9-9-多级队列调度"><a href="#9-9-多级队列调度" class="headerlink" title="9.9 多级队列调度"></a>9.9 多级队列调度</h2><p>这个他们就是提了一句，感觉也不是很难。就是说设计好几个任务队列，每个任务队列都有自己的功能划分，所以队列自己就有优先级。各个队列也可以分别设置不同的调度策略。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230618163040.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>06.同步与互斥</title>
    <url>/2023/06/30/OS-06-%E5%90%8C%E6%AD%A5%E4%B8%8E%E4%BA%92%E6%96%A5/</url>
    <content><![CDATA[<p>同步与互斥</p>
<span id="more"></span>

<h1 id="1-进程同步"><a href="#1-进程同步" class="headerlink" title="1. 进程同步"></a>1. 进程同步</h1><p>同步说的就是如何解决进程异步的问题，众所周知操作系统的各个进程异步执行，谁先谁后不可预知，但是有些时候我们又需要控制进程的执行顺序，比如在管道通信中，写肯定得发生在读之前，这就是进程同步要解决的问题。</p>
<h1 id="2-进程互斥"><a href="#2-进程互斥" class="headerlink" title="2. 进程互斥"></a>2. 进程互斥</h1><p>在一个时间段内只允许一个进程使用的资源我们称之为临界资源，比如打印机这种资源，一个进程用了另一个进程就不能用了。</p>
<p>对于临界资源的访问必须互斥的进行。互斥，或者称为间接制约关系。进程互斥指的就是访问临界资源时，另一个想要访问该临界资源的进程必须等待。</p>
<p>对临界资源的访问，可以在逻辑上分为下面四个部分：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619155340.png" alt="image.png"></p>
<p>如果一个进程暂时不能进入临界区，那么该进程是否应该一直占着处理机？这个进程有没有可能一直进不了临界区？这都是互斥要考虑的东西。需要遵循下面四个原则：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619155551.png" alt="image.png"></p>
<p>总结：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619155612.png" alt="image.png"></p>
<h1 id="3-互斥的软件实现"><a href="#3-互斥的软件实现" class="headerlink" title="3. 互斥的软件实现"></a>3. 互斥的软件实现</h1><p>如果两个进程使用打印机，但是不上锁，不涉及到互斥，会出现的问题就是，进程A使用打印机打印了一半时间片用完，然后CPU就去处理进程B，进程B也会获得打印机资源开始打印，然后A和B打印的东西就混在一起了。</p>
<p>为了解决这个问题，可以在代码层面实现互斥。</p>
<h2 id="3-1-单标志法"><a href="#3-1-单标志法" class="headerlink" title="3.1 单标志法"></a>3.1 单标志法</h2><p>核心思想：代码会规定现在只能哪个进程来访问临界区（注意：是访问临界区代码，执行临界区代码的时候肯定已经拿到了临界资源的锁），指定的进程访问完临界资源后，会把临界区的访问权限给另一个进程。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 当前只有0进程可以执行临界区</span></span><br><span class="line"><span class="type">int</span> turn = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// P1进程</span></span><br><span class="line"><span class="keyword">while</span>(turn != <span class="number">0</span>);</span><br><span class="line">critical section;</span><br><span class="line">turn = <span class="number">1</span>;</span><br><span class="line">remainder section;</span><br><span class="line"></span><br><span class="line"><span class="comment">// P2 进程</span></span><br><span class="line"><span class="keyword">while</span>(turn != <span class="number">1</span>);</span><br><span class="line">critical section;</span><br><span class="line">turn = <span class="number">0</span>;</span><br><span class="line">remainder section;</span><br></pre></td></tr></table></figure>

<p>如果进程P2先上处理机，就会卡死在while循环，因为发现turn 确实不等于1，说明自己不能访问临界资源，等到P2的时间片用完了，P1执行，P1就不会卡while，而是会往下执行，最后将 turn 改为1，供P2执行。</p>
<p>这个算法体现了一个谦让的思路，两个进程其中一个只要执行完了临界区，就会把临界区的访问权谦让出去。但是如果P2谦让给了P1，P1因为某种原因迟迟不执行临界区，那么P2也就没发使用临界区，这就<strong>违背了空闲让进</strong>的原则。</p>
<h2 id="3-2-双标志先检查"><a href="#3-2-双标志先检查" class="headerlink" title="3.2 双标志先检查"></a>3.2 双标志先检查</h2><p>核心思想：设置一个布尔型数组 flag[]，数组中各个元素用来表示<strong>各个进程想要进入临界区的意愿</strong>，比如 <code>flag[0] = true</code> 就表示0号进程想要访问临界区。那么每个进程访问临界区之前都要先检查当前其他进程有没有想要进入临界区的意思，如果没有，把自己的 flag 设置为true，然后开始访问临界区。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619161255.png" alt="image.png"></p>
<p>4 和 8 就是退出区。</p>
<p>但是有个问题，就是这种算法的进入区代码分两步：检查和上锁，是非原子性的，并发情况下很可能出现错误，导致两个进程全都进入了临界区。违反了忙则等待。</p>
<h2 id="3-3-双标志后检查"><a href="#3-3-双标志后检查" class="headerlink" title="3.3 双标志后检查"></a>3.3 双标志后检查</h2><p>这个和前面的几乎一样，只是进入区的代码有调整，之前是先检查后上锁，结果会出现锁失效，那么这里就让他先上锁后检查：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619161837.png" alt="image.png"></p>
<p>结果这会更完蛋，每个进程先上锁，然后检查，如果检查发现不能进入临界区他也不会释放锁，这就会导致死锁了。违背了 “空闲让进”和“有限等待”，会产生饥饿。</p>
<h2 id="3-4-Peterson-算法"><a href="#3-4-Peterson-算法" class="headerlink" title="3.4 Peterson 算法"></a>3.4 Peterson 算法</h2><p>这种算法是单标志法和双标志法的结合。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619162402.png" alt="image.png"></p>
<p>就是说一个线程想要进入临界区首先要加锁，加完锁以后还要客气一下执行谦让动作，表明可以让对方进程优先进入。如果这个时候因为并发的原因另一个进程也加了锁，并且也谦让了，相当于该进程的临界区使用权就被让回来了，就可以正常进入临界区。</p>
<p>可以这么理解，谁最后谦让了，谁就会失去行动的优先权。对方进程就会进入临界区。</p>
<p>算法的前三句是进入区。遵循了前三个原则，但是没有遵循<strong>让权等待</strong>。也就是进程会不停的检查自己有没有进入临界区的资格，会占用CPU。</p>
<h2 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619163002.png" alt="image.png"></p>
<h1 id="4-互斥的硬件实现"><a href="#4-互斥的硬件实现" class="headerlink" title="4. 互斥的硬件实现"></a>4. 互斥的硬件实现</h1><h2 id="4-1-中断屏蔽方法"><a href="#4-1-中断屏蔽方法" class="headerlink" title="4.1 中断屏蔽方法"></a>4.1 中断屏蔽方法</h2><p>这个就是使用“关&#x2F;开中断指令”实现，之前说过，执行了关中断指令，后面的指令就不会执行例行检查，所以就一定不会发生进程切换，可以保证原子性。</p>
<p>可以咋办？先执行关中断指令，然后访问临界区，最后执行开中断指令，这样就不会被打断。</p>
<p>优点：简单，高效。</p>
<p>缺点：不适合多核处理机；只适合操作系统内核进程，不适合用户进程。</p>
<h2 id="4-2-TestAndSet指令"><a href="#4-2-TestAndSet指令" class="headerlink" title="4.2 TestAndSet指令"></a>4.2 TestAndSet指令</h2><p>简称TS指令，也叫 TestAndSetLock，或者TSL指令。该指令用硬件实现，执行的过程不允许被中断，只能一气呵成。用C语言表达的话就是：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619163913.png" alt="image.png"></p>
<p>TSL 指令就是说给lock上锁（不管锁原本啥样），同时返回原来的锁状态。当一个进程要访问一个加了锁的资源时，执行TSL指令就会得到true，就不能进入临界区。当另一个进程释放了锁，让lock&#x3D;false时，再执行TSL指令就会得到false，同时自己也会给它上锁。</p>
<p>优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞；适用于多处理机环境。</p>
<p>缺点：不满足让权等待，进程会不停的检查锁的状态，占用CPU。</p>
<h2 id="4-3-Swap-指令"><a href="#4-3-Swap-指令" class="headerlink" title="4.3 Swap 指令"></a>4.3 Swap 指令</h2><p>也叫Exchange指令，其实就是交换，也是由硬件实现，而且也是原子性的指令。思想就是：通过这个原子性的指令，将锁的状态给它换出来，然后检查，如果发现换出来个false，说明锁被释放，自己就可以进入临界区。同时也会将true给换进去，代表加锁。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619164705.png" alt="image.png"></p>
<p>当条件允许，也就是lock为false时，old为true，交换后old为false，lock为true，就相当于自己进程持有了锁。</p>
<h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619164818.png" alt="image.png"></p>
<h1 id="5-互斥锁"><a href="#5-互斥锁" class="headerlink" title="5. 互斥锁"></a>5. 互斥锁</h1><p>这个好像不是个重点，截个图完事儿：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619165144.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619165217.png" alt="image.png"></p>
<h1 id="6-信号量机制"><a href="#6-信号量机制" class="headerlink" title="6. 信号量机制"></a>6. 信号量机制</h1><p>之前的方法里面，比如双标志先检查法，进入区的检查和上锁两步不能一气呵成，就导致两个进程可能会同时进入。而且，所有的解决方案都无法实现让权等待。</p>
<p>为了解决这几个问题，就提出了信号量机制。</p>
<p>用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而可以很方便的实现了进程互斥、进程同步。</p>
<p>信号量其实就是一个变量（可以是整数，也可以是很复杂的记录行变量），可以<font color='red'>用一个信号量来表示系统中某种资源的数量</font>，比如：系统中只有一台打印机，就可以给打印机设置初始值为1的信号量。</p>
<p>操作系统提供了一对原语：wait(S)和signal(S)，可以类比成两个函数，信号量S就是传入的一个参数。</p>
<p>wait和signal操作常被简称为 PV操作，因此也经常把 wait(S) 和 signal(S) 写作P(S) 和 V(S)。</p>
<h2 id="6-1-整型信号量"><a href="#6-1-整型信号量" class="headerlink" title="6.1 整型信号量"></a>6.1 整型信号量</h2><p>用一个整数型变量作为信号量，用来表示系统中某种资源的数量。普通的整数可以进行运行，而整数型信号量只能做三个操作：初始化、P操作、V操作。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619170359.png" alt="image.png"></p>
<p>我们会发现它其实就是先检查后上锁，但是原子性的，所以更安全。但是这种仍旧是自旋锁，不满足“让权等待”，会发生忙等。</p>
<p>这里有个问题，就是wait原语里面一直自旋，难道不会一直占用CPU？我们姑且认为不会。</p>
<h2 id="6-2-记录型信号量"><a href="#6-2-记录型信号量" class="headerlink" title="6.2 记录型信号量"></a>6.2 记录型信号量</h2><p>为了解决忙等的问题，人们又提出了“记录行信号量”，用记录型数据结构表示信号量。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619170747.png" alt="image.png"></p>
<p>就是说如果发现资源不够不能上锁，就会主动阻塞当前进程，将其挂在信号量的阻塞队列上。等其他进程调用V操作释放资源的时候会主动去唤醒之前阻塞的进程，就不会发生忙等，符合“让权等待”。很有monitor那味。</p>
<h2 id="6-3-总结"><a href="#6-3-总结" class="headerlink" title="6.3 总结"></a>6.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619172000.png"></p>
<h1 id="7-信号量机制实现互斥、同步、前驱"><a href="#7-信号量机制实现互斥、同步、前驱" class="headerlink" title="7. 信号量机制实现互斥、同步、前驱"></a>7. 信号量机制实现互斥、同步、前驱</h1><h2 id="7-1-进程互斥"><a href="#7-1-进程互斥" class="headerlink" title="7.1 进程互斥"></a>7.1 进程互斥</h2><p>这个很简单，初始化一个为1的信号量mutex，每个进程要访问临界区都要执行P（wait）操作，成功进入临界区并执行完以后，需要执行V操作释放mutex。</p>
<p>这个mutex就可以理解成进程临界区的名额只能有一个，P了以后就占用了这个名额。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一般默认的都是记录型信号量</span></span><br><span class="line">semaphore mutex = <span class="number">1</span>; <span class="comment">// 做题的话就用这种方式定义信号量就行了</span></span><br><span class="line"></span><br><span class="line">P1() &#123;</span><br><span class="line">	P(mutex);</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	V(mutex);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">P2() &#123;</span><br><span class="line">	P(mutex);</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	V(mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-2-进程同步"><a href="#7-2-进程同步" class="headerlink" title="7.2 进程同步"></a>7.2 进程同步</h2><p>我们要控制几个进程的执行顺序，比如：P1 要执行code 1 2 3 ，P2要执行 code 4 5 6，我们要求P2必须在P1执行完code2之后执行，怎么做？</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore s = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">P1() &#123;</span><br><span class="line">	code <span class="number">1</span>;</span><br><span class="line">	code <span class="number">2</span>;</span><br><span class="line">	V(s);</span><br><span class="line">	code <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">P2() &#123;</span><br><span class="line">	P(s);</span><br><span class="line">	code <span class="number">4</span>;</span><br><span class="line">	code <span class="number">5</span>;</span><br><span class="line">	code <span class="number">6</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里千万注意，信号量要初始化为0，要是初始化为1的话，P2执行 value–，然后发现 value &#x3D;&#x3D; 0 满足 value &gt;&#x3D; 0，P2直接就进去了。</p>
<p>简单说，前操作之后执行V，后操作之前执行P。</p>
<h2 id="7-3-前驱关系"><a href="#7-3-前驱关系" class="headerlink" title="7.3 前驱关系"></a>7.3 前驱关系</h2><p>就是更为复杂的前驱关系，多个进程需要协同前进。其实非常的简单，每一种前驱关系都设定一个信号量，然后两两成对的前V后P即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619173559.png" alt="image.png"></p>
<h2 id="7-4-总结"><a href="#7-4-总结" class="headerlink" title="7.4 总结"></a>7.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619173733.png" alt="image.png"></p>
<h1 id="8-相关问题"><a href="#8-相关问题" class="headerlink" title="8. 相关问题"></a>8. 相关问题</h1><h2 id="8-1-生产者-消费者"><a href="#8-1-生产者-消费者" class="headerlink" title="8.1 生产者-消费者"></a>8.1 生产者-消费者</h2><p>这个问题很经典啊，就是说有一个缓冲区，生产者往缓冲区写数据，消费者从缓冲区读数据。如果缓冲区满了，生产者阻塞，如果缓冲区空了，消费者阻塞。同时，生产者和消费者不为一，所以各个角色都要互斥的访问缓冲区。</p>
<p>分析：这就是我们之前说的进程同步，缓冲区没空，然后消费者拿数据；反过来，缓冲区没满，则生产者放数据。这就是两个信号量，生产者生产数据，则缓冲区没空，生产者V，消费者P；消费者获取数据，证明缓冲区没满，消费者V，生产者P。这里的没空和没满，就是两个信号量，两个信号量full和empty分别记录缓冲区中数据的个数和缓冲区空位个数。</p>
<p>进程内如何判空？信号量同时记录着资源的剩余数量，所以释放锁的时候给信号量+1，就可以代表缓冲区内的数据个数，同理，获取锁的时候信号量-1，如果&lt;0，证明缓冲区里面没有数据了，阻塞。</p>
<p>不要考虑什么时候阻塞，而是考虑不阻塞时，先干什么，后干什么。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore mutex = <span class="number">1</span>;</span><br><span class="line">semaphore full = <span class="number">0</span>;</span><br><span class="line">semaphore empty = n;</span><br><span class="line"></span><br><span class="line">Producer() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(empty);</span><br><span class="line"></span><br><span class="line">		P(mutex);</span><br><span class="line">		<span class="comment">// 生产数据</span></span><br><span class="line">		V(mutex);</span><br><span class="line"></span><br><span class="line">		V(full);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Consumer() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(full);</span><br><span class="line"></span><br><span class="line">		P(mutex);</span><br><span class="line">		<span class="comment">// 获取数据</span></span><br><span class="line">		V(mutex);</span><br><span class="line"></span><br><span class="line">		V(empty);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619195303.png" alt="image.png"></p>
<h2 id="8-2-多生产-多消费"><a href="#8-2-多生产-多消费" class="headerlink" title="8.2 多生产-多消费"></a>8.2 多生产-多消费</h2><p>多个生产者生产不同类型的消息，多个消费者对应的消费不同类型的消息，举个例子：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619225251.png" alt="image.png"></p>
<p>分析：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619225436.png" alt="image.png"></p>
<p>实现：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619225644.png" alt="image.png"></p>
<p>这里有个点：即便是不设置 mutex互斥信号量，依然可以正常运作。因为 apple orange 和 plate 三个同步信号量在同一时间只能有一个是1，所以各个进程一上来的P操作就可以防止其他线程进入临界区。如果plate的值是2，也就是盘子可以放两个水果的话，dad和mom可就有可能同时操作盘子了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619230248.png" alt="image.png"></p>
<h2 id="8-3-吸烟者问题"><a href="#8-3-吸烟者问题" class="headerlink" title="8.3 吸烟者问题"></a>8.3 吸烟者问题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619230421.png" alt="image.png"></p>
<p>将桌子看作一个缓冲区，容量为1，原材料两两为一个组合，同时要注意轮流这个事儿，他给的解决办法是设置一个i让他%更新。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230619231036.png" alt="image.png"></p>
<h2 id="8-4-读者-写者问题"><a href="#8-4-读者-写者问题" class="headerlink" title="8.4 读者-写者问题"></a>8.4 读者-写者问题</h2><p>这个玩意是真的难，说一下：有一个共享文件，写进程（可以是多个）往文件里写，读进程（可以是多个）从文件里读，如何实现同步互斥。</p>
<p>说一下要求：</p>
<ul>
<li>读进程之间不需要互斥，多个读进程可以同时访问文件</li>
<li>写进程之间需要互斥，否则可能会导致覆盖</li>
<li>写进程写完之前不允许读进程读，还得让所有已有的读写进程退出。</li>
</ul>
<h3 id="8-4-1-简单实现"><a href="#8-4-1-简单实现" class="headerlink" title="8.4.1 简单实现"></a>8.4.1 简单实现</h3><p>最简单的就是弄个文件的信号量进行同步：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore file = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">writer() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(file);</span><br><span class="line">		<span class="comment">// write...</span></span><br><span class="line">		V(file);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reader() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(file);</span><br><span class="line">		<span class="comment">// read...</span></span><br><span class="line">		V(file);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是这样无法让读进程同时进入，读进程之间也会阻塞，咋办？可以这样，让第一个进来的reader上锁，后来的reader可以跳过上锁，让最后一个reader释放锁：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">reader() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span>(count == <span class="number">0</span>) P(file);</span><br><span class="line">		count++;</span><br><span class="line">		<span class="comment">// read...</span></span><br><span class="line">		count--;</span><br><span class="line">		<span class="keyword">if</span>(count == <span class="number">0</span>) V(file);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是这又有个问题：代码的进入区有三条语句，判断，上锁，count自增，不保证原子性，就有可能发生冲突，咋办？那就让他保证原子性，给这三条语句上互斥锁：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore mutex = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">reader() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(mutex);</span><br><span class="line">		<span class="keyword">if</span>(count == <span class="number">0</span>) P(file);</span><br><span class="line">		count++;</span><br><span class="line">		V(mutex);</span><br><span class="line">		<span class="comment">// read...</span></span><br><span class="line">		P(mutex);</span><br><span class="line">		count--;</span><br><span class="line">		<span class="keyword">if</span>(count == <span class="number">0</span>) V(file);</span><br><span class="line">		V(mutex);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-4-2-写优先"><a href="#8-4-2-写优先" class="headerlink" title="8.4.2 写优先"></a>8.4.2 写优先</h3><p>上面这种又会出现一个问题，如果有源源不断的读进程，那么file就一直不会被释放，锁进程就会饥饿，如何解决饥饿的问题？</p>
<p>再弄一个信号量，实现“写优先”（并不是真正的写优先，只是暂时能解决问题）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore w = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">writer() &#123; <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">	P(w);  <span class="comment">// 获取w锁，表明现在有writer要写，新来的reader先等等。   </span></span><br><span class="line">	P(file);</span><br><span class="line">	<span class="comment">// write...</span></span><br><span class="line">	V(file);</span><br><span class="line">	V(w); &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reader() &#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">		P(w); <span class="comment">// 读之前看看有没有writer正在写或者想要写</span></span><br><span class="line">		mutex&#123; <span class="comment">// 只是省事儿这么写，考试别这么写</span></span><br><span class="line">			<span class="keyword">if</span>(count == <span class="number">0</span>) P(file);</span><br><span class="line">			count++;</span><br><span class="line">		&#125;</span><br><span class="line">		V(w);  <span class="comment">// 在read之前释放w，保证reader进程并发</span></span><br><span class="line">		<span class="comment">// read...</span></span><br><span class="line">		mutex&#123;</span><br><span class="line">			count--;</span><br><span class="line">			<span class="keyword">if</span>(count == <span class="number">0</span>) V(file);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这回就变成啥了？首先如果是两个reader进来，reader1获取了w，然后reader2阻塞，reader1在读之前释放了w，然后reader2就会唤醒，可以同时read。</p>
<p>如果是一个writer多个reader的话，reader1经过了前面正在进行read，这个时候writer进来，持有了w锁，然后准备写（但是不能写，因为reader1还持有file锁），然后reader2也来了，尝试获取w失败，就会阻塞，count就不会自增，相当于强制reader读完以后释放file锁，然后writer写，写完了唤醒reader2去读。</p>
<p>这种算法并不能真正实现写优先，而是相对公平的先来先服务原则，这种算法也叫读写公平法。</p>
<h2 id="8-5-哲学家进餐"><a href="#8-5-哲学家进餐" class="headerlink" title="8.5 哲学家进餐"></a>8.5 哲学家进餐</h2><h1 id="9-管程"><a href="#9-管程" class="headerlink" title="9. 管程"></a>9. 管程</h1><p> 这个东西就是一种比较牛逼的数据结构，它里面提供了进程安全（线程安全）的一些方法，比如insert方法，往队列中插入元素，remove方法，从队列中拿出元素等，完了里面还提供了 condition 条件变量，简单说就是阻塞队列。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620104904.png" alt="image.png"></p>
<p>感觉这个管程也不是重点，提一句得了。<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620104938.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>03.进程</title>
    <url>/2023/06/30/OS-03-%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>进程</p>
<span id="more"></span>

<h1 id="1-进程概念"><a href="#1-进程概念" class="headerlink" title="1. 进程概念"></a>1. 进程概念</h1><p>程序就是磁盘上的可执行文件，而进程就是动态的执行。</p>
<p>如果我们一次打开多个进程，操作系统怎么知道哪个是哪个？</p>
<h1 id="2-进程的组成"><a href="#2-进程的组成" class="headerlink" title="2. 进程的组成"></a>2. 进程的组成</h1><p>先说结论，进程实体由PCB、程序段、数据段 组成：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617214531.png" alt="image.png"></p>
<h2 id="2-1-PCB-程序控制块"><a href="#2-1-PCB-程序控制块" class="headerlink" title="2.1 PCB-程序控制块"></a>2.1 PCB-程序控制块</h2><p>操作系统会为每个进程分配一个ID——PID，同时操作系统还会记录当前这个进程的所属用户UID，还要记录给这个进程分配了多少资源；以及记录进程的运行情况，比如 CPU 使用时间，磁盘使用情况等。</p>
<p>操作系统需要为一个进程维护这么多信息，这些信息就会统一的保存在一个数据结构中——PCB（Process Control Block），也就是<strong>进程控制块</strong>，操作系统需要对各个并发运行的进程进行管理，单发管理时所需要的信息，都会放在PCB中。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617213809.png" alt="image.png"></p>
<h2 id="2-2-程序段和数据段"><a href="#2-2-程序段和数据段" class="headerlink" title="2.2 程序段和数据段"></a>2.2 程序段和数据段</h2><p>这个其实好理解，一个可执行文件，运行的时候就会把指令放在内存中供CPU读取执行，那么这些内存中的指令，就是程序段。而执行过程中肯定会产生不少数据，这些数据也会存在内存中，这么用来存数据的部分，就是这个进程的数据段。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617214306.png" alt="image.png"></p>
<h1 id="3-进程的特征"><a href="#3-进程的特征" class="headerlink" title="3. 进程的特征"></a>3. 进程的特征</h1><p>一张图：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617214648.png" alt="image.png"></p>
<h1 id="4-进程状态"><a href="#4-进程状态" class="headerlink" title="4. 进程状态"></a>4. 进程状态</h1><h2 id="4-1-进程的各个状态"><a href="#4-1-进程的各个状态" class="headerlink" title="4.1 进程的各个状态"></a>4.1 进程的各个状态</h2><p>这个和线程状态感觉特别像。</p>
<p><strong>创建态</strong></p>
<p>当进程被创建时，它的状态就是“创建态”，这个阶段操作系统会给她分配资源，初始化PCB。</p>
<p><strong>就绪态</strong></p>
<p>当进程创建完成后，就会进入“就绪态”，处于就绪态的进程已经具备了运行条件，但是由于CPU比较忙，所以还不能运行这个进程。</p>
<p><strong>运行态</strong></p>
<p>等CPU空闲了，就会拿过来一个处于就绪态的进程去运行，那么这个被运行的进程就处于“运行态”。</p>
<p><strong>阻塞态</strong></p>
<p>假设这个进程就是WPS，他要让打印机进行打印，然后CPU就会给这个进程分配打印机资源，但是这个打印机正在干活，没空为这个进程服务，那么这个进程就会进入“阻塞态”。总的来说，进程运行时，可能会请求等待某个事件的发生，这里就是等待打印机空闲，在这个事件发生之前，操作系统就会让这个进程下CPU，并让他进入“阻塞态”。</p>
<p>等到打印机空闲了，这个进程就会重新回到就绪态，然后等待被调度上CPU。</p>
<p><strong>终止态</strong></p>
<p>使用完打印机，这个进程就该结束了，然后进程就会执行 exit 系统调用，请求操作系统终止该进程。此时进程就会进入“终止态”，操作系统就会让这个进程下CPU，并回收内存空间等资源，最后回收这个进程的PCB。</p>
<h2 id="4-2-进程状态的转换"><a href="#4-2-进程状态的转换" class="headerlink" title="4.2 进程状态的转换"></a>4.2 进程状态的转换</h2><p>这个转换和线程的状态转换也是非常像：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617220127.png" alt="image.png"></p>
<h2 id="4-3-总结"><a href="#4-3-总结" class="headerlink" title="4.3 总结"></a>4.3 总结</h2><p>看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617220107.png" alt="image.png"></p>
<h1 id="5-进程的组织"><a href="#5-进程的组织" class="headerlink" title="5. 进程的组织"></a>5. 进程的组织</h1><p>这个说的就是操作系统如何管理各个进程的PCB，这里说两个组织方式：</p>
<h2 id="5-1-链接方式"><a href="#5-1-链接方式" class="headerlink" title="5.1 链接方式"></a>5.1 链接方式</h2><p>操作系统提供几个指针来指向不同的PCB：</p>
<ul>
<li>执行指针：指向当前运行的进程PCB</li>
<li>就绪队列指针：将所有就绪的进程PCB放入队列，优先级高的进程放在队头，然后指针指向队头</li>
<li>阻塞队列指针：和上面类似。</li>
</ul>
<p>阻塞队列指针有的时候会分开，比如进程1 3 5 等待打印机，就会把PCB1 3 5 放入打印机的阻塞队列，进程 2 4 6 等待磁盘，就会把PCB 2 4 6 放入磁盘的阻塞队列。</p>
<h2 id="5-2-索引方式"><a href="#5-2-索引方式" class="headerlink" title="5.2 索引方式"></a>5.2 索引方式</h2><p>也会提供指针，但是指针不会直接指向PCB。</p>
<ul>
<li>执行指针：也是指向当前运行进程的PCB</li>
<li>就绪表指针：指向了一个记录就绪进程表的指针，表里面记录了PCB的位置</li>
<li>阻塞表指针：同理</li>
</ul>
<p>看看图就理解了：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617220726.png" alt="image.png"></p>
<h2 id="5-3-总结"><a href="#5-3-总结" class="headerlink" title="5.3 总结"></a>5.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617220803.png" alt="image.png"></p>
<h1 id="6-进程控制"><a href="#6-进程控制" class="headerlink" title="6. 进程控制"></a>6. 进程控制</h1><p>前面重点说了进程的状态以及操作系统如何组织PCB，这里就说说操作系统具体如何实现各个进程的转换，也就是进程控制。</p>
<h2 id="6-1-如何实现进程控制"><a href="#6-1-如何实现进程控制" class="headerlink" title="6.1 如何实现进程控制"></a>6.1 如何实现进程控制</h2><p>这里首先复习一下，前面说过一个词——“原语”，这个东西是操作系统内核的组成部分，非常重要。我们这里先给结论：进程控制需要使用原语来实现。</p>
<p>一个进程从阻塞态变为就绪态需要干两件事：将这个进程的PCB的state改为2，此时这个PCB在阻塞队列里；然后将PCB放入就绪队列中。这两件事儿一定要一起执行，如果中断，就会导致PCB的state和所处队列不一致，可能就会出现BUG。</p>
<p>之前说过，原语的执行具有原子性，执行原语的过程中不允许被打断，和上面说的就非常吻合，所以就要用原语来实现进程控制。</p>
<h2 id="6-2-原语为啥原子性"><a href="#6-2-原语为啥原子性" class="headerlink" title="6.2 原语为啥原子性"></a>6.2 原语为啥原子性</h2><p>一般情况下，CPU每执行完一个指令，就会去检查有没有外部的中断信号，如果有就会中断，去执行中断处理程序。为了变面外中断干扰，CPU提供了两条特权指令：</p>
<ul>
<li>关中断指令：CPU执行这条指令后，往后面的指令都不会检查外部中断，一定会往下执行</li>
<li>开中断指令：CPU执行后，恢复到以前的执行完检查外中断的模式，往后就不能保证原子性</li>
</ul>
<p>依靠这两条指令就可以实现原子性：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617222120.png" alt="image.png"></p>
<p>图中，指令a 和 指令b 一起执行，这两条指令就有了原子性。</p>
<h2 id="6-3-进程控制相关原语"><a href="#6-3-进程控制相关原语" class="headerlink" title="6.3 进程控制相关原语"></a>6.3 进程控制相关原语</h2><h3 id="6-3-1-创建原语"><a href="#6-3-1-创建原语" class="headerlink" title="6.3.1 创建原语"></a>6.3.1 创建原语</h3><p>也就是涉及到创建进程的原语：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617222353.png" alt="image.png"><br>这里提一句：这个作业调度里面的作业，指的就是外存里面的程序，把外存里面的程序读入内存，就是作业调度。</p>
<h3 id="6-3-2-撤销原语"><a href="#6-3-2-撤销原语" class="headerlink" title="6.3.2 撤销原语"></a>6.3.2 撤销原语</h3><p>让进程结束要用到的原语：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617222743.png" alt="image.png"></p>
<h3 id="6-3-3-阻塞和唤醒"><a href="#6-3-3-阻塞和唤醒" class="headerlink" title="6.3.3 阻塞和唤醒"></a>6.3.3 阻塞和唤醒</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617222901.png" alt="image.png"></p>
<h3 id="6-3-4-切换原语"><a href="#6-3-4-切换原语" class="headerlink" title="6.3.4 切换原语"></a>6.3.4 切换原语</h3><p>这个原语是干嘛的？就是说时间片轮转嘛，一个进程的时间片到了，他就需要从运行态返回就绪态，然后另一个进程上CPU，从就绪态变成运行态。切换原语就是干这个的：<br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617223007.png" alt="image.png"></p>
<h3 id="6-3-5-进程的运行环境"><a href="#6-3-5-进程的运行环境" class="headerlink" title="6.3.5 进程的运行环境"></a>6.3.5 进程的运行环境</h3><p>前面说要把进程的运行环境保存到PCB中，进程的运行环境是啥？</p>
<p>首先说一下：CPU里面有两个比较重要的寄存器，PC和IR，PC也就是程序计数器，它指向了下一条要执行的指令；IR是当前正在执行的指令。然后还有一些别的寄存器就不说了。</p>
<p>如果现在只有一个进程在运行，有指令 1 2 3 4，那很好解释，CPU将指令1存入IR，PC指向指令2，然后执行IR中的指令。然后CPU根据PC找到指令2，将指令2存入IR，然后PC接着指向指令3，然后CPU执行指令2，以此类推。</p>
<p>但是如果要进行时间片轮转，执行到指令2之后要下CPU了，咋办？下次再上CPU，CPU如何恢复这些IR和PC？操作系统就会把CPU这些寄存器的数据存到PCB中，等下一次再将PCB读会到CPU。那么这些寄存器的数据，就是这个进程的运行环境信息。</p>
<h2 id="6-4-总结"><a href="#6-4-总结" class="headerlink" title="6.4 总结"></a>6.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617224219.png" alt="image.png"></p>
<h1 id="7-进程通讯"><a href="#7-进程通讯" class="headerlink" title="7. 进程通讯"></a>7. 进程通讯</h1><p>首先，进程之间通讯需要操作系统进行支持。进程是分配系统资源的单位（包括内存地址空间），因此各个进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间。</p>
<p>所以，操作系统为进程通讯提供了三种方式：共享存储、消息传递、管道通讯。</p>
<h2 id="7-1-共享存储"><a href="#7-1-共享存储" class="headerlink" title="7.1 共享存储"></a>7.1 共享存储</h2><p>这个很好理解，一个进程需要对外暴露共享，他就可以在内存中再申请一片空间，共享数据往这片空间写就行了，然后别的进程来这片空间读即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617225020.png" alt="image.png"></p>
<p>互斥这里注意一下就行了，为了避免两个进程都往共享区里面写，操作系统会让写这个操作为互斥操作。</p>
<p>共享存储又分出来两种：基于存储区和基于数据结构。基于存储区的共享，操作系统只负责在内存中划分出来一块共享存储区，数据的形式、存放位置都是通过通信简称控制，而不是操作系统。这种共享方式速度很快，是一种<strong>高级通信</strong>方式。</p>
<p>而基于数据结构的共享，就是操作系统规定，共享空间只能放一个 int[10]，这种共享方式速度慢，限制多，是一种<strong>低级通信</strong>方式。</p>
<p>将内存区域映射到进程的虚拟地址空间，这个先有个印象，往后会详细说。</p>
<h2 id="7-2-消息传递"><a href="#7-2-消息传递" class="headerlink" title="7.2 消息传递"></a>7.2 消息传递</h2><p>进程间的数据交换以<strong>格式化消息</strong>（Message） 为单位。进程通过操作系统提供的“发送消息&#x2F;接收消息”两个<strong>原语</strong>进行数据交换。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617230026.png" alt="image.png"></p>
<h3 id="7-2-1-直接通讯"><a href="#7-2-1-直接通讯" class="headerlink" title="7.2.1 直接通讯"></a>7.2.1 直接通讯</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617230239.png" alt="image.png"></p>
<ul>
<li>首先进程P写一个消息，肯定是在P的地址空间写消息，然后执行发送原语，将消息发出。</li>
<li>进程Q的PCB在操作系统内核空间，PCB内部都有一个消息队列，进程P发来的消息就会挂到这个队列上</li>
<li>然后进程Q执行接收原语，就会在PCB的消息队列上找，哪个是进程P发来的消息</li>
<li>找到消息以后，将这个消息从内核空间PCB上，复制到进程Q的地址空间。</li>
</ul>
<p>所谓的直接通讯，也就是在发送和接收消息的时候指名道姓的说，我这个消息是发给哪个进程的。</p>
<h3 id="7-2-2-间接通信"><a href="#7-2-2-间接通信" class="headerlink" title="7.2.2 间接通信"></a>7.2.2 间接通信</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617230752.png" alt="image.png"></p>
<p>这个也很好理解：</p>
<ul>
<li>进程P同样在自己的地址空间填写消息，但是不再发送给进程Q，而是发送给信箱A。</li>
<li>进程Q会使用接收原语，从信箱A获取这个消息，同样是将消息复制到Q的地址空间。</li>
</ul>
<p>这个就可以多个进程往信箱中发送消息。</p>
<h2 id="7-3-管道通讯"><a href="#7-3-管道通讯" class="headerlink" title="7.3 管道通讯"></a>7.3 管道通讯</h2><p>所谓管道就是特殊的共享文件，又名 pipe 文件。其实就是在内存中开辟一个大小固定的内存缓冲区。这个管道单向传递数据，而且必须按顺序读取数据，类似循环队列。</p>
<p>进程P和进程Q建立pipe，进程P只能往pipe里写，进程Q只能从pipe里读。而且，进程Q只能读最前面未读取的数据，不能像前面共享存储那样，随心所欲想读哪读哪。</p>
<p>重点：</p>
<ul>
<li>管道只能采取半双工通信，也就是在某一时间只能实现单向传输。传输完了以后pipe的方向可以改。如果想要同时进行两个方向的传输，需要设置两个管道。</li>
<li>各个进程要护齿的访问管道，由操作系统实现</li>
<li>当管道写满时，写进程将阻塞，直到读进程将数据取走，即可唤醒写进程</li>
<li>当管道为空时，读进程将阻塞，直到写进程写入数据，即可唤醒读进程。</li>
<li>数据被读走后就会彻底消失。因此如果多个进程同时读一个pipe时，可能会造成混乱。解决方案是：1-一个管道允许多个写进程，一个读进程；2-允许多个写进程多个读进程，但是读进程会轮流读取数据（Linux做法）</li>
</ul>
<p>如果是考试的话，就按多个写进程，一个读进程来就行了。还有，只要pipe没空，读进程就可以读，不用非等pipe满了以后才读，反过来也一样。</p>
<h2 id="7-4-总结"><a href="#7-4-总结" class="headerlink" title="7.4 总结"></a>7.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230617232207.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>09.虚拟内存</title>
    <url>/2023/06/30/OS-09-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</url>
    <content><![CDATA[<p>虚拟内存</p>
<span id="more"></span>

<h1 id="1-虚拟内存概念"><a href="#1-虚拟内存概念" class="headerlink" title="1. 虚拟内存概念"></a>1. 虚拟内存概念</h1><p>传统的内存管理分为连续分配和非连续分配，共同点都是需要将全部的进程数据加载到内存中才可以运行。这就会造成两个问题：</p>
<ul>
<li>作业很大时，不能全部装入内存，导致大作业无法运行，比如各种大型游戏</li>
<li>大量作业要求运行时，由于内存无法装入所有作业，因此只有少量作业能够运行，导致多道程序并发度下降</li>
</ul>
<p>驻留性：一旦作业被装入内存，就会一直驻留在内存中，直到作业运行结束，实际上一个时间段内只需要访问作业的一小部分数据即可正常运行，这就导致内存中驻留大量的暂时用不到的数据，浪费资源。</p>
<h2 id="1-1-局部性原理"><a href="#1-1-局部性原理" class="headerlink" title="1.1 局部性原理"></a>1.1 局部性原理</h2><p>虚拟内存就是基于局部性原理出来的，局部性分为两种：</p>
<ul>
<li>时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很可能再次被执行</li>
<li>空间局部性：如果访问了某个存储单元，那么附近的其他存储单元也可能被访问</li>
</ul>
<h2 id="1-2-虚拟内存定义和特征"><a href="#1-2-虚拟内存定义和特征" class="headerlink" title="1.2 虚拟内存定义和特征"></a>1.2 虚拟内存定义和特征</h2><p>基于局部性原理，当程序装入内存时，可以将程序中很快会被用到的部分装入内存，暂时用不到的部分留在外存，然后开始执行。</p>
<p>执行过程中，当访问信息不在内存中时，操作系统将所需要信息从外存调入内存，然后继续执行进程。</p>
<p>如果内存空间不够，操作系统负责将内存中暂时不到的信息换出内存。</p>
<p>所以在操作系统的管理下，用户就会觉得似乎有一个比实际内存大的多的内存空间，这个就是虚拟内存。</p>
<p>虚拟内存的三个主要特征：</p>
<ul>
<li>多次性：无需在作业运行时一次性装入内存，而是允许多次调入内存</li>
<li>对换性：在作业运行时无需一直常驻内存，而是运行在作业运行过程中将作业换入换出</li>
<li>虚拟性：在逻辑上扩充了内存容量，在用户看来内存多于实际容量</li>
</ul>
<h2 id="1-3-如何实现虚拟内存技术"><a href="#1-3-如何实现虚拟内存技术" class="headerlink" title="1.3 如何实现虚拟内存技术"></a>1.3 如何实现虚拟内存技术</h2><p>既然允许多次调入内存，那么连续分配方式就不太合适了。因此虚拟内存的前提是操作系统支持离散分配内存的管理方式。</p>
<p>传统的离散管理方式：</p>
<ul>
<li>分页式管理</li>
<li>分段式管理</li>
<li>段页式管理</li>
</ul>
<p>虚拟内存的实现方式：</p>
<ul>
<li>请求分页存储管理</li>
<li>请求分段存储管理</li>
<li>请求段页式存储管理</li>
</ul>
<p>区别在于，进程执行过程中，当访问的信息不在内存时，操作系统负责将所需信息从外存调入内存，然后继续执行，操作系统需要提供请求调页功能。空间不够时，操作系统负责将内存中暂时用不到的信息换出到外存，操作系统需要提供页面置换功能。</p>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628231408.png" alt="image.png"></p>
<h1 id="2-请求分页存储管理方式"><a href="#2-请求分页存储管理方式" class="headerlink" title="2. 请求分页存储管理方式"></a>2. 请求分页存储管理方式</h1><p>对比基本分页管理方式，主要需要提供两个功能：</p>
<ul>
<li>请求调页：发现访问的信息不在内存中，OS将所需信息从外存调入内存</li>
<li>页面置换：内存空间不够，OS负责将不需要的信息换出到外存</li>
</ul>
<h2 id="2-1-页表机制"><a href="#2-1-页表机制" class="headerlink" title="2.1 页表机制"></a>2.1 页表机制</h2><p>与基本分页管理中的页表相比，有以下区别：</p>
<ul>
<li>OS 需要知道每个页面是否已经调入内存，如果没有，也需要知道页面在外存中的位置。</li>
<li>内存不够时需要进行页面置换，OS 需要通过某些指标来决定到底换出哪个页面；有的页面没有被修改过就不需要换出，修改过的页面就需要会写到外存覆盖旧数据。</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628232041.png" alt="image.png"></p>
<h2 id="2-2-缺页中断机构"><a href="#2-2-缺页中断机构" class="headerlink" title="2.2 缺页中断机构"></a>2.2 缺页中断机构</h2><p>根据上图，假设我们现在要访问页号为0的页面，结果OS发现0号页面不在内存中，就会产生一个缺页中断，然后由OS的缺页中断处理程序处理中断。</p>
<p>此时缺页的进程阻塞，放入阻塞队列，调页完成后再唤醒，放回阻塞队列。</p>
<p>在调页的过程中，如果发现内存中有空闲页框，就将页框分配给0号页，同时修改页表中的内存块号为响应的页框号。如果发现内存中没有空闲位置了，就会由页面置换算法选择一个页面淘汰，比如淘汰2号页面，发现页面被修改，则将内存块c的内容覆盖回外存z的位置，然后修改内存块号为无，修改位为0，再将内存块c分配给0号页面，修改内存块号为c。</p>
<p>缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生，属于内中断，可以被修复，所以属于故障。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628232837.png" alt="image.png"></p>
<h2 id="2-3-地址转换"><a href="#2-3-地址转换" class="headerlink" title="2.3 地址转换"></a>2.3 地址转换</h2><p>这个和基本的分页管理其实没啥大的不同，只是多了三步：</p>
<ol>
<li>如果发现页面不在内存则请求调页</li>
<li>如果发现没有空闲的页框则则页面置换</li>
<li>需要修改页表中的页表项</li>
</ol>
<p>完整流程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628233547.png" alt="image.png"></p>
<p>这里再说一个点：如果页面被调出内存放入外存，快表中的表项会一并删除，双写一致性了属于是。</p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628233922.png" alt="image.png"></p>
<h1 id="3-页面置换算法"><a href="#3-页面置换算法" class="headerlink" title="3. 页面置换算法"></a>3. 页面置换算法</h1><p>将页面置换出外存需要额外的IO开销，所以好的页面置换算法就要追求更少的缺页率，下面介绍5个页面置换算法。</p>
<h2 id="3-1-最佳置换算法OPT"><a href="#3-1-最佳置换算法OPT" class="headerlink" title="3.1 最佳置换算法OPT"></a>3.1 最佳置换算法OPT</h2><p>每次淘汰的页面都是以后永不使用，或者最长时间内不再被访问的页面，这样可以保证最低的缺页率。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628235452.png" alt="image.png"></p>
<p>第一次缺页发生在第四列，也就是第一次访问2的时候，当前内存中有7 0 1 三个页面，然后用这三个页面挨个往后数，最后出现的那个页面，就是要被置换出去的页面，所以置换出7，将2放在内存块1的位置。往后每次缺页都按照这个方法确定置换出的页面。</p>
<p>最佳置换算法可以保证最低的缺页率，但是进程执行过程中才能知道接下来会访问到哪个位置页面。操作系统无法提前预判页面访问序列，所以这种算法实际无法实现。</p>
<h2 id="3-2-先进先出置换算法FIFO"><a href="#3-2-先进先出置换算法FIFO" class="headerlink" title="3.2 先进先出置换算法FIFO"></a>3.2 先进先出置换算法FIFO</h2><p>很好理解，每次置换出去的页面都是最早进入内存的页面。实现方法也很简单，将调入内存的页面根据调入顺序排成一个队列，需要换出页面时选择队头页面即可，队列最大长度取决于系统为进程分配了多少个内存块。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628235917.png" alt="image.png"></p>
<p>这个图十分好理解，而且很有规律，反正就是依次往后按顺序置换就是了。</p>
<p>这种置换算法可能有个异常：Belady 异常：当为进程分配的内存块增多时，缺页次数不减反增。只有FIFO 算法会出现这种异常，另外，这种算法虽然实现简单，但是算法与进程的实际运行时的规律不适应，因此算法性能很差。</p>
<h2 id="3-3-最近最久未使用置换算法LRU"><a href="#3-3-最近最久未使用置换算法LRU" class="headerlink" title="3.3 最近最久未使用置换算法LRU"></a>3.3 最近最久未使用置换算法LRU</h2><p>每次淘汰的页面都是最近最久未使用的页面。实现方法也简单，页表中加一项访问字段，该字段记录该页面自上次被访问以来所经历的时间t。每当要淘汰一个页面时，选择现有页面中t最大的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629064833.png" alt="image.png"></p>
<p>怎么算呢，和前面的OPT一样的思路，在访问3号页面的时候需要调入页面，此时内存中有1、8、7、2 四个页面，那就从3开始往前数，这四个数字最晚出现的那个就是最近最久未使用的，淘汰即可。这里从3往前数分别是8、1、2、7，7最后出现，所以淘汰7号页面。</p>
<p>这种算法需要专门的硬件支持，虽然算法性能很好，但是实现困难，开销大。</p>
<h2 id="3-5-时钟置换算法CLOCK"><a href="#3-5-时钟置换算法CLOCK" class="headerlink" title="3.5 时钟置换算法CLOCK"></a>3.5 时钟置换算法CLOCK</h2><p>也叫最近未用算法NRU，分为两种：简单的CLOCK算法和改进型CLOCK算法。</p>
<h3 id="3-5-1-简单的时钟置换算法"><a href="#3-5-1-简单的时钟置换算法" class="headerlink" title="3.5.1 简单的时钟置换算法"></a>3.5.1 简单的时钟置换算法</h3><p>为每个页面设置一个访问位，再将内存中的页面都通过链接指针连接成一个循环队列。当某个页被访问时，其访问位时1。当要淘汰一个页面时，只需要检查页的访问位。如果是0，则该页换出；如果是1，则将其改为0，暂不换出，继续顺着循环队列检查下一个页面。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629065651.png" alt="image.png"></p>
<p>如果第一轮扫描所有页面的访问位都是1，第二轮扫描肯定能扫到了。</p>
<p>假设系统为某个进程分配了5个内存块，并考虑到有以下页面号引用串：1，3，4，2，5，6，3，4，7.</p>
<p>首先一上来 1，3，4，2，5 五个页面会组成一个循环链表：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629070308.png" alt="image.png"></p>
<p>然后访问6号页面的时候就会开始选择一个页面淘汰，从1号页面扫描到5号页面，访问位都是1，全部改为0后开始第二轮扫描，发现1的访问位是0，则换出1号页面，将6号页面加载进来，访问位设为1。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629070501.png" alt="image.png"></p>
<p>然后访问3，4，7号页面。3号和4号页面再次访问，所以给访问位设为1，访问7号页面时需要置换，则从3号页面开始扫描，3号和4号的访问位刚刚被设为1，所以暂时不淘汰并访问位设为0，最终淘汰2号页面，将7号页面加载。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629070703.png" alt="image.png"></p>
<p>我们会发现他的淘汰策略就像时钟一样一直在转圈扫描，所以这种算法就叫时钟置换算法。</p>
<h3 id="3-5-2-改进型时钟置换算法"><a href="#3-5-2-改进型时钟置换算法" class="headerlink" title="3.5.2 改进型时钟置换算法"></a>3.5.2 改进型时钟置换算法</h3><p>这种算法还考虑了页面是否被修改过。如果淘汰的页面没有被修改过，是不需要往外存里面回写的，因此在页表里面加一个修改位，修改位&#x3D;0，说明页面没有被修改，修改位&#x3D;1则修改过。根据（访问位，修改位）来决定是否淘汰。</p>
<p>算法规则：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629071456.png" alt="image.png"></p>
<p>还是挺好理解的。</p>
<h2 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629071520.png" alt="image.png"></p>
<h1 id="4-页面分配策略"><a href="#4-页面分配策略" class="headerlink" title="4. 页面分配策略"></a>4. 页面分配策略</h1><h2 id="4-1-页面分配、置换策略"><a href="#4-1-页面分配、置换策略" class="headerlink" title="4.1 页面分配、置换策略"></a>4.1 页面分配、置换策略</h2><p>首先说一个概念：驻留集：请求分页存储管理中给进程分配的物理块的集合；说白了就是进程持有的全部内存块。</p>
<p>页面分配策略有两种：</p>
<ul>
<li>固定分配：操作系统为每个进程分配一组固定数目的物理块，进程运行期间不再改变，也就是驻留集大小不变。</li>
<li>可变分配：很好理解，进程运行期间视情况修改物理块数目，也就是驻留集大小可变。</li>
</ul>
<p>页面置换策略也有两种：</p>
<ul>
<li>局部置换：一个进程只能将自己进程的页面置换出内存</li>
<li>全局置换：操作系统可以将空闲的内存块分配给缺页进程，也可以将其他进程的内存块置换到外存，在跟配给缺页进程。</li>
</ul>
<p>两种分配、置换策略组合，得到三种模式：</p>
<table>
<thead>
<tr>
<th></th>
<th>局部置换</th>
<th>全局置换</th>
</tr>
</thead>
<tbody><tr>
<td>固定分配</td>
<td>Y</td>
<td>-</td>
</tr>
<tr>
<td>可变分配</td>
<td>Y</td>
<td>Y</td>
</tr>
</tbody></table>
<p>三种策略具体如下，太多了直接看图吧，还算好理解：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230629073646.png" alt="image.png"></p>
<h2 id="4-2-如何调入页面"><a href="#4-2-如何调入页面" class="headerlink" title="4.2 如何调入页面"></a>4.2 如何调入页面</h2><p>两种办法：</p>
<ul>
<li>预调页策略：根据局部性原理，访问一个页的话，附近的页最近也可能被访问到。所以一次调入若干个相邻的页面可能比调入一个页面更高效。但是如果预先调入的页面没有被使用，则又是低效的。因此可以预测不久后会用到的页面将他们一批调入内存，但是预测率只有50%左右。所以这种策略主要用于进程首次调入内存，由程序猿制定应该先调入哪些部分。核心是运行前调入。</li>
<li>请求调页策略：这个就是之前说的，只有在运行期间发现缺页才会将页面调入内存。这种策略调入的页面肯定会被访问到，但是每次只能调入一个页面，因此IO开销大。运行时调入。</li>
</ul>
<h2 id="4-3-从哪里调入页面"><a href="#4-3-从哪里调入页面" class="headerlink" title="4.3 从哪里调入页面"></a>4.3 从哪里调入页面</h2><p>我们之前学进程挂起的时候学过磁盘中有一块地方叫对换区，里面数据连续存储，IO速度更快，所以围绕对换区，有三种办法：</p>
<ol>
<li>如果磁盘对换区空间够的话，在进程运行前就会将数据从文件区复制到对换区，往后的调页和页面置换都会在对换区完成</li>
<li>对换区空间不够，则不会被修改的数据直接从文件区调入内存，毕竟不需要回写，下次使用仍旧从文件区调入，需要被修改的数据一开始也是从文件区调入，但是页面置换会置换到交换区，下次再从置换去调页。</li>
<li>UNIX方式：运行前所有文件放在文件区，故未使用过的页面都可以从文件区调入。若被使用过的页面需要换出，则回写到交换区，下次再从交换区调入。</li>
</ol>
<h2 id="4-4-抖动（颠簸）现象"><a href="#4-4-抖动（颠簸）现象" class="headerlink" title="4.4 抖动（颠簸）现象"></a>4.4 抖动（颠簸）现象</h2><p>刚刚调入的页面马上又被换出内存，刚刚被换出的页面马上又被调入，这种频繁的调度行为称为抖动。主要原因就是进程频繁访问的页面数目高于实际可用的物理块，简单说就是物理块分配少了。</p>
<h2 id="4-5-工作集"><a href="#4-5-工作集" class="headerlink" title="4.5 工作集"></a>4.5 工作集</h2><p>上面的问题，如果分配的物理块少，会发生抖动，如果多了，可能造成浪费，所以提出了工作集的概念。</p>
<p>和驻留集类似，驻留集：给进程分配的所有物理块的集合。工作集：在某段时间内，进程实际访问页面的集合。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630082003.png" alt="image.png"></p>
<h2 id="4-6-总结"><a href="#4-6-总结" class="headerlink" title="4.6 总结"></a>4.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630082036.png" alt="image.png"></p>
<h1 id="5-内存映射文件"><a href="#5-内存映射文件" class="headerlink" title="5. 内存映射文件"></a>5. 内存映射文件</h1><h2 id="5-1-传统文件读写方式"><a href="#5-1-传统文件读写方式" class="headerlink" title="5.1 传统文件读写方式"></a>5.1 传统文件读写方式</h2><p>传统读文件方式相当复杂，假设有一个文件 index.txt，磁盘里面都是分块存的，所以文件也被分成了好几个块放在磁盘。读取的顺序如下：</p>
<ul>
<li>open 系统调用：打开文件</li>
<li>seek 系统调用：将读写指针移到某个位置，比如移到了第二个磁盘块的位置</li>
<li>read 系统调用：从读写指针位置读入多个数据放入内存，比如将第二个磁盘块调入内存</li>
<li>然后就可以访问内存读取文件</li>
<li>如果在内存中修改文件的话，最后要使用 write 系统调用，根据读写指针将内存中的制定数据写回磁盘</li>
</ul>
<h2 id="5-2-内存映射文件"><a href="#5-2-内存映射文件" class="headerlink" title="5.2 内存映射文件"></a>5.2 内存映射文件</h2><p>内存映射文件可以让读写文件变得更简单，操作文件的时候，会将文件在磁盘中的位置映射到进程的虚拟内存上，但不会真正将文件加载到内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630103536.png" alt="image.png"></p>
<p>当我们真正访问1号地址的时候，就会发生缺页异常，操作系统就会自动将磁盘中的内存调入内存。如果我们要修改文件内容，直接修改内存中的数据即可，结束后操作系统会自动将修改过的内存块回写到磁盘。</p>
<p>流程如下：</p>
<ul>
<li>open 系统调用：打开文件</li>
<li>mmap 系统调用：将文件映射到进程的虚拟地址空间</li>
</ul>
<p>然后我们就可以以访问内存的方式访问文件数据，文件数据的读入和写出都由操作系统自动完成。进程关闭文件时，操作系统自动将文件被修改的数据写回磁盘。</p>
<p>同时，内存映射文件还可以实现文件共享。两个进程访问一个文件，两个进程的虚拟存储空间都会映射这个文件，两个进程的虚拟空间会通过页表映射到同一块物理内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630104129.png" alt="image.png"></p>
<h2 id="5-3-总结"><a href="#5-3-总结" class="headerlink" title="5.3 总结"></a>5.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630104147.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>08.内存管理</title>
    <url>/2023/06/30/OS-08-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>内存管理</p>
<span id="more"></span>

<h1 id="1-内存基础知识"><a href="#1-内存基础知识" class="headerlink" title="1. 内存基础知识"></a>1. 内存基础知识</h1><h2 id="1-1-什么是内存"><a href="#1-1-什么是内存" class="headerlink" title="1.1 什么是内存"></a>1.1 什么是内存</h2><p>内存可存放数据。程序执行钱需要先放到内存中才能被 CPU 处理，以此缓和 CPU 和硬盘之间的速度矛盾。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620214937.png" alt="image.png"><br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620215209.png" alt="image.png"></p>
<h2 id="1-2-进程运行的基本原理"><a href="#1-2-进程运行的基本原理" class="headerlink" title="1.2 进程运行的基本原理"></a>1.2 进程运行的基本原理</h2><h3 id="1-2-1-指令工作原理"><a href="#1-2-1-指令工作原理" class="headerlink" title="1.2.1 指令工作原理"></a>1.2.1 指令工作原理</h3><p>假设我们现在要执行一条语句：<code>x = x + 1</code>，这条语句可能就会被编译成下面三条CPU指令：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621095105.png" alt="image.png"></p>
<ul>
<li>指令一：数据传送，将内存中 01001111 地址（X变量的位置，值为10）的数据，传送到 00000011 寄存器</li>
<li>指令二：加速指令，将寄存器 00000011 中的数据 加上 00000001</li>
<li>指令三：数据传送，将寄存器 00000011 中的数据，传送给内存 01001111 地址（将 X 的值更新到内存）</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621095349.png" alt="image.png"></p>
<p>这里我们假设地址从0开始，那么指令中的所有地址都是真实的“物理地址”。那如果指令不是从 0 开始的，如何应对？</p>
<h3 id="1-2-2-逻辑地址-VS-物理地址"><a href="#1-2-2-逻辑地址-VS-物理地址" class="headerlink" title="1.2.2 逻辑地址 VS 物理地址"></a>1.2.2 逻辑地址 VS 物理地址</h3><p>为了简化理解，我们默认操作系统会给进程分配一片连续的内存空间。如果程序所在的物理地址起始位置不是0，那么指令中的地址如何修改？</p>
<p>可以这么着，指令中的地址不是真实的物理地址，而是一种相对地址，相对于当前进程在物理地址中的起始位置的一种偏移量。比如：指令要求从内存的 79 地址处拿到x，这个79是进程的起始地址往后数 79 个，而非真正的物理79。如果进程起始地址为100，那么x的位置就是 100 + 79。</p>
<h3 id="1-2-3-如何实现地址转换"><a href="#1-2-3-如何实现地址转换" class="headerlink" title="1.2.3 如何实现地址转换"></a>1.2.3 如何实现地址转换</h3><p>计算机中可执行文件也叫装入模块，将装入模块装入内存的时候如何将地址进行转换？这就涉及到三种装入方式：</p>
<p><strong>绝对装入</strong></p>
<p>在编译时，可以预知程序会被放入到哪个位置，那么编译器将产生绝对地址的目标代码，装入程序按照装入模块中的地址，将程序和数据装入内存。也就是说编译出来的可执行文件（装入模块）里面地址就已经写死了。</p>
<p>比如，我们已经知道程序会被装入到 100 的位置，那么编译的时候直接把 x 的位置修改成 179 物理地址即可，也就是绝对地址。这种方式只适合单道程序环境，换一台电脑这个可执行文件怕是就没法用了。</p>
<p><strong>可重定位装入</strong></p>
<p>也叫可重定位装入。编译，链接后装入模块的地址都是从0开始，指令地址中的地址都是相对于起始地址而言的逻辑地址。但是在装入模块被装入内存时会进行地址转换，根据装入的实际位置，将指令中的所有地址修改为物理地址。</p>
<p>这样有个要求：作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入作业。且作业一旦装入完成，运行期间作业不能移动，也不能申请新的内存空间。</p>
<p><strong>动态运行时装入</strong></p>
<p>也叫动态运行时装入，装入模块里面的指令是逻辑地址，装入内存后的指令同样是逻辑地址。然后会有一个重定位寄存器，记录着装入模块存放的起始位置，运行时只需要将指令中的逻辑地址和寄存器中的起始地址相加即可获取真实的物理地址。</p>
<h3 id="1-2-4-写程序到程序运行"><a href="#1-2-4-写程序到程序运行" class="headerlink" title="1.2.4 写程序到程序运行"></a>1.2.4 写程序到程序运行</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621101032.png" alt="image.png"></p>
<p>这里说一下：这个目标模块同样也是指令，然后里面的地址全都是逻辑地址，各个模块的逻辑地址相互独立。链接就是将这些目标模块整合起来，变成一个完整的逻辑地址，当然这些地址同时包含着你用到的一些库函数。最后装入我们之前已经说过了。</p>
<p>这里的链接同样有三种模式：</p>
<p><strong>静态链接</strong></p>
<p>和图里的意思一样，在程序运行之前，将各个目标模块已经库函数链接成一个完整的装入模块，以后不再拆开。</p>
<p><strong>装入时动态链接</strong></p>
<p>这种方式并不会一上来就链接，而是在装入内存时，边装入边链接。</p>
<p><strong>运行时动态链接</strong></p>
<p>运行时将逻辑地址转换为物理地址，需要设置重定位寄存器。如果运行时不需要某个目标模块，则不会加载。</p>
<h2 id="1-3-总结"><a href="#1-3-总结" class="headerlink" title="1.3 总结"></a>1.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621101659.png" alt="image.png"></p>
<h1 id="2-内存管理概念"><a href="#2-内存管理概念" class="headerlink" title="2. 内存管理概念"></a>2. 内存管理概念</h1><h2 id="2-1-内存的分配和回收"><a href="#2-1-内存的分配和回收" class="headerlink" title="2.1 内存的分配和回收"></a>2.1 内存的分配和回收</h2><p>操作系统要负责内存空间的分配与回收，操作系统如何记录哪些内存区域已经被分配出去，哪些空闲。进程结束后又如何回收内存空间。一个新进程来了，该将他放到哪片内存上，这都是问题。</p>
<h2 id="2-2-内存空间的扩展"><a href="#2-2-内存空间的扩展" class="headerlink" title="2.2 内存空间的扩展"></a>2.2 内存空间的扩展</h2><p>操作系统需要提供某种技术从逻辑上对内存空间进行扩充。</p>
<h2 id="2-3-地址转换"><a href="#2-3-地址转换" class="headerlink" title="2.3 地址转换"></a>2.3 地址转换</h2><p>操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。这个我们之前已经说过了，也就是三种装入方式。</p>
<h2 id="2-4-内存保护"><a href="#2-4-内存保护" class="headerlink" title="2.4 内存保护"></a>2.4 内存保护</h2><p>操作系统在内存中有专门的一片空间专门用于保存操作系统的一些数据，如何避免其他进程非法访问，这就是内存保护。</p>
<h3 id="2-4-1-上下限寄存器"><a href="#2-4-1-上下限寄存器" class="headerlink" title="2.4.1 上下限寄存器"></a>2.4.1 上下限寄存器</h3><p>CPU 会提供一对上下限寄存器，分别存放进程的上下限地址。进程的指令要访问地址时，CPU 就会首先检查地址是否越界。</p>
<h3 id="2-4-2-重定位寄存器"><a href="#2-4-2-重定位寄存器" class="headerlink" title="2.4.2 重定位寄存器"></a>2.4.2 重定位寄存器</h3><p>和上面这个也很类似，CPU 提供两个寄存器：重定位寄存器（基址寄存器），保存进程的起始物理地址；界地址寄存器（限长寄存器），记录指令中允许的最大偏移地址。执行指令时，首先检查逻辑地址是否在最大偏移地址之内，合法则通过重定位寄存器找到真实的物理地址进行执行。</p>
<h2 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621102838.png" alt="image.png"></p>
<h1 id="3-覆盖与交换"><a href="#3-覆盖与交换" class="headerlink" title="3. 覆盖与交换"></a>3. 覆盖与交换</h1><h2 id="3-1-覆盖技术"><a href="#3-1-覆盖技术" class="headerlink" title="3.1 覆盖技术"></a>3.1 覆盖技术</h2><p>前朝的计算机内存通常非常的小，所以经常出现内存不够用的情况，如何将一个更大的程序装入内存成功运行？这就提出了覆盖技术。</p>
<p>简单说，内存会给进程提供固定区和覆盖区，固定区存储进程的核心部分，覆盖区存储不可能被同时访问的程序段。一个模块不用了就可以调出内存腾地方。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621103405.png" alt="image.png"></p>
<h2 id="3-2-交换技术"><a href="#3-2-交换技术" class="headerlink" title="3.2 交换技术"></a>3.2 交换技术</h2><p>核心思想和之前说到的中级调度（挂起）很像：内存空间紧张时，系统将内存中某些进程暂时换出内存，把内存中某些已具备运行条件的进程换入内存（进程在内存和磁盘间动态调度）。</p>
<p>再说一句：即便进程被挂起，PCB 也会被记录到内存的挂起队列中，PCB 会记录进程在磁盘中的挂起位置，所以 PCB 一定是常驻内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621103801.png" alt="image.png"></p>
<p>之前的七状态模型再拿过来看一眼。</p>
<h3 id="3-2-1-换出位置"><a href="#3-2-1-换出位置" class="headerlink" title="3.2.1 换出位置"></a>3.2.1 换出位置</h3><p>外存的什么位置用来保存被换出的进程？具有交换功能的操作系统中，通常把磁盘空间分为“文件区”和“交换区”。</p>
<p>文件区只负责存文件，主要追求存储空间的利用率，因为文件区空间的管理<font color = 'red'>采用离散分配方式</font>。而交换区主要追求的就是交换速度，所以采用<font color = 'red'>连续分配方式</font>，总之就是交换区比文件区更快。</p>
<h3 id="3-2-2-什么时候交换"><a href="#3-2-2-什么时候交换" class="headerlink" title="3.2.2 什么时候交换"></a>3.2.2 什么时候交换</h3><p>许多进程运行而且内存吃紧的时候进行交换，当系统负荷降低就暂停交换。比如：进程运行时进场发生缺页，则内存吃紧，就可以换出一些进程。如果缺页率显著下降，则暂停换出</p>
<h3 id="3-2-3-换出哪些进程"><a href="#3-2-3-换出哪些进程" class="headerlink" title="3.2.3 换出哪些进程"></a>3.2.3 换出哪些进程</h3><p>优先换出阻塞进程；优先级低的进程；为了防止优先级低的继承在被调入内存后很快又被换出，有些系统还会考虑进程在内存的驻留时间。</p>
<h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621104505.png" alt="image.png"></p>
<h1 id="4-连续分配管理方式"><a href="#4-连续分配管理方式" class="headerlink" title="4. 连续分配管理方式"></a>4. 连续分配管理方式</h1><p>第四和第五章开始说一下内存管理的重点：内存分配与回收。分为两类：连续分配管理和非连续分配管理。</p>
<p>连续分配指的就是：系统为用户进程分配的必须是一个连续的内存空间。其中又分为三种方式。</p>
<h2 id="4-1-单一连续分配"><a href="#4-1-单一连续分配" class="headerlink" title="4.1 单一连续分配"></a>4.1 单一连续分配</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621105053.png" alt="image.png"></p>
<h2 id="4-2-固定分区分配"><a href="#4-2-固定分区分配" class="headerlink" title="4.2 固定分区分配"></a>4.2 固定分区分配</h2><p>就是升级版的单一连续分配，将整个用户区分为多个小分区，每个小分区只能放入一个进程，或者说一道作业，这就是最早的最简单的一种可以运行多道程序的内存管理方式。内存的分区数被预先划分。</p>
<p>在某些特定场景下，分区的大小全都相等，比如炼钢厂，每个钢炉的控制程序都一样，就可以将内存分为多个大小相等的区放入控制程序。</p>
<p>分区的大小也可以不相等，增加了灵活性。根据常在系统中运行的作业大小情况来划分。可以划分多个小分区，适量中分区，少量大分区。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621105655.png" alt="image.png"></p>
<h2 id="4-3-动态分区分配"><a href="#4-3-动态分区分配" class="headerlink" title="4.3 动态分区分配"></a>4.3 动态分区分配</h2><p>也叫可变分区分配，这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态建立分区，让分区的大小正好适合进程的需要，因此系统分区的大小和数目可变。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621110137.png" alt="image.png"><br><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621110210.png" alt="image.png"></p>
<p>最后一个问题：如何分配和回收。</p>
<p>这个其实很简单，就是要更新空闲分区表或者空闲分区链。分配的时候看有没有填满某个空闲分区，以此决定是更新该分区的参数还是直接删除该空闲分区。回收的时候，看前后是否有相邻的空闲分区，以此来决定是合并空闲分区还是添加空闲分区。如果是要增加一个空闲分区，这个空闲分区排在哪个位置由动态分区分配算法来决定。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621110917.png" alt="image.png"></p>
<p>紧凑技术就是把内存中的各个进程往紧拼一拼，将外部碎片整理起来。</p>
<p>说一下第二个问题：</p>
<ul>
<li>肯定是要用动态运行时装入方式，那么肯定要用到重定位寄存器</li>
<li>紧凑之后，肯定要修改进程的起始地址，这个地址原本是存在重定位寄存器中，但是在进程调度的时候之前说过，会将各种寄存器保存到 PCB 中。所以这个时候进程的起始地址肯定是在 PCB 里面，我们只需要修改 PCB 中的起始地址即可。</li>
</ul>
<h2 id="4-5-分配方式总结"><a href="#4-5-分配方式总结" class="headerlink" title="4.5 分配方式总结"></a>4.5 分配方式总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230621111411.png" alt="image.png"></p>
<h2 id="4-6-动态分区分配算法"><a href="#4-6-动态分区分配算法" class="headerlink" title="4.6 动态分区分配算法"></a>4.6 动态分区分配算法</h2><p>这个东西比较多，所以单独放一起。上面说过了动态分区分配策略，里面有一个空闲分区表，现在一个新的进程来了，该把他放在哪个空闲分区？这就是分配算法要解决的问题。</p>
<h3 id="4-2-1-首次适应算法"><a href="#4-2-1-首次适应算法" class="headerlink" title="4.2.1 首次适应算法"></a>4.2.1 首次适应算法</h3><p>这个很简单，空闲表或者空闲链会根据地址从低到高排列，一个新的进程来了以后，会从头开始，依次寻找满足条件的空闲分区，一旦找到直接分配。分配完成以后修改空闲分区结构。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623111452.png" alt="image.png"></p>
<p>看图可知，空闲表和空闲链就是按照内存从上到下维护空闲空间。</p>
<h3 id="4-2-2-最佳适应算法"><a href="#4-2-2-最佳适应算法" class="headerlink" title="4.2.2 最佳适应算法"></a>4.2.2 最佳适应算法</h3><p>因为动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片空间。所以为了保证“大进程”来了以后有足够的空间分配，所以该算法会尽可能优先使用小空闲分区。</p>
<p>空闲分区表或者链会按照空闲分区的大小从小到大依次排列，当一个进程来了以后同样是从头开始找，第一个满足条件的分区就会是最小分区。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623111907.png" alt="image.png"></p>
<p>缺点：内存中会遗留很多非常小的外部碎片，这些外部碎片很难被利用。</p>
<h3 id="4-2-3-最坏适应算法"><a href="#4-2-3-最坏适应算法" class="headerlink" title="4.2.3 最坏适应算法"></a>4.2.3 最坏适应算法</h3><p>和最佳相反，为了不留下很多难以利用的外部碎片，这种算法会优先分配大的空闲分区。</p>
<p>空闲分区数据结构按照空闲分区大小从大到小排列，进程来了以后也是从头开始找，分配第一个满足要求的分区。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623112131.png" alt="image.png"></p>
<p>这种的缺点就显而易见了：大进程来了以后可能就会导致内存分区不够用。</p>
<h3 id="4-2-4-邻近适应算法"><a href="#4-2-4-邻近适应算法" class="headerlink" title="4.2.4 邻近适应算法"></a>4.2.4 邻近适应算法</h3><p>这种算法是为了解决首次适应算法的一个小问题：首次适应算法优先将低地址空闲分区分配出去，这就会导致低地址部分出现很多小的外部碎片。而下一次分配还会扫描低地址的这些碎片，没有必要。</p>
<p>所以临近适应算法就会从上一次分配的位置开始往下找，而不是从开头。数据结构仍然是按照地址从低到高排序，如果是空闲分区链的话可以设计成一个双向循环链表。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623112644.png" alt="image.png"></p>
<p>现在要分配一个 5M 的进程，就会从链头开始找，发现 6 这个空闲分区可以分配，然后进行分配空间，将链表修改为 4 -&gt; 1 -&gt; 10 -&gt; 4。</p>
<p>下一次一个3M的进程来了，就会从 1 的位置开始找，然后找到了 10 这个空闲分区，进行分配，修改链表为 4 -&gt; 1 -&gt; 7 -&gt; 4。</p>
<p>这样的一个优点就是：空闲分区表不需要重新排列。缺点就是降低了低地址部分小分区的利用率，不利于保存高地址部分的大分区。</p>
<h3 id="4-2-4-总结"><a href="#4-2-4-总结" class="headerlink" title="4.2.4 总结"></a>4.2.4 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623113100.png" alt="image.png"></p>
<h1 id="5-非连续分配管理方式"><a href="#5-非连续分配管理方式" class="headerlink" title="5. 非连续分配管理方式"></a>5. 非连续分配管理方式</h1><h2 id="5-1-基本分页存储管理"><a href="#5-1-基本分页存储管理" class="headerlink" title="5.1 基本分页存储管理"></a>5.1 基本分页存储管理</h2><p>将内存分为一个个大小相等的分区，假设每个分区4kb，每个分区就是一个<font color = 'red'>页框（页帧，内存快，物理块，物理页）</font>。然后每一个页框都会给编上号，这个号就叫<font color='red'>页框号</font>。从 0 开始。</p>
<p>每个进程的逻辑地址空间（也就是存放指令的那一部分）也会被划分为大小相等的一个个分区，每个分区就叫<font color='red'>页（页面）</font>。同理有一个编号：<font color='red'>页号</font>。从 0 开始。</p>
<p>操作系统就会以页框为单位给各个进程分配内存空间。进程的每个页面分别放入一个页框中，进程的页面和内存的页框一一对应。整个进程在内存中对应的页框不一定会连续存储。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623114108.png" alt="image.png"></p>
<p>对应的，操作系统为了知道每个进程的页面在内存中的存放位置，就会给每个进程创建一张 <font color = 'red'>页表</font>。页表通常也会存在 PCB 中。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623114348.png" alt="image.png"></p>
<h3 id="5-1-1-页表占用空间大小"><a href="#5-1-1-页表占用空间大小" class="headerlink" title="5.1.1 页表占用空间大小"></a>5.1.1 页表占用空间大小</h3><p>假设内存 4GB，每个页框4KB，那么：</p>
<p>$$ 4GB &#x3D; 2^2 * 2^{20} &#x3D; 2 ^ {32} $$</p>
<p>$$ 4KB &#x3D; 2 ^ 2 * 2 ^ {10} &#x3D; 2 ^ {12} $$<br>$$ 4GB &#x2F; 4KB &#x3D; 2^{20} $$</p>
<p>所以内存中总共有 2 ^ 20 个内存块，想要编号就需要 24bit 也就是 3Byte 来存储页框号。</p>
<p>页号呢？页号不需要占用空间，因为页号从0开始，类似于数组下标，所以是隐藏的。因此，每个表项占 3B，存储整个表就需要 3 * (n+1) 字节。但是，页表中记录的仅仅是页框号，而不是页框的物理地址，如果想要得到物理地址还需要 页框号 * 页框大小。</p>
<h3 id="5-1-2-如何地址转换"><a href="#5-1-2-如何地址转换" class="headerlink" title="5.1.2 如何地址转换"></a>5.1.2 如何地址转换</h3><p>之前说：进程如果在内存中被连续分配，那么指令中的地址就可以是相对于当前内存的一个偏移量。而在页存储中，如何记录指令中的地址？虽然各个页面是离散存放的，但是页面内部是连续的，所以指令中的逻辑地址A，就需要：</p>
<ul>
<li>确定逻辑地址A对应的页号P</li>
<li>确定P号页面在内存中的其实地址（需要查找页表，也就是页框号 * 页框大小）</li>
<li>确定逻辑地址A的页内偏移量 W</li>
</ul>
<p>然后，逻辑地址A对应的物理地址 &#x3D; P号页面在内存中的起始地址 + 页内偏移量 W。</p>
<p><strong>如何确定逻辑地址对应的页号和页内偏移量？</strong></p>
<p>假设：页面大小 50B。进程的逻辑地址空间是 200B，则逻辑地址110对应的页号和页内偏移量是多少？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623121352.png" alt="image.png"></p>
<p>如果页面大小是2的整数次方的话，这个事就会变的比较简单。比如，一个页面的大小是 4KB，计算机用 32 个比特位来表示逻辑地址。那么 4KB &#x3D; 2^12 B，需要12个比特位来表示这些存储单元（每个存储单元一个Byte），则：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">0号页面逻辑地址范围 0 - 4095：</span><br><span class="line">00000000000000000000｜000000000000 - 00000000000000000000｜111111111111</span><br><span class="line"></span><br><span class="line">1号页面逻辑地址范围 4096 - 8191：</span><br><span class="line">00000000000000000001｜000000000000 - 00000000000000000001｜111111111111</span><br><span class="line"></span><br><span class="line">2号页面逻辑地址范围 8192 - 12287：</span><br><span class="line">00000000000000000010｜000000000000 - 00000000000000000010｜111111111111</span><br></pre></td></tr></table></figure>
<p>我们就可以发现，多少号逻辑地址，就是把它化成二进制，然后前20位就是他的页号，后12位就是他的页内偏移量。</p>
<p>然后，逻辑地址要转化成物理地址，如果这个计算机的物理地址也适用32个bit来表示的话，那么页框的划分就和上面几乎一样，比如一条逻辑地址在一号页面，偏移地址为000000000011，一号页面分配对应九号页框，9的二进制是 1001，那么这条逻辑地址的物理地址就是：<code>00000000000000001001｜000000000011</code>。也就是页框号的二进制直接拼接页内偏移地址。</p>
<p>如果不满足这种特性的话，就需要去算页框的起始地址。</p>
<p>综上说的，我们可以吧逻辑地址看作这种结构：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623160805.png" alt="image.png"></p>
<h3 id="5-1-3-总结"><a href="#5-1-3-总结" class="headerlink" title="5.1.3 总结"></a>5.1.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623160851.png" alt="image.png"></p>
<h2 id="5-2-基本地址变换机构"><a href="#5-2-基本地址变换机构" class="headerlink" title="5.2 基本地址变换机构"></a>5.2 基本地址变换机构</h2><p>这个机构是顺着上一部分说的，上面说到了逻辑地址转化为物理地址可以怎么转，这里就是说具体哪个部件负责干这个事儿。</p>
<p>基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。通常会在系统中设置一个<strong>页表寄存器（PRT）</strong>，存放页表的内存中的起始地址F和页表长度M。进程未执行时，页表的起始地址和页表长度存放在PCB 中，当进程被调度时，操作系统内核会把他们放到页表寄存器。</p>
<h3 id="5-2-1-地址转换流程"><a href="#5-2-1-地址转换流程" class="headerlink" title="5.2.1 地址转换流程"></a>5.2.1 地址转换流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623161519.png" alt="image.png"></p>
<p>文字说一下：</p>
<ol>
<li>首先要计算逻辑地址A在哪一页的哪个偏移量上，这个上一节就说过了。得出页号 P 和偏移量 W。</li>
<li>比较页号 P 和 页表长度 M。M就是说页表总共有几项，如果发现 P &gt;&#x3D; M，则发生越界中断，否则继续执行（如果 P &#x3D;= M 也不行）</li>
<li>根据页表寄存器中的页表起始地址 F 和页号 P 就可以访问到页表：<code>页表项地址 = 页表起始地址 F + 页号 P * 页表项长度（页框号所占字节）</code>，这个地址就可以得到 b。</li>
<li>顺着 b 就可以算出具体的地址：逻辑地址A的物理地址 &#x3D; b * 页面大小 + 页面偏移量。</li>
</ol>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623162703.png" alt="image.png"></p>
<h3 id="5-2-2-页表项长度"><a href="#5-2-2-页表项长度" class="headerlink" title="5.2.2 页表项长度"></a>5.2.2 页表项长度</h3><p>这个之前讲过了，如果内存 4G，一个页是 4K，总共就有2^20 个页框，也就需要20个bit来表示页框号，所以操作系统会给页框号划分 3B。</p>
<p>页表这个结构最后也是会存储在内存的页框中的，一个页框4K，但是一个页表项3B，那么一个页框可以存储1365个页表项， 4096 % 3 &#x3D; 1，也就是说最后这个页框会产生 1B 的内部碎片。</p>
<p>如果我们要计算1365号页表项的话，由于上面产生了1B的碎片，所以1365号页表项的地址就要在计算结果的基础上 + 1。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623163426.png" alt="image.png"></p>
<p>解决办法就是，页表项也就是页框号，我们直接给他划 4B 的空间，让页表能把页框填满。如果题目中要问最小的页表项可以是多少，还按 3B 来。</p>
<h3 id="5-2-3-总结"><a href="#5-2-3-总结" class="headerlink" title="5.2.3 总结"></a>5.2.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623163653.png" alt="image.png"></p>
<p>这里提到一个概念：页式管理中地址是一维的，就是说 CPU 想要知道逻辑地址对应的物理地址，只需要知道逻辑地址的值即可。</p>
<h2 id="5-3-快表"><a href="#5-3-快表" class="headerlink" title="5.3 快表"></a>5.3 快表</h2><p>快表就是基本地址变换结构的改进版本，可以让地址转换更快。快表也叫联想寄存器（TLB），是一种访问速度比内存快很多的高速缓存（注意，这可不是内存，而是在 CPU 内部的一种缓存），用来存放最近访问的页表项的副本，可以加快地址变换的速度。因为访问高速缓存比访问内存块，所以叫快表，对应的内存中的页表常叫慢表。</p>
<p>由于快表成本高，存储空间小，所以不能存放完整的页表。</p>
<h3 id="5-3-1-地址变换流程"><a href="#5-3-1-地址变换流程" class="headerlink" title="5.3.1 地址变换流程"></a>5.3.1 地址变换流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623164440.png" alt="image.png"></p>
<p>这玩意儿，就是一种缓存，具体流程如下：</p>
<ol>
<li>第一次访问 0-0 地址，除去基本流程外，会去看快表里面有没有页号为0的记录，发现没有，未命中。</li>
<li>按照慢表的思路，去内存里面找到页表，然后发现页号0对应页框600，然后将 0-600 复制到快表中一份。然后访问物理地址。</li>
<li>第二次访问0-4地址，去看快表，发现有了0号页表的记录，0号页表指向600号页框，那他就会拿着600直接去和偏移量拼接得到真实的物理地址，然后访问。</li>
<li>第三次访问0-8，同样的道理，不说了。</li>
</ol>
<p>如果快表存满了，会按照一种算法进行替换，这种算法后面会说。由于局部性原理，快表的命中率可以达到 90% 以上。假设访问一次快表1us，访问一次内存100us，那么平均访问内存时间 ：</p>
<p>$$<br>(1 + 100) * 0.9 + (1 + 100 + 100) * 0.1 &#x3D; 111us<br>$$</p>
<p>1 + 100 就是访问快表然后访问页框，1 + 200 就是先访问快表没命中，然后访问慢表，再访问页框。有些系统支持快表慢表同时访问，那么 （1+100+100）可以优化成 （100 + 100），最后的时间就是 110.9us。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623170308.png" alt="image.png"></p>
<h3 id="5-3-2-局部性原理"><a href="#5-3-2-局部性原理" class="headerlink" title="5.3.2 局部性原理"></a>5.3.2 局部性原理</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623170418.png" alt="image.png"></p>
<h3 id="5-3-3-总结"><a href="#5-3-3-总结" class="headerlink" title="5.3.3 总结"></a>5.3.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623170441.png" alt="image.png"></p>
<h2 id="5-4-两级页表"><a href="#5-4-两级页表" class="headerlink" title="5.4 两级页表"></a>5.4 两级页表</h2><p>假设内存 4GB，页面大小 4KB，页表项长度 4B。则系统会将内存划分为 2^20 个页框，相应的用户进程最多有 2^20页，进而一个进程的页表中，最多有2^20个页表项，一个页表最大需要 2^22 B，共需要2^10个页框存储该页表。</p>
<p>然后，虽然说进程所对应的页框不一定要连续存放，但是表页却需要连续存放，因为我们要顺着页表找页框号，所以内存就需要给这个页表分配 1024 个页框。而且，进程在一段时间内，只需要用到几个页框，其他页框可能并不需要。</p>
<p>所以问题：</p>
<ul>
<li>页表必须连续存放，如果页表很大，则需要占用很多连续的页框</li>
<li>没有必要让页表常驻内存，因为一段时间内可能只需要访问某几个特定的页框。</li>
</ul>
<h3 id="5-4-1-两级页表设计"><a href="#5-4-1-两级页表设计" class="headerlink" title="5.4.1 两级页表设计"></a>5.4.1 两级页表设计</h3><p>为了解决上面的第一个问题，就出现了两级页表。之前，我们是将进程的逻辑内存空间按照页划分，这回我们将页表按同样的形式进行划分。</p>
<p>如果计算机内存 4GB，页表项 4B，页面大小 4KB，则一个页面可以装入 1024 个页表项，我们就可以按照1024将页表进行划分，然后将这些小页表离散的存储到内存中。然后，为这些小页表建立上层的页目录表（顶级页表或者叫外层页表）：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623214709.png" alt="image.png"></p>
<h3 id="5-4-2-如何地址变换"><a href="#5-4-2-如何地址变换" class="headerlink" title="5.4.2 如何地址变换"></a>5.4.2 如何地址变换</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623215054.png" alt="image.png"></p>
<p>这个顺着图看就行了：</p>
<ol>
<li>根据一级页号 0 去页目录表中找到了页框号3，也就是说二级页表存在了3号页框也就是起始地址为12KB的位置。</li>
<li>读取三号页框，得到了二级页表，根据二级页号 1 找到了页框号4，就是说我们要访问的地址在4号页框。</li>
<li>然后 4号页框的起始地址 4 x 4KB 加上偏移地址 111111111111 也就是 1023 得到了最终的物理地址。</li>
</ol>
<p>或者我们也可以把二级页号的哪个值理解成页框号在二级页表所在的页框中的偏移量。所以说，这里一个页面可以存 2^10 个页表项，那么二级页号就需要 10bit 来存储。</p>
<h3 id="5-4-3-如何按需访问页表"><a href="#5-4-3-如何按需访问页表" class="headerlink" title="5.4.3 如何按需访问页表"></a>5.4.3 如何按需访问页表</h3><p>这个是为了解决上面的第二个问题，这里涉及到虚拟存储技术，以后再说。可以在页表项中添加一个标志为，用于表示该页面是否已经调入内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623215457.png" alt="image.png"></p>
<h3 id="5-4-4-多级页表"><a href="#5-4-4-多级页表" class="headerlink" title="5.4.4 多级页表"></a>5.4.4 多级页表</h3><p>是一个例题：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623220447.png" alt="image.png"></p>
<p>这里解释一下为啥弄三级页表：题目规定各级页表的大小不能超过一个页面，一个页面只能存 1024 个页表项，也就需要 10bit 来表示偏移量。</p>
<p>假设我们让他是二级页表结构，则28bit的页号就分为了 18bit的一级页表和 10bit 的二级页表，则一级页表理论上就可以储存最多 2^18个页表项，一个页面显然存不下了，所以需要再给这个一级页表按页分层，然后上层设计更高级的目录。</p>
<h3 id="5-4-5-总结"><a href="#5-4-5-总结" class="headerlink" title="5.4.5 总结"></a>5.4.5 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623220419.png" alt="image.png"></p>
<h2 id="5-5-基本分段存储管理"><a href="#5-5-基本分段存储管理" class="headerlink" title="5.5 基本分段存储管理"></a>5.5 基本分段存储管理</h2><p>这个是从进程本身出发，根据程序的自身逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序猿使用段名来编程），每段从0开始编址。进程的每个段可以在内存中不连续，但是段内是连续的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623221313.png" alt="image.png"></p>
<p>分了段之后如何访问地址？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623221515.png" alt="image.png"></p>
<p>系统为了找到程序的每个段在内存中的物理地址，就设计出了段表：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623221633.png" alt="image.png"></p>
<h3 id="5-5-1-地址变换"><a href="#5-5-1-地址变换" class="headerlink" title="5.5.1 地址变换"></a>5.5.1 地址变换</h3><p>这个和之前的分页存储很像，分段式系统里面同样会提供一个段表寄存器，里面存放段表地址F和段表长度M，这个东西也是存在PCB中，然后进程上 CPU 之后被放入寄存器。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623222346.png" alt="image.png"></p>
<p>这里所说的段表长度就是段长C和基址b所占的字节数。</p>
<h3 id="5-5-2-分段、分页对比"><a href="#5-5-2-分段、分页对比" class="headerlink" title="5.5.2 分段、分页对比"></a>5.5.2 分段、分页对比</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623222714.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623222930.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623223002.png" alt="image.png"></p>
<h3 id="5-5-3-总结"><a href="#5-5-3-总结" class="headerlink" title="5.5.3 总结"></a>5.5.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230623223110.png" alt="image.png"></p>
<h2 id="5-6-段页式存储管理"><a href="#5-6-段页式存储管理" class="headerlink" title="5.6 段页式存储管理"></a>5.6 段页式存储管理</h2><p>其实就是分段和分页式管理，先给进程分段，然后给每个段分页，将分好的页填到内存的页框中。按照这种方法的话，逻辑地址的设计如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628094725.png" alt="image.png"></p>
<ul>
<li>段号规定当前地址在哪个段，同时段号的位数也规定了这个进程最多可以分多少段</li>
<li>页号规定当前地址在段内的哪个页上，页号位数规定了一个段可以分出来多少页</li>
<li>页内偏移量好理解。同时位数规定了页面大小、内存快大小</li>
</ul>
<p>所以上面这图，进程可以分2^16个段，每个段可以分4个页，每个页 2^12页就是4K大小。对于程序员来说，段是程序猿决定的。</p>
<h3 id="5-6-1-段表、页表"><a href="#5-6-1-段表、页表" class="headerlink" title="5.6.1 段表、页表"></a>5.6.1 段表、页表</h3><p>同理，系统也会给进程维护一个段表，同时每个段还要分页，所以每个段自己还有一个页表。所以段表的结构就是：段号-页表长度-当前段的页表所在的页框号。根据页框号，就可以得到这个段自己的页表，然后页表里面记录 页号-内存页框号，再得到段里面页的实际物理地址。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628095607.png" alt="image.png"></p>
<p>一个进程对应一个段表，但是每个段都会对应一个页表。</p>
<h3 id="5-6-2-地址变换"><a href="#5-6-2-地址变换" class="headerlink" title="5.6.2 地址变换"></a>5.6.2 地址变换</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628095944.png" alt="image.png"></p>
<p>我们会发现这个寻址过程，三种内存管理方式都大差不差，一个套路。</p>
<ul>
<li>首先，肯定都会提供一个寄存器，什么段表寄存器，什么页表寄存器，他们的作用就是记录这个表的起始位置和每一个表项的大小，只要有了段号或者页号，就可以根据这两个数值访问到具体的表项。</li>
<li>拿到表项以后根据需求不同的到具体的段地址或者页地址，或者是这种情况得到的是段页表。</li>
</ul>
<h3 id="4-6-3-总结"><a href="#4-6-3-总结" class="headerlink" title="4.6.3 总结"></a>4.6.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230628100408.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>11.文件层次结构</title>
    <url>/2023/07/12/OS-11-%E6%96%87%E4%BB%B6%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>07.死锁</title>
    <url>/2023/06/30/OS-07-%E6%AD%BB%E9%94%81/</url>
    <content><![CDATA[<p>死锁</p>
<span id="more"></span>

<h1 id="1-死锁的概念"><a href="#1-死锁的概念" class="headerlink" title="1. 死锁的概念"></a>1. 死锁的概念</h1><p>前面的哲学家进餐就是一个典型的死锁，每个进程要申请其他进程锁住的临界资源，同时自己还占着别的进程的临界资源，就会发生死锁。</p>
<p>然后需要和饥饿，死循环区分一下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620105802.png" alt="image.png"></p>
<h1 id="2-死锁产生的必要条件"><a href="#2-死锁产生的必要条件" class="headerlink" title="2. 死锁产生的必要条件"></a>2. 死锁产生的必要条件</h1><p>字太多了，懒得打：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620110257.png" alt="image.png"></p>
<h1 id="3-什么时候会发生死锁"><a href="#3-什么时候会发生死锁" class="headerlink" title="3. 什么时候会发生死锁"></a>3. 什么时候会发生死锁</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620110332.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620110439.png" alt="image.png"></p>
<h1 id="4-死锁的处理策略"><a href="#4-死锁的处理策略" class="headerlink" title="4. 死锁的处理策略"></a>4. 死锁的处理策略</h1><h2 id="4-1-静态-预防死锁"><a href="#4-1-静态-预防死锁" class="headerlink" title="4.1 静态-预防死锁"></a>4.1 静态-预防死锁</h2><p>上面说了死锁产生的四个条件：互斥条件，不剥夺条件，请求和保持条件，循环等待条件。预防就是依次把这些条件给他破坏了就行。</p>
<h3 id="4-1-1-破坏互斥条件"><a href="#4-1-1-破坏互斥条件" class="headerlink" title="4.1.1 破坏互斥条件"></a>4.1.1 破坏互斥条件</h3><p>只有对必须互斥使用的资源的争抢才会导致死锁。如果把这些互斥资源改造成共享资源，则系统不会进入死锁状态。比如后面要说到的一个 SPOOLing技术，将独占的设备改造成逻辑上共享的设备。这样的话在进程看起来请求资源会被立即接收处理，无需等待。</p>
<p>缺点就是为了保证系统的安全，某些设备必须要被设计成互斥的。</p>
<h3 id="4-1-2-破坏不剥夺条件"><a href="#4-1-2-破坏不剥夺条件" class="headerlink" title="4.1.2 破坏不剥夺条件"></a>4.1.2 破坏不剥夺条件</h3><p>正常情况下，进程获得资源以后，只有使用完成才会释放资源，其他人不能剥夺他的资源。如果其他人可以强制让他释放资源也就不会发生死锁。</p>
<p>方案一：进程请求信资源得不到满足的时候，就会立即释放他持有的资源，等以后需要的时候重新申请，其实就是他自己发现自己活干不了了就主动躺平了。</p>
<p>方案二：如果发现自己要的资源被其他进程占用了，可以让操作系统出面调解，强行剥夺其他进程持有的资源。这种方式需要考虑优先级（比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用）。</p>
<p>破坏不剥夺条件的缺点：</p>
<ul>
<li>实现复杂</li>
<li>释放已经获得的资源可能会导致前面的工作作废，所以这种办法适合那种易于保存和恢复的资源，比如CPU。</li>
<li>反复申请和释放资源会增加系统开销，降低系统吞吐量。</li>
<li>方式一的话可能会导致饥饿。</li>
</ul>
<h3 id="4-1-3-破坏请求和保持条件"><a href="#4-1-3-破坏请求和保持条件" class="headerlink" title="4.1.3 破坏请求和保持条件"></a>4.1.3 破坏请求和保持条件</h3><p>这个条件本身说的是：进程已经保持了至少一个资源，同时还提出了新的资源<strong>请求</strong>，而该罪案又被其他进程占用，此时请求进程阻塞，仍<strong>保持</strong>着自己已有的资源。</p>
<p>可以使用静态分配方法，进程在运行前一次性申请完他所需要的资源，如果没有申请到，那就不让他运行。一旦运行资源就会一直归他所有，根本上避免进程申请别的资源。</p>
<p>缺点：资源浪费，资源利用率低，可能导致饥饿。</p>
<h3 id="4-1-4-破坏循环等待条件"><a href="#4-1-4-破坏循环等待条件" class="headerlink" title="4.1.4 破坏循环等待条件"></a>4.1.4 破坏循环等待条件</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620112309.png" alt="image.png"></p>
<h3 id="4-1-5-总结"><a href="#4-1-5-总结" class="headerlink" title="4.1.5 总结"></a>4.1.5 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620112338.png" alt="image.png"></p>
<h2 id="4-2-动态-避免死锁"><a href="#4-2-动态-避免死锁" class="headerlink" title="4.2 动态-避免死锁"></a>4.2 动态-避免死锁</h2><h3 id="4-2-1-安全序列"><a href="#4-2-1-安全序列" class="headerlink" title="4.2.1 安全序列"></a>4.2.1 安全序列</h3><p>假设现在有个银行发放贷款，然后各个企业向银行借钱，这些企业会有个借贷总金额的上限，借贷次数可以是多次。现在规定，如果某一次不能满足企业的借贷需求，之前借出去的钱也就要不回来了。</p>
<p>现在问：按照什么顺序给企业发放贷款可以满足全部需求？</p>
<p>假设你有100亿，B企业最多借70亿，A企业最多借40亿，T企业最多借50亿。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620162845.png" alt="image.png"></p>
<p>那如果，借完第一波，A企业又想借30亿，敢借么？如果借出去的话，B或者T企业在来要钱就没了，就不能满足需求。</p>
<p>所以，按照什么顺序依次给这些企业放贷，就是“银行家问题”，得到的这个序列，就是“安全序列”。如果按照安全序列分配资源，每个进程都能顺利完成，那么系统就会处在“安全状态”。如果我们没有按照安全序列分配资源，系统就进入了“不安全状态”，就可能产生死锁问题，如果这个时候某些资源归还了资源，系统就有可能回到“安全状态”。</p>
<h3 id="4-2-2-寻找安全序列"><a href="#4-2-2-寻找安全序列" class="headerlink" title="4.2.2 寻找安全序列"></a>4.2.2 寻找安全序列</h3><p>其实很简单，就是打表然后挨个对比，假设现在有5个进程，每个进程都要申请三种资源，现在已经给他们分配了一部分：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620165403.png" alt="image.png"></p>
<p>现在还剩余（3，3，2），然后用这个和P0-P4挨个对比，看看能满足谁，就给谁分配，分配完了以后进程结束会归还之前的资源，然后重新计算剩余资源数，再去挨个对比。</p>
<p>这里，（3，3，2）可以满足P1，所以把 P1 加入安全队列，P1 使用完资源以后归还之前的资源（2，0，0）和（1，2，2），剩余资源变成（5，3，2）。然后再用（5，3，2）去挨个对比，发现P3可以满足，然后将P3放入安全队列…..一次类推。</p>
<p>手算的话可以简单一点，一上来（3，3，2）可以满足P1和P3，直接把P1和P3加入安全队列就行了，然后加上他们之前持有的资源，然后循环比对。</p>
<p>最后尽可能将所有进程都添加到安全队列中。</p>
<h3 id="4-2-3-银行家算法"><a href="#4-2-3-银行家算法" class="headerlink" title="4.2.3 银行家算法"></a>4.2.3 银行家算法</h3><p>Dijkstra为银行系统设计的一种算法，确保银行放贷的时候可以满足所有客户的需求。在操作系统上，就是提前预知系统会不会进入不安全状态，以此解决资源分配请求，这就是算法的核心思想。银行家算法代码实现的逻辑如下：</p>
<p>系统中有n个进程m种资源。</p>
<p>每个进程都需要先声明对各种资源的最大需求利郎，可以用一个 n * m 的矩阵来表示各种：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620170704.png" alt="image.png"></p>
<p>同时用 Available &#x3D; （3，3，2） 来表示当前剩余的资源量。假设 P0 现在发起请求 Req0 &#x3D; （2，1，1）也就是要申请这么多资源我们就可以这么着：</p>
<ul>
<li>判断 Req &lt;&#x3D; Need，如果不满足认为出错，不给分配资源</li>
<li>判断 Req &lt;&#x3D; Available，如果不满足说明资源紧张，当前进程等待</li>
<li>系统会试探的将资源分配给P0，根据 Available 修改 P0 的 Allocation 和 Need 矩阵。</li>
<li>系统执行安全性算法，根据当前修改寻找安全队列，判断系统是否可以进入安全状态。如果安全，则真正的将资源分配给 P0。</li>
</ul>
<p>这里所谓的安全性算法就是前面的寻找安全队列。</p>
<h2 id="4-3-死锁的检测和解除"><a href="#4-3-死锁的检测和解除" class="headerlink" title="4.3 死锁的检测和解除"></a>4.3 死锁的检测和解除</h2><h3 id="4-3-1-死锁检测"><a href="#4-3-1-死锁检测" class="headerlink" title="4.3.1 死锁检测"></a>4.3.1 死锁检测</h3><p>要检测死锁，就需要做两件事：</p>
<ul>
<li>用某种数据结构来保存资源的请求和分配信息。</li>
<li>提供一种算法，利用上述信息来检测系统是否已经进入死锁状态。</li>
</ul>
<p>数据结构如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620212656.png" alt="image.png"></p>
<p>P1 和 P2 两个进程，蓝色的箭头代表他们分别要申请什么资源。R1 和 R2 代表两种资源，里面的点代表资源个数，绿色箭头代表已经给进程分配了多少资源，注意是已经分配的。</p>
<p>然后根据图来分析，P1 进程 要申请1一个R2，R2 已经给了P2一个资源还剩一个资源，所以就可以正常分配给 P1，P1执行结束后，返还资源，也就是将 P1 连着的边全部消除。证明 P1 执行完成并释放资源。同样的方法看 P2，最后也可以消边，最终这个图里面就不存在边，只剩各个节点，则称这个图<font color='red'>可完全简化</font>。</p>
<p>如果一个图可以完全简化，那么此时一定没有发生死锁，其实就相当于我们根据这个图找到了一个安全序列。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620213210.png" alt="image.png"></p>
<p>如果是这种情况，P3 可以正常消边，P1 和 P2 根据分析发现完全没法动，则说明该图不能完全简化，那么就发生了死锁。</p>
<p><strong>具体检测方法</strong></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620213940.png" alt="image.png"></p>
<h3 id="4-3-2-死锁解除"><a href="#4-3-2-死锁解除" class="headerlink" title="4.3.2 死锁解除"></a>4.3.2 死锁解除</h3><p>根据上面的方法检测到死锁以后，如何解除？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620214029.png" alt="image.png"></p>
<p>我们再根据以下指标来判断对谁开刀：</p>
<ul>
<li>进程优先级</li>
<li>已经执行多长时间</li>
<li>还要多久完成</li>
<li>进程已经使用了多少资源</li>
<li>进程是交互式的还是批处理式的</li>
</ul>
<h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230620214230.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>13.IO核心子系统</title>
    <url>/2023/07/12/OS-13-IO%E6%A0%B8%E5%BF%83%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>前面说过，设备独立性软件、设备驱动程、中断处理程序 三个都属于OS内核部分，也就是 IO系统或者叫 IO 核心子系统。</p>
<p>我们主要需要掌握和理解的功能是：IO调度、设备保护、假脱机技术、设备分配与回、缓冲区管理。</p>
<span id="more"></span>

<p>这些功能都和硬件没有关系，所以涉及不到设备驱动程序和中断处理程序。其中 假脱机技术（SPOOLing 技术）要是用到设备独立性软件的一些功能，所以一般在用户层软件实现。剩下的 IO调度、设备保护都在设备独立性软件实现。</p>
<h1 id="1-IO调度"><a href="#1-IO调度" class="headerlink" title="1. IO调度"></a>1. IO调度</h1><p>就和其他的调度一模一样，算法都是类似的，比如磁盘有的算法：</p>
<ul>
<li>先来先服务算法</li>
<li>最短寻道优先算法</li>
<li>SCAN 算法</li>
<li>C-SCAN 算法</li>
<li>LOOK 算法</li>
<li>C-LOOK 算法</li>
</ul>
<p>IO 调度也都差不多，比如打印机等设备也可以用用先来先服务、优先级算法、短作业优先算法来确定 IO 调度顺序。</p>
<h1 id="2-设备保护"><a href="#2-设备保护" class="headerlink" title="2. 设备保护"></a>2. 设备保护</h1><p>很多操作系统会将设备看作一种特殊的文件，所以每个设备也会有对应的 FCB。当用户请求访问某个设备时，系统根据 FCB 中记录的信息来判断该用户是否有相应的访问权限，以此实现设备保护的功能。</p>
<p>细节就看文件保护的内容。</p>
<h1 id="3-假脱机技术-SPOOLing"><a href="#3-假脱机技术-SPOOLing" class="headerlink" title="3. 假脱机技术 SPOOLing"></a>3. 假脱机技术 SPOOLing</h1><h2 id="3-1-脱机技术"><a href="#3-1-脱机技术" class="headerlink" title="3.1 脱机技术"></a>3.1 脱机技术</h2><p>之前我们说过，最早的计算机需要输入纸带，计算机读取纸带的时间很长，会导致 CPU 性能浪费。所以后面在批处理阶段引入了<strong>脱机技术</strong>。</p>
<p>程序员将纸带的内容通过 <strong>外围控制机</strong> 输入到磁带中，然后计算机读取磁带。完成操作后，计算机同样将内容写回磁带，然后使用 <strong>外围控制机</strong> 将磁带中的数据打回纸带。</p>
<p>“脱机” 的意思就是，脱离主机的控制进行输入输出操作，输入输出使用 外围控制机 来实现，和计算机没有关系。</p>
<p>好处就是缓和了 CPU 和纸带的速度差。同时，如果 CPU 忙碌，外围控制机也可以先将数据读入磁带。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710211704.png" alt="image.png"></p>
<h2 id="3-2-假脱机技术"><a href="#3-2-假脱机技术" class="headerlink" title="3.2 假脱机技术"></a>3.2 假脱机技术</h2><p>就是用软件来模拟外围控制机。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710212016.png" alt="image.png"></p>
<p>这里面，输入进程用来模拟输入端的外围控制机，当 IO 设备输入数据时，输入进程会首先将数据暂存到内存的输入缓冲区中，然后将数据放到输入井中，这个输入井就可以理解成输入时的磁带。至于输入缓冲区，那是外围控制机的缓存。</p>
<p>输出也是同理，磁盘上的输出井就是输出时的磁带，要将数据输出到 IO 设备上，就需要通过输出进程将数据从输出井经过内存上的输出缓冲区，给输出设备。</p>
<h2 id="3-3-共享打印机"><a href="#3-3-共享打印机" class="headerlink" title="3.3 共享打印机"></a>3.3 共享打印机</h2><p>SPOOLing 的一个应用就是共享打印机。之前说过，这类型的 IO 设备，用户进程1 在使用的时候，用户进程2 必须阻塞，如果一块用就会导致打印出来的东西串行。可不可以实现不阻塞用户进程2，先应答进程2 的请求，等到打印机空闲的时候自动开始打印进程2 的数据。</p>
<p>使用 SPOOLing 的流程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710212811.png" alt="image.png"></p>
<p>当用户进程申请打印但是打印机正忙的时候，系统会马上答应进程请求，然后假脱机管理进程会为其做以下操作：</p>
<ul>
<li>在磁盘的输出井中为进程申请一个空闲的缓冲区（磁盘中），并将要打印的数据从用户进程放到缓冲区中。</li>
<li>为用户进程申请一张空白的打印请求表，并将用户的打印请求填入表内，再将表挂到假脱机文件队列上。</li>
</ul>
<p>这个打印请求表，里面就记录了用户要打印啥东西，这个东西存在了输出井的什么位置等信息。当打印机空闲时，输出进程会从文件队列的队头取出一张打印申请表，然后根据里面的内容，从输出井中找到打印数据，将其发送到输出缓冲区，最后送给打印机打印。</p>
<p>这样的话不管有多少个任务，系统都会马上应答，然后将任务细节挂到队列上，让输出进程依次执行。这种技术就将物理上的一个设备变为了逻辑上的多个设备。每个用户都认为自己独占着设备。</p>
<h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710213339.png" alt="image.png"></p>
<h1 id="4-设备的分配和回收"><a href="#4-设备的分配和回收" class="headerlink" title="4. 设备的分配和回收"></a>4. 设备的分配和回收</h1><h2 id="4-1-设备分配因素"><a href="#4-1-设备分配因素" class="headerlink" title="4.1 设备分配因素"></a>4.1 设备分配因素</h2><p><strong>设备固有属性</strong></p>
<p>分为三类：独占设备、共享设备、虚拟设备。</p>
<ul>
<li>独占设备：一个时间段只能分配给一个进程，比如打印机</li>
<li>共享设备：可以同时分配给多个进程使用，比如磁盘，各个进程往往是宏观上同时共享使用设备，而微观上交替使用。</li>
<li>虚拟设备：比如 SPOOLing 虚拟出来的设备，典型的虚拟打印机。</li>
</ul>
<p><strong>设备分配算法</strong></p>
<p>比如先来先服务、优先级高者优先、短任务优先 等等。这种从名字上就可以判断了。</p>
<p><strong>设备分配的安全性</strong></p>
<p>安全分配方式：为进程分配一个设备后就将进程阻塞，本次 IO 完成后才将其唤醒。比如使用打印机，按理说只需要将数据给打印机就行了，但是非得把进程阻塞，啥也不能干。优点是破坏了“请求和保持” 的条件，不会死锁；缺点是对于一个进程来说，CPU 和 IO 设备只能串行工作。</p>
<p>不安全分配方式：进程发出 IO 请求后，系统为其分配 IO 设备，进程可以继续执行，之后还可以发送新的 IO 请求。只有某个 IO 请求得不到满足时才会阻塞。有点就是计算任务 和 IO 任务可以并行处理，缺点就是有可能发生死锁（回忆死锁避免、死锁检测、死锁解除）。</p>
<h2 id="4-2-设备分配"><a href="#4-2-设备分配" class="headerlink" title="4.2 设备分配"></a>4.2 设备分配</h2><h3 id="4-2-1-静态分配-和-动态分配"><a href="#4-2-1-静态分配-和-动态分配" class="headerlink" title="4.2.1 静态分配 和 动态分配"></a>4.2.1 静态分配 和 动态分配</h3><p>静态分配就是如果进程在执行前不能为其分配所有的资源，进程就不能启动。很好理解。这种方式不会发生死锁，因为没有保持。</p>
<p>动态分配指的是进程运行过程中动态申请设备资源。</p>
<h3 id="4-2-2-设备分配管理的数据结构"><a href="#4-2-2-设备分配管理的数据结构" class="headerlink" title="4.2.2 设备分配管理的数据结构"></a>4.2.2 设备分配管理的数据结构</h3><p>一个树的结构：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710214431.png" alt="image.png"></p>
<p>系统中可能不止一个通道，每个通道管理多个控制器，每个控制器管理多个设备。</p>
<p>系统会为每个设备配置一个 <font color='red'>设备控制表 DCT</font>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710214627.png" alt="image.png"></p>
<p>说几个点：</p>
<ul>
<li>设备表示符：这个在前面一大章的设备独立性软件里面的 LUT 中说过，这个就是一个设备的唯一表示符。</li>
<li>重复执行次数：就是说IO操作失败了，比如打印机卡纸了，CPU 不会马上认为当前操作失败，而是会重新几次。</li>
<li>设备队列的队首指针：就是说如果多个进程等待这个软件，这些进程就会阻塞。系统会将这些阻塞进程的 PCB 挂到这个队列上。</li>
</ul>
<p>然后系统会给管道管理的控制器构建一个<font color='red'>控制器控制表 COCT</font>，系统根据这个表对控制器进行管理：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710215150.png" alt="image.png"></p>
<p>这些和前面大同小异不解释。</p>
<p>控制器上面还有通道，所以系统还会为每个通道构建一个 <font color='red'>通道控制表 CHCT</font>，根据这个对通道进行管理：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710215355.png" alt="image.png"></p>
<p>同时操作系统自己还管理着全部的设备，系统中有一张 <font color='red'>系统设备表 SDT</font>，记录系统中全部设备的情况，每个设备对应一个表项：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710215537.png" alt="image.png"></p>
<h3 id="4-2-3-设备分配的步骤"><a href="#4-2-3-设备分配的步骤" class="headerlink" title="4.2.3 设备分配的步骤"></a>4.2.3 设备分配的步骤</h3><ol>
<li>进程直接请求一个物理设备（也就是直接给出物理设备名），系统根据物理设备名查找 SDT，去和表项里面的设备表示符对比，找对其 DCT。</li>
<li>如果设备繁忙，则将进程的 PCB 挂到 DCT 的阻塞队列上，不忙就将其分配给进程。</li>
<li>同时根据 DCT 的 <strong>指向控制器表的指针</strong> 找到对应控制器的 COCT，重复上面的步骤，忙则挂，不忙则将控制器分配给进程。</li>
<li>然后再根据 COCT 的 <strong>指向通道表的指针</strong> 找到对应的 CHCT，同理重复操作。</li>
</ol>
<p>只有将 通道、控制器、设备 三个东西全部分配给进程的时候，才算是分配成功，然后启动 IO 设备进行数据传送。</p>
<p>这种分配思路的问题就是：</p>
<ol>
<li>用户必须使用物理设备名也就是表示符，假设明天我的键盘换了，设备标识符变了，那我写的程序就不能用了。很麻烦。</li>
<li>如果请求的物理设备繁忙，及时同类型的物理设备还有，我也必须等待阻塞。</li>
</ol>
<h3 id="4-2-4-步骤改进"><a href="#4-2-4-步骤改进" class="headerlink" title="4.2.4 步骤改进"></a>4.2.4 步骤改进</h3><p>建立逻辑设备名和物理设备名 的映射机制，用户编程时只需要提供逻辑设备名即可。</p>
<ol>
<li>根据进程请求的<font color='red'>逻辑设备名</font>查找 SDT（大部分时候这个逻辑设备名就是设备类型，比如我就是要请求键盘，啥键盘我管不着）。SDT 中每个表项都记录了该设备的类型。</li>
<li>找到一个指定类型的、空闲的设备，将其分配给该进程。然后 OS 会在<font color='red'>逻辑设备表LUT</font> 中新增一个表项。如果同类型的全部设备都繁忙则阻塞该进程。</li>
<li>然后的顺序就和之前一样了，根据这个设备的 DCT 找到 COCT，然后再找 CHCT，最后三个都分配则分配成功。</li>
</ol>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710221124.png" alt="image.png"></p>
<p>再说说 LUT：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710221248.png" alt="image.png"></p>
<p>如果 LUT 是整个系统一张的话，不同用户之间就不能使用相同逻辑设备名的设备，这问题有点大，所以适合单用户操作系统。</p>
<p>如果是多用户操作系统，那就给每个用户都分配一个 LUT 即可。</p>
<h3 id="4-2-5-总结"><a href="#4-2-5-总结" class="headerlink" title="4.2.5 总结"></a>4.2.5 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710221419.png" alt="image.png"></p>
<h1 id="5-缓冲区管理"><a href="#5-缓冲区管理" class="headerlink" title="5. 缓冲区管理"></a>5. 缓冲区管理</h1><p>缓冲区是一个存储区域，可以用专门的硬件寄存器实现，也可以用内存作为缓冲区。使用硬件的成本较高，容量也较小，一般用在对速度要求非常高的场合（比如快表）。一般情况下是利用内存作为缓冲区。“设备独立性软件” 的缓冲区管理就是要组织管理好这些缓冲区。</p>
<h2 id="5-1-缓冲区作用"><a href="#5-1-缓冲区作用" class="headerlink" title="5.1 缓冲区作用"></a>5.1 缓冲区作用</h2><p>第一：缓和 CPU 与 IO 设备之间速度不匹配的矛盾。CPU 可以将数据写入到速度快的内存中，然后 CPU 去干别的事，磁盘再从内存中慢慢拿走数据。</p>
<p>第二：减少对 CPU 的中断频率，放宽对 CPU 中断相应的时间的限制。就是说如果是字符型设备，每输入完一个字符就要向 CPU 发送一次中断信号，CPU 开销大。可以先将数据读入缓冲区。</p>
<p>第三：解决数据粒度不匹配的问题。输出进程每次可以生成一块数据，但是 IO 设备只能输出一个字符。通过缓冲区就可以解决。</p>
<p>第四：提高 IO 设备和 CPU 的并行性。</p>
<h2 id="5-2-单缓冲"><a href="#5-2-单缓冲" class="headerlink" title="5.2 单缓冲"></a>5.2 单缓冲</h2><p>某个用户进程请求某种块设备读入若干块数据。采用单缓冲策略，OS 就会在内存中为其分配一个缓冲区（如果没有明说，默认缓冲区就是一个块）。</p>
<p>当缓冲数据非空时，不能往缓冲区中冲入数据，只能从缓冲区把数据传出；当缓冲区为空时，可以忘缓冲区中冲入数据，但必须把缓冲区充满后，才能将数据读出。</p>
<p>我们一般认为内存中有两个区域，一个是用户进程的工作区，一个是进程的缓冲区，数据读入的流程是块设备将数据冲入缓冲区，然后数据从缓冲区再到工作区，最后交给 CPU 处理。所以这种时候就可以计算 处理一块数据的平均用时。</p>
<p>计算这玩意儿我们一般假定一个初始状态，分析下次到达相同状态需要多少时间，这个就是平均时间。</p>
<p>一般来说假设的初始状态是 <strong>工作区满，缓冲区空</strong>，根据 CPU 处理时间 和 块设备冲入缓冲区的时间分为两种情况：</p>
<p>第一种：T &gt; C:</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711101418.png" alt="image.png"></p>
<p>第二种：T &lt; C:</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711101513.png" alt="image.png"></p>
<p>所以平均耗时 &#x3D; MAX(C, T) + M。</p>
<h2 id="5-3-双缓冲"><a href="#5-3-双缓冲" class="headerlink" title="5.3 双缓冲"></a>5.3 双缓冲</h2><p>流程和单缓冲几乎一样，这回内存中会有两块缓冲区。这种要计算处理一块数据的平均耗时也和之前一样，找一个初始状态：工作区空，其中一个缓冲区满，另一个缓冲区空。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711101800.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711102033.png" alt="image.png"></p>
<p>所以平均耗时 &#x3D; MAX(T, C + M)</p>
<h2 id="5-4-缓冲区用于通信"><a href="#5-4-缓冲区用于通信" class="headerlink" title="5.4 缓冲区用于通信"></a>5.4 缓冲区用于通信</h2><p>两台计算机 A 和 B 要进行通信，如果采用单缓冲的策略，A 先向自己的缓冲区中写入数据，然后发送给 B，B 接收到数据缓冲区不为空，必须等到 CPU 将数据处理完成后，缓冲区为空才能向缓冲区中写入数据发送给 A。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711102416.png" alt="image.png"></p>
<p>这种方式不能实现双向传输，A 不能在发送数据的同时接收到 B 的数据。</p>
<p>如果使用双缓冲的方式，可以设置一个发送缓冲区，一个接收缓冲区，A 在往发送缓冲区中写的时候，B 也可以往自己的发送缓冲区中写，发送给 A 的接受缓冲区，然后 A 同时可以将数据发送给 B 的接受缓冲区，实现双向通讯。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711102623.png" alt="image.png"></p>
<h2 id="5-5-循环缓冲区"><a href="#5-5-循环缓冲区" class="headerlink" title="5.5 循环缓冲区"></a>5.5 循环缓冲区</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711102851.png" alt="image.png"></p>
<h2 id="5-6-缓冲池"><a href="#5-6-缓冲池" class="headerlink" title="5.6 缓冲池"></a>5.6 缓冲池</h2><p>这个东西由一大堆缓冲区组成，然后根据不同的类型构建三条不同的队列：</p>
<ul>
<li>空缓冲队列</li>
<li>装满输入数据的缓冲队列（输入队列）</li>
<li>装满输出数据的缓冲队列（输出队列）</li>
</ul>
<p>另外，根据缓冲区在实际运算中扮演的功能不同，又设置四种工作缓冲区：</p>
<ul>
<li>收容输入数据的工作缓冲区 （hin）</li>
<li>用于提取输入数据的工作缓冲区（sin）</li>
<li>用于收容输出数据的工作缓冲区（hout）</li>
<li>用于提取输出数据的共奏缓冲区（sout）</li>
</ul>
<p>工作流程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711103752.png" alt="image.png"></p>
<p>输入进程想要请求输入数据，从空缓冲队列的队头上取下来一个，放到 hin 中，设备将数据写入到这个空缓冲上，然后将空缓冲挂到 输入队列的队尾。</p>
<p>计算进程想要取得一块已经输入的数据，需要从输入队列的队头上取下来一块满了的缓冲区，放到 sin 上，将数据提取到用户进程。然后缓冲区被取空，再将其放回空缓冲队列的队尾。</p>
<p>计算进程想要将准备好的数据写入缓冲区，需要从空缓冲队列的队头取下来一个空缓冲区放到 hout 上，用户进程将数据写入到缓冲区中，然后挂到输出队列队尾。</p>
<p>输出进程请求输出数据，就从输出队列的队头取下来一块缓冲区放到 sout 上，将数据提取到设备中，然后缓冲区空了，挂回空缓冲队列队尾。</p>
<h2 id="5-7-总结"><a href="#5-7-总结" class="headerlink" title="5.7 总结"></a>5.7 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711103916.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>10.文件管理</title>
    <url>/2023/07/02/OS-10-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>操作系统如何管理文件。</p>
<span id="more"></span>

<h1 id="1-文件管理概念"><a href="#1-文件管理概念" class="headerlink" title="1. 文件管理概念"></a>1. 文件管理概念</h1><h2 id="1-1-操作系统向上提供的功能"><a href="#1-1-操作系统向上提供的功能" class="headerlink" title="1.1 操作系统向上提供的功能"></a>1.1 操作系统向上提供的功能</h2><p>我们要创建一个文件，操作系统会给我们提供 <strong>create</strong> 系统调用，然后我们用记事本读取文件使用到了 <strong>read</strong> 系统调用。当我们修改文件后，将文件保存到磁盘中，会使用到 <strong>write</strong> 系统调用。最终我们删除文件，使用了 <strong>delete</strong> 系统调用。</p>
<p>除此之外，我们打开文件和关闭文件还需要用到 <strong>open</strong> 和 <strong>close</strong> 系统调用，这个在上一章最后也说过一点。</p>
<h2 id="1-2-文件如何存放在外存"><a href="#1-2-文件如何存放在外存" class="headerlink" title="1.2 文件如何存放在外存"></a>1.2 文件如何存放在外存</h2><p>磁盘和内存很像，磁盘也是由一个个存储单元组成，每个存储单元可以存储一定量的数据，比如一个字节，每个存储单元都对应一个物理地址。</p>
<p>内存中，会将一定量的存储单元分页，磁盘中也会分为一个个“块&#x2F;磁盘块&#x2F;物理块”，每个块的大小相等，每块一般包含2的整数幂个地址。文件的地址也可以分为逻辑块号，块内地址，操作系统需要将逻辑块号转变为物理地址的形式。</p>
<p>操作系统以“块”为单位给文件分配存储空间，即便一个文件只有1B，操作系统也会给他分配1K的块。同时外存中的数据读入内存同样是以块为单位。</p>
<p>一个文件在磁盘中，是连续存放，还是离散存放，这个往后会说。</p>
<h2 id="1-3-总结"><a href="#1-3-总结" class="headerlink" title="1.3 总结"></a>1.3 总结</h2><p>其实还有点别的内容，只是没啥用，很简单，就没记，直接看图就得了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630150838.png" alt="image.png"></p>
<h1 id="2-文件的逻辑结构"><a href="#2-文件的逻辑结构" class="headerlink" title="2. 文件的逻辑结构"></a>2. 文件的逻辑结构</h1><p>这个类似数据结构的逻辑结构和物理结构，比如一个线性表，就是一个逻辑结构，只要有前后关系就是线性表。但是如果我们使用链表来实现，则各个元素在物理上不相连，无法实现随机访问。而使用顺序表，则可以实现随机访问。</p>
<p>文件的逻辑结构指的就是，在用户看来，文件内部的数据应该是如何组织起来的。而物理结构指的就是在操作系统看来，文件的数据应该如何存放在外存。</p>
<p>文件的逻辑结构大致分为两类：无结构文件、有结构文件。</p>
<h2 id="2-1-无结构文件"><a href="#2-1-无结构文件" class="headerlink" title="2.1 无结构文件"></a>2.1 无结构文件</h2><p>这个很好理解，就是文件里面的数据没有明显的结构，就是一系列二进制或者字符流组成，也叫”流式文件“，典型的就是 Windows 系统下的 txt 文件。</p>
<h2 id="2-2-有结构文件"><a href="#2-2-有结构文件" class="headerlink" title="2.2 有结构文件"></a>2.2 有结构文件</h2><p>这个就是说文件里面的内容是由一条条记录构成的，也叫“记录式文件”，比较典型的就是数据库表，就是一种结构。一般来说，每条记录有一个数据项可以作为<strong>关键字</strong>，比如数据库的主键。</p>
<p>再根据里面记录的数据项长度是否固定，又分为定长记录和可变长记录</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630152210.png" alt="image.png"></p>
<p>有结构文件在逻辑上如何组织？可以分为三类：顺序文件、索引文件、索引顺序文件。</p>
<h3 id="2-2-1-顺序文件"><a href="#2-2-1-顺序文件" class="headerlink" title="2.2.1 顺序文件"></a>2.2.1 顺序文件</h3><p>文件的记录一条一条的顺序排列（逻辑上），记录可以是定长的或者是可变长的。各个记录在物理上可以是<strong>顺序存储</strong>或者是<strong>链式存储</strong>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630152515.png" alt="image.png"></p>
<p>如果按照记录的排列顺序，也可以将顺序文件分为两类：</p>
<ul>
<li>串结构：记录之间的顺序和关键字无关，比如可以按照记录的插入时间来排序</li>
<li>顺序结构：记录之间的顺序按照关键字的顺序排列</li>
</ul>
<p>然后思考两个问题：不同的存储方式是否可以实现随机存取？是否可以根据关键字快速查找到记录？</p>
<p>直接看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630152947.png" alt="image.png"></p>
<p>为啥可变长记录按照顺序存储依旧不能随机存取？因为可变长记录的开头可能会记录该记录的具体长度，比如2个字节。每一条记录的长度不固定，就不能随机存取。</p>
<p>注意：链式存储很少用，考题中如果说到了“顺序文件”指的就是<font color='red'>物理上顺序存储的顺序文件</font>。往后我们默认也是如此。</p>
<p>顺序文件的缺点就是修改插入文件比较困难，如果是串结构的话还好，直接追加在末尾就行了。</p>
<h3 id="2-2-2-索引文件"><a href="#2-2-2-索引文件" class="headerlink" title="2.2.2 索引文件"></a>2.2.2 索引文件</h3><p>就是给所有的记录构建一张索引表，看图就明白了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630153824.png" alt="image.png"></p>
<p>索引表本身是一个定长记录的顺序文件，因此可以快速找到第i个记录对应的索引项。</p>
<p>可以将记录的关键字作为索引号内容，如果按照关键字排列，还可以支持按照关键字折半查找，效率很高。每当要增加或删除一个记录，需要对索引表进行修改。由于索引文件有很快的检索速度，因此适用于对信息处理及时性要求比较高的场合。</p>
<p>同时，我们可以根据不同的数据项为数据文件建立不同的索引表。</p>
<h3 id="2-2-3-索引顺序文件"><a href="#2-2-3-索引顺序文件" class="headerlink" title="2.2.3 索引顺序文件"></a>2.2.3 索引顺序文件</h3><p>这个东西就有 B+Tree那味了。如果一条记录只有8B，而一条索引却有10B，那索引文件比数据文件还大，这就不合适了。</p>
<p>可以将数据分组，然后索引文件中记录每组的第一条记录的关键字，然后索引指向这一组的地址。查找的话只需要进入这一组之后再找即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630154727.png" alt="image.png"></p>
<p>加入一个记录文件（不是定长记录、顺序结构的顺序文件）有10000条记录，按照这种100-100 分组，首先在索引文件中顺序查找，平均50次得到分组，然后进入分组后，平均查找50次得到记录。要比直接10000记录顺序查找快得多。</p>
<h3 id="2-2-4-多级索引表"><a href="#2-2-4-多级索引表" class="headerlink" title="2.2.4 多级索引表"></a>2.2.4 多级索引表</h3><p>如果数据特别多，就算是分组索引表里面的数据也多的离谱，我们就可以给索引表在分组，然后给索引表建立一个顶级索引表：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630155204.png" alt="image.png"></p>
<p>比如有10^6条记录，按照100-100-100分组，平均只需要查找150次即可得到结果。</p>
<h2 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630155359.png" alt="image.png"></p>
<h1 id="3-文件目录"><a href="#3-文件目录" class="headerlink" title="3. 文件目录"></a>3. 文件目录</h1><p>其实就是Windows里面的文件夹。</p>
<h2 id="3-1-文件控制块"><a href="#3-1-文件控制块" class="headerlink" title="3.1 文件控制块"></a>3.1 文件控制块</h2><p>目录本身也是一种文件，里面记录了这个目录中所有文件的信息，比如现在D盘根目录的目录文件张这样：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630155739.png" alt="image.png"></p>
<p>目录本身就是一种有结构文件，由一条条记录组成。每条记录对应一个目录下的文件。</p>
<p>加入我们这里双击“照片”，操作系统干的事就是：从这个目录表中找到关键字“照片”对应的目录项，从外存中将该目录的信息读入内存，然后就可以显示照片里面的内容了。然后照片的目录文件：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630160315.png" alt="image.png"></p>
<p>FCB的有序集合成文“文件目录”（可别跟目录文件搞混了），一个FCB就是一个文件目录项。FCB中包含了文件的基本信息（文件名、物理地址、逻辑结构、物理结构等），存取控制信息（是否可读、科协，用户黑名单等），实用信息（文件的建立时间、修改时间等）。其中最重要的还是文件名、文件存放的物理地址。</p>
<p>FCB 实现了文件名和文件之间的映射。也就是建立了文件名和物理地址之间的关系。使用户可以实现“按名存取”。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630222347.png" alt="image.png"></p>
<h2 id="3-2-目录结构"><a href="#3-2-目录结构" class="headerlink" title="3.2 目录结构"></a>3.2 目录结构</h2><h3 id="3-2-1-单级目录结构"><a href="#3-2-1-单级目录结构" class="headerlink" title="3.2.1 单级目录结构"></a>3.2.1 单级目录结构</h3><p>早起的操作系统不支持多级目录，整个OS只会建立一张目录表，每个文件占用一个目录项。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630222630.png" alt="image.png"></p>
<p>单级目录实现了“按名存取”，FCB中也存储了文件名，但是不允许文件重名。创建一个文件时，首先检查是否重名，然后新建文件，并将新文件对应的目录项插入目录表中。</p>
<p>这种方式显然不适合多用户操作系统。</p>
<h3 id="3-2-2-两级目录结构"><a href="#3-2-2-两级目录结构" class="headerlink" title="3.2.2 两级目录结构"></a>3.2.2 两级目录结构</h3><p>为了解决多用户的问题，一个OS只有两级目录，分为主文件目录（MFD）和用户文件目录（UFD）。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630222843.png" alt="image.png"></p>
<h3 id="3-2-3-多级目录结构"><a href="#3-2-3-多级目录结构" class="headerlink" title="3.2.3 多级目录结构"></a>3.2.3 多级目录结构</h3><p>也叫树形目录结构，是目前常用的目录结构，解决了上面用户不能自己给文件分类的问题。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630223039.png" alt="image.png"></p>
<p>用户要访问某个文件时要用文件的绝对路径，这个不多说了，比如 <code>/照片/2015-08/自拍.jpg</code>，系统根据绝对路径一层一层找到下一级目录，刚开始从外存中读入跟目录的目录表；找到“照片”目录的存放位置后，从外存读入对应的目录表；在找到 2015-08 目录的存放位置，同理读入目录表，最后找到文件。整个过程需要三次IO。</p>
<p>如果我们已经打开了“照片”的目录文件，也就是这张目录表已经调入内存，那么可以将它设置为“当前目录”。用户想要访问一个文件时，也可以使用从当前目录出发的“相对路径”。</p>
<p>这种文件结构很方便的对文件进行分类，层次清晰，也能很有效的进行文件的管理和保护。但是树形结构<font color='red'>不便于实现文件的共享</font>。因此提出了“无环图目录结构”。</p>
<h3 id="3-2-4-无环图目录结构"><a href="#3-2-4-无环图目录结构" class="headerlink" title="3.2.4 无环图目录结构"></a>3.2.4 无环图目录结构</h3><p>其实很简单，就是在多级目录的基础上，多个用户中的文件可以指向一个同一个文件甚至目录，这就实现了共享。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630223805.png" alt="image.png"></p>
<p>这样的话删除文件就不能像之前那么简单了，需要给每个共享节点设置一个<font color='red'>共享计数器</font>，用于记录此时有多少个地方在共享节点。用户提出删除文件请求时，只是会删除该用户的FCB，并使共享计数器-1，并不会直接删除。</p>
<p>这种不同于数据复制，一个用户修改了共享节点，其他用户也可以看到变化。</p>
<h2 id="3-3-索引结点"><a href="#3-3-索引结点" class="headerlink" title="3.3 索引结点"></a>3.3 索引结点</h2><p>这是一种对 FCB 的改进，我们查找一个文件的过程中实际上只需要用到“文件名”这一个属性，只有这个属性命中以后我们才需要关心这个文件的其他信息，比如权限信息等等。</p>
<p>可以将除文件名以外的所有信息打包成一个索引结点，然后目录文件中只存储文件名和索引结点的指针，每个文件&#x2F;目录都只对应一个索引结点。当文件名命中后，才会去索引结点中检查其他信息。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630224359.png" alt="image.png"></p>
<p>这样的好处就是减少了目录文件的开销，一个磁盘块可以存储更多的目录项，查找文件时加载的磁盘块更少。</p>
<p>当找到文件名对应的目录项时，才需要将索引结点调入内存，然后根据结点的其他具体信息找到文件。存放在外存中的索引结点称为<font color='red'>“磁盘索引结点”</font>，当索引放入内存后称为<font color='red'>“内存索引结点”</font>，相比之下内存索引结点需要增加一些信息，比如文件是否被修改，此时有多少进程正在访问。</p>
<h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630224928.png" alt="image.png"></p>
<h1 id="4-文件的物理结构"><a href="#4-文件的物理结构" class="headerlink" title="4. 文件的物理结构"></a>4. 文件的物理结构</h1><p>操作系统需要对磁盘块进行哪些管理：</p>
<ul>
<li>对非空闲磁盘块的管理（文件的物理结构&#x2F;文件分配方式）</li>
<li>对空闲磁盘块的管理（文件存储空间管理）</li>
</ul>
<p>这一大章说的就是第一个问题：文件的物理结构&#x2F;文件分配方式，也就是文件数据应该咋放到外存中。文件分配方式主要是三种：连续分配、链接分配（又分为隐式链接、显式链接）、索引分配。</p>
<h2 id="4-1-文件块、磁盘块"><a href="#4-1-文件块、磁盘块" class="headerlink" title="4.1 文件块、磁盘块"></a>4.1 文件块、磁盘块</h2><p>再说一下这个，我们之前说过，磁盘里面也会分为一个个大小相等的磁盘块，很多操作系统中把磁盘块的大小和内存块的大小设计成一样的，因为将磁盘数据调入内存是以块为单位，这么做会很方便。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630230129.png" alt="image.png"></p>
<h2 id="4-2-连续分配"><a href="#4-2-连续分配" class="headerlink" title="4.2 连续分配"></a>4.2 连续分配</h2><p>这种分配方式要求每个文件在磁盘上占有一组连续的块，也就是逻辑上相邻的块在物理上也相邻。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630230339.png" alt="image.png"></p>
<p>这种分配方式下如何实现地址转换，实现（逻辑块号，块内地址）-&gt; （物理块号，块内地址）？其实很简单，既然各个磁盘块相邻，我们只需要知道逻辑块0对应的物理块号即可，然后我们访问 起始块号+逻辑块号 即可访问。比如我们要访问逻辑块号2，只需要起始地址4+逻辑块号2，即可得到物理块号6，然后去6号磁盘块访问块内地址即可。</p>
<p>这样的话文件FCB如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630230632.png" alt="image.png"></p>
<p>操作系统还是会检查一下用户提供的逻辑块号是否合法（逻辑块号&gt;&#x3D;长度则不合法）。所以说顺序分配支持顺序访问（想要访问逻辑块2，必须要从0号块开始访问）和直接访问（随机访问，就是说我们想要访问逻辑块2，不需要从0号块开始）。</p>
<h3 id="4-2-1-优点"><a href="#4-2-1-优点" class="headerlink" title="4.2.1 优点"></a>4.2.1 优点</h3><p>优点就是顺序分配读取文件的速度最快，因为磁盘是有磁头的，想要读取某些块必须让磁头扫描，连续的块距离最近，所以扫描速度最快。</p>
<p>同时顺序分配支持顺序访问和直接访问。</p>
<h3 id="4-2-2-缺点"><a href="#4-2-2-缺点" class="headerlink" title="4.2.2 缺点"></a>4.2.2 缺点</h3><p><strong>文件拓展开销更大</strong></p>
<p>一个文件本来占用三个磁盘块，然后文件变大了，需要四个磁盘块，就需要将原本的三个磁盘块复制到另一片连续的四个磁盘块上，这个开销比较大。</p>
<p><strong>产生难以分配的磁盘碎片</strong></p>
<p>这个和之前的内存差不多，一些零散的磁盘碎片很难被利用，造成空间浪费。可以通过紧凑的方式来处理，但是这个会有很大的代价。</p>
<h2 id="4-3-链接分配"><a href="#4-3-链接分配" class="headerlink" title="4.3 链接分配"></a>4.3 链接分配</h2><p>这种方式就和链表一样，每个磁盘块都相连，这种分配方式又分出两种：隐式链接、显式链接。如果题目中说到了链接分配，<font color='red'>默认指的是隐式链接的分配方式</font>。</p>
<h3 id="4-3-1-隐式链接"><a href="#4-3-1-隐式链接" class="headerlink" title="4.3.1 隐式链接"></a>4.3.1 隐式链接</h3><p>文件的每个块内部有一个指针指向下一个块，不需要我们显式的指定。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630233435.png" alt="image.png"></p>
<p>用户要访问23号块，系统就会读入文件的 FCB，找到起始块号9，将9号块读入内存，然后顺着指针找到2号块，然后将其读入内存，以此类推，最终找到23号磁盘块。</p>
<p>因此，要访问 i号块，就需要i+1次磁盘IO操作，这种方式只支持顺序访问，不支持随机访问，所以查找效率低，另外指向下一块的指针也需要耗费少量的存储空间。</p>
<p>如果要对文件进行拓展就很方便了，随便在磁盘中找一个空闲块，然后连到文件的结束块后面，并修改文件的 FCB。所有的空闲磁盘块都可以利用起来，外存利用率高。</p>
<h3 id="4-3-2-显式链接"><a href="#4-3-2-显式链接" class="headerlink" title="4.3.2 显式链接"></a>4.3.2 显式链接</h3><p>系统会使用一张表，将指向下一块的指针显示的记录在<font color='red'>文件分配表</font>中，也就是 FAT。假如有个新文件 aaa，一次存放的磁盘块 <code>2 -&gt; 5 -&gt; 0 -&gt; 1</code>，则FAT如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230630234107.png" alt="image.png"></p>
<p>一个磁盘设置一张 FAT 即可，开机时，将 FAT 读入内存，并常驻内存。FAT 的各个表项在物理上连续存储，且每个表项长度相同，因此“物理块号”字段可以省略。</p>
<p><strong>如何地址转换</strong></p>
<p>我们想要访问i号块，其实和之前差不多，OS找到该文件的 FCB，得到了文件的起始块号，然后拿着块号去 FAT 中找，然后顺着链表顺序一直找到 i 号块。因为 FAT 常驻内存，所以这个过程不需要读磁盘。</p>
<p>所以这种方式支持顺序访问，也支持随机访问，可以直接通过 FAT 找到第i号块，由于块号转换过程中不需要访问磁盘，所以速度要比隐式链接快很多。</p>
<p>这种方式的缺点就是 FAT 也需要占用一定的存储空间。</p>
<h2 id="4-4-索引分配"><a href="#4-4-索引分配" class="headerlink" title="4.4 索引分配"></a>4.4 索引分配</h2><p>这种方式类似之前的页表，操作系统为每个文件都建立了一个逻辑块号到物理块号的索引表，索引表也会存储在外存中，索引表存放的磁盘块称为索引块，文件数据存放的磁盘块称为数据块。</p>
<p>假设某个文件 aaa 的数据依次存放在 <code>2 -&gt; 5 -&gt; 13 -&gt; 9</code> 四个磁盘块中，7号磁盘块作为aaa文件的索引块，索引块中保存了索引表的内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701110507.png" alt="image.png"></p>
<p>注意：对比显示链接分配，显示链接分配的 FAT 是真个磁盘只有一个，而这种一个文件就对应一个索引表。</p>
<p>同理，索引表的逻辑块号一列可以省略，假设一个磁盘 1TB，也就是 2^40 B，磁盘块大小为 1KB，则总共有 2^30 个磁盘块，则可以用 2^32 也就是 4B 来表示磁盘块号，故索引表的一个表项是 4B。</p>
<h3 id="4-4-1-如何地址转换"><a href="#4-4-1-如何地址转换" class="headerlink" title="4.4.1 如何地址转换"></a>4.4.1 如何地址转换</h3><p>操作系统根据文件的 FCB 找到文件的索引块，然后根据索引块找到第i号逻辑块对应的磁盘块，然后将磁盘块调入内存即可。</p>
<p>这种分配方式支持随机访问，文件扩展也很容易实现，只需要给文件分配一个空闲块，并增加一个索引表表项即可。只不过索引表自己也要占用点空间。</p>
<h3 id="4-4-2-索引分配-链接方案"><a href="#4-4-2-索引分配-链接方案" class="headerlink" title="4.4.2 索引分配-链接方案"></a>4.4.2 索引分配-链接方案</h3><p>假设根据之前说的一个索引表的表项占用4B，一个磁盘块1KB，则一个磁盘块只能存储256个索引项，如果索引表的大小超过了256，一个块存不下索引表了，咋办？</p>
<p>链接方案指的就是，将多个索引块链接起来存放，索引块内会存储指向下一个索引块的指针，FCB 中只需要记录第一个索引块即可。类似之前的隐式链接分配。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701111623.png" alt="image.png"></p>
<p>文件查找的话就需要从第一个索引块开始依次往后找，显然很低效。</p>
<h3 id="4-4-3-索引分配-多集索引"><a href="#4-4-3-索引分配-多集索引" class="headerlink" title="4.4.3 索引分配-多集索引"></a>4.4.3 索引分配-多集索引</h3><p>和多级页表十分的相似，第一层索引块指向第二层索引块，还可以根据文件的大小要求再建立第三层甚至第四层。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701112015.png" alt="image.png"></p>
<p>采用 K层索引结构，且顶级索引表未调入内存，则访问一个数据块只需要 K+1 次读磁盘操作。</p>
<p>注：这里计算文件的最大长度得会算。</p>
<h3 id="4-4-4-索引分配-混合索引"><a href="#4-4-4-索引分配-混合索引" class="headerlink" title="4.4.4 索引分配-混合索引"></a>4.4.4 索引分配-混合索引</h3><p>顶级索引表中，即包含直接地址索引（直接指向数据块），又包含一级间接索引（指向单层索引表）、还包含了两级间接索引（指向两层索引表）。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701112354.png" alt="image.png"></p>
<h3 id="4-4-5-总结"><a href="#4-4-5-总结" class="headerlink" title="4.4.5 总结"></a>4.4.5 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701114018.png" alt="image.png"></p>
<h2 id="4-5-总结"><a href="#4-5-总结" class="headerlink" title="4.5 总结"></a>4.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701114117.png" alt="image.png"></p>
<h1 id="5-逻辑结构-VS-物理结构"><a href="#5-逻辑结构-VS-物理结构" class="headerlink" title="5. 逻辑结构 VS 物理结构"></a>5. 逻辑结构 VS 物理结构</h1><p>用 C 语言的例子来解释下啥是逻辑结构，啥是物理结构。</p>
<h2 id="5-1-流式文件"><a href="#5-1-流式文件" class="headerlink" title="5.1 流式文件"></a>5.1 流式文件</h2><p>我们现在用 C 语言写一个程序，创建一个 test.txt 文件，往里面写入 10000个 helloworld，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">FILE *fp = fopen(<span class="string">&quot;test.txt&quot;</span>, <span class="string">&quot;w&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++)&#123;</span><br><span class="line">	<span class="built_in">fputs</span>(<span class="string">&quot;hello world!&quot;</span>, fp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fclose(fp);</span><br></pre></td></tr></table></figure>

<p>这段代码就会往文件里面写入10000个helloworld，在我们看来，这些helloworld顺序存放，我们可以按照顺序访问到某个字节，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">FILE *fp = fopen(<span class="string">&quot;test.txt&quot;</span>, <span class="string">&quot;r&quot;</span>);</span><br><span class="line"></span><br><span class="line">fseek(fp, <span class="number">16</span>, SEEK_SET); <span class="comment">// 将文件指针移动到第16个字节的位置</span></span><br><span class="line"><span class="type">char</span> c = fgetc(fp);      <span class="comment">// 获取当前文件指针的字节</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, c);</span><br><span class="line">fclose(fp);</span><br></pre></td></tr></table></figure>

<p>也就是说，按照逻辑结构，我们认为第16个位置就是那个字符，每个字符顺序存放。</p>
<p>然而操作系统视角如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701120446.png" alt="image.png"></p>
<p>也就是说我们指定的 16 这个位置起始就是文件的逻辑地址，读取这个位置时使用系统调用 Read，操作系统会根据逻辑地址访问相应的物理地址，然后读取到具体的数据。这个文件的物理结构可能是顺序的，也有可能是索引结构的。</p>
<h2 id="5-2-顺序文件"><a href="#5-2-顺序文件" class="headerlink" title="5.2 顺序文件"></a>5.2 顺序文件</h2><p>我们创建一个 Student 结构体，然后将结构体数组存储到文件中，也就生成了一个顺序文件：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">typeof <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">	<span class="type">int</span> number;</span><br><span class="line">	<span class="type">char</span> name[<span class="number">30</span>];</span><br><span class="line">	<span class="type">char</span> major[<span class="number">30</span>];</span><br><span class="line">&#125; Student_info;   <span class="comment">// sizeof(Student_info) = 64B</span></span><br><span class="line"></span><br><span class="line">FILE *fp = fopen(<span class="string">&quot;students.info&quot;</span>, <span class="string">&quot;w&quot;</span>);</span><br><span class="line"></span><br><span class="line">Student_info student[N];</span><br><span class="line"></span><br><span class="line"><span class="comment">// ... 省略填充数组过程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入，具体数据是这个数组，每一项 sizeof 长度，总共 N 项，往 fp 里面写</span></span><br><span class="line">fwrite(student, <span class="keyword">sizeof</span>(Student_info), N, fp);</span><br><span class="line">fclose(fp);</span><br></pre></td></tr></table></figure>

<p>然后我们想要读取第6个学生的数据：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">FILE *fp = fopen(<span class="string">&quot;students.info&quot;</span>, <span class="string">&quot;r&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将文件指针移到第六个学生开头，也就是前面有 5 * sizeof(Student_info) 长度</span></span><br><span class="line">fseek(fp, <span class="number">5</span> * <span class="keyword">sizeof</span>(Student_info), SEEK_SET);</span><br><span class="line"></span><br><span class="line">Student_info stu;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从文件指针开始，往后读取 1 项 sizeof(Student_info) 长度数据，填充到 stu 中</span></span><br><span class="line">fread(&amp;stu, <span class="keyword">sizeof</span>(Student_info), <span class="number">1</span>, fp);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;stu number: %d&quot;</span>, stu.number);</span><br><span class="line">fclose(fp);</span><br></pre></td></tr></table></figure>

<p>这个逻辑结构很清晰，存的时候顺序存，取得时候跳过前面的数据取一定长度，起码在我们用户的角度，我们认为这个文件是连续的。</p>
<p>同理在物理上文件不一定是连续存储的，我们给出了逻辑地址，操作系统会去对应的物理地址上访问数据。</p>
<p>如果在此基础上，我们让 Student_info 数组变为链表，也就是之前说的顺序存储中的链式存储，给 Student_info 里面添加一个数组下标代表下一个指向的信息，物理上不会变的。</p>
<p>区分：</p>
<ul>
<li>链式存储：逻辑上的概念，各个数据项之间有前后关系，但是具体到物理上可不一定是链式的</li>
<li>链接分配：物理上的概念，操作系统负责将各个磁盘块链接起来，不代表数据本来是链表，文件仍然有可能是流式文件。</li>
</ul>
<h2 id="5-3-总结"><a href="#5-3-总结" class="headerlink" title="5.3 总结"></a>5.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701122520.png" alt="image.png"></p>
<h1 id="6-文件存储空间管理"><a href="#6-文件存储空间管理" class="headerlink" title="6. 文件存储空间管理"></a>6. 文件存储空间管理</h1><p>第四章主要说的是操作系统对非空闲磁盘块的管理，这一章就是操作系统对空闲磁盘块的管理。</p>
<h2 id="6-1-存储空间的划分与初始化"><a href="#6-1-存储空间的划分与初始化" class="headerlink" title="6.1 存储空间的划分与初始化"></a>6.1 存储空间的划分与初始化</h2><p>拿到一块磁盘后，我们首先要给磁盘分区，比如 C盘 D盘这种，这种就是将一个物理磁盘划分为一个个<font color='red'>文件卷</font>（逻辑卷、逻辑盘）。存储空间会进行初始化，将各个文件卷划分为目录区、文件区。</p>
<p>目录区主要存放文件目录信息（FCB）、用于磁盘存储空间管理的信息。文件区自然就是用户存放文件。</p>
<p>有的系统支持超大型文件，可以支持由多个物理磁盘组成一个文件卷。</p>
<h2 id="6-2-管理方法"><a href="#6-2-管理方法" class="headerlink" title="6.2 管理方法"></a>6.2 管理方法</h2><p>主要就是理解三个问题：</p>
<ul>
<li>用什么方式记录、组织空闲块</li>
<li>如何分配磁盘块</li>
<li>如何回收磁盘块</li>
</ul>
<h3 id="6-2-1-空闲表法"><a href="#6-2-1-空闲表法" class="headerlink" title="6.2.1 空闲表法"></a>6.2.1 空闲表法</h3><p>这种适用于“连续分配”方式。给磁盘建立一张空闲表，里面记录第一个空闲块号和与之相连的空闲块的个数（包括第一个）。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701124650.png" alt="image.png"></p>
<p>这里的首次适应、最佳适应、最坏适应都在之前遇到过，这里再提一句：</p>
<ul>
<li>首次适应：根据空闲表，找到第一个合适的空闲区直接分配</li>
<li>最佳适应：从小到大排序，分配最小的空闲空间</li>
<li>最坏适应：从大到小排序，分配最大的空闲空间</li>
</ul>
<p>回收的话和之前的页表也是一样的，要考虑回收后空闲表是新增还是扩充某一项。很简单，不说了。</p>
<h3 id="6-2-2-空闲链表法"><a href="#6-2-2-空闲链表法" class="headerlink" title="6.2.2 空闲链表法"></a>6.2.2 空闲链表法</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701154245.png" alt="image.png"></p>
<p>分配与回收：</p>
<p>空闲盘块链：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701155755.png" alt="image.png"></p>
<p>空闲盘区链：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701155926.png" alt="image.png"></p>
<h3 id="6-2-3-位示意图"><a href="#6-2-3-位示意图" class="headerlink" title="6.2.3 位示意图"></a>6.2.3 位示意图</h3><p>最常考的一种方法，就是用一张二进制位表来表示磁盘块是否空闲。这个表的行叫字号，列叫位号，就可以通过（字号，位号）推出具体的磁盘块号。这个事需要重点掌握的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701160451.png" alt="image.png"></p>
<p>如果字号和位号都是从0开始，那么 （i，j）对应的磁盘块号&#x3D; ni + j（n是位长度）。b号盘块对应的字号 i &#x3D; b &#x2F; n，位号 j &#x3D; b % n。</p>
<p>字号位号从1开始的话得改一下了，不多说了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701160754.png" alt="image.png"></p>
<p>这种方式连续分配和离散分配都适用。</p>
<h3 id="6-2-4-成组链接法"><a href="#6-2-4-成组链接法" class="headerlink" title="6.2.4 成组链接法"></a>6.2.4 成组链接法</h3><p>空闲表法、空闲链表法不适用于大型文件系统，因为空闲表和空闲链表可能过大。UNIX 系统采用了成组链接法对磁盘空闲块进行管理。</p>
<p><strong>文件卷的目录区</strong>中专门用一个磁盘块作为<font color='red'>超级块</font>，当系统启动时需要将超级块读入内存，并保证内存中的和外存中的数据一致。</p>
<h2 id="6-3-总结"><a href="#6-3-总结" class="headerlink" title="6.3 总结"></a>6.3 总结</h2><p> <img src="https://gitee.com/pthef/imgrepo/raw/master/20230701162632.png" alt="image.png"></p>
<h1 id="7-文件的基本操作"><a href="#7-文件的基本操作" class="headerlink" title="7. 文件的基本操作"></a>7. 文件的基本操作</h1><p>操作系统向上提供的几种基本功能（系统调用）：</p>
<ul>
<li>创建文件 create 系统调用</li>
<li>删除文件 delete 系统调用</li>
<li>读文件 read 系统调用</li>
<li>写文件 write 系统调用</li>
<li>打开文件 open 系统调用</li>
<li>关闭文件 close 系统调用</li>
</ul>
<h2 id="7-1-创建文件"><a href="#7-1-创建文件" class="headerlink" title="7.1 创建文件"></a>7.1 创建文件</h2><p>在电脑中新建一个文件，背后就调用了 “create系统调用”。进行 create 系统调用时，需要提供的几个主要参数：</p>
<ul>
<li>所需要分配的外存空间大小，比如分配一个盘块 1KB。</li>
<li>文件存放路径，比如 D:&#x2F;demo</li>
<li>文件名</li>
</ul>
<p>操作系统进行 create 时，主要做了两件事：</p>
<ul>
<li>外存中找到文件所需的空间，使用上面说到的各个方法找到空闲空间</li>
<li>根据文件存放路径的信息找到该目录对应的目录文件，在目录中创建该文件对应的目录项。</li>
</ul>
<h2 id="7-2-删除文件"><a href="#7-2-删除文件" class="headerlink" title="7.2 删除文件"></a>7.2 删除文件</h2><p>我们在系统中删除文件，背后就调用了 “delete系统调用”。调用delete需要两个参数：</p>
<ul>
<li>文件存放路径</li>
<li>文件名</li>
</ul>
<p>操作系统在 Delete 时，主要做了两件事：</p>
<ul>
<li>根据文件存放路径找到对应的目录文件，从目录文件中找到该文件名对应的目录项也就是 FCB。</li>
<li>根据目录项纪录的文件信息，比如在外存中的存放位置、文件大小等，回收文件占用的磁盘块，根据前面分配的方式进行回收。</li>
<li>删除目录文件中的目录项</li>
</ul>
<h2 id="7-3-打开文件"><a href="#7-3-打开文件" class="headerlink" title="7.3 打开文件"></a>7.3 打开文件</h2><p>在很多操作系统中，对文件操作之前要求用户先使用 open 系统调用“打开文件”，需要提供三个参数；</p>
<ul>
<li>文件存放路径</li>
<li>文件名</li>
<li>要对文件的操作类型，比如 r-只读，rw-读写</li>
</ul>
<p>操作系统处理 open 系统调用时，主要做了几件事：</p>
<ul>
<li>根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项，并检查该用户是否有指定的操作权限。</li>
<li>内存中会有一个<font color='red'>打开文件表</font>，这个表用于记录OS中所有被打开的文件状态，检查完了以后会将该文件对应的 FCB 复制到打开文件表，并将对应表目的编号返回给用户。之后用户使用打开文件表的编号来指明要操作的文件。这样后面操作文件就不需要重新查目录了，加快访问速度。</li>
</ul>
<h3 id="7-3-1-打开文件表"><a href="#7-3-1-打开文件表" class="headerlink" title="7.3.1 打开文件表"></a>7.3.1 打开文件表</h3><p>每个用户进程都会有自己的一个打开文件表，OS自己还有一个打开文件表，整个系统只有一个。如果两个用户都打开了一个文件，两个用户的打开文件表都会指向系统打开文件表的同一项。所以系统的打开文件表里面还有一个字段：打开计数器，记录当前有多少个用户进程打开了文件。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701164705.png" alt="image.png"></p>
<p>用户进程的打开文件表里面还有两个比较特殊的字段：</p>
<ul>
<li>读写指针：记录当前用户进程的文件指针在哪个位置</li>
<li>访问权限：每个用户进程打开文件时的权限不一定一样，所以这个字段就放在了用户的打开文件表中。</li>
</ul>
<h2 id="7-4-关闭文件"><a href="#7-4-关闭文件" class="headerlink" title="7.4 关闭文件"></a>7.4 关闭文件</h2><p>进程使用完文件以后要关闭文件，OS处理 Close 系统调用时做了如下事情：</p>
<ul>
<li>将进程的打开文件表相应表项删除</li>
<li>回收分配给该文件的内存空间等资源</li>
<li>系统打开文件表的打开计数器 - 1，如果减到0，则删除表项。</li>
</ul>
<h2 id="7-5-读文件"><a href="#7-5-读文件" class="headerlink" title="7.5 读文件"></a>7.5 读文件</h2><p>因为读文件之前已经 open 了这个文件，用户进程的打开文件表里面有了这个文件的FCB，且用户持有了打开文件表编号。只需要给出打开文件表编号即可定位要操作的文件。</p>
<p>读文件也就是将文件读入内存，调用OS的“read系统调用”，需要指定：哪个文件、读入多少数据、读入的数据放到内存的什么位置。</p>
<p>操作系统处理 read 系统调用时，从读指针指向的外存中，将用户指定大小的数据读入用户指定的内存区域。</p>
<h2 id="7-6-写文件"><a href="#7-6-写文件" class="headerlink" title="7.6 写文件"></a>7.6 写文件</h2><p>和读文件同理，如果已经 open，只需要指定打开文件表编号即可。</p>
<p>保存文件内存，就是将修改过的内存回写到外存，调用了OS的“write系统调用”，需要指明：哪个文件、写入多少数据、写回的数据放在内存的什么位置。</p>
<p>OS处理时，会从用户指定的内存区域中将制定大小的数据写回写指针指向的外存。</p>
<h2 id="7-7-总结"><a href="#7-7-总结" class="headerlink" title="7.7 总结"></a>7.7 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701165734.png" alt="image.png"></p>
<h1 id="8-文件共享"><a href="#8-文件共享" class="headerlink" title="8. 文件共享"></a>8. 文件共享</h1><p>多个用户共享一个文件，意味着系统中只有“一份”文件数据。并且只要某个用户修改了该文件的数据，其他用户也可以看见文件数据的变化。这种效果“复制”达不到。</p>
<h2 id="8-1-基于索引结点的共享方式"><a href="#8-1-基于索引结点的共享方式" class="headerlink" title="8.1 基于索引结点的共享方式"></a>8.1 基于索引结点的共享方式</h2><p>回忆一下索引结点：我们在查找文件的时候一般只需要通过文件名查找，所以可以将除了文件名以外的文件信息封装到一个索引结点中，目录文件中的目录项只需要包含文件名和指向索引结点的指针即可。</p>
<p>索引结点中可以添加一个链接计数器count，用于表示链接到本索引结点上的用户目录项个数。如果 count &#x3D; 2，说明现在有两个用户目录项链接到该结点上，可以说两个用户在共享此文件。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701212159.png" alt="image.png"></p>
<p>某个用户决定删除文件，只需要删除该用户的目录项，然后索引结点的 count - 1，等 count 真正减到0，再删除文件，否则说明还有其他用户要使用该文件。</p>
<p>这种方式也叫 <font color='red'>硬链接</font>。</p>
<h2 id="8-2-基于符号链的共享方式"><a href="#8-2-基于符号链的共享方式" class="headerlink" title="8.2 基于符号链的共享方式"></a>8.2 基于符号链的共享方式</h2><p>这个和 Windows 的快捷方式很像，还是上面的例子，User1和User2共享了文件1，然后现在来了一个User3，创建了一个文件 ccc，这个ccc也想共享文件1，咋办？可以通过软连接的方式，创建一个 Link 型的文件，记录文件1的存放路径。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701212646.png" alt="image.png"></p>
<p>当 User3 访问 ccc 时，OS判断 ccc 属于 Link 型文件，于是会根据其中纪录的路径去找到 User1 目录表中的 aaa 表项，于是找到了文件1的索引结点。</p>
<p>注意：他不是直接链接到物理文件，而是链接到其他用户的逻辑文件上，也就是其他用户的目录表项。</p>
<h2 id="8-3-总结"><a href="#8-3-总结" class="headerlink" title="8.3 总结"></a>8.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701212856.png" alt="image.png"></p>
<h1 id="9-文件保护"><a href="#9-文件保护" class="headerlink" title="9. 文件保护"></a>9. 文件保护</h1><h2 id="9-1-口令保护"><a href="#9-1-口令保护" class="headerlink" title="9.1 口令保护"></a>9.1 口令保护</h2><p>为文件设置一个“口令”，用户请求访问该文件时必须提供口令。一般这个口令会存放在 FCB 或者索引结点中，操作系统会拿到你的口令去对比。</p>
<p>保存口令的空间开销不多，验证口令的时间开销也很小。但是正确的“口令”存放在系统内部，不够安全。</p>
<h2 id="9-2-加密保护"><a href="#9-2-加密保护" class="headerlink" title="9.2 加密保护"></a>9.2 加密保护</h2><p>使用某个“密码”对文件进行加密，访问文件时需要提供正确的密码才能对文件进行正确的解密。最简单的就是<strong>异或加密</strong>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701214305.png" alt="image.png"></p>
<p>很简单，只需要用密码依次的对数据进行异或运算即可加密，解密同理也是异或运算，只要加密解密提供的密码一样，就可以得到正确的结果。</p>
<p>这种方式的好处就是保密性强，不需要在系统中存储“密码”。去诶单就是编码&#x2F;译码要花费一定的时间。</p>
<h2 id="9-3-访问控制"><a href="#9-3-访问控制" class="headerlink" title="9.3 访问控制"></a>9.3 访问控制</h2><p>每个文件的 FCB 或者索引结点中都增加一个<font color='red'>访问控制表 ACL</font>，该表中记录了各个用户可以对该文件执行哪些操作。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701214639.png" alt="image.png"></p>
<p>精简的访问列表：直接把各个用户分成好多组，每一组赋予一定的权限，当用户要访问文件时，OS会检查该用户所数组是否有相应的权限。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701215237.png" alt="image.png"></p>
<h2 id="9-4-总结"><a href="#9-4-总结" class="headerlink" title="9.4 总结"></a>9.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230701215441.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>14.磁盘</title>
    <url>/2023/07/12/OS-14-%E7%A3%81%E7%9B%98/</url>
    <content><![CDATA[<p>磁盘.</p>
<span id="more"></span>

<h1 id="1-磁盘结构"><a href="#1-磁盘结构" class="headerlink" title="1. 磁盘结构"></a>1. 磁盘结构</h1><h2 id="1-1-磁盘、磁道、扇区"><a href="#1-1-磁盘、磁道、扇区" class="headerlink" title="1.1 磁盘、磁道、扇区"></a>1.1 磁盘、磁道、扇区</h2><p>磁盘里面最重要的三个概念：磁盘、磁道、扇区。</p>
<p>磁盘就是硬盘里面那个光滑的碟就是磁盘，然后从里到外会划分很多的圈，每个圈就是一个磁道。每个磁道会划分一些区，每个区存储的数据量相同，这个就是我们之前所说的磁盘块。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711164959.png" alt="image.png"></p>
<h2 id="1-2-如何读写数据"><a href="#1-2-如何读写数据" class="headerlink" title="1.2 如何读写数据"></a>1.2 如何读写数据</h2><p>需要把 “磁头” 移动到想要读写的扇区所在的磁道。然后马达带动磁盘转动，磁头就可以划过目标扇区，才能完成对扇区的读写操作。</p>
<h2 id="1-3-盘面、柱面"><a href="#1-3-盘面、柱面" class="headerlink" title="1.3 盘面、柱面"></a>1.3 盘面、柱面</h2><p>一个硬盘里面可能多有个磁盘也就是多个盘片，每个盘片都有自己的一个磁头。有些时候一个盘片甚至有两个盘面。这些盘片的磁头是通过一个磁臂控制的，所有的磁头共进退。</p>
<p>所有盘面中相同位置的磁道，就是柱面，其实就是几个磁道摞在一起，就变成了柱面。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711170115.png" alt="image.png"></p>
<p>可以通过一个三元组来描述一个磁盘块：（柱面号，盘面号，扇区号）。</p>
<p>读取一个块的流程：</p>
<ul>
<li>根据柱面号将磁头移动到相应的位置</li>
<li>激活指定盘面对应的磁头</li>
<li>磁盘旋转，指定的扇区划过磁头，完成读写。</li>
</ul>
<h2 id="1-4-磁盘的分类"><a href="#1-4-磁盘的分类" class="headerlink" title="1.4 磁盘的分类"></a>1.4 磁盘的分类</h2><p>我们之前说的磁头可以移动的，叫活动头磁盘，磁臂可以来回伸缩来定位磁道。</p>
<p>磁头不可移动的叫固定头磁盘，这种磁盘中每个磁道有一个磁头。</p>
<p>有些磁盘的盘片可以更换，就是可换盘磁盘，不能换的就是固定盘磁盘。</p>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711170045.png" alt="image.png"></p>
<h1 id="2-磁盘调度算法"><a href="#2-磁盘调度算法" class="headerlink" title="2. 磁盘调度算法"></a>2. 磁盘调度算法</h1><h2 id="2-1-磁盘读写操作时间"><a href="#2-1-磁盘读写操作时间" class="headerlink" title="2.1 磁盘读写操作时间"></a>2.1 磁盘读写操作时间</h2><p>磁盘进行一次读写的操作有：寻道（将磁头移动到指定的磁道或者柱面上）、旋转（转动磁盘将制定扇区转到磁头上）、传输（让扇区划过磁头）。所以读写时间就是这三步骤的和：</p>
<p><strong>寻道时间 Ts</strong></p>
<p>这个步骤分为两个小步骤：</p>
<ul>
<li>启动磁臂，假设花费时间 s</li>
<li>移动磁头，假设磁头匀速移动，每跨越一个磁道耗时 m，总共要跨越 n 个磁道。</li>
</ul>
<p>则寻道时间 &#x3D; Ts &#x3D; s + m x n.</p>
<p><strong>延迟时间 Tr</strong></p>
<p>通过旋转磁盘，使磁头顶味道目标扇区所需要的时间。假设磁盘转速为 r（单位：转&#x2F;秒、转&#x2F;分），则平均所需时间 Tr &#x3D; (1&#x2F;2) x (1&#x2F;r) &#x3D; 1&#x2F;(2r). 1&#x2F;r 就是转一圈需要的时间，然后 1&#x2F;2 求个平均。</p>
<p><strong>传输时间 Tt</strong></p>
<p>就是磁头划过整个扇区的时间，假设磁盘转速为 r，每次读写 b 个字节，每个磁道上的字节数为 N。则传输时间 Tt &#x3D; (1&#x2F;r) x (b&#x2F;N) &#x3D; b&#x2F;(rN).</p>
<p>总的平均存取时间 Ta &#x3D; Ts + 1&#x2F;(2r) + b&#x2F;(rN)</p>
<h2 id="2-2-磁盘调度算法"><a href="#2-2-磁盘调度算法" class="headerlink" title="2.2 磁盘调度算法"></a>2.2 磁盘调度算法</h2><h3 id="2-2-1-先来先服务-FCFS"><a href="#2-2-1-先来先服务-FCFS" class="headerlink" title="2.2.1 先来先服务 FCFS"></a>2.2.1 先来先服务 FCFS</h3><p>很简单，多个进程依次请求访问不同的磁道，FCFS 就会依照这个顺序，按要求到达给定的位置进行存取。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711213556.png" alt="image.png"></p>
<p>优点：公平，如果请求的磁道还算集中的话，效率也还行。</p>
<p>缺点：如果有大量进程竞争使用磁盘，请求的磁道很分散，则性能很差，寻道时间长。</p>
<h3 id="2-2-2-最短寻找时间优先-SSTF"><a href="#2-2-2-最短寻找时间优先-SSTF" class="headerlink" title="2.2.2 最短寻找时间优先 SSTF"></a>2.2.2 最短寻找时间优先 SSTF</h3><p>也很好理解，优先处理距离磁头最近的寻道请求：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711213908.png" alt="image.png"></p>
<p>他会优先访问 90 号磁道，因为 90 距离 100 最近，然后访问距离 90 最近的 58，以此类推。</p>
<p>优点：性能可以，平均寻道时间短</p>
<p>缺点：可能发生饥饿。比如磁头到达 18 号的时候，又来了 20 16 15 10 四个寻道请求，那么磁头就会一直在这块范围内溜达。</p>
<h3 id="2-2-3-扫描算法-SCAN"><a href="#2-2-3-扫描算法-SCAN" class="headerlink" title="2.2.3 扫描算法 SCAN"></a>2.2.3 扫描算法 SCAN</h3><p>为了解决上面那种磁头在一小块范围内来回转的问题，这种算法规定：只有在磁头扫描到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外侧移动。磁头的移动方式有点像电梯，所以这种算法也叫电梯算法。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711214338.png" alt="image.png"></p>
<p>磁头大道 184 的时候，即便没有 200 磁道的寻道请求，磁头依旧会移动到 200 号磁道，这样才能往回扫描。</p>
<p>优点：肯定是不会饥饿了，平均寻道时间短。</p>
<p>缺点：有的时候没有必要移动到最外侧磁道。而且对于各个位置的磁道响应频率不平均，比如刚刚处理了 90 号磁道，然后磁头正在外移，则下一次访问 90 号磁道就比较慢。而刚刚响应过 184 号磁道，下一次访问 184 就很快，因为刚刚掉头。</p>
<h3 id="2-2-4-LOOK-调度算法"><a href="#2-2-4-LOOK-调度算法" class="headerlink" title="2.2.4 LOOK 调度算法"></a>2.2.4 LOOK 调度算法</h3><p>这种算法为了解决上面 SCAN 的非要移动到最外侧的问题，磁头会边移动边观察，如果移动到 184 磁道上发现右边已经没有寻道请求了，磁头就会立即掉头。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711215205.png" alt="image.png"></p>
<h3 id="2-2-5-循环扫描算法-C-SCAN"><a href="#2-2-5-循环扫描算法-C-SCAN" class="headerlink" title="2.2.5 循环扫描算法 C-SCAN"></a>2.2.5 循环扫描算法 C-SCAN</h3><p>解决了 SCAN 里面响应时间不平均的问题。磁道只有在想特定方向移动的时候才会处理寻道请求，然后最终走到了磁盘最外侧（也可能是最内侧，这个可不会观察掉头），然后直接从一端移动到另外一端，中间不会处理任何寻道请求。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711215526.png" alt="image.png"></p>
<p>虽然没有 200 号磁道的寻道请求，但是为了掉头也需要走到200，然后从 200 到 0 不会处理请求。</p>
<p>优点：比起 SCAN，对于各个位置的寻道的响应频率都很平均。</p>
<p>缺点：和 SCAN 一样，不能观察及时掉头。而且磁头返回时只需要返回 18 即可，不需要返回到 0.平均寻道时间更长。</p>
<h3 id="2-2-6-C-LOOK-算法"><a href="#2-2-6-C-LOOK-算法" class="headerlink" title="2.2.6 C-LOOK 算法"></a>2.2.6 C-LOOK 算法</h3><p>这个算法就是 LOOK 和 C-SCAN 的结合体。同样是边移动边观察，当发现移动方向上没有寻道请求了，直接掉头，将磁头移动到有磁道访问请求的磁道上即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711220527.png" alt="image.png"></p>
<p>和 C-SCAN 一样，184 到 18 之间不会处理任何寻道请求。</p>
<h2 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711220627.png" alt="image.png"></p>
<h1 id="3-减少延迟时间"><a href="#3-减少延迟时间" class="headerlink" title="3. 减少延迟时间"></a>3. 减少延迟时间</h1><p>每次寻道结束，操作完一个扇区，磁盘并不能马上开始扫描下一个扇区，而是需要一点时间进行额外处理。</p>
<p>假设我们要连续访问 2 3 4 扇区，当访问完 2 号扇区之后，并不能马上访问 3 号扇区，然后因为旋转的原因，3 号扇区就错过了，必须等磁盘旋转一周回来，才能访问 3 号扇区，4 号扇区同理。这就导致延迟。</p>
<h2 id="3-1-交替编号"><a href="#3-1-交替编号" class="headerlink" title="3.1 交替编号"></a>3.1 交替编号</h2><p>可以将连续的扇区间隔开编号：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711221532.png" alt="image.png"></p>
<p>当我们要访问 0 1 2 3 号扇区时，访问完 0 号扇区，需要一段时间恢复，然后旋转就会错过 4 号扇区，恢复完成后，正好接着访问 1 号扇区，不需要转一周回来。</p>
<h2 id="3-2-磁盘地址结构设计"><a href="#3-2-磁盘地址结构设计" class="headerlink" title="3.2 磁盘地址结构设计"></a>3.2 磁盘地址结构设计</h2><p>之前说过，为啥磁盘的物理地址三元组是（柱面号，盘面号，扇区号），而不是（盘面号，柱面号，扇区号），这三个指标能不能改顺序？</p>
<h3 id="3-2-1-盘面号在前设计"><a href="#3-2-1-盘面号在前设计" class="headerlink" title="3.2.1 盘面号在前设计"></a>3.2.1 盘面号在前设计</h3><p>如果磁盘的物理地址为（盘面号，柱面号，扇区号），则 （00，000，0000）到 （00，000，1111）这所有的地址就是一个盘面的一个磁道对应的所有扇区，转两圈就能转完了（因为间隔编号，所以是两圈）。</p>
<p>然后我们再访问 （00，001，0000）到（00，001，1111），这些地址就是同一个盘面的下一个磁道的所有扇区数据。磁道改变了，就需要移动磁臂。两轮寻址，地址都是连续的，但是需要启动磁臂移动磁头。</p>
<h3 id="3-2-2-柱面号在前设计"><a href="#3-2-2-柱面号在前设计" class="headerlink" title="3.2.2 柱面号在前设计"></a>3.2.2 柱面号在前设计</h3><p>按之前的说法，地址设计为（柱面号，盘面号，扇区号），仍旧访问上面这些地址，第一轮寻址找的是第一个磁面，第二轮寻址，找的是第二个磁面，只需要激活不同的磁头即可，无需移动磁头。减少了磁头移动的时间：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711222508.png" alt="image.png"></p>
<h2 id="3-3-错位命名"><a href="#3-3-错位命名" class="headerlink" title="3.3 错位命名"></a>3.3 错位命名</h2><p>这个原理和之前的交替编号差不多，指示针对的是多个磁面的情况。</p>
<p>如果两个磁片按照相同的位置编址，然后我们访问（000，00，000）到 （000，01，000）这些地址，步骤如下：</p>
<p>访问第一个盘面的0号磁道的 0 号扇区一直到 111 号扇区，也就是访问整个0号磁道。根据我们之前说的，需要转两圈，最终磁头停在 7 号扇区末尾，紧挨着 0 扇区：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711223042.png" alt="image.png"></p>
<p>然后我们要紧接着访问 1 号盘面的 0 号磁道的 0 号扇区，但是磁头紧挨着 0 号扇区，不能马上访问，所以又像之前那样，得空转一周。</p>
<p>解决办法就是让两个磁面错开一位编号：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711223253.png" alt="image.png"></p>
<p>这回就对头了，两个盘面上面的扇区号错开一位，就可以紧接着访问下一个盘面的0号扇区。</p>
<h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711223344.png" alt="image.png"></p>
<h1 id="4-磁盘管理"><a href="#4-磁盘管理" class="headerlink" title="4. 磁盘管理"></a>4. 磁盘管理</h1><h2 id="4-1-磁盘初始化"><a href="#4-1-磁盘初始化" class="headerlink" title="4.1 磁盘初始化"></a>4.1 磁盘初始化</h2><p>懒得写了，直接看图了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711223702.png" alt="image.png"></p>
<h2 id="4-2-引导块"><a href="#4-2-引导块" class="headerlink" title="4.2 引导块"></a>4.2 引导块</h2><p>计算机开机时需要进行一系列的初始化工作，这些初始化工作是通过 <strong>初始化程序（自举程序）</strong> 完成的，这个程序可以放在 ROM 中，这个 ROM 通常是集成在主板上的一块 ROM 芯片。</p>
<p>众所周知，ROM 只读，如果我们想要更改自举程序岂不是很麻烦，怎么解决？</p>
<p>实际上，ROM 上只会有一个很小的 “自举装入程序”，他是指向完整装入程序的一个东西。完整的自举程序放在磁盘的启动块（也就是引导块&#x2F;启动分区）上，启动块位于磁盘的固定位置。</p>
<p>开机时，计算机运行 “自举装入程序”，通过执行该程序可以找到引导块，并将完成的“自举程序”读入内存，完成初始化。</p>
<p>装着引导块的这个磁盘，就是启动磁盘，Windows 也就是 C 盘。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711224249.png" alt="image.png"></p>
<h2 id="4-3-坏块管理"><a href="#4-3-坏块管理" class="headerlink" title="4.3 坏块管理"></a>4.3 坏块管理</h2><p>就是说这个扇区不能用了，属于硬件故障，这个 OS 只能是避免把数据存储到坏块上。所以需要将所有的坏块标记出来。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711224521.png" alt="image.png"></p>
<h1 id="5-固态硬盘-SSD"><a href="#5-固态硬盘-SSD" class="headerlink" title="5. 固态硬盘 SSD"></a>5. 固态硬盘 SSD</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711230228.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230711230316.png" alt="image.png"></p>
<p>两张图对比着看吧，懒得记了。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>12.IO设备</title>
    <url>/2023/07/12/OS-12-IO%E8%AE%BE%E5%A4%87/</url>
    <content><![CDATA[<p>IO设备</p>
<span id="more"></span>

<h1 id="1-IO-设备基本概念"><a href="#1-IO-设备基本概念" class="headerlink" title="1. IO 设备基本概念"></a>1. IO 设备基本概念</h1><p>IO设备就是可以将数据输入到计算机或者可以接受计算机输出数据的外部设备，属于计算机中的硬件部件。</p>
<p>UNIX 系统将外部设备抽象成一种特殊的文件，用户可以使用与文件相同的方式对外部设备进行操作。比如对文件 Write 操作就是向外部设备写出数据，Read 操作就是从键盘中读入数据。</p>
<p>IO 设备按使用特性分类：</p>
<ul>
<li>人机交互类外部设备，比如鼠标键盘，数据传输速度慢</li>
<li>存储设备，比如外接硬盘，光盘等，数据传输速度快</li>
<li>网络通讯设备，比如 TPLINK，速度介于上面二者之间</li>
</ul>
<p>IO设备按传输速率分类：</p>
<ul>
<li>低速设备，还是鼠标键盘</li>
<li>中速设备，比如激光打印机</li>
<li>高速设备，比如磁盘</li>
</ul>
<p>IO设备按照信息交换单位分类（重点）：</p>
<ul>
<li>块设备，比如磁盘，OS可以通过块来进行寻址访问</li>
<li>字符设备，比如鼠标键盘，数据传输的基本单位是字符，在 IO 时通常采用中断驱动方式</li>
</ul>
<h1 id="2-IO-控制器"><a href="#2-IO-控制器" class="headerlink" title="2. IO 控制器"></a>2. IO 控制器</h1><h2 id="2-1-IO-控制器概念"><a href="#2-1-IO-控制器概念" class="headerlink" title="2.1 IO 控制器概念"></a>2.1 IO 控制器概念</h2><p>俩概念：</p>
<ul>
<li>IO设备机械部件：主要用于执行具体的 IO操作。比如显示器，鼠标键盘这种的。</li>
<li>IO设备电子部件：通常是以块插入主板扩展槽的印刷电路板</li>
</ul>
<p>上面说到的 IO 设备电子部件就是 IO控制器，他是 CPU 和 IO 设备机械部件之间的中介，用于实现 CPU 对设备的控制。</p>
<p>IO 控制器的功能：</p>
<ul>
<li>接受和识别 CPU 发出的命令，比如 CPU 发来的 read&#x2F;write 指令，IO控制器就需要相应的控制寄存器来存放指令和参数</li>
<li>向 CPU 报告设备状态，IO控制器中就会有状态寄存器，用于记录 IO 设备当前的状态，比如 1 代表空闲，0 表示忙碌</li>
<li>数据交换，所以 IO 控制器中就需要提供数据寄存器，这个东西和内存中的 MDR 一个道理，用于暂存和 CPU 交互的数据。</li>
<li>地址识别。说的可不是磁盘啊，上面说到 IO 控制器中可能有各种各样的寄存器，就需要给这些寄存器编址。IO控制器通过 CPU 提供的“地址”来判断 CPU 要操作哪个寄存器。</li>
</ul>
<h2 id="2-2-IO-控制器组成"><a href="#2-2-IO-控制器组成" class="headerlink" title="2.2 IO 控制器组成"></a>2.2 IO 控制器组成</h2><p>直接上图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708202210.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>CPU 会通过地址线 和 控制线告诉 IO 逻辑，我现在要操作哪一个 IO 设备，具体要干啥</li>
<li>比如 CPU 向 IO 设备中输出数据，就先将数据暂存到 数据寄存器中，然后具体指令暂存到 控制寄存器中。</li>
<li>IO 设备及时的将自己的状态发送给 IO 逻辑，然后IO逻辑将状态信息发送到状态寄存器中。</li>
</ul>
<p>细节：</p>
<ul>
<li>一个 IO逻辑可以对应多个 IO 设备</li>
<li>既然有多个 IO 设备，则 各种类型的寄存器肯定会有多个，有的计算机会让这些寄存器占用内存中的一部分，称为<font color='red'>内存映像I&#x2F;O</font>；另一些计算机则会采用 IO 专用地址，即<font color='red'>寄存器独立编制</font>.</li>
</ul>
<h2 id="2-3-内存映像-I-x2F-O-VS-寄存器独立编址"><a href="#2-3-内存映像-I-x2F-O-VS-寄存器独立编址" class="headerlink" title="2.3 内存映像 I&#x2F;O VS 寄存器独立编址"></a>2.3 内存映像 I&#x2F;O VS 寄存器独立编址</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708202626.png" alt="image.png"></p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708202712.png" alt="image.png"></p>
<h1 id="3-I-x2F-O-控制方式"><a href="#3-I-x2F-O-控制方式" class="headerlink" title="3. I&#x2F;O 控制方式"></a>3. I&#x2F;O 控制方式</h1><p>就是说用什么方式来控制 IO 设备进行数据的读写。总共四种方式：</p>
<ul>
<li>程序直接控制方式</li>
<li>中断驱动方式</li>
<li>DMA 方式</li>
<li>通道控制方式</li>
</ul>
<p>对于不同的方式，要着重看他们的几个问题：</p>
<ul>
<li>完成一次读写操作的流程</li>
<li>CPU 敢于的频率</li>
<li>数据传送的单位</li>
<li>数据的流向</li>
<li>主要优点和缺点</li>
</ul>
<h2 id="3-1-程序直接控制方式"><a href="#3-1-程序直接控制方式" class="headerlink" title="3.1 程序直接控制方式"></a>3.1 程序直接控制方式</h2><p>总结来说就是：轮询。</p>
<h3 id="3-1-1-操作流程"><a href="#3-1-1-操作流程" class="headerlink" title="3.1.1 操作流程"></a>3.1.1 操作流程</h3><p>因为 IO 设备比 CPU 慢很多，CPU 向 IO 逻辑发送了读指令，请求读取 IO 设备，但是这个时候 IO 设备还没准备好，状态寄存器为1未就绪，然后 CPU 就会一直轮询状态寄存器。</p>
<p>当 IO 设备准备好了，就会向控制器的数据寄存器发送数据，同时将自己的状态同步到状态寄存器中改为0，CPU 发现状态为0，就会将数据从控制器的数据寄存器读入到CPU的寄存器，然后再将数据写入内存。</p>
<p>所以这里数据不能直接到内存，数据必须经过 CPU 的寄存器才能到内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708203452.png" alt="image.png"></p>
<p>流程图如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708203636.png" alt="image.png"></p>
<h3 id="3-1-2-CPU-干预频率"><a href="#3-1-2-CPU-干预频率" class="headerlink" title="3.1.2 CPU 干预频率"></a>3.1.2 CPU 干预频率</h3><p>很频繁，这个流程中，数据的接受和发送都需要经过 CPU 寄存器，同时 CPU 在等待 IO 设备的时候需要不停的轮询寄存器。CPU 开销较大。</p>
<h3 id="3-1-3-数据传送单位"><a href="#3-1-3-数据传送单位" class="headerlink" title="3.1.3 数据传送单位"></a>3.1.3 数据传送单位</h3><p>每次读写一个字。</p>
<h3 id="3-1-4-数据的流向"><a href="#3-1-4-数据的流向" class="headerlink" title="3.1.4 数据的流向"></a>3.1.4 数据的流向</h3><p>读操作：IO 设备 - CPU - 内存；写操作：内存 - CPU - IO设备。每个字的读写都需要 CPU 介入。</p>
<h3 id="3-1-5-优缺点"><a href="#3-1-5-优缺点" class="headerlink" title="3.1.5 优缺点"></a>3.1.5 优缺点</h3><p>优点就是实现简单。缺点就是 CPU 和 IO 只能串行工作，CPU 需要一直轮询检查，不能去干别的事，造成了忙等。</p>
<h2 id="3-2-中断驱动方式"><a href="#3-2-中断驱动方式" class="headerlink" title="3.2 中断驱动方式"></a>3.2 中断驱动方式</h2><p>引入了中断机制。CPU 发出读写请求后，将等待 IO 的进程阻塞。当 IO 完成后，IO 控制器向 CPU 发送中断信号，然后 CPU 检测到了，保存运行环境，然后执行中断处理程序。</p>
<h3 id="3-2-1-操作流程"><a href="#3-2-1-操作流程" class="headerlink" title="3.2.1 操作流程"></a>3.2.1 操作流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708204209.png" alt="image.png"></p>
<p>注意：</p>
<ul>
<li>CPU 会在每个指令周期的末位检查中断</li>
<li>中断处理过程需要保存当前进程的运行环境，这个过程存在开销。所以如果中断发生的过于频繁就会降低系统性能。</li>
</ul>
<h3 id="3-2-2-CPU-干预频率"><a href="#3-2-2-CPU-干预频率" class="headerlink" title="3.2.2 CPU 干预频率"></a>3.2.2 CPU 干预频率</h3><p>每次 IO 操作开始之前、完成后需要 CPU 介入，其他时间 CPU 可以干别的事儿。</p>
<h3 id="3-2-3-数据传送单位"><a href="#3-2-3-数据传送单位" class="headerlink" title="3.2.3 数据传送单位"></a>3.2.3 数据传送单位</h3><p>每次读写一个字</p>
<h3 id="3-2-4-数据的流向"><a href="#3-2-4-数据的流向" class="headerlink" title="3.2.4 数据的流向"></a>3.2.4 数据的流向</h3><p>读：IO - CPU - 内存；写：内存 - CPU - IO设备。这个和之前一样，仍旧需要 CPU 寄存器介入。</p>
<h3 id="3-2-5-优缺点"><a href="#3-2-5-优缺点" class="headerlink" title="3.2.5 优缺点"></a>3.2.5 优缺点</h3><p>优点就是 CPU 不用忙等，不用轮询，效率会更高，CPU 和 IO 设备可以实现并行。缺点就是每个字的传输仍旧需要 CPU 的介入，同时频繁的中断会消耗 CPU 时间。</p>
<h2 id="3-3-DMA-方式"><a href="#3-3-DMA-方式" class="headerlink" title="3.3 DMA 方式"></a>3.3 DMA 方式</h2><p>DMA（Direct Memory Access，直接存储器存取）。主要用于块设备的 IO 控制。</p>
<p>改进：</p>
<ul>
<li>数据的传送单位是 “块”。不再是一个字一个字传送</li>
<li>数据的流向直接从设备放入内存，或者从内存直接放入设备，不需要 CPU 介入</li>
<li>仅在传送一个或多个数据块的开始和结束时，才需要 CPU 干预。</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708205013.png" alt="image.png"></p>
<p>这种方式需要一个专门的 DMA 控制器。</p>
<h3 id="3-3-1-DMA-控制器"><a href="#3-3-1-DMA-控制器" class="headerlink" title="3.3.1 DMA 控制器"></a>3.3.1 DMA 控制器</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708205230.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>DR 数据寄存器 Data Register，暂存内存和IO设备交互的数据</li>
<li>MAR，老熟人了，输入时，MAR 表示数据应该放到内存中的什么位置；输出时 MAR 表示要输出的数据放到内存的什么位置</li>
<li>DC 数据计数器 Data Counter，表示剩余要读写的字节数</li>
<li>CR 命令&#x2F;状态寄存器 Command Register，用于存放 CPU 发来的 IO 命令或者设备的状态信息。</li>
</ul>
<p>这些寄存器同样不止一个。同时需要注意的是：DMA 读取数据不是直接一块一块读，其实也是一个字节一个字节的读，将每个字写入 DR 然后放入内存，然后循环到一整块都完成读写。</p>
<p>操作流程之前已经有图了，这里不说了。</p>
<h3 id="3-3-2-CPU-干预频率"><a href="#3-3-2-CPU-干预频率" class="headerlink" title="3.3.2 CPU 干预频率"></a>3.3.2 CPU 干预频率</h3><p>仅在传送一个或者多个块的开始和结束时，才需要 CPU 干预。也就是说 CPU 只需要告诉 DMA 控制器我要读入了，CPU 就不用管了，然后 DMA 读完以后再跟 CPU 说一声就行了。</p>
<h3 id="3-3-3-数据传送单位"><a href="#3-3-3-数据传送单位" class="headerlink" title="3.3.3 数据传送单位"></a>3.3.3 数据传送单位</h3><p>每次读写一个块或者多个块。每次读写的只能是连续的多个块，这些块读入内存后必须连续。</p>
<h3 id="3-3-4-数据的流向"><a href="#3-3-4-数据的流向" class="headerlink" title="3.3.4 数据的流向"></a>3.3.4 数据的流向</h3><p>这回不用 CPU 了，IO 和 内存直接传输。</p>
<h3 id="3-3-5-优缺点"><a href="#3-3-5-优缺点" class="headerlink" title="3.3.5 优缺点"></a>3.3.5 优缺点</h3><p>优点：数据传送以块为单位，CPU 介入频率降低。数据的传送不再需要 CPU 寄存器的介入，效率提高。</p>
<p>缺点：一次只能读写一个或者多个连续的块，还是有点慢。</p>
<h2 id="3-4-通道控制方式"><a href="#3-4-通道控制方式" class="headerlink" title="3.4 通道控制方式"></a>3.4 通道控制方式</h2><p>通道就是一种硬件，可以理解成简化版的 CPU。通道可以识别并执行一系列的通道指令。</p>
<h3 id="3-4-1-操作流程"><a href="#3-4-1-操作流程" class="headerlink" title="3.4.1 操作流程"></a>3.4.1 操作流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708210736.png" alt="image.png"></p>
<p>简单说，就是 CPU 想要读取一堆数据，CPU 就会给出一个通道程序，通道程序可以理解成一个批处理，里面通道的任务清单，一批的通道指令。</p>
<p>然后 CPU 就会告诉通道，我要操作哪个 IO 设备，你需要去内存的哪个地方找通道程序，然后 CPU 就干别的去了。</p>
<p>通道就会执行通道程序，然后按要求将数据从 IO 设备读入内存。读完了以后照旧跟 CPU 说一声，发出中断信号，然后 CPU 处理。</p>
<p>所以说通道是一个简化版的 CPU，通道也可以执行指令，但是指令非常单一，并且通道程序放在主机内存中，也就是说通道与 CPU 共享内存。</p>
<h3 id="3-4-2-CPU-干预频率"><a href="#3-4-2-CPU-干预频率" class="headerlink" title="3.4.2 CPU 干预频率"></a>3.4.2 CPU 干预频率</h3><p>极低，通道根据 CPU 的指示执行相应的通道程序，只有完成一组数据块的读写后才需要发出中断信号，请求 CPU 干预。</p>
<h3 id="3-4-3-数据传送单位"><a href="#3-4-3-数据传送单位" class="headerlink" title="3.4.3 数据传送单位"></a>3.4.3 数据传送单位</h3><p>每次读写一组数据。也就是执行通道程序内的一组指令。</p>
<h3 id="3-4-4-数据的流向"><a href="#3-4-4-数据的流向" class="headerlink" title="3.4.4 数据的流向"></a>3.4.4 数据的流向</h3><p>同样，在通道的控制下，IO 设备和 内存直接传送。</p>
<h3 id="3-4-5-优缺点"><a href="#3-4-5-优缺点" class="headerlink" title="3.4.5 优缺点"></a>3.4.5 优缺点</h3><p>缺点：实现复杂，需要专门的通道硬件支持</p>
<p>优点：CPU、通道、IO设备可并行工作，资源利用率高</p>
<h2 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708211528.png" alt="image.png"></p>
<h1 id="4-IO-软件层次结构"><a href="#4-IO-软件层次结构" class="headerlink" title="4. IO 软件层次结构"></a>4. IO 软件层次结构</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709153444.png" alt="image.png"></p>
<h2 id="4-1-用户层软件"><a href="#4-1-用户层软件" class="headerlink" title="4.1 用户层软件"></a>4.1 用户层软件</h2><p>用户层软件实现了与用户交互的接口，用户可以直接使用该层提供的、与 IO 操作相关的库函数对设备进行操作。比如 C 语言的 printf。</p>
<p>设备独立性软件为上层提供系统调用，用户层软件将用户请求比如 printf 翻译成格式化的 IO 请求，并通过 “系统调用”请求操作系统内核的服务。</p>
<p>简单说，用户层软件为用户提供库函数，然后将用户请求翻译成系统调用比如 write，系统调用由设备独立性软件提供。所以设备独立性软件也叫系统调用处理层。</p>
<h2 id="4-2-设备独立性软件"><a href="#4-2-设备独立性软件" class="headerlink" title="4.2 设备独立性软件"></a>4.2 设备独立性软件</h2><p>也叫设备无关性软件。与设备的硬件特性无关的功能都在这一层实现。除了对上层提供系统调用外，还有一个主要功能是对设备的保护，原理类似文件保护，因为有些系统会将IO设备看作特殊的文件。</p>
<p>第三个主要功能是差错处理，但是差错的类型很多，这里不说了。</p>
<p>第四个功能是设备的分配和回收，因为很多设备也是一种临界资源。</p>
<p>第五个功能是数据缓冲区管理</p>
<p>第六个功能是建立设备名到物理设备名的映射关系；根据设备类型选择调用相应的驱动程序。</p>
<p>这个单独说一下，比如说我们看到的打印机1，打印机2，指的就是逻辑设备名，我们指定打印机2开始工作，OS 需要根据这个逻辑名去找到真实的物理设备，并找到这个设备的驱动程序。</p>
<p>设备独立性软件里面要根据设备的逻辑名找到对应的驱动程序入口，怎么做到的？类比文件管理，操作系统会构建一张 <strong>逻辑设备表 LUT</strong> 来实现的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709155108.png" alt="image.png"></p>
<p>如果整个系统只有一张 LUT，就会出现之前文件里面的问题，即用户之间不同设备不能同名，所以系统会给每个用户都建立一张 LUT。LUT 就放在用户管理进程的 PCB 中。</p>
<h2 id="4-3-设备驱动程序"><a href="#4-3-设备驱动程序" class="headerlink" title="4.3 设备驱动程序"></a>4.3 设备驱动程序</h2><p>就是说操作系统不能直接操作IO设备，因为不同型号的IO设备内部构造不一定一样，需要 IO 设备的厂家向OS提供一个设备驱动程序用来操作该 IO 设备。</p>
<p>所以说设备独立性软件不能直接操作设备，只能通过调用设备驱动程序的方式来操作设备。</p>
<p>驱动程序一般会一个独立进程的方式存在。</p>
<h2 id="4-4-中断处理程序"><a href="#4-4-中断处理程序" class="headerlink" title="4.4 中断处理程序"></a>4.4 中断处理程序</h2><p>当 IO 设备任务完成时，IO控制器会发送一个中断信号，系统会根据中断信号的类型找到相应的中断处理程序并执行。流程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709155718.png" alt="image.png"></p>
<p>中断处理程序 和 设备驱动程序 都会直接和硬件交互。</p>
<h2 id="4-5-总结"><a href="#4-5-总结" class="headerlink" title="4.5 总结"></a>4.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709155835.png" alt="image.png"></p>
<h1 id="5-输入-x2F-输出应用程序接口"><a href="#5-输入-x2F-输出应用程序接口" class="headerlink" title="5. 输入&#x2F;输出应用程序接口"></a>5. 输入&#x2F;输出应用程序接口</h1><p>简单说，设备独立性软件向用户层软件提供接口，但是根据IO设备的不同，一个接口不能实现全部的功能，比如对于块设备，可以想像用户层软件提供 read write 接口，需要指明要读写的地址。但是如果用操作键盘这类字符型设备，write 或者 read 就不行了。</p>
<p>故设备独立性软件需要给用户层软件提供不同的接口来应对不同的设备。</p>
<h2 id="5-1-字符设备接口"><a href="#5-1-字符设备接口" class="headerlink" title="5.1 字符设备接口"></a>5.1 字符设备接口</h2><p>提供 get &#x2F; put 系统调用：向字符设备读&#x2F;写一个字符。</p>
<h2 id="5-2-块设备接口"><a href="#5-2-块设备接口" class="headerlink" title="5.2 块设备接口"></a>5.2 块设备接口</h2><p>提供 read &#x2F; write 系统调用：向块设备的读写指针位置读&#x2F;写多个字符。seek 系统调用：修改读写指针位置。</p>
<h2 id="5-3-网络设备接口"><a href="#5-3-网络设备接口" class="headerlink" title="5.3 网络设备接口"></a>5.3 网络设备接口</h2><p>也叫<strong>网络套接字（socket）接口</strong>。socket 系统调用：创建一个网络套接字，需要指明网络协议。bind：将套接字绑定到某个本地端口。connect：将套接字链接到远程地址。read&#x2F;write：从套接字读&#x2F;写数据。</p>
<p>这个详细看看流程：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709162240.png" alt="image.png"></p>
<ol>
<li>主机2 要进行网络通讯，就会调用 socket 系统调用，创建一个套接字 socket（其实就是在内核空间申请一片空间，用于进行数据收发），然后内核空间会给用户空间返回一个描述符，可以理解成指向 socket 的指针。</li>
<li>然后调用 bind 系统调用，将套接字绑定到主机的一个端口，比如 6666。然后主机2 就可以等待被链接。</li>
<li>主机1按照同样的流程创建套接字并绑定 211 端口。</li>
<li>主机1 调用 connect 系统调用，将两个套接字链接到一起，咋连的先甭管了。</li>
<li>主机1 要向主机2 发送数据，数据已经在用户空间准备好了，就可以调用 write 系统调用。设备独立性软件接收到 write 指令，就会将数据包从用户态复制到内核态中的套接字缓冲区里面。这一步是设备独立性软件负责的。</li>
<li>设备独立性软件会调用网卡的“网络控制器驱动程序”，将数据从缓冲区复制到网卡，然后实现数据发送。</li>
<li>主机2的网卡接收到数据，IO 控制器就会发送中断，中断处理程序调用 “网络控制器驱动程序” 将数据从网卡拿到套接字缓冲区中。</li>
<li>然后主机2的用户就可以调用 read 系统调用，指明我要从 fd 对应的 套接字中拿数据，设备独立性软件就会将数据从套接字中拿到用户态。</li>
</ol>
<h2 id="5-4-阻塞-x2F-非阻塞-IO"><a href="#5-4-阻塞-x2F-非阻塞-IO" class="headerlink" title="5. 4 阻塞&#x2F;非阻塞 IO"></a>5. 4 阻塞&#x2F;非阻塞 IO</h2><p>阻塞IO：应用程序发出 IO 系统调用，进程需要转为阻塞态等待IO设备响应。比如字符设备接口，从键盘拿一个字符，就需要等待，典型的 scanf 函数。</p>
<p>非阻塞IO：应用程序发出 IO 系统调用，系统调用可迅速返回，进程无需等待。比如 块设备接口，向磁盘中写数据 write。设备独立性软件只需要将数据先复制到内核态即可，用户进程无需等待，然后内核态慢慢往磁盘里面写。</p>
<h1 id="6-设备驱动程序接口"><a href="#6-设备驱动程序接口" class="headerlink" title="6. 设备驱动程序接口"></a>6. 设备驱动程序接口</h1><p>如果不同的IO设备的驱动程序向设备独立性软件提供的接口不统一，则调用会麻烦。所以操作系统就会给出一套标准接口规范，IO设备的厂商必须实现规范才能让设备在系统上运行。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709162945.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>深入字符串</title>
    <url>/2022/06/02/String/</url>
    <content><![CDATA[<p>字符串，嗯，面试的重点，多少都会涉及。而且字符串看似简单，其实要深入JVM理解字符串还是有些难度的，所以这一章就来单独说一下字符串的小坑。</p>
<span id="more"></span>

<h1 id="1-String基础"><a href="#1-String基础" class="headerlink" title="1. String基础"></a>1. String基础</h1><h2 id="1-1-String基本特性"><a href="#1-1-String基本特性" class="headerlink" title="1.1 String基本特性"></a>1.1 String基本特性</h2><ul>
<li><p>String 不是基础数据类型，即便他能 String x &#x3D; “” 直接赋值</p>
</li>
<li><p>String 实现了 Comparable 和 Serializable，也就是可以序列化和比大小</p>
</li>
<li><p>String 被final 修饰不能继承</p>
</li>
<li><p>String 在 jdk8之前他的底层是char[] value,jdk9 以后修改成了byte[] value，为啥？</p>
</li>
</ul>
<h2 id="1-2-jdk8-9-对于String底层的修改"><a href="#1-2-jdk8-9-对于String底层的修改" class="headerlink" title="1.2 jdk8 9 对于String底层的修改"></a>1.2 jdk8 9 对于String底层的修改</h2><p>jdk8以前String底层是char数组，jdk9就变成了byte数组，为啥？</p>
<p>首先，可以去官网看：<u><span spellcheck="false" class="md-link md-pair-s"><a href="http://openjdk.java.net/jeps/254">JEP 254: Compact Strings</a></span></u> 里面的motivation详细说了，这里概括一下：</p>
<p>以前的java实现String 里面采用 char[] value的形式存储字符串，一个字符 占两个字节，然后String 是堆空间里面主要的存储单位，数量特别多。但是他们发现，大部分的字符串包含的都是一些 Latin-1(拉丁，简单理解，拼音) 字符，这些字符其实一个字节就可以表示了，也就是说，大部分情况下，字符串里面一半的空间都被浪费了。</p>
<p>那么问题又来了，有的时候的确要存非拉丁字符，比如汉字，这咋整，他们在String里面又存储了charset 字段用来保存这个字符的编码，按照编码来分配是一个字节存还是两个字节存。</p>
<p>凡是和String有关系的类，比如 StringBuilder StringBuffer 底层都变成了 byte[]。</p>
<h2 id="1-3-String-的不可变"><a href="#1-3-String-的不可变" class="headerlink" title="1.3 String 的不可变"></a>1.3 String 的不可变</h2><p>什么鬼，忘得特别干净，复习一下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 字面量赋值：  </span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 创建字符串，只要是这种通过字面量创建出来的字符串，他们的值都是存在字符串常量池中的，而且字符串常量池中不允许重复  </span></span><br><span class="line"><span class="comment">// 所以如果两个字符串通过字面量赋值相同，那么这两个字符串其实指向的是同一个地址，俩字符串的hashcode 相同。  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;  </span><br><span class="line">System.out.println(s1 == s2); <span class="comment">// 这里肯定是 true  </span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 如果对这种字符串进行重新赋值，他并不会修改常量池中的值，而是重新造一个值，然后改变指向，这就体现了字符串的不可变  </span></span><br><span class="line"><span class="comment">// 同理 字符串拼接，也是一个道理，并不是修改值，而是重新造一个值并修改指向  </span></span><br><span class="line"><span class="comment">// 包括 String.replace(old, new)，这个也是新造，不是修改。  </span></span><br><span class="line">s1 = <span class="string">&quot;hello&quot;</span>;  </span><br><span class="line">System.out.println(s1 == s2); <span class="comment">// 这回就是 false，因为s1 已经改变了指向  </span></span><br><span class="line">​  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 下面这个，s 还是 hello，别问，不知道为啥，但是如果直接在main 方法里面设置 s = &quot;test&quot;，他是可以修改成功的  </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;  </span><br><span class="line">    <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;hello&quot;</span>);  </span><br><span class="line">    change(s);  </span><br><span class="line">    System.out.println(s);  </span><br><span class="line">&#125;  </span><br><span class="line">​  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">change</span><span class="params">(String s)</span>&#123;  </span><br><span class="line">    s = <span class="string">&quot;test&quot;</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-4-字符串常量池"><a href="#1-4-字符串常量池" class="headerlink" title="1.4 字符串常量池"></a>1.4 字符串常量池</h2><ul>
<li><p>字符串常量池：String Pool 或者也叫 StringTable 是一个固定大小的HashMap，HashMap 总学过吧。默认大小是 1009 (jdk6)，如果存入的字符串过多，那么得到的HashKey也就会很多，从而导致链表过长，然后效率降低。</p>
</li>
<li><p>使用 <code>-XX:StringTableSize</code> 来指定常量池的大小。</p>
</li>
<li><p>jdk6中默认是 1009，固定的，可以通过参数修改，如果字符串过多则效率降低</p>
</li>
<li><p>jdk7以后默认就是60013，1009 是设置的最小长度</p>
</li>
</ul>
<h1 id="2-字符串拼接"><a href="#2-字符串拼接" class="headerlink" title="2. 字符串拼接"></a>2. 字符串拼接</h1><p>详细的说一说字符串拼接的操作, 当然也是介绍概念：</p>
<ul>
<li><p>常量和常量拼接结果在常量池，原理是编译期优化</p>
</li>
<li><p>常量池中不会重复</p>
</li>
<li><p>只要拼接的东西里面有一个是变量，那么拼接结果就放在堆里面，变量拼接原理是StringBuilder</p>
</li>
<li><p>如果拼接的结果调用inturn() 方法，则主动将常量池中还没有的字符串对象放入池中，返回地址</p>
</li>
</ul>
<p>然后我们一个一个说：</p>
<h2 id="2-1-常量拼接常量结果在常量池"><a href="#2-1-常量拼接常量结果在常量池" class="headerlink" title="2.1 常量拼接常量结果在常量池"></a>2.1 常量拼接常量结果在常量池</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// s1 是常量拼接字符串，所以他的结果在常量池里面，所以s1 == s2 是 true  </span></span><br><span class="line"><span class="comment">// 而且，如果我们把编译出来的class文件在idea里面打开，让idea 给我们做反编译，我们就会看到  </span></span><br><span class="line"><span class="comment">// s1 里面写的根本不是拼接操作，而是直接 String s1 = &quot;abc&quot;;  </span></span><br><span class="line"><span class="comment">// 这个就是编译期优化，他在编译的时候，发现你常量拼接，他就直接给你转化成拼接结果了。  </span></span><br><span class="line">​  </span><br><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span>+<span class="string">&quot;b&quot;</span>+<span class="string">&quot;c&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;  </span><br><span class="line">System.out.println(s1 == s2);  </span><br><span class="line">System.out.println(s1.equals(s2));</span><br></pre></td></tr></table></figure>

<h2 id="2-2-拼接变量结果入堆"><a href="#2-2-拼接变量结果入堆" class="headerlink" title="2.2 拼接变量结果入堆"></a>2.2 拼接变量结果入堆</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;java&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;hadoop&quot;</span>;  </span><br><span class="line">​  </span><br><span class="line"><span class="type">String</span> <span class="variable">s3</span> <span class="operator">=</span> <span class="string">&quot;javahadoop&quot;</span>;  </span><br><span class="line"><span class="comment">// 什么是编译期优化，就是两个字面值的字符串做拼接，在javac编译的时候就已经可以知道拼接结果了</span></span><br><span class="line"><span class="comment">// 那么他就会在编译的时候就给你把值赋好</span></span><br><span class="line"><span class="type">String</span> <span class="variable">s4</span> <span class="operator">=</span> <span class="string">&quot;java&quot;</span> + <span class="string">&quot;hadoop&quot;</span>; <span class="comment">// 编译期优化，等同于 s4 = &quot;javahadoop&quot;;  </span></span><br><span class="line"></span><br><span class="line">s3 == s4  <span class="comment">// true，且 s3 和 s4 都指向了字符串常量池中的javahadoop</span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 这里拼接出现了变量，如果我们去看字节码就会发现，他这里会创建一个StringBuilder给你进行拼接操作</span></span><br><span class="line"><span class="comment">// 然后拼接完成后给你return StringBuilder.toString(); </span></span><br><span class="line"><span class="comment">// 然后这个 toString() 方法会new String().</span></span><br><span class="line"><span class="comment">// 所以四舍五入就相当于在堆中 new String(),拼接结果位 javahadoop  </span></span><br><span class="line"><span class="comment">// 也就是，下面三个，都是独立的对象，那肯定是不相等了。  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s5</span> <span class="operator">=</span> s1 + <span class="string">&quot;hadoop&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s6</span> <span class="operator">=</span> <span class="string">&quot;java&quot;</span> + s2;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s7</span> <span class="operator">=</span> s1 + s2;  </span><br><span class="line"></span><br><span class="line">s3 == s5; <span class="comment">// false，而且s3和 s5 s6 s7 都不相等，愿意你很简单，一个是字符串常量池，另外的是堆中对象</span></span><br><span class="line">s5 == s6; <span class="comment">// false  </span></span><br><span class="line">s5 == s7; <span class="comment">// false  </span></span><br><span class="line">s6 == s7; <span class="comment">// false</span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// s6 是 javahadoop 是吧，很好，intern()就是判断常量池里面有没有 javahadoop，  </span></span><br><span class="line"><span class="comment">// 如果存在，则返回他的地址，如果不存在，则在常量池中创建一个，然后返回他的地址。  </span></span><br><span class="line"><span class="comment">// 至于这个intern方法后面会专门说。</span></span><br><span class="line"><span class="type">String</span> <span class="variable">s8</span> <span class="operator">=</span> s6.intern();   </span><br><span class="line">​  </span><br><span class="line">s3 == s8; <span class="comment">// true</span></span><br></pre></td></tr></table></figure>

<h1 id="3-变量拼接的底层原理"><a href="#3-变量拼接的底层原理" class="headerlink" title="3. 变量拼接的底层原理"></a>3. 变量拼接的底层原理</h1><p>我们写一个变量拼接：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">a1</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">a2</span> <span class="operator">=</span> <span class="string">&quot;def&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">a3</span> <span class="operator">=</span> a1 + a2;</span><br></pre></td></tr></table></figure>

<p>然后我们看他的字节码文件，如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">00 ldc #10 &lt;abc&gt;</span><br><span class="line">02 astore_0</span><br><span class="line">03 ldc #11 &lt;def&gt;</span><br><span class="line">05 astore_1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上面就对应a1 和 a2 的赋值操作，不说了，主要是下面：</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先new一个StringBuilder</span></span><br><span class="line">06 new #12 &lt;java/lang/StringBuilder&gt;</span><br><span class="line">09 dup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后调用构造函数</span></span><br><span class="line">10 invokespecial #13 &lt;java/lang/StringBuilder.&lt;init&gt; : ()V&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">读取局表的0位也就是 a1</span></span><br><span class="line">13 aload_0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">调用了StringBuilder的 append 方法，把a1传入</span></span><br><span class="line">14 invokevirtual #14 &lt;java/lang/StringBuilder.append :...;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">读取局表1位也就是a2</span></span><br><span class="line">17 aload_1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同理调用append方法</span></span><br><span class="line">18 invokevirtual #14 &lt;java/lang/StringBuilder.append : ...;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再调用toString 方法,这个toString 方法比较特殊，他的实现是 <span class="built_in">return</span> new String();</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所以 toString 约等于 new String() 为啥说约等于，以后再说。</span></span><br><span class="line">21 invokevirtual #15 &lt;java/lang/StringBuilder.toString : ...;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把结果存储到局表2位</span></span><br><span class="line">24 astore_2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">剩下就是输出了</span></span><br><span class="line">25 getstatic #2 &lt;java/lang/System.out :...;&gt;</span><br><span class="line">28 aload_2</span><br></pre></td></tr></table></figure>

<p>注意，用StringBuilder底层去拼接的，必须是变量，可不是说必须是引用，举个例子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">a</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span> + <span class="string">&quot;def&quot;</span>;  </span><br><span class="line">​  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 这个，它仅仅是应用，而不是变量，所以这种情况下他也不会用StringBuilder来构建  </span></span><br><span class="line"><span class="comment">// 所以这里仍旧会进行编译期优化  </span></span><br><span class="line"><span class="keyword">final</span> <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;  </span><br><span class="line"><span class="keyword">final</span> <span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;def&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s3</span> <span class="operator">=</span> s1 + s2;</span><br></pre></td></tr></table></figure>

<h2 id="3-1-执行效率问题"><a href="#3-1-执行效率问题" class="headerlink" title="3.1 执行效率问题"></a>3.1 执行效率问题</h2><p>直接创建StringBuilder来拼接肯定是快，而且快很多，所以我们要字符串拼接我们不如直接创建一个StringBuilder或者StringBuffer来得实在。</p>
<p>默认情况下 StringBuilder的容量是16，如果不够了会进行扩容，也消耗性能，所以我们尽可能的给他确定一下容量。</p>
<h2 id="3-2-创建对象数"><a href="#3-2-创建对象数" class="headerlink" title="3.2 创建对象数"></a>3.2 创建对象数</h2><p>我们创建一个字符串：<code>new String(&quot;abc&quot;)</code>，这行代码创建了几个对象。很好，遇事不决字节码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第一步，创建一个 String，也就是 new</span></span><br><span class="line">00 new #16 &lt;java/lang/String&gt;</span><br><span class="line">03 dup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后，在常量池里面创建字符串 <span class="string">&quot;abc&quot;</span>,然后把 abc 传入 构造函数</span></span><br><span class="line">04 ldc #10 &lt;abc&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">调用构造，根据常量池里面的字符串在堆中创建对象</span></span><br><span class="line">06 invokespecial #17 &lt;java/lang/String.&lt;init&gt; : (Ljava/lang/String;)V&gt;</span><br><span class="line">09 astore_0</span><br><span class="line">10 return</span><br></pre></td></tr></table></figure>

<p>所以这么来看创建了几个对象？很显然是两个：一个是堆中的String，一个是常量池中的abc。</p>
<p>然后再说一下这个常量池的问题，为啥这里创建String的时候会在常量池中也创建一个？我个人觉得是因为我们传入的是一个字面量的字符串，所以他会把这个字面量存入常量池。</p>
<h2 id="3-3-更高级的对象数问题"><a href="#3-3-更高级的对象数问题" class="headerlink" title="3.3 更高级的对象数问题"></a>3.3 更高级的对象数问题</h2><p>一行代码：<code>String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);</code> ，这行代码创建了几个对象。同理，于是不决字节码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 创建 StringBuilder 对象，用来待会的拼接操作</span></span><br><span class="line">00 new #5 &lt;java/lang/StringBuilder&gt;</span><br><span class="line">03 dup</span><br><span class="line">04 invokespecial #6 &lt;java/lang/StringBuilder.&lt;init&gt; : ()V&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2.创建 String 对象，对应 new String(<span class="string">&quot;a&quot;</span>);</span></span><br><span class="line">07 new #2 &lt;java/lang/String&gt;</span><br><span class="line">10 dup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3.在字符串常量池里面创建 <span class="string">&quot;a&quot;</span></span></span><br><span class="line">11 ldc #7 &lt;a&gt;</span><br><span class="line">13 invokespecial #4 &lt;java/lang/String.&lt;init&gt; :...&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里 StringBuilder 进行了 append操作。</span></span><br><span class="line">16 invokevirtual #8 &lt;java/lang/StringBuilder.append :...;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4.创建String对象，对应 new String(<span class="string">&quot;b&quot;</span>);</span></span><br><span class="line">19 new #2 &lt;java/lang/String&gt;</span><br><span class="line">22 dup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5.常量池里面创建 <span class="string">&quot;b&quot;</span></span></span><br><span class="line">23 ldc #9 &lt;b&gt;</span><br><span class="line">25 invokespecial #4 &lt;java/lang/String.&lt;init&gt; : ...&gt;</span><br><span class="line">28 invokevirtual #8 &lt;java/lang/StringBuilder.append :  ...;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">6.StringBuilder 调用 toString 方法，这里又创建一个 String</span></span><br><span class="line">31 invokevirtual #10 &lt;java/lang/StringBuilder.toString : ...;&gt;</span><br><span class="line">34 astore_0</span><br><span class="line">35 return</span><br></pre></td></tr></table></figure>

<p>根据上面的解析，可以知道，一个语句总共创建了6个对象，只得注意的是，最终结果是 “ab”，但是直到最后 常量池里面也没有 “ab” 这个字符串，虽然说在toString 里面创建了字符串，通过 new String() ，我们之前说 new String(xxx) 会在pool中创建xxx，但是这里为啥就不创建了？我觉得是因为构造函数里面传入的不是字面量了，而是变量，所以不会再创建ab常量了。</p>
<h1 id="4-intern方法"><a href="#4-intern方法" class="headerlink" title="4. intern方法"></a>4. intern方法</h1><p>可以去String类里面看看他的注释，全英语的，反正我看不懂，所以下面大致给说一下</p>
<h2 id="intern-方法介绍"><a href="#intern-方法介绍" class="headerlink" title="intern 方法介绍"></a>intern 方法介绍</h2><p>首先，本地方法。</p>
<p>一个不是用字面量创建的字符串(注意，不是字面量创建的)，调用这个方法，他就会去 pool 里面找，有没有和当前字符串相等的字符串常量，如果有，则返回这个字符串的引用；如果没有，则在pool里面创建一个，然后返回引用。</p>
<p>如果有两个字符串 s t, s.intern() &#x3D;&#x3D; t.intern() 成立，当且仅当 s.equals(t) 成立。</p>
<p>举个例子：</p>
<p><code>String s = new String(&quot;hello world&quot;).intern()</code></p>
<p>这行代码就是：堆中创建了一个 字符串 “hello world”，然后调用 intern 去看 StringTable 里面有没有 helloworld，如果没有，则创建一个，然后返回引用给s。</p>
<p>再看一个例子：</p>
<p><code>(&quot;a&quot; + &quot;b&quot; + &quot;c&quot;).intern() == &quot;abc&quot;</code></p>
<p>这个必然是 true，因为在 最前面拼接的时候，就已经在pool里面创建了”abc”。</p>
<p>所以总结一下，就是去字符串常量池中找有没有当前字符串的字面量常量，如果有则返回，如果没有则创建后返回。总之执行完这个方法，可以保证返回的东西指向了字符串常量池。</p>
<h1 id="5-一道String面试题"><a href="#5-一道String面试题" class="headerlink" title="5. 一道String面试题"></a>5. 一道String面试题</h1><p>上代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="comment">// 首先，创建了 s1，堆中一个，pool中一个，都是 &quot;a&quot;  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;a&quot;</span>);  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 这条代码是在pool中创建对象，但是已经有了，所以这行没用，同时他没有接收，s1 不变。  </span></span><br><span class="line">s1.intern();  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 又创建了一个对象，指向pool中的 &quot;a&quot;  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span>;  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 所以这个没有异议，肯定是 false  </span></span><br><span class="line"><span class="comment">// jdk6/7/8   false  </span></span><br><span class="line">System.out.println(s1 == s2);            </span><br><span class="line">​  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 这里就开始扯淡了，看这行代码，创建了一堆对象，常量池中的 &quot;a&quot; 堆中的 &quot;a&quot;,  </span></span><br><span class="line"><span class="comment">// s3 是堆中的 aa，但常量池中可没有aa，老生常谈了，上面就重点说过。  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;a&quot;</span>) + <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;a&quot;</span>);  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 然后在常量池中创建 &quot;aa&quot;,这里就开始有区别了，  </span></span><br><span class="line"><span class="comment">// jdk6 中，常量池在永久代里面，和堆没半毛钱关系，所以就是你想的那样，在pool中创建了 &quot;aa&quot;  </span></span><br><span class="line"><span class="comment">// 然后s4是常量池中的，s3 是堆中的，没关系，所以结果是 false。  </span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 而jdk7/8 不一样，jdk7/8的常量池在堆中，他在常量池创建对象的时候，一看，哎，  </span></span><br><span class="line"><span class="comment">// 堆里面已经有了一个对象(注意是堆中，不是常量池中)，所以他为了节省资源，他不会在常量池中再次创建对象，  </span></span><br><span class="line"><span class="comment">// 而是在常量池中创建一个引用，这个引用指向堆中，在这里就是s3,  </span></span><br><span class="line"><span class="comment">// 最后的结果就是，s4 指向常量池中的那个值，结果常量池中的值指向了s3，相当于 s4 变相的指向了 s3.  </span></span><br><span class="line"><span class="comment">// 所以结果是 true  </span></span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 但是注意，jdk7/8 中这种从常量池指向堆这种行为，只有 intern() 才会触发，  </span></span><br><span class="line"><span class="comment">// 你正常的 s5 = &quot;aa&quot;; 他是不会触发这种指向的，他还是会正常的在常量池中创建。  </span></span><br><span class="line">s3.intern();  </span><br><span class="line"><span class="type">String</span> <span class="variable">s4</span> <span class="operator">=</span> <span class="string">&quot;aa&quot;</span>;  </span><br><span class="line"><span class="comment">// jdk6 false   jdk7/8 true  </span></span><br><span class="line">System.out.println(s3 == s4);</span><br></pre></td></tr></table></figure>

<h2 id="变式"><a href="#变式" class="headerlink" title="变式"></a>变式</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这回的结果就是 false，原因很简单，根据上面的叙述，常量池引用堆只有intern才会触发，  </span></span><br><span class="line"><span class="comment">// 这里改变顺序，先创建 s2，这里就会在常量池中创建 &quot;aa&quot;,然后intern() 就会发现已经存在 &quot;aa&quot;，就不会指向堆。  </span></span><br><span class="line"><span class="comment">// 所以 s1 和 s2 是两个不同的对象，结果是false  </span></span><br><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;a&quot;</span>) + <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;a&quot;</span>);  </span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;aa&quot;</span>;  </span><br><span class="line">s1.intern();  </span><br><span class="line">System.out.println(s1 == s2);</span><br></pre></td></tr></table></figure>

<h2 id="总结-intern-的使用："><a href="#总结-intern-的使用：" class="headerlink" title="总结 intern 的使用："></a>总结 intern 的使用：</h2><h3 id="jdk6"><a href="#jdk6" class="headerlink" title="jdk6"></a>jdk6</h3><ul>
<li><p>如果池中有，则不会创建，而是返回地址</p>
</li>
<li><p>池中没有，把当前字符串拷贝一份放入池中</p>
</li>
</ul>
<h3 id="jdk7-x2F-8"><a href="#jdk7-x2F-8" class="headerlink" title="jdk7&#x2F;8"></a>jdk7&#x2F;8</h3><ul>
<li><p>池中有，则返回地址，和上面一样</p>
</li>
<li><p>池中没有，则拷贝当前字符串的地址放到池中，让池指向堆，节约空间，然后返回地址。</p>
</li>
</ul>
<h1 id="6-G1的String去重行为"><a href="#6-G1的String去重行为" class="headerlink" title="6. G1的String去重行为"></a>6. G1的String去重行为</h1><blockquote>
<p>首先说一下G1，简单说，就是jdk7以后jvm里面的一个垃圾回收器。</p>
<p>这个gc并不分minor gc 还是 major gc，我查了一下，他似乎是一个整体的垃圾回收器，然后里面细分为回收年轻代 老年代等的行为。所以G1(G First) 就是一个全局的垃圾回收器。</p>
</blockquote>
<p>明确一个概念，这里的去重，当然不是指的字符串常量池中去重，pool中本来就没有重复对象，这个去重指的是堆中去重。</p>
<h2 id="6-1-去重的背景"><a href="#6-1-去重的背景" class="headerlink" title="6.1 去重的背景"></a>6.1 去重的背景</h2><p>对于许多java应用，经过测试发现如下：</p>
<ul>
<li><p>堆存活数据集合里面String 对象占25%</p>
</li>
<li><p>堆存活数据集合里面重复的String 占 13%</p>
</li>
<li><p>String 平均长度 45</p>
</li>
</ul>
<h2 id="6-2-实现"><a href="#6-2-实现" class="headerlink" title="6.2 实现"></a>6.2 实现</h2><ul>
<li><p>当垃圾收集器工作时会访问堆上的存活对象，检查是否是候选的去重字符串</p>
</li>
<li><p>如果是，把字符串加入一个队列，一个去重的后台线程对这个队列进行处理，处理就是删除队列元素然后尝试进行去重操作</p>
</li>
<li><p>使用一个hashtable来记录所有被String使用的不重复的char数组(就是String底层的char数组，去重主要是去重这个)，进行去重的时候会去查这个char数组，来检查堆上是否已经存在了一个一模一样的char数组。</p>
</li>
<li><p>如果存在，那么当前String就会改为引用已有的那个char数组，它本身的那个char数组会被释放。</p>
</li>
<li><p>如果不存在，那么当前char数组进入hashtable，然后对下一个String去重。</p>
</li>
</ul>
<h2 id="6-3-开启"><a href="#6-3-开启" class="headerlink" title="6.3 开启"></a>6.3 开启</h2><p>UseStringDeduplication(boolean) 开启String去重，默认是不开启的。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>字节码指令</title>
    <url>/2022/06/13/bytecode-command/</url>
    <content><![CDATA[<p>这章就是具体的各种字节码指令，深入的说一下每个指令都是干嘛的。</p>
<span id="more"></span>

<h1 id="1-加载与存储指令"><a href="#1-加载与存储指令" class="headerlink" title="1. 加载与存储指令"></a>1. 加载与存储指令</h1><p>因为我们之前说过了，数据的来源可以是局部变量表，常量池，方法调用，所以这里还得区分。</p>
<h2 id="1-1-局部变量压栈指令"><a href="#1-1-局部变量压栈指令" class="headerlink" title="1.1 局部变量压栈指令"></a>1.1 局部变量压栈指令</h2><p>从局部变量表中的取得相应的数据，压入操作数栈，大体可以分为两类：</p>
<ul>
<li><p>xload (x 可以是 i l f d a)</p>
</li>
<li><p>xload&lt;_n&gt; (n 从 0 - 3)</p>
</li>
</ul>
<p>为啥要分出两个，_n 有啥用？很简单，根据概率来说，xload 0 1 2 3 用的最多，所以封装成了 xload_0 1 2 3.在字节码文件中，一个指令只有一个字节，而操作数2个字节，用 xload_n可以省地方。</p>
<p>然后这里面涉及到了局部变量表，这里复习一下：局部变量表里面有槽位，一个槽slot是4个字节，然后如果我们把long放进去，那long就是占两个slot，比如 0 位是this，1位是long，那3位就是int，没有2了，1 2 都被long占用了。</p>
<p>然后具体说说后面的操作数，现在有一个指令: xload 5，那他就是把局部变量表中index&#x3D;5的东西，压入栈。注意，是index&#x3D;5，索引为5的局表数据，看好了，可不是局表里面第一列那个数字，那是个数。</p>
<h2 id="1-2-常量入栈指令"><a href="#1-2-常量入栈指令" class="headerlink" title="1.2 常量入栈指令"></a>1.2 常量入栈指令</h2><p>指令const系列：这个命令用于特定常量压操作数栈，注意是特定常量，这个常量直接写在指令中，且后面没有操作数，注意这个很重要，const指令没有操作数，而且这个常量得注意，不是说非得是 final 修饰的常量，字面量也算是这里的常量，我们定义一个字面量 int i &#x3D; 10 那这里也会用这些指令进行压栈操作。具体指令如下：</p>
<ul>
<li><p>iconst_i (i -&gt; -1(m1) 到 5)</p>
</li>
<li><p>lconst_l (l -&gt; 0到1)</p>
</li>
<li><p>fconst_f (f -&gt; 0 到 2)</p>
</li>
<li><p>dconst_d (d -&gt; 0 到 1)</p>
</li>
<li><p>aconst_null (压null)</p>
</li>
</ul>
<p>是的，这些数据范围没有任何规律，别问为啥，反正就是这样。</p>
<p>比如，将常量 2 压入栈，那就是 iconst_2，那压6呢？iconst 6么，我们之前说了，const系列指令没有操作数，所以显然不行。这里得用另外一个系列指令：push系列指令。</p>
<p>指令 push 系列：主要就是 bipush 和 sipush，主要就是接收数据类型不同，bipush接收8位整数压栈，sipush接收16位整数压栈。(128就已经是16位了)，具体范围就是 bipush：-128 - 127. sipush：-32768 - 32767</p>
<p>如果还是不行，那就可以使用 ldc 指令，这个指令是干嘛的呢，他接受一个8位参数，这个参数指向常量池中 int float String 索引，然后将常量池中的指定内容压入栈。如果索引比较大，可以使用 ldc_w指令，接受两个8位参数，仅仅是索引范围变大了而已。如果压入 long double，那就是用 ldc2_w，怎么理解呢，粗略的理解成double 和 long 占两个槽位吧。</p>
<p>三个的区别就是 const -&gt; push -&gt; ldc 范围依次增大。</p>
<h2 id="1-3-出栈装入局部变量表指令"><a href="#1-3-出栈装入局部变量表指令" class="headerlink" title="1.3 出栈装入局部变量表指令"></a>1.3 出栈装入局部变量表指令</h2><p>首先我先猜测一下，一般来说数据不会直接装入局表，除非是方法的形参已经实例方法的this。一般来说局部变量都是先进入操作数栈，再从栈出来进入局表，大致应该是啊。</p>
<p>装入局表指令 store 系列：</p>
<ul>
<li><p>xstore&lt;_n&gt; 同理x可以是 i l f d a. n可以是 0 - 3</p>
</li>
<li><p>xstore</p>
</li>
</ul>
<p>这个命令的意思是，把操作数栈 栈顶的元素，弹出，然后放入局部变量表index 为 n 的地方。注意，始终弹得是栈顶元素。</p>
<p>当然了，有特殊的东西，比如存入数组这种的，去看尚硅谷的手册，我这里不提供了。</p>
<h1 id="2-算数指令"><a href="#2-算数指令" class="headerlink" title="2. 算数指令"></a>2. 算数指令</h1><p>加法指令：iadd，ladd，fadd，dadd</p>
<p>减法指令：isub，lsub，fsub，dsub</p>
<p>乘法指令：imul，lmul，fmul，dmul</p>
<p>除法指令：idiv，ldiv，fdiv，ddiv</p>
<p>取余指令：irem，lrem，frem，drem # remainder</p>
<p>取反指令：ineg，lneg，fneg，dneg # negation</p>
<p>自增指令：iinc xx(局表index) by xx(增加的具体数值)</p>
<p>需要注意的是，前面的很多指令，比如 add，div这种，其实是把操作数栈中的栈顶两个数，弹出，运算，再压栈，所以没有操作数。但是比较特殊的就是 iinc，比如我们 <code>int i = 0; int j = i + 10;</code> 这里就会用到自增，int j &#x3D; i + 10的指令就是 <code>iinc i在局表的位置 by 10</code>.</p>
<h1 id="3-数据类型转化"><a href="#3-数据类型转化" class="headerlink" title="3. 数据类型转化"></a>3. 数据类型转化</h1><p>基本格式很简单，就是 x2y，x y 分别代表俩类型呗，然后 to 呗，很简单，然后我们细分一下。</p>
<p>首先，根据转化的类型，分为两种：宽化数据类型转换，窄化数据类型转换，其实很简单，就是 小范围到大范围 和 大范围到小范围，我们先说宽化：</p>
<h2 id="3-1-宽化数据类型转换"><a href="#3-1-宽化数据类型转换" class="headerlink" title="3.1 宽化数据类型转换"></a>3.1 宽化数据类型转换</h2><ul>
<li><p>int 到大范围：i2l, i2f, i2d</p>
</li>
<li><p>long 到大范围：l2f, l2d</p>
</li>
<li><p>float 到大范围：f2d</p>
</li>
</ul>
<p>说白了就是： int –&gt; long –&gt; float –&gt; double，这个也就是自动类型转换，虽然你的代码没有体现任何的类型转换，但是字节码会给你加上这部分的。</p>
<h2 id="3-2-精度问题"><a href="#3-2-精度问题" class="headerlink" title="3.2 精度问题"></a>3.2 精度问题</h2><p>既然这里宽数据类型转换，那就肯定要涉及到精度问题：</p>
<ul>
<li><p>首先 int 转换为 long，double 不会发生精度丢失。</p>
</li>
<li><p>int 或者 long 转换为 float，或者 long 转化成 double，都有可能造成精度丢失，可能会丢失最低有效位上的某些值，转化后的浮点数值是根据 IEEE754最接近舍入模式所得到的正确整数值。</p>
</li>
</ul>
<p>这里举个例子，有如下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">123123123</span>;</span><br><span class="line"><span class="type">float</span> <span class="variable">j</span> <span class="operator">=</span> i;</span><br><span class="line">System.out.println(j);</span><br></pre></td></tr></table></figure>

<p>这里的 j 就是 1.2312312E8，也就是 123123120。</p>
<h2 id="3-3-关于-byte-short-char-的问题"><a href="#3-3-关于-byte-short-char-的问题" class="headerlink" title="3.3 关于 byte short char 的问题"></a>3.3 关于 byte short char 的问题</h2><p>是的，你没有看到任何关于 byte short char 的转换指令，为啥？因为压根就没有，比如 byte -&gt; long，其实jvm底层是用的 i2l 来实现的，JVM 肯定会把 byte short long 当做int处理。</p>
<p>至于为什么这么设计，因为在局部变量表中一个slot就是4个字节的，或者说32bit，那你这个 byte short long 存进去，那不还是用int的slot来存么，那在底层就完全没有必要区分byte short char了，而且，如果再设计这些指令，指令集可就不够了，毕竟一个指令就是一个字节，所以最多只有256 个指令。</p>
<h2 id="3-4-窄化类型转换"><a href="#3-4-窄化类型转换" class="headerlink" title="3.4 窄化类型转换"></a>3.4 窄化类型转换</h2><p>说的好高级啊，其实就是强制类型转化，把大范围数据类型强制转化为小范围</p>
<ul>
<li><p>int 转化为 byte short char：i2b, i2s, i2c</p>
</li>
<li><p>long转化为 int：l2i</p>
</li>
<li><p>float 转化为 int 或者 long：f2i, f2l</p>
</li>
<li><p>double 转化为 int, long, float：d2i, d2l, d2f</p>
</li>
<li><p>如果是 float 或者 long 转化为 byte 这种，没有直接的指令支持，那就只好两步走：f2i + i2b</p>
</li>
<li><p>如果是 double -&gt; byte，肯定不会 d2f, f2i, i2b, 直接就是 d2i, i2b。一般来说转化最多就是两步</p>
</li>
</ul>
<p>这个也会有精度损失问题，而且很有可能出现精度损失，但是不管精度损失成啥样，都不会抛出异常，特殊的，如果是 byte 转化为 short，直接就是 i2s，没有b2i这一说啊记着。</p>
<h2 id="3-5-窄化的特殊情况："><a href="#3-5-窄化的特殊情况：" class="headerlink" title="3.5 窄化的特殊情况："></a>3.5 窄化的特殊情况：</h2><p>当一个浮点数转化为整数时，遵循以下规则：</p>
<ul>
<li><p>浮点数是 NaN，转化结果就是 int 或者 long 的0</p>
</li>
<li><p>如果浮点数不是无穷大，那没啥好说的，直接取舍就行了</p>
</li>
</ul>
<p>当一个double转化为 float的时候：</p>
<ul>
<li><p>double如果特别接近0，接近到float都没法表示了，转化结果就为正负0</p>
</li>
<li><p>如果double是无穷大，float没法表示，结果就是 float的正负无穷大 Infinity</p>
</li>
<li><p>如果double是NaN，那float转化完也是NaN</p>
</li>
</ul>
<p>那当double转化为 long 或者 int 呢，如果double大到int long 没法表示，那int 和long 就会被转化为他们所能表示的最大值。</p>
<h1 id="4-对象创建与访问指令"><a href="#4-对象创建与访问指令" class="headerlink" title="4. 对象创建与访问指令"></a>4. 对象创建与访问指令</h1><p>因为 Java是面向对象的语言，所以在字节码层面就对对象做了非常好的支持，有很多指令都是用于对象的。同时对象又分出两类，一类就是类的实例，另一类就是数组，各种各样的数组。</p>
<h2 id="4-1-对象创建指令"><a href="#4-1-对象创建指令" class="headerlink" title="4.1 对象创建指令"></a>4.1 对象创建指令</h2><p>分为两种，创建类实例和创建数组。</p>
<ul>
<li><p>创建类实例：new，操作码就是new，操作数是一个指向常量池的索引，这个索引就是具体的类全限定名</p>
</li>
<li><p>创建数组：newarray 创建基本数据类型数组，anewarray 创建引用数据类型数组，multianewarray 创建多维数组，如果是基本数据类型数组，后面的操作数就是数组长度，如果是引用数据类型，操作数就是指向常量池的索引，具体就是你引用的类型的全限定命名。</p>
</li>
</ul>
<p>创建完成后，自动把创建好的对象压入操作数栈。</p>
<p>关于数组的创建这里，有点坑，就是 关于 multianewarray这个指令，什么时候会用这个指令呢？就是你多维数组的维数完全确定，才会用这个指令，比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[][] s1 = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">10</span>][<span class="number">5</span>];</span><br><span class="line"><span class="comment">// 这里的指令是 multianewarray</span></span><br><span class="line"></span><br><span class="line">String[][] s2 = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">10</span>][];</span><br><span class="line"><span class="comment">// 这里的指令是 anewarray</span></span><br></pre></td></tr></table></figure>

<p>至于为啥，如果你的维数不确定，那JVM只能知道你创建了一个一维数组，但是一维数组里面的数组长度是多少JVM不知道，所以JVM不确定你里面的是不是数组，只有维数确定的情况下，JVM才能肯定你是要创建一个多维数组，才给你用 multianewarray 这个指令</p>
<h2 id="4-2-类成员-字段-的访问指令"><a href="#4-2-类成员-字段-的访问指令" class="headerlink" title="4.2 类成员(字段)的访问指令"></a>4.2 类成员(字段)的访问指令</h2><p>这里只针对类里面的字段，对于数组的还有专门的指令。</p>
<ul>
<li><p>访问类字段：getstatic，putstatic。分别代表 把类字段压入操作数栈，和 给类字段赋值。</p>
</li>
<li><p>访问类实例字段：getfield，putfield。代表的东西和上面一样。</p>
</li>
</ul>
<p>get 这个指令没啥好说的其实，就是后面跟这个常量池索引，把响应的内容（也就是字段信息，fieldref）压入操作数栈。</p>
<p>put 这个还真得说说，看下面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Order</span>&#123; id = <span class="number">10</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="type">Order</span> <span class="variable">order</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Order</span>();</span><br><span class="line">order.id = <span class="number">20</span>;</span><br><span class="line"><span class="comment">// new #x &lt;....Order&gt;</span></span><br><span class="line"><span class="comment">// dup</span></span><br><span class="line"><span class="comment">// invokespecial #x &lt;....Order.&lt;init&gt;</span></span><br><span class="line"><span class="comment">// astore_1</span></span><br><span class="line"><span class="comment">// aload_1</span></span><br><span class="line"><span class="comment">// bipush 20</span></span><br><span class="line"><span class="comment">// putfield #x &lt;...Order.id&gt;</span></span><br></pre></td></tr></table></figure>

<p>最后就是 putfield #x，所以这个putfield到底是怎么运作的？</p>
<p>我们在给 id 赋值的之前，操作数栈栈顶就是order对象的地址（为了省事，以后直接说对象），然后赋值的时候又压入操作数栈 20，然后putfield，putfield这个时候就会把栈里面的前两个东西弹出来，根据后面的操作数（一个fieldref_info）确定要给对象的哪个字段赋值，然后就会给弹出来的第二个对象的相应字段赋上第一个弹出来的值。</p>
<p>说人话，就是现在操作数栈里有一个对象和一个待赋的值，然后putfield给他俩弹出来，根据接收的操作数，就给对象的响应字段赋上那个值。</p>
<p>注意，这两种指令：getstatic 和 putstatic 指令，他们的操作数都是一个 fieldref_info，表示要给哪个字段赋值或者取出，但是具体执行这个操作的对象，以及要被赋的值，都是从操作数栈中弹出来的。</p>
<h2 id="4-3-数组元素操作指令"><a href="#4-3-数组元素操作指令" class="headerlink" title="4.3 数组元素操作指令"></a>4.3 数组元素操作指令</h2><ul>
<li>把数组元素压入操作数栈指令：baload, saload, caload, iaload, laload, faload, daload, aaload，首先 aload 代表 arrayLoad，然后这些首字母分别代表：byte short char int long float double 引用。</li>
</ul>
<p>xaload系列的指令需要从操作数栈中弹出2个值，分别是：数组元素索引（int），数组引用，然后他就会把指定数组里面的指定索引的元素对应的值重新压回操作数栈。</p>
<ul>
<li>把操作数栈的值赋值给数组元素：bastore, castore, sastore, iastore, lastore, fastore, dastore, aastore，和上面差不多，不多解释。</li>
</ul>
<p>这个xastore系列指令需要从操作数栈弹出3个值，分别是（按顺序）：待赋的值，数组元素的引用（int），数组引用。astore指令就会给对应的数组的指定索引的元素赋上对应的值。</p>
<ul>
<li>获取数组长度：arraylength，也没有操作数，从操作数栈栈顶弹出数组引用，获取长度，然后把长度（int）重新压回操作数栈。</li>
</ul>
<p>这两类指令可都没有操作数，只有一个操作码，操作数全都是从操作数里弹出来的。</p>
<p>还有就是上面的那些数据类型没有boolean，很简单，boolean数组用的指令也是 baload和bastore。</p>
<h2 id="4-4-类型检查指令"><a href="#4-4-类型检查指令" class="headerlink" title="4.4 类型检查指令"></a>4.4 类型检查指令</h2><p>Java语法层面有instanceof 关键字，就是判断一个对象是不是一个类的实例，如果是，那就可以强制类型转换，那么强制转换在JVM层面怎么执行的？</p>
<ul>
<li><p>instanceof 指令：跟着一个操作数，这个操作数是一个常量索引，一个类名，他会从操作数栈中弹出栈顶的实例引用，然后把弹出的引用和操作数的类型作对比。如果满足，把true压入操作数栈，如果不满足，压入false。（其实我也不知道他到底最后压回栈的是啥，姑且说是true&#x2F;false）。</p>
</li>
<li><p>checkcast 指令：类型进行强制转换的时候会有，他会判断能否进行转换，和 instanceof 差不多，他有一个操作数也是指向常量池的，一个类，然后也会从操作数栈弹出栈顶的实例引用，如果可以强制转换，那就转换就行了，如果不行，抛出 ClassCastException。</p>
</li>
</ul>
<h1 id="5-方法指令"><a href="#5-方法指令" class="headerlink" title="5. 方法指令"></a>5. 方法指令</h1><h2 id="5-1-方法调用"><a href="#5-1-方法调用" class="headerlink" title="5.1 方法调用"></a>5.1 方法调用</h2><p>方法调用总共就几个指令，分别是：</p>
<ul>
<li><p>invokevirtual：用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），支持多态，是Java中最常见的调用指令。这个具体说说，就是说JVM在执行你的方法的时候，并不知道你这个方法是谁的，还真不一定是当前类型的，因为很可能你这里用到了类的上转型（可不是接口的啊，接口引用调用方法可就是invokeinterface了），比如 <code>Thread t = new XXXThread(); t.run(); </code>，你这个run，已经被你XXXThread重写了，所以JVM搞不清楚了，这个得具体情况具体分析，得运行以后根据你具体的实现类，去调用方法，这就叫虚方法分派。</p>
</li>
<li><p>invokeinterface：这个就是调用接口回调的方法，比如 <code>XXXInterface xx = new XXXInterfaceImpl(); xx.func();</code>，这个情况下就是 invokeinterface指令。</p>
</li>
<li><p>invokespecial：调用 构造器，私有方法，父类方法的时候的指令，这三种方法比较特殊，因为都不能重写，构造器和私有方法那是废话，子类是铁定不能重写的，那调用父类方法？这个调用父类方法就是 super.xxx() 这种形式，这个就算你子类重写了，你super也是调用的父类的方法，和你当前子类没半毛钱关系。</p>
</li>
<li><p>invokestatic：调用静态方法，这个好理解。</p>
</li>
<li><p>invokedynamic：这个比较复杂，不说了。</p>
</li>
</ul>
<p>特别的，如果一个方法是 private static 的，那优先考虑 static，指令那就是 invokestatic。</p>
<p>如果是接口中的已经实现的方法呢？众所周知（我还真不知道JDK8的接口可以有静态方法），jdk8的接口可以有default 方法和 static 方法（都可以实现），那么我们调用这两种方法，指令是啥？看例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">AA</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="title function_">method1</span><span class="params">()</span>&#123; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">default</span> <span class="title function_">method2</span><span class="params">()</span>&#123; &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BB</span> <span class="keyword">implements</span> <span class="title class_">AA</span>&#123; &#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">    <span class="type">AA</span> <span class="variable">aa</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BB</span>();</span><br><span class="line">    aa.method2(); <span class="comment">// invokeinterface</span></span><br><span class="line">    AA.method1(); <span class="comment">// invokestatic</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，即便是方法在接口中已经实现了，指令仍旧是 invokeinterface，但是接口中的静态方法可不是invokeinterface，即便他是在接口中定义的，调用接口中的静态方法指令是 invokestatic，可以看得出来static的优先级比interface高。</p>
<h2 id="5-2-方法返回："><a href="#5-2-方法返回：" class="headerlink" title="5.2 方法返回："></a>5.2 方法返回：</h2><p>这个倒是很简单，分为有返回值和无返回值：</p>
<ul>
<li><p>有返回值：ireturn（返回 boolean byte char short int），lreturn，freturn，dreturn，areturn。这个返回值类型啊，主要看的是你定义方法的时候写的方法返回值，就算你是 <code>public float f()&#123;int i = 10; return i;&#125;</code> 最后返回也是freturn，和你具体返回的啥没太大关系。</p>
</li>
<li><p>无返回值：return</p>
</li>
</ul>
<p>如果有返回值，那他具体会干啥？他会把当前栈帧的操作数栈的栈顶元素弹出，然后结束方法，方法一结束栈帧出栈，操作数栈也没了，然后把这个栈顶元素，压入调用这个方法的方法的操作数栈。</p>
<h1 id="6-操作数栈管理指令："><a href="#6-操作数栈管理指令：" class="headerlink" title="6. 操作数栈管理指令："></a>6. 操作数栈管理指令：</h1><p>这里的管理，指的是不需要借助任何的东西，操作数栈自己进行操作。</p>
<ul>
<li><p>直接废弃栈顶元素，直接弹出：pop，pop2。区别就是 pop 弹出一个slot的元素，pop2弹出两个slot的元素。</p>
</li>
<li><p>复制操作：dup，dup2，dup_x1，dup2_x1，dup_x2，dup2_x2。</p>
</li>
<li><p>交换：swap，交换栈顶的两个 1slot元素，注意，只能是两个 1slot的元素交换，JVM没有提供两个 2slot的元素的交换指令。</p>
</li>
<li><p>nop：啥也不干，对应的16进制是0x00，就是用来站位。</p>
</li>
</ul>
<p>dup需要特别说一下，这个复制是复制栈顶的一个或者两个元素，注意，可以一次复制两个的。然后 dup 和 dup2的区别就是 dup复制1slot的元素，dup2复制占2slot的对应元素，注意我说的可以占2slot的东西，还真不一定是仅仅复制一个2slot的单个元素。比如dup2可以复制栈顶的long，double，也可以复制栈顶的两个元素，一个是int，另一个是float。</p>
<p>然后，dup指令如果后面带有_x，那就不是单纯的复制，而是复制完了以后把复制品插入到另外的位置。那么具体插入到哪呢？有个技巧：</p>
<p>dup[n]_xm，对吧，n 如果没有那就是 1，有了那就是2。这条指令的具体意思是，先复制，然后把复制结果往下挪 n + m 个slot。</p>
<p>首先举例子：什么情况下会pop，看下面的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Object</span> <span class="variable">obj1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    <span class="type">Object</span> <span class="variable">obj2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 上面的指令省略，不用想，肯定是 new dup invokespecial astore，着重看下面两行：</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">hash</span> <span class="operator">=</span> obj1.toString();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// invokevirtual &lt;...Object.toString&gt;</span></span><br><span class="line">    <span class="comment">// astore_2</span></span><br><span class="line">    <span class="comment">// 这里因为我们把他赋值给了局部变量，所以存入局部变量表，那么说明这个 toString 的返回值有用</span></span><br><span class="line">    obj2.toString();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// invokevirtual &lt;...Object.toString&gt;</span></span><br><span class="line">    <span class="comment">// pop</span></span><br><span class="line">    <span class="comment">// return</span></span><br><span class="line">    <span class="comment">// 这里为啥就pop了？因为我们就是调用了一下 toString 方法，返回值并没有保存，所以没用，没用操作数栈就把结果直接弹出</span></span><br><span class="line">    <span class="comment">// 又因为是个 String，引用类型，所以弹出一个slot的值就行了</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">bar</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test2</span><span class="params">()</span>&#123;</span><br><span class="line">    bar();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// invokespecial &lt;...bar&gt;</span></span><br><span class="line">    <span class="comment">// pop2</span></span><br><span class="line">    <span class="comment">// return</span></span><br><span class="line">    <span class="comment">// 这里为啥就是 pop2？因为返回值没用，所以需要弹栈，然后因为返回值是long，占用了操作数栈两个slot，索引pop2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="7-比较指令："><a href="#7-比较指令：" class="headerlink" title="7. 比较指令："></a>7. 比较指令：</h1><p>比较指令，说白了就是比较大小的呗，从栈中弹出俩数比较大小。</p>
<p>这里我先规定：现在操作数栈中有俩数，按顺序是 v2 和 v1，注意是按顺序，也就是v2 压在 v1上面，是栈顶（其实也很好理解，v1 &gt; v2，肯定是先压入v1，再压入 v2，所以v2 在 v1上面）。然后有下面指令：</p>
<ul>
<li><p>fcmpl, fcmpg</p>
</li>
<li><p>dcmpl, dcmpg</p>
</li>
<li><p>lcmp</p>
</li>
</ul>
<p>第一个字母代表类型（float，double，long），cmp不说，最后一个字母 l 和 g 代表 lower 和 greater。其实没啥区分，正常情况下，这些指令都是弹出v2 和 v1 进行比较，如果 v1 &gt; v2，操作数栈压入1，如果 v1 &#x3D;&#x3D; v2，操作数栈压入0，如果 v1 &lt; v2，压-1。唯一的区别就是：如果v1 或者 v2有一个出现NaN，那么 lower 压入 -1，greater 压入 1.仅此而已。</p>
<p>所以为啥 lcmp 没有lg，因为long没有 NaN。</p>
<h1 id="8-控制转移指令："><a href="#8-控制转移指令：" class="headerlink" title="8. 控制转移指令："></a>8. 控制转移指令：</h1><h2 id="8-1-条件跳转指令："><a href="#8-1-条件跳转指令：" class="headerlink" title="8.1 条件跳转指令："></a>8.1 条件跳转指令：</h2><p>条件跳转指令一般是用栈顶元素和0或者null去进行跳转，和比较指令关联很大，一般情况下都是比较指令先把比较结果压入栈顶，然后判断指令从栈顶获取结果进行跳转。</p>
<p>必须要注意的是，这些跳转指令 后面都有一个操作数，代表如果判断位真则跳转到第几行指令。</p>
<ul>
<li><p>ifeq（if_equals），ifne（if_nonequals）如果栈顶元素 &#x3D;&#x3D; 0 &#x2F; !&#x3D; 0 ，则跳转。</p>
</li>
<li><p>iflt，ifle，ifgt，ifge。当栈顶元素 &gt; &gt;&#x3D; &lt; &lt;&#x3D; 0 时跳转。</p>
</li>
<li><p>ifnull，ifnonnull。如果栈顶元素是null&#x2F;不是null 时跳转。</p>
</li>
</ul>
<p>特别需要注意一个地方，看下面代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">0</span>; <span class="comment">// iconst_0, istore_1</span></span><br><span class="line">    <span class="keyword">if</span>(a == <span class="number">0</span>) <span class="comment">// iload_1, ifne xx &lt;a = 20&gt;</span></span><br><span class="line">        a = <span class="number">10</span>; <span class="comment">// bipush 10, istore_1, goto xx &lt;return&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        a = <span class="number">20</span>; <span class="comment">// bipush 20, istore_1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a; <span class="comment">// iload_1, ireturn</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>是的，我知道很简单，我们仔细看一看，如果if判断的结果为真，那他会接着if后面的按顺序执行，也就是走if路线的话根本没有跳转，只有在 if 判断不通过的情况下，走到else，这个时候才发生了指令跳转。但是这些判断指令后面又必须跟一个跳转地址，所以说这里我们判断得是 a&#x3D;&#x3D;0，如果等于则干啥，但是指令其实是反过来的，指令中判断 如果 a !&#x3D; 0，则跳转到else的地方。</p>
<p>总结一下，就是条件跳转指令会给我们写的if判断的条件取反，我们让他判断 a 是否等于0，指令则会判断 a 是否不等于0，如果是，则直接跳转到 else，如果不是，则不跳转，接着按顺序执行if后面的指令。</p>
<p>还有啊，这个条件跳转指令，针对的是 一个 int 和 一个常数比较，比如你直接 a &#x3D;&#x3D; 0，就会用条件跳转，如果是连个float，那就是两个float先 cmp，往操作数栈中压入比较结果，然后再条件跳转。</p>
<h2 id="8-2-比较条件跳转指令"><a href="#8-2-比较条件跳转指令" class="headerlink" title="8.2 比较条件跳转指令"></a>8.2 比较条件跳转指令</h2><p>这个东西就是把条件跳转和比较 结合在一起了，仅此而已。主要针对两个int（或者说JVM给你转换以后是int，害，其实就是 byte short）或者两个引用的比较，当然这里的比较引用肯定是比较的hashcode。</p>
<ul>
<li><p>if_icmpeq，if_icmpne，if_icmplt，if_icmple，if_icmpgt，if_icmpge：从栈顶弹出v2 和 v1 两个int，如果 &#x3D;&#x3D; !&#x3D; &lt; &lt;&#x3D; &gt; &gt;&#x3D; 的话，就跳转</p>
</li>
<li><p>if_acmpeq，ifacmpne：从栈顶弹出两个引用，判断 &#x3D;&#x3D; !&#x3D;</p>
</li>
</ul>
<h2 id="8-3-多条件跳转指令"><a href="#8-3-多条件跳转指令" class="headerlink" title="8.3 多条件跳转指令"></a>8.3 多条件跳转指令</h2><p>这个多条件不是else if 啊，指的是 switch case 结构。</p>
<p>具体分为两个：tableswitch 和 lookupswitch，这两个都是规定了如何跳转。区别就是 如果case 的后面的东西连续，那就是tableswitch，可以直接定位。如果不连续，那就需要用到 lookupswitch。</p>
<p>lookupswitch 优化为题：</p>
<p>因为lookupswitch不连续，所以他的效率可能慢一点，但是这个指令自己会优化，他会把你所有的case 条件，按顺序排序，比如你是 case 100, 500, 200，那他最后优化就会变成：100, 200, 500.但是这是不是说明，如果你不break，那他就不按从上到下的顺序一溜往下走了？不是的，具体为啥，你可以去看字节码。</p>
<p>还有jdk7支持的 case 字符串。这个东西更玄学，不细说了，挺多的，可以看：cn.chl.SwitchCase.java 这个文件。</p>
<h2 id="8-4-无条件跳转指令"><a href="#8-4-无条件跳转指令" class="headerlink" title="8.4 无条件跳转指令"></a>8.4 无条件跳转指令</h2><p>goto 指令，后面跟着一个2字节的操作数，代表往哪里跳转，如果两个字节（65535，无符号的2字节数）不够，那就是用 goto_w 这个指令，和goto一样，区别就是goto_w 接受一个4字节的操作数。</p>
<p>这里还可以涉及到循环，JVM中可没有任何的循环指令，其实循环都是 条件跳转指令 + 无条件跳转指令实现的。</p>
<h1 id="9-异常与异常处理"><a href="#9-异常与异常处理" class="headerlink" title="9. 异常与异常处理"></a>9. 异常与异常处理</h1><p>很好，我们都很讨厌异常</p>
<h2 id="9-1-异常的生成"><a href="#9-1-异常的生成" class="headerlink" title="9.1 异常的生成"></a>9.1 异常的生成</h2><p>众所周知，Java中的异常，其实就是 Exception对象，说的再准确点，就是 Throwable 实现类，所以异常，首先也要创建，然后使用关键字throw出来。</p>
<p>JVM层面，throw 的指令：athrow。但是这个指令仅限于我们手动抛出异常，如果是自动抛出的异常，比如除以0的异常，会在执行指令idiv和ldiv时自动抛出，那么这里自动抛出的异常就不会涉及athrow指令。</p>
<p>一旦抛出异常，直接清空方法的操作数栈（不光是清空操作数栈，整个栈帧都会直接弹出），然后把异常对象，压入方法调用者的操作数栈上。</p>
<h2 id="9-2-异常的捕获"><a href="#9-2-异常的捕获" class="headerlink" title="9.2 异常的捕获"></a>9.2 异常的捕获</h2><p>早期的JVM采用了 jsr ret 等指令来对异常进行处理，但是是早期，现在JVM已经把这些指令废弃了，取而代之的是异常表。</p>
<p>异常表其实很简单，就是一张表，规定了如果发生哪类异常，则跳转到哪条指令。一般来说只要你存在try catch 或者 try finally 则会出现这个东西。当</p>
<p>异常表有有你catch的所有异常，如果发生异常，就会去和你异常表匹配，匹配到哪个异常，跳转到哪个异常的处理位置，如果没有匹配，则弹出当前栈帧。</p>
<p>异常表结构如下：</p>
<table>
<thead>
<tr>
<th>Nr.</th>
<th>Start PC</th>
<th>End Pc</th>
<th>Handler PC</th>
<th>Catch Type</th>
</tr>
</thead>
<tbody><tr>
<td>第几个，毛用没有</td>
<td>try的起始位置</td>
<td>try的结束位置</td>
<td>抛出异常后的处理位置</td>
<td>处理的异常类型</td>
</tr>
</tbody></table>
<p>这个举个例子，看 cn.chl.ExceptionByteCode，里面的test5 方法，他的异常表如下：</p>
<table>
<thead>
<tr>
<th>Nr.</th>
<th>Start PC</th>
<th>End PC</th>
<th>Handler PC</th>
<th>Catch Type</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>6</td>
<td>9</td>
<td>java.lang.ClassNotFoundException</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>6</td>
<td>21</td>
<td>java.lang.RuntimeException</td>
</tr>
</tbody></table>
<p>所以具体什么意思呢？很简单，第一个，如果在 0 - 6 行字节码出现ClassNotFoundException，则跳转到 9 行进行处理，第二个，如果在 0 - 6 行出现RuntimeException，则跳转到 21行进行处理。就是这么简单。</p>
<h1 id="10-同步控制指令"><a href="#10-同步控制指令" class="headerlink" title="10. 同步控制指令"></a>10. 同步控制指令</h1><p>说白了，就是同步代码块。</p>
<p>首先，同步，有两种办法：</p>
<ul>
<li><p>直接给方法加上 synchronized 关键字，然后这个方法就是一个同步方法，一次只允许一个线程调用。这种办法在字节码指令角度看不到任何东西，是的，任何，一个方法你加不加同步，字节码都是那样。唯一的区别就是，方法的访问标识符会变。加上的话，方法的访问标识就会变成 public synchronzied。</p>
</li>
<li><p>使用同步代码块：synchronized(临界资源)。这个比较牛逼了，下面主要说这个东西。</p>
</li>
</ul>
<p>如果方法内想要进入同步代码块，使用 monitorenter指令，这个指令从操作数栈中弹出这个临界资源（一般是一个对象），我们之前讲对象头结构的时候说过，对象头中存储着线程的信息，比如当前对象是否有锁，这个锁是谁拿着的。那么现在 monitorenter指令得到这个临界资源后，会去对象头中找这俩属性：</p>
<ul>
<li><p>看当前对象有没有被加锁，如果没有，ok，我给加上，然后我进入同步代码块</p>
</li>
<li><p>如果有锁，看看这个锁是谁拿着的，如果是我拿着的，行，我也可以进入这个代码块</p>
</li>
<li><p>如果这个锁不是我拿着，那很遗憾，我就得等着了。</p>
</li>
</ul>
<p>所以我进入了同步代码块，怎么出来？monitorexit指令，这个指令也会从操作数栈得到临界资源，然后修改他的对象头，释放锁。</p>
<p>需要注意的是，即便我们在同步代码块中没有使用try catch，JVM也会给我们生成异常表，为啥？如果出现异常，难道说当前线程就不释放锁了？不能吧。只要出现异常，则马上跳出同步代码块来释放锁。</p>
<p>细说一下：上面我们提到，对象头中有一个东西记录这个对象是否有锁，这个东西叫 “监视器计数器”，如果计数器&#x3D;0，说明没有锁，线程可以进入，如果为1，那说明有锁，你得等着了。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM-字节码</title>
    <url>/2022/06/13/bytecode/</url>
    <content><![CDATA[<p>前面几经讲完了JVM的一些底层原理，从这章开始，我们会深入字节码文件，说一说字节码的各种指令，从指令层面了解Java代码。</p>
<span id="more"></span>

<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p>从这里开始，就进入了字节码和类加载器篇，这一篇讲字节码文件，可能还有类加载器。</p>
<h2 id="1-1-正式开始之前，先来道题"><a href="#1-1-正式开始之前，先来道题" class="headerlink" title="1.1 正式开始之前，先来道题"></a>1.1 正式开始之前，先来道题</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Integer</span> <span class="variable">i1</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line"><span class="type">Integer</span> <span class="variable">i2</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">System.out.println(i1 == i2);</span><br><span class="line"></span><br><span class="line"><span class="type">Integer</span> <span class="variable">i3</span> <span class="operator">=</span> <span class="number">128</span>;</span><br><span class="line"><span class="type">Integer</span> <span class="variable">i4</span> <span class="operator">=</span> <span class="number">128</span>;</span><br><span class="line">System.out.println(i3 == i4);</span><br><span class="line"></span><br><span class="line"><span class="type">Integer</span> <span class="variable">i5</span> <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> <span class="variable">i6</span> <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line">System.out.println(i5 == i6);</span><br></pre></td></tr></table></figure>

<p>解决这个问题，光看代码不行，你这一看，行啊，false   false   false 呗，为啥？那对象和int能比么,对象比对象那不是比的hashCode吗，俩对象，hash不一致，对吧。结果让你头疼，结果还真就不是，而是 true      false      true。</p>
<p>所以为了解决这道题，我们就得看字节码，我们会发现，在字节码的角度来说 Integer i1 &#x3D; 10 其实是 <code>Integer i1 = Integer.valueOf(10);</code>  而不是 <code>Integer i1 = new Integer(10)</code>，那问题肯定是在valueOf 上了，所以我们进入源码看 valueOf。我们就会发现惊人的事实，以下高能：</p>
<p>Integer 内部有一个IntegerCache，里面缓存了一部分Integer对象，这部分对象是已经创建好的，范围是 -128 - 127，如果他发现你传入的int是在这个范围内的话，他就会把对应的Integer直接给你而不会创建新的Integer，所以说上面 i1 和 i2 其实都是一个IntegerCache中的一个固定的Integer，压根就是同一个对象所以肯定想等。</p>
<p>i5 和 i6 是咋回事？还得看字节码，我们会发现在判断的时候其实i5做了一个intValue的动作得到了 int 5，所以 i5 &#x3D;&#x3D; i6 其实是 i5.intValue() &#x3D;&#x3D; i6，那这个intValue是一个int，所以说也相等。</p>
<h2 id="1-2-正式开始前，再来一道阴间题目"><a href="#1-2-正式开始前，再来一道阴间题目" class="headerlink" title="1.2 正式开始前，再来一道阴间题目"></a>1.2 正式开始前，再来一道阴间题目</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Father</span>&#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Father</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.print();</span><br><span class="line">        <span class="built_in">this</span>.x = <span class="number">20</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Father.x=&quot;</span> + x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Son</span> <span class="keyword">extends</span> <span class="title class_">Father</span>&#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">30</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Son</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.print();</span><br><span class="line">        <span class="built_in">this</span>.x = <span class="number">40</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Son.x=&quot;</span> + x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="comment">// 1. Father f = new Son();</span></span><br><span class="line">        <span class="comment">// 2. Father f = new Father();</span></span><br><span class="line">        System.out.println(f.x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这家伙，要想想明白这个事，咱们先不看2，咱们先看1.</p>
<p>众所周知，这个成员变量的赋值顺序：</p>
<ul>
<li>默认赋值</li>
<li>显式赋值 &#x2F; 实例代码块中赋值</li>
<li>构造器赋值</li>
<li>后期直接 XXX.xxx 或者 XXX.setXxx(xxx)</li>
</ul>
<p>那现在，直接 <code>Father f = new Father();</code> 对吧，根据顺序，首先 x &#x3D; 10，然后构造，所以一上来打印：Father.x &#x3D; 10,然后打印 f.x，那就是 20呗，这个没啥异议。</p>
<p>然后看2，这个时候看不太懂了，我们去看看字节码，我们又会发现一个小秘密：我们以前说过，创建子类对象会首先调用父类的构造方法，也就是有一个隐藏的 super()，这个super我们说必须放在构造器第一行，对吧。但是我们看字节码我们发现，何止是第一行，父类构造器是整个 &lt;init&gt; 方法的第一步。</p>
<p>我们的Son类，首先 int x &#x3D; 30 对吧，这个按顺序应该是&lt;init&gt;() 方法的第一步，这是正常情况下，但是在继承中， x &#x3D; 30 和 x &#x3D; 40 却在后面，第一步是调用了 Father.&lt;init&gt;() 方法，然后进入了Father.init，Father调用了 print 方法，但是print已经被子类重写了， 所以调用的其实是子类的print方法，子类要打印子类的x，这个时候因为我们前面说的原因，x &#x3D; 30 还没有执行，所以目前x 只有默认0值，所以打印出来的结果居然是 son.x &#x3D; 0。</p>
<p>父类构造器执行完成，返回子类构造器，子类x必定是显式初始化了对吧，所以30，调用print，没有异议，然后最后打印 f.x，Java中，成员可没有多态，所以打印的父类的x，也就是20。~~~~</p>
<p>最后结果：</p>
<p>Son.x&#x3D;0;Son.x&#x3D;30;20</p>
<h2 id="1-3-普及几个概念"><a href="#1-3-普及几个概念" class="headerlink" title="1.3 普及几个概念"></a>1.3 普及几个概念</h2><p>这些概念后面要用：</p>
<p>操作码：opcode</p>
<p>就是字节码指令的前面那部分，比如 bipush</p>
<p>操作数：operand</p>
<p>就是操作码后面的参数，一般是一个数</p>
<h1 id="2-解析字节码文件"><a href="#2-解析字节码文件" class="headerlink" title="2. 解析字节码文件"></a>2. 解析字节码文件</h1><p>很好，终于是到了这步了，很显然我们的 class文件都是乱码，那么我们就需要把他转成16进制看。以后肯定不用这么的，直接 JClassLib 插件看就行，但是刚开始嘛，多学点，总是好的。</p>
<p>Windows特别方便，直接notepad++安装一个 hex editor 插件就行了，Ubuntu 不行啊，好吧，vim 走起，弄一个class文件，然后：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim xxx.class</span><br><span class="line">:%!xxd</span><br></pre></td></tr></table></figure>

<p>就行了。</p>
<h2 id="2-1-Class文件存储方式"><a href="#2-1-Class文件存储方式" class="headerlink" title="2.1 Class文件存储方式"></a>2.1 Class文件存储方式</h2><p>Class 文件整体采用一种类似 C 语言结构体的存储方式，存储单位有两个：无符号数 和 表，下面具体区分：</p>
<ul>
<li>无符号数：用于存储基本数据类型，分为 u1 u2 u4 u8 4种类型，分别代表  1 2 4 8 个字节的无符号数，这个东西可以用来描述：数字，索引引用，数量，或者 utf-8 编码的字符串值。</li>
<li>表：表是由多个无符号数或者其他表构成的复合数据类型，所有表都习惯性的以 _info 结尾。表 用于描述有层次关系的复合结构的数据，整个class文件其实就是一张表，由于一个表长度不一定，所以一般会在表前面加一个数字来表示表长。</li>
</ul>
<h2 id="2-2-Class文件结构"><a href="#2-2-Class文件结构" class="headerlink" title="2.2 Class文件结构"></a>2.2 Class文件结构</h2><p>这里写一下java虚拟机规范中的说明：</p>
<table>
<thead>
<tr>
<th>所用类型</th>
<th>文件结构</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>u4</td>
<td>magic 魔数</td>
<td>识别class文件的标识</td>
</tr>
<tr>
<td>u2</td>
<td>minor_version : class文件副版本</td>
<td>识别class文件版本</td>
</tr>
<tr>
<td>u2</td>
<td>major_version: class文件主版本</td>
<td>识别class文件版本</td>
</tr>
<tr>
<td>u2</td>
<td>constant_pool_count：常量池长度</td>
<td>记录常量池长度.就像之前说的.一个表会在前面记录表长</td>
</tr>
<tr>
<td>cp_info</td>
<td>constant_pool[c_p_c-1]：常量池</td>
<td>特别重要.以后再说</td>
</tr>
<tr>
<td>u2</td>
<td>access_flags：访问标志</td>
<td>体现你这个东西是个类还是个接口.public还是private</td>
</tr>
<tr>
<td>u2</td>
<td>this_class：类索引</td>
<td></td>
</tr>
<tr>
<td>u2</td>
<td>super_class：父类索引</td>
<td></td>
</tr>
<tr>
<td>u2</td>
<td>interfaces_count：接口索引集合长度</td>
<td></td>
</tr>
<tr>
<td>u2</td>
<td>interfaces[interfaces_count-1]:接口索引集合</td>
<td></td>
</tr>
<tr>
<td>u2</td>
<td>fields_count：字段表集合 长度</td>
<td>记录字段表长度,这里的字段就是成员.或者我们平常说属性</td>
</tr>
<tr>
<td>field_info</td>
<td>fields[fields_count-1]：字段表集合</td>
<td>记录所有的字段</td>
</tr>
<tr>
<td>u2</td>
<td>methods_count：方法表集合 长度</td>
<td>记录方法表长</td>
</tr>
<tr>
<td>method_info</td>
<td>methods[methods_count-1]：方法表集合</td>
<td>记录所有方法</td>
</tr>
<tr>
<td>u2</td>
<td>attributes_count：属性表集合 长度</td>
<td>这个属性指的是当前类自己的属性,比如类名这种的信息,不是字段</td>
</tr>
<tr>
<td>attribute_info</td>
<td>attributes[attributes_count-1]：属性表 集合</td>
<td></td>
</tr>
</tbody></table>
<p>是不是觉得上面的特别多，其实很多东西是合二为一的，下面总结一下，ClassFile的结构：</p>
<ul>
<li>魔数</li>
<li>class文件版本</li>
<li>常量池</li>
<li>访问标志</li>
<li>类索引 父类索引 接口索引集合</li>
<li>字段表集合</li>
<li>方法表集合</li>
<li>属性表集合</li>
</ul>
<p>很好，知道了这些以后，来吧，开始手撕16进制字节码。</p>
<h1 id="3-字节码文件详解"><a href="#3-字节码文件详解" class="headerlink" title="3. 字节码文件详解"></a>3. 字节码文件详解</h1><p>上面已经说了字节码文件分为了那么多部分，所以这里详细说一说每个部分都是干嘛的</p>
<h2 id="3-1-Magic-魔数"><a href="#3-1-Magic-魔数" class="headerlink" title="3.1 Magic 魔数"></a>3.1 Magic 魔数</h2><p>魔数，占用4个字节，用于表示这个class文件是一个合法的class文件，可以被jvm识别。</p>
<p>肯定是 0xCAFEBABE，如果不是，那说明不是合法的class文件，就会抛出错误，具体啥错误我就不说了。</p>
<p>这个东西应用比较广，比如两张图片，你去对比他们的十六进制，会发现他们的第一行基本一样。</p>
<h2 id="3-2-class文件版本号"><a href="#3-2-class文件版本号" class="headerlink" title="3.2 class文件版本号"></a>3.2 class文件版本号</h2><p>跟在magic后面， 5 6 字节一组，7 8 字节一组，56是 minor version，也叫小版本，78是major version，大版本。两个东西共同组成class文件的版本号，比如 大版本是M，小版本是m，那么class文件的版本就是 M.m。</p>
<p>那这玩意有啥用，不同的编译器，编译出来的版本不一样，下面是一个对照表：</p>
<table>
<thead>
<tr>
<th>大版本(后面)</th>
<th>小版本(前面)</th>
<th>对应编译器版本</th>
</tr>
</thead>
<tbody><tr>
<td>45</td>
<td>3</td>
<td>1.1</td>
</tr>
<tr>
<td>46</td>
<td>0</td>
<td>1.2</td>
</tr>
<tr>
<td>47</td>
<td>0</td>
<td>1.3</td>
</tr>
</tbody></table>
<p>不往后写了，因为后面的小版本都是0，然后编译器每加一个版本，大版本+1.</p>
<p>别犯傻啊，字节码文件里面可是16进制，你看到是34，其实是52，也就是 jdk1.8.</p>
<p>目前，高版本的编译器可以执行低版本编译器编译出来的字节码文件，但是反过来不行，如果class文件版本高于当前编译器版本，会抛出异常</p>
<blockquote>
<p>java.lang.UnsupportedClassVersionError</p>
</blockquote>
<h2 id="3-3-常量池-ConstantPool"><a href="#3-3-常量池-ConstantPool" class="headerlink" title="3.3 常量池 ConstantPool"></a>3.3 常量池 ConstantPool</h2><p>这东西是class文件中内容最丰富的地方之一，而且这个对class文件的字段和方法解析也非常的重要。</p>
<p>随着java的发展，常量池的内容日渐丰富，可以说常量池是class文件的基石。</p>
<p>这东西分为两部分，首先是版本号后面紧跟着的 常量池计数器，毕竟字节码文件没有分隔符，jvm又得分隔，所以这里就写一个计数器，告诉jvm后面的东西到第几个就结束了，不同于java语言，这个计数器从1开始，而不是0。第二部分是若干常量池表项，常量池表项中，用于存放编译时期产生的各种字面量和符号引用，这部分内容将在类加载以后进入方法区，存在运行时常量池中。</p>
<h3 id="3-3-1-常量池计数器-Constant-pool-count"><a href="#3-3-1-常量池计数器-Constant-pool-count" class="headerlink" title="3.3.1 常量池计数器 Constant_pool_count"></a>3.3.1 常量池计数器 Constant_pool_count</h3><p>说过了，起始是1，也就是如果常量池计数器&#x3D;1，说明常量池中没东西，那为啥从1开始？因为常量池的东西相互之间各种引用，如果里面的一项谁都没有引用怎么整，怎么表示，那就是引用0呗，所以把0空出来。这里我的常量池计数器是16，也就是22，那么常量池的范围就是1-21.</p>
<h3 id="3-3-2-常量池表-ConstantPool"><a href="#3-3-2-常量池表-ConstantPool" class="headerlink" title="3.3.2 常量池表 ConstantPool"></a>3.3.2 常量池表 ConstantPool</h3><p>常量池主要存放两大类常量：字面量Literal和符号引用SymbolicReferences。</p>
<ul>
<li><p>字面量：两种，第一种是文本字符串，第二种是声明为final的常量值。</p>
</li>
<li><p>符号引用：类和接口的全限定名，字段的名称和描述符，方法的名称和描述符。</p>
<ul>
<li><p>全限定名：包名+类名，但是和全类名不一样，他把全类名的 . 换成了 &#x2F;，比如：cn&#x2F;zhzp&#x2F;commons&#x2F;JwtUtils 这就是全限定名，为了不混淆，一般在最后面加一个 ; 表示结尾，就是 cn&#x2F;zhzp&#x2F;commons&#x2F;JwtUtils;</p>
</li>
<li><p>简单名称：上面提到的 字段名，方法名，仅仅是那个名字，就是简单名称，比如 main 方法的 main这个单词，就是一个简单名称。</p>
</li>
<li><p>描述符：用于描述字段的数据类型，方法的形参列表，返回值类型。这里提到了数据类型，按照规定，有以下规则来表示类型：</p>
<table>
<thead>
<tr>
<th>标志符</th>
<th>数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>B</td>
<td>基本数据类型 byte</td>
</tr>
<tr>
<td>C</td>
<td>基本数据类型 char</td>
</tr>
<tr>
<td>D</td>
<td>基本数据类型 double</td>
</tr>
<tr>
<td>F</td>
<td>基本数据类型 float</td>
</tr>
<tr>
<td>I</td>
<td>基本数据类型 int</td>
</tr>
<tr>
<td>J</td>
<td>基本数据类型 long</td>
</tr>
<tr>
<td>S</td>
<td>基本数据类型 short</td>
</tr>
<tr>
<td>Z</td>
<td>基本数据类型 boolean</td>
</tr>
<tr>
<td>V</td>
<td>代表void类型</td>
</tr>
<tr>
<td>L</td>
<td>代表对象类型，L + 全限定名，比如 Ljava&#x2F;lang&#x2F;Object</td>
</tr>
<tr>
<td>[</td>
<td>代表一维数组，比如 int[][][][][] [] [] -&gt; [[[I</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>这里我们再回到我们刚学jvm的时候学到的类加载三个阶段：加载链接初始化，链接阶段分为 验证 准备 解析，最后一步解析当时说的是：把字节码文件中的符号引用替换成直接引用。这里我们详细的说一说：</p>
<p>这里我们提到符号引用记录全限定名，比如我们用到了 System.out.println()，那他符号引用就会记录 Ljava&#x2F;lang&#x2F;System（不一定对，我猜的啊，只是举个例子），就说明我们当前这个类需要引用到 System，但这只是一个符号。然后在类加载阶段，就会解析这个符号引用，然后去加载这个 System类，加载完以后我们也学过方法区了，System这个类就会放在方法区，就会有一个内存地址，这个时候，把常量池中的符号引用，替换成内存地址，让常量池可以真正引用到方法区的System类。</p>
<p>这个不局限于类或者接口，同理方法也是这样的，常量池中有一个 add 符号，啥也不是，然后类加载之后把他真正的指向方法区中的add方法内存。</p>
<p>所以再说啥叫符号引用和直接引用：</p>
<p>符号引用，和内存半毛钱关系没有，仅仅是一个符号，用来表示这个class引用了啥。</p>
<p>直接引用，一个内存地址，偏移量，或者句柄，总之可以定位到真正的对象，和内存有直接关系。</p>
</blockquote>
<p>常量池中包含了这个class结构和他的子结构中包含的所有：字符串常量，类和接口名，字段名，和其他常量。</p>
<p>常量池中的每一项都具有相同的结构，每一项的第一个字节是类型标记符，用于确定这一项的格式，这个字节叫做 tag byte。</p>
<p>再具体的，就是说常量池中每一部分都是怎么构成的，不说了，太多了，我在里面又放了一个尚硅谷的md文件，看那个就行了。</p>
<h2 id="3-4-访问标志-Access-Flag"><a href="#3-4-访问标志-Access-Flag" class="headerlink" title="3.4 访问标志 Access_Flag"></a>3.4 访问标志 Access_Flag</h2><p>常量池后面u2是访问标志，访问标志有很多啊，比如 ACC_PUBLIC, ACC_SUPER 这种的，每一种访问标志都有一个十六进制数值表示，然后class文件中的这个访问标志其实个加和，是多个访问标志加到一起得到的数字。</p>
<p>各个访问标志也在尚硅谷的md里面，需要的话自己看，不多说了。</p>
<p>补充说明：</p>
<ul>
<li>带有 ACC_INTERFACE 标识的class，说明他是一个接口，没带，那就是类。</li>
<li>如果一个class有 ACC_INTERFACE,那他必须同时有 ACC_ABSTRACT，不能有 ACC_SUPER  ACC_ENUM  ACC_FINAL.</li>
<li>注解类型必须有 ACC_ANNOTATION 标识，如果有 ACC_ANNOTATION，那必须同时有 ACC_INTERFACE 标识。</li>
<li>ACC_SUPER，只要是类，那基本都有这个标志，详细的不多说了。</li>
</ul>
<h2 id="3-5-类索引-父类索引-接口索引集合"><a href="#3-5-类索引-父类索引-接口索引集合" class="headerlink" title="3.5 类索引 父类索引 接口索引集合"></a>3.5 类索引 父类索引 接口索引集合</h2><p>先说啥叫索引，上面不是有常量池吗，常量池中有符号引用对吧，然后常量池里面的每一项都一个位置对吧，那么索引的意思就是指向了常量池的哪个位置，指向了常量池的第几项。所以索引是一个u2。</p>
<p>放在这里也很好理解了，类索引就是常量池中本类符号引用的位置，父类索引同理，然后接口索引集合，首先他是个集合，那他肯定前面肯定有一个u2的计数器，然后后面才是每一个索引。</p>
<h2 id="3-6-字段表集合"><a href="#3-6-字段表集合" class="headerlink" title="3.6 字段表集合"></a>3.6 字段表集合</h2><p>首先，集合，所有u2的计数器，不多说。</p>
<p>然后，我们着重看看字段表里面包含了啥，包含以下内容：</p>
<ul>
<li>访问标志，这里的访问表示还不同于上面的class文件访问标识，而是字段自己的一套访问表示，在尚硅谷那里都有写，这里不说了，占用u2</li>
<li>字段名索引，显然是指向常量池中的属性名称。</li>
<li>字段描述符搜因，字段的描述符就是这个字段的类型，同理指向常量池</li>
<li>字段属性表集合，这个东西比较特殊，有些字段也是有属性的，用于存放一些额外信息，比如初始化值(主要针对常量)，注释等信息，这里不举例了，了解就行。</li>
</ul>
<h2 id="3-7-方法表集合"><a href="#3-7-方法表集合" class="headerlink" title="3.7 方法表集合"></a>3.7 方法表集合</h2><p>在字节码文件中，每一个 method_info 都对应着当前类或接口中的方法，用于描述这个方法的方法名，访问标识，返回值类型，参数列表等信息。</p>
<p>如果一个方法不是abstract 不是native的，那么这个方法就会在字节码中体现出来。</p>
<p>methods 中只会有当前类或者接口中声明的方法，不会有父类的方法，同时，methods中可能会有些类加载期间自动加上的方法，比如 clinit init 这种方法。</p>
<p>方法表中包含的信息，总的来说，包括这些：u2访问标识，u2方法名索引，u2描述符索引，u2属性计数器，attribute_info属性集合。</p>
<p>然后属性里面有啥东西？特别麻烦，各种 code，什么 本地变量表，操作数栈深度，还什么line_number_table，不说了，太恶心了，这里不说了。</p>
<h2 id="3-8-属性表集合"><a href="#3-8-属性表集合" class="headerlink" title="3.8 属性表集合"></a>3.8 属性表集合</h2><p>一上来u2计数器，不说了。</p>
<p>只要是属性，不管是这里的属性，还是字段表的属性，还是方法表的属性，都有有些共同的地方，一般来说，属性表肯定有三个东西：</p>
<ul>
<li>属性名索引</li>
<li>属性长度</li>
<li>属性表</li>
</ul>
<p>然后，根据属性名索引找到属性名，然后拿着属性名去找这个名字的属性里面包含了哪些信息，就这么个过程，不细说了。</p>
<h1 id="4-字节码相关命令"><a href="#4-字节码相关命令" class="headerlink" title="4. 字节码相关命令"></a>4. 字节码相关命令</h1><p>上面的字节码，一个一个16进制扣，看得我反胃了开始，不看了，太恶心了。</p>
<p>说一说一些命令，以及一些命令的参数：</p>
<h2 id="4-1-javac-命令"><a href="#4-1-javac-命令" class="headerlink" title="4.1 javac 命令"></a>4.1 javac 命令</h2><p>肯定都用过这个东西，有个小知识点得说一说，使用这个命令的时候如果加上 -g 参数，就会生成局部变量表，不加的话，是没有局部变量表的。</p>
<p>idea 或者 eclipse 给我们编译都会把局部变量表编译出来。</p>
<p>其他参数：</p>
<ul>
<li><p>-version，返回 javac所在的jdk的版本，而不是class是被哪个jdk生成的，和class文件没关系，直接 javac -version就行了</p>
</li>
<li><p>-public，仅显示当前class中的公开成员</p>
</li>
<li><p>-protected，显示当前class中的高于protected成员</p>
</li>
<li><p>-p、-private，显示高于private成员</p>
</li>
<li><p>-package，显示程序包&#x2F;受保护的&#x2F;公开类 和成员</p>
</li>
<li><p>-sysinfo，显示正在处理的类的系统信息，比如路径，大小，md5，散列 等等信息。</p>
</li>
<li><p>-constants，显示静态常量，和上面的其实差不多，只是上面的显示常量不显示值，这里会显示值而已。</p>
</li>
</ul>
<h2 id="4-2-javap命令"><a href="#4-2-javap命令" class="headerlink" title="4.2 javap命令"></a>4.2 javap命令</h2><p>也用过吧，这玩意用来反编译的，参数如下：</p>
<ul>
<li><p>-s，输出内部类型签名，其实就是返回每个成员的描述信息</p>
</li>
<li><p>-l，返回行号和局部变量表，前提是你得有局部变量表</p>
</li>
<li><p>-c，对代码进行反汇编，挺高深奥，其实就是返回你每个方法的code属性，代码都给你转成jvm指令</p>
</li>
<li><p>-v、-verbose，输出附加信息，包括行号，本地变量表，反汇编等详细信息。简单说，一个v包括上面的所有东西，但是不包括私有，你要包括私有咋办，直接 <code>javap -v -p xxx.class</code></p>
</li>
</ul>
<p>常用的是 -v -c -l</p>
<p>顺带说一句，javap里面你看不到clinit和init，因为javap又给你还原成了你的构造方法，或者代码块。</p>
<h1 id="5-字节码指令"><a href="#5-字节码指令" class="headerlink" title="5. 字节码指令"></a>5. 字节码指令</h1><p>字节码指令，首先众所周知，分为两个部分，操作符 和 操作数，然后每个操作符都会有一个助记符，说白了，就是每一个指令，都会有一个对应的16进制数字来表示，方便在字节码文件中体现，然后助记符后面又会有一个16进制操作数。这就是一个指令具体在字节码中的结构。</p>
<h2 id="5-1-执行模型"><a href="#5-1-执行模型" class="headerlink" title="5.1 执行模型"></a>5.1 执行模型</h2><p>jvm执行指令的流程，如果不考虑异常处理的话，可以概括成以下过程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">    自动计算PC寄存器的值 + <span class="number">1</span>;</span><br><span class="line">    根据PC寄存器的值到相应的地方取出指令;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(指令存在操作数)</span><br><span class="line">        取出操作数;</span><br><span class="line"></span><br><span class="line">    执行操作码对应的操作;</span><br><span class="line"></span><br><span class="line">&#125;<span class="keyword">while</span>(字节码长度 &gt; <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<h2 id="5-2-字节码数据类型"><a href="#5-2-字节码数据类型" class="headerlink" title="5.2 字节码数据类型"></a>5.2 字节码数据类型</h2><p>一般情况下，字节码指令是有数据类型区分的，比如 iload，这个i就是int，fload 自然就是 load float。常见的数据类型：</p>
<ul>
<li><p>int -&gt; i</p>
</li>
<li><p>float -&gt; f</p>
</li>
<li><p>double -&gt; d</p>
</li>
<li><p>char -&gt; c</p>
</li>
<li><p>byte -&gt; b</p>
</li>
<li><p>short -&gt; s</p>
</li>
<li><p>long -&gt; l</p>
</li>
</ul>
<p>需要注意的是，绝大多数指令对于整数，一般不支持 byte short char，甚至不支持 boolean，其实在运算的时候，会通过带符号扩展 变为 int，而对于boolean，boolean这会通过 零位扩展转化为char进行运算。这个规则也适用于数组，数组里面的各个元素也会转为int。所以大部分对于 char byte short boolean 的操作，其实都是用int操作的。</p>
<h2 id="5-3-指令分类"><a href="#5-3-指令分类" class="headerlink" title="5.3 指令分类"></a>5.3 指令分类</h2><p>指令，那太多了，所以我们先分个类，对于字节码指令，有以下分类：</p>
<ul>
<li><p>加载与存储指令</p>
</li>
<li><p>算数指令</p>
</li>
<li><p>类型转换指令</p>
</li>
<li><p>对象的创建和访问指令</p>
</li>
<li><p>操作数栈管理指令</p>
</li>
<li><p>比较控制指令</p>
</li>
<li><p>异常处理指令</p>
</li>
<li><p>同步控制指令</p>
</li>
</ul>
<p>注意：</p>
<p>一个指令，可以从局部变量表，常量池，堆中对象，方法调用，系统调用中获取数据，这些数据会压入操作数栈</p>
<p>一个指令，也可以从操作数栈获取多个数据，也就是pop多次，然后可以进行各种操作，然后结果还可以存入操作数栈</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM-类加载</title>
    <url>/2022/06/13/classload/</url>
    <content><![CDATA[<p>类加载，说一说类加载的时候各种成员的初始化如何进行。</p>
<span id="more"></span>

<h1 id="1-类加载"><a href="#1-类加载" class="headerlink" title="1. 类加载"></a>1. 类加载</h1><p>是的，字节码说完了，然后就是下面的一大块东西：类加载。</p>
<p>之前学Java反射的时候了解过，类加载分为5个阶段，如下：</p>
<ul>
<li>加载：通过类加载器加载一个二进制流数据</li>
<li>链接：又分为 验证 准备 解析 三个阶段</li>
<li>初始化</li>
<li>使用：比如调用方法，创建对象等</li>
<li>卸载</li>
</ul>
<p>后面我们就开始着重看这5个阶段。</p>
<h1 id="2-类加载-Loading-阶段"><a href="#2-类加载-Loading-阶段" class="headerlink" title="2. 类加载 Loading 阶段"></a>2. 类加载 Loading 阶段</h1><h2 id="2-1-加载的理解"><a href="#2-1-加载的理解" class="headerlink" title="2.1 加载的理解"></a>2.1 加载的理解</h2><p>什么是加载，或者说loading阶段到底干了啥？很简单，类加载器读取一大堆二进制流，然后转化成一个类模版对象，然后把这个类模版对象存储到方法区。这样在运行时，我们就可以通过反射来获取类的属性，比如这个类的属性，方法等。</p>
<p>但是需要注意的是，这个类模版，并不是我们获取的 Class对象，不是的，两回事，有关系，但不是一个。</p>
<h2 id="2-2-加载完成的操作"><a href="#2-2-加载完成的操作" class="headerlink" title="2.2 加载完成的操作"></a>2.2 加载完成的操作</h2><p>就是一件事，读取class文件，生成类模版。具体说 JVM 需要完成下面三件事：</p>
<ul>
<li>获取类的全限定命名，从而得到这个类的class文件，进而获取二进制流（当然这个流可以从数据库中获得，获取其他的方式，总之，要的就是二进制流）；</li>
<li>解析这个二进制流，生成对应的Java类模版，存储在方法区</li>
<li>创建 Class对象，这个对象作为方法区类模版的访问入口，也就是说，Class对象其实是指向了方法区中的模版。</li>
</ul>
<h2 id="2-3-类模版和Class的位置"><a href="#2-3-类模版和Class的位置" class="headerlink" title="2.3 类模版和Class的位置"></a>2.3 类模版和Class的位置</h2><p>在完成类加载后，会在方法区（jdk8的话就是元空间）生成一个类模版对象，然后又会在堆中，没错，就是堆中，生成这个类的Class对象，然后这个Class指向了方法区中的类模版，然后我们就可以通过Class得到类的属性。</p>
<p>只是作为了解，不展开说，挺复杂的东西。</p>
<h2 id="2-4-数组类的创建"><a href="#2-4-数组类的创建" class="headerlink" title="2.4 数组类的创建"></a>2.4 数组类的创建</h2><p>数组比较特殊，数组并不是类加载器创建的，而是JVM根据你数组类型和数组维度动态创建的，过程如下：</p>
<ul>
<li>如果数组是引用数据类型，那么JVM则会根据需要 递归的去加载数据类型</li>
<li>根据数组所需要的数据类型和数组维度，JVM动态的声明数组</li>
</ul>
<h1 id="3-链接阶段"><a href="#3-链接阶段" class="headerlink" title="3. 链接阶段"></a>3. 链接阶段</h1><p>众所周知，链接阶段分为三个步骤：验证，准备，解析。ok，我们一个一个说：</p>
<h2 id="3-1-验证阶段"><a href="#3-1-验证阶段" class="headerlink" title="3.1 验证阶段"></a>3.1 验证阶段</h2><p>所谓验证阶段，那肯定就是验证文件是否合法这种的。所以在这一步，它主要验证一下内容：</p>
<ul>
<li>格式检查：检查字节码的魔数，版本以及指令长度等其他信息（没有在方法区中生成类模版）</li>
<li>语义检查：检查有没有格式错误，比如继承final，是否存在父类，抽象方法有没有实现等（这个时候已经在方法区中生成了模版）</li>
<li>字节码验证：跳转指令的跳转位置是否合法，函数调用传参类型是否正确，变量赋值的类型是否一致 等。</li>
<li>符号引用验证：符号引用是否有直接饮用</li>
</ul>
<p>这个阶段有个特殊的东西：StackMapTable 栈映射帧，是干嘛的呢？用来检测操作数栈中的数据类型和局部变量表的数据类型是否匹配，然而并不能100%判断字节码没错，只是尽可能的判断。</p>
<p>第四步的符号引用验证，简单说就是：常量池中有个ClassRefInfo信息，比如指向了一个 java.lang.String，这里就需要判断这个 String 是否存在，既视感这个的。</p>
<p>顺带一提，验证阶段和加载阶段分的没有那么开，一般都是同时进行的。</p>
<h2 id="3-2-准备阶段"><a href="#3-2-准备阶段" class="headerlink" title="3.2 准备阶段"></a>3.2 准备阶段</h2><p>准备阶段 Preparation，简单说，就是给这个类的静态变量（注意，是变量，是变量，不是常量，static final 可不在这里处理）分配内存空间，并给他们赋一个默认值，这个默认值应该不用说了吧，数字类型都是0，boolean是false，ref 是 null。</p>
<p>注意：</p>
<ul>
<li>说过了，这里不对final进行操作，static final 的常量在编译的时候就已经被显式的赋值了，在准备阶段静态常量已经有值了。</li>
<li>这里不对实例变量进行操作，类变量的内存被分配到了方法区，和类模版在一起，实例变量则是在堆中，和对象在一起。</li>
<li>这个过程没有任何的代码被执行</li>
</ul>
<p>有个特殊情况，如果有如下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;CONST&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>那么这个属性的赋值也是在编译阶段完成的，但是仅限于通过字面量给String赋值，如果你是 new String，那也就不行了。</p>
<h2 id="3-3-解析阶段"><a href="#3-3-解析阶段" class="headerlink" title="3.3 解析阶段"></a>3.3 解析阶段</h2><p>解析 Resolution 阶段，简单说，把符号引用替换成直接饮引用。听不懂是吧，来，举个例子：</p>
<p>我们都已经学过字节码了，字节码文件中有常量池没毛病吧，比如常量池中有个常量 Methodref_info 这个信息，这个信息里面有两部分：Class_name 和 Name_And_Type，然后这俩又是俩常量池索引，比如：Class_name #3， Name_and_type #8。这里非常的敷衍，就告诉你是 #3和#8，和内存完全没关系，这就是符号引用。</p>
<p>这个阶段下，你不能在敷衍的告诉我 Class_name 是#3啦，太费劲了，咋办，比如这个Methodref_info是 System.out.println() 方法，行，这里你得具体告诉我 System.out 这个 Class_name 的真实内存地址，#3我不认可啦，那么在这个阶段下，Class_name #3 Name_and_type #8 就被替换成了：</p>
<p>同时，JVM会给每个类提供一个方法表，那么你这个println方法在方法表中是第几个位置，这个就相当于方法的直接引用。</p>
<h1 id="4-初始化阶段"><a href="#4-初始化阶段" class="headerlink" title="4. 初始化阶段"></a>4. 初始化阶段</h1><blockquote>
<p>create  by  陈HL_pthef on  2021&#x2F;11&#x2F;4 下午6:58</p>
</blockquote>
<h2 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4.1 概述"></a>4.1 概述</h2><p>初始化阶段，简单说就是给static进行赋值。很重要的一点，在初始化阶段，真正的涉及一些Java代码的执行。</p>
<p>这个过程最重要的就是生成 &lt;clinit&gt; 方法，这个方法主要就是用来给static赋值的，他会按顺序收集你类中所有的static赋值语句（包括static代码块），整合到一起，然后生成 clinit方法，这个方法只能由JVM生成，并由JVM调用。</p>
<h2 id="4-2-说明"><a href="#4-2-说明" class="headerlink" title="4.2 说明"></a>4.2 说明</h2><ul>
<li><p>一个类调用 clinit 方法时，总会先去调用 父类的clinit方法，所以说，父类的static代码块优先级高于子类</p>
</li>
<li><p>什么情况下不会生成 clinit方法：</p>
<ul>
<li>一个类压根没有静态</li>
<li>有静态，但是没有赋值，就是光秃秃一个 <code>public static int num;</code></li>
<li>有静态，也有赋值，但是这个静态是常量，而且赋值的方式还是字面量赋值，也不会clinit。</li>
</ul>
</li>
</ul>
<h2 id="4-3-static-final-显式赋值到底发生在哪个阶段？"><a href="#4-3-static-final-显式赋值到底发生在哪个阶段？" class="headerlink" title="4.3 static final 显式赋值到底发生在哪个阶段？"></a>4.3 static final 显式赋值到底发生在哪个阶段？</h2><p>这玩意，越来越不会了，太恶心了。</p>
<p>首先，看最简单的；</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">I</span> <span class="operator">=</span> <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p>这个倒是好说，i 肯定是在clinit中赋值，然后 I 是在链接阶段的准备环节赋的值，所以说，是不是final修饰的就一定不在clinit中赋值？再看下面这个：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">Integer</span> <span class="variable">int1</span> <span class="operator">=</span> Integer.valueOf(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Integer</span> <span class="variable">INT2</span> <span class="operator">=</span> Integer.valueOf(<span class="number">1000</span>);</span><br></pre></td></tr></table></figure>

<p>这俩是在哪赋的值？直接说，这俩都是在 clinit 中赋值。那我们又猜，是不是说 引用数据类型不管是不是final都在clinit中赋值？再看下面：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="string">&quot;hello1&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">S</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;hello2&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这俩都是引用，在哪里赋值啊？s 在准备阶段，S 在clinit赋值。</p>
<p>所以说，总结一下，什么情况下会在链接阶段的准备过程赋值：</p>
<ul>
<li>大前提，static final 修饰的</li>
<li>基本数据类型，给他赋一个确定的值，且不需要代码支持（比如 new Random().random() 这种的），在准备过程赋值</li>
<li>字符串，且通过字面量的形式给他赋值，也发生在准备阶段。</li>
</ul>
<p>首先明确的是，绝对不是说 static final 就一定在准备阶段完成赋值。</p>
<h2 id="4-4-clinit-方法的线程安全问题"><a href="#4-4-clinit-方法的线程安全问题" class="headerlink" title="4.4 clinit 方法的线程安全问题"></a>4.4 clinit 方法的线程安全问题</h2><p>首先，clinit是线程安全的，但是这个方法的访问修饰只有static，并没有synchronized，所以他这个锁是一个隐式的锁，JVM给自动加的。</p>
<p>正是因为这玩意线程安全，所以说如果一个类的clinit过于繁琐，耗时较长，则会导致很多线程阻塞，有可能导致死锁。</p>
<h2 id="4-5-类的主动使用和被动使用问题"><a href="#4-5-类的主动使用和被动使用问题" class="headerlink" title="4.5 类的主动使用和被动使用问题"></a>4.5 类的主动使用和被动使用问题</h2><p>首先，主被动使用会影响啥？不是说一个类被动使用就不会加载了，不是的，一个类要用，那就肯定需要加载，但是如果一个类是被动使用的，那么这个 初始化阶段是很有可能不执行的。注意，仅限于初始化阶段不执行。那么初始化阶段不执行就可能导致结果不一致。</p>
<p>顺带一提，这里说的使用不是说的类的第四个阶段：使用。更多说的是首次使用。</p>
<h3 id="4-5-1-类的主动使用"><a href="#4-5-1-类的主动使用" class="headerlink" title="4.5.1 类的主动使用"></a>4.5.1 类的主动使用</h3><p>类的主动使用会调用 &lt;clinit&gt;() 方法，也就是会经过初始化过程。</p>
<ul>
<li><p>创建一个类的实例，比如 new，通过反射，反序列化（是的，反序列化也是主动使用）</p>
</li>
<li><p>调用类的静态方法，对应指令就是执行 invokestatic 指令，很简单，不说了</p>
</li>
<li><p>操作类的静态字段（static修饰的，没有final），对应指令就是 getstatic 和 putstatic。同时还有接口的静态字段。</p>
<p>这里得特别说明：并不是绝对的，不是说我们操作static final 就一定不触发初始化。我认为是啥呢，就是说你这个static final 是不是在&lt;clinit&gt;() 中被赋值，如果是，那么这里你操作static final也照样会触发初始化，如果不是，那这里就不触发初始化。</p>
<p>同时，对于接口，也是差不多的道理，如果接口中的 static final 不需要代码支持，那就不会clinit，如果需要，那就也会被初始化</p>
</li>
<li><p>使用反射类的方法，比如 Class.forName() 这种的，触发初始化。</p>
</li>
<li><p>初始化子类之前，会初始化父类。</p>
<p>特殊：JVM加载一个类，要求是所有父类都必须初始化，但是这条规则并不适用与接口。</p>
<ul>
<li>初始化一个类，并不会初始化他所有实现的接口</li>
<li>初始化一个接口，并不会初始化他继承的所有的类</li>
</ul>
<p>只有当程序首次使用特定字段的时候才会触发接口的初始化。</p>
</li>
<li><p>如果你的接口存在default 方法，那么直接或间接实现这个接口的类 触发了初始化，那么这个接口也会被初始化</p>
</li>
<li><p>当虚拟机启动时，用户会指定一个主类，那么JVM会优先家在这个主类</p>
</li>
<li><p>使用 MethodHandle 类，JVM会初始化这个方法指向的方法所在的类</p>
<p>我猜啊，这个类是用来调用方法的，他可以调用任何一个类的任何一个方法（不绝对啊，private我不知道行不行）</p>
</li>
</ul>
<h3 id="4-5-2-类的被动使用"><a href="#4-5-2-类的被动使用" class="headerlink" title="4.5.2 类的被动使用"></a>4.5.2 类的被动使用</h3><p>被动使用，就是类加载不会经过初始化过程。</p>
<ul>
<li>访问static字段，只有真正定义了这个static字段的类才会被初始化。举个例子，父类有个static，然后我们通过子类访问这个字段，最终被初始化的只有父类，自卑不会被初始化。具体看 cn.chl.PassiveUse</li>
<li>创建引用数据类型数组，数组数据类型对应的类不会初始化。就是说你 XXX[] a &#x3D; new XXX[10]; 这个时候 XXX 不会初始化，只有 a[0] &#x3D; new XXX() 的时候才会初始化（废话）</li>
<li>访问类的 final static（具体得看你这个final static需不需要被clinit进行赋值，上面有说，具体问题具体分析）</li>
<li>调用 ClassLoader 的loadClass 方法，加载一个类，不会初始化</li>
</ul>
<h1 id="5-类卸载"><a href="#5-类卸载" class="headerlink" title="5. 类卸载"></a>5. 类卸载</h1><p>是的，类的使用没有说，废话，有啥说的，就是用呗。没的说。这里直接开始说类的卸载。</p>
<p>要想说明白这个类卸载，我们先要明白 类 类加载器 类实例 的关系。大致的关系就是：我们加载一个类，首先在方法区中创建这个类的模版，然后在堆区创建这个类的Class对象作为方法区模版的访问入口，同时这个类的类加载器也保存在堆区，加载器和Class互相指向，创建实例的话，实例也存在堆区，并指向Class对象。接下来我们具体说说每个部分。</p>
<h2 id="5-1-类-类加载器-类实例的关系"><a href="#5-1-类-类加载器-类实例的关系" class="headerlink" title="5.1 类  类加载器   类实例的关系"></a>5.1 类  类加载器   类实例的关系</h2><p>我们之前说过，JVM中的类加载器主要分为三类：</p>
<ul>
<li>BootstrapClassLoader：启动类加载器，或者说 引导类加载器，Java核心类库使用这个</li>
<li>ExtensionClassLoader：扩展类加载器，第三方jar包多数用这个</li>
<li>ApplicationClassLoader：应用程序类加载器，或者叫系统类加载器，我们自己写的用这个</li>
</ul>
<p>Class对象和ClassLoader之间双向关联，Class里面有个方法：<code>getClassLoader()</code> 方法，可以得到这个类的类加载器。所以大体结构如下：</p>
<p><img src="/../images/Class.png" alt="image-20211106131529171"></p>
<p>看的非常清楚，不再多说。</p>
<h2 id="5-2-类的生命周期"><a href="#5-2-类的生命周期" class="headerlink" title="5.2 类的生命周期"></a>5.2 类的生命周期</h2><p>简单说，什么时候一个类就被回收了？以上面这图来说，当 Sample 类的Class对象不再被引用，也就是不可触及时，Sample的生命周期结束，就会卸载方法区中的 Sample类模版。</p>
<p>看似简单，其实不然，我们通过上面这图可以看出，什么时候Class就不会被引用？</p>
<ul>
<li>没有任何的实例引用。没有实例，那么 Sample实例到Class的引用就相当于断开了</li>
<li>没有 Class对象的引用。这是废话</li>
<li>没有 Sample 类加载器的引用，这样 MyClassLoader的引用断开，就相当于Loader到Class的引用断开</li>
</ul>
<p>只有达到这三个条件，才说明类不再使用。</p>
<p>所以总结一下，卸载一个类，其实对应的就是方法区中的GC。方法区GC主要针对不再使用的常量和不再使用的类，常量好说，不用了呗，但是类，必须满足下面三个条件：</p>
<ul>
<li>这个类的所有实例，也包括派生子类的实例，全部被回收</li>
<li>类的ClassLoader被回收（这个条件极其难以达成，除非是被精心设计的一些类的类加载器）</li>
<li>没有引用指向 Class对象</li>
</ul>
<h2 id="5-3-类的卸载"><a href="#5-3-类的卸载" class="headerlink" title="5.3 类的卸载"></a>5.3 类的卸载</h2><ul>
<li>引导类加载器不可能被卸载，也就是说被引导类加载器加载的类，运行期间你是别想卸载了</li>
<li>系统类加载器和扩展类加载器被收集的可能性极小，因为在运行期间他们的类总是能被直接或者间接的指向</li>
<li>我们自己写的类加载器有可能被回收，但是仅限与在简单的上下文环境中，复杂环境下依旧是直接间接引用满天飞。而且就算是回收了加载器，我们也得强制调用GC方法</li>
</ul>
<p>方法区回收垃圾，时间是不确定的，而且效果也不好，因为没几个类是不用的。所以，千万不要在类卸载的前提下考虑业务。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收</title>
    <url>/2022/06/02/garbage-collect/</url>
    <content><![CDATA[<p>这章开始进入垃圾回收，只是这一章不讲垃圾回收的具体回收器，而是讲一下垃圾回收的一些基本概念。</p>
<span id="more"></span>

<h1 id="1-GC-垃圾收集"><a href="#1-GC-垃圾收集" class="headerlink" title="1. GC 垃圾收集"></a>1. GC 垃圾收集</h1><p>同理，首先明确几个概念：</p>
<ul>
<li><p>什么是垃圾</p>
</li>
<li><p>为啥要清理垃圾</p>
</li>
<li><p>垃圾回收机制</p>
</li>
</ul>
<h2 id="1-1-什么是垃圾"><a href="#1-1-什么是垃圾" class="headerlink" title="1.1 什么是垃圾"></a>1.1 什么是垃圾</h2><p>垃圾指的是，在程序运行期间没有任何指针指向的对象，这个对象就是垃圾。</p>
<p>如果不及时清理垃圾，这些垃圾对象就会一直存在占用空间，可能导致内存溢出。</p>
<h2 id="1-2-为什么要GC"><a href="#1-2-为什么要GC" class="headerlink" title="1.2 为什么要GC"></a>1.2 为什么要GC</h2><ul>
<li><p>对于高级语言来说，如果不进行GC，内存迟早消耗完，所以需要不断地分配内存和回收内存</p>
</li>
<li><p>除了垃圾回收，GC同时还能整理内存碎片，碎片整理把堆内存移到堆的一端，给新对象腾地方</p>
</li>
<li><p>业务越来越庞大，没有GC程序就没法运行，而经常GC会导致频繁地STW，所以就需要不断的对GC进行优化。</p>
</li>
</ul>
<h2 id="1-3-Java垃圾回收机制"><a href="#1-3-Java垃圾回收机制" class="headerlink" title="1.3 Java垃圾回收机制"></a>1.3 Java垃圾回收机制</h2><ul>
<li><p>自动内存管理，无需开发人员手动分配和释放，降低了内存溢出的可能性。</p>
</li>
<li><p>能让我们更专注于 业务逻辑的开发</p>
</li>
</ul>
<h1 id="2-GC-机制与算法-标记阶段"><a href="#2-GC-机制与算法-标记阶段" class="headerlink" title="2. GC 机制与算法-标记阶段"></a>2. GC 机制与算法-标记阶段</h1><p>大纲：</p>
<ul>
<li><p>标记阶段：引用计数算法</p>
</li>
<li><p>标记阶段：可达性分析算法</p>
</li>
<li><p>对象的 finalization 机制</p>
</li>
<li><p>MAT和JProfiler 的 GC roots 溯源</p>
</li>
<li><p>清除阶段：标记清除算法</p>
</li>
<li><p>清除阶段：复制算法</p>
</li>
<li><p>清除阶段：标记-压缩 算法</p>
</li>
</ul>
<h2 id="2-1-垃圾标记阶段"><a href="#2-1-垃圾标记阶段" class="headerlink" title="2.1 垃圾标记阶段"></a>2.1 垃圾标记阶段</h2><ul>
<li><p>在堆中存放着几乎所有的Java实例，在回收之前，首先要区分哪些是存活对象，哪些对象已经死了，只有已经死亡的对象，GC才会在收集的时候释放他们的内存，这个区分死活的阶段就是<strong>垃圾标记阶段</strong></p>
</li>
<li><p>如何判断一个对象已经死了？就是，没有任何指针指向他，不被任何存活对象引用，那他就死了</p>
</li>
<li><p>判断没有引用的算法有两个：<strong>引用计数算法</strong> 和 <strong>可达性分析算法</strong></p>
</li>
</ul>
<h3 id="2-1-1-引用计数算法"><a href="#2-1-1-引用计数算法" class="headerlink" title="2.1.1 引用计数算法"></a>2.1.1 引用计数算法</h3><ul>
<li><p>Reference Counting，比较简单，就是给每一个对象保留一个引用计数器来记录被引用的情况</p>
</li>
<li><p>当一个对象引用A对象，A的计数器+1，同理，引用失效，计数器 - 1</p>
</li>
<li><p>优点：实现简单，垃圾对象便于标识；判定效率高，没有延迟</p>
</li>
<li><p>缺点：</p>
<ul>
<li><p>需要另外的字段存储计数器，有额外存储空间开销</p>
</li>
<li><p>每次操作都需要更新计数器，伴随着 - + 操作，额外时间开销</p>
</li>
<li><p>无法处理循环引用问题，导致 Java 垃圾回收器不使用这个东西</p>
<blockquote>
<p>什么叫循环引用：</p>
<p><img src="/images/gc/gc_ref_counting.png"></p>
<p>如上图第二种情况，如果三个对象循环引用，那么根据技术算法，他们的计数器都是1，不是0，但是其实，这三个对象已经是垃圾了，但是由于算法问题，这个垃圾不被回收。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>小结：</p>
<ul>
<li><p>引用计数算法是很多语言的标记算法，比如python</p>
</li>
<li><p>具体场景下，可能还会使用引用计数，来提高系统的吞吐量</p>
</li>
<li><p>Java没有选择引用计数是因为循环依赖不好处理</p>
</li>
<li><p>python如何解决循环依赖：1. 解除相互之间的引用；2.引入强引用和弱引用</p>
</li>
</ul>
</li>
</ul>
<h3 id="2-1-2-可达性分析算法-根搜索，追踪性垃圾收集"><a href="#2-1-2-可达性分析算法-根搜索，追踪性垃圾收集" class="headerlink" title="2.1.2 可达性分析算法(根搜索，追踪性垃圾收集)"></a>2.1.2 可达性分析算法(根搜索，追踪性垃圾收集)</h3><ul>
<li><p>相对引用计数来说，可达算法同样简单高效，而且这个算法可以很好的解决循环引用问题</p>
</li>
<li><p>Java C# 都采用可达算法</p>
</li>
</ul>
<p>说先说一个基本概念：GC Roots：一个必须活跃的引用集合，在这个基础上，进行可达性分析算法的基本思路</p>
<ul>
<li><p>以GC Roots 为起始点，往下<strong>搜索被根对象集合连接的目标对象是否可达</strong></p>
</li>
<li><p>经过可达性分析后，内存中存活的对象直接或间接的被根对象集合连接着，搜索过的路径就叫做 <strong>引用链</strong></p>
</li>
<li><p>如果目标对象没有被任何引用链相连，则不可达，说明对象已经死亡，需要被收集</p>
</li>
<li><p>可达算法中，只有被根对象集合直接或间接引用的对象，才是存活对象</p>
</li>
<li><p>可达性分析必须在数据的快照中进行，来保证数据一致性</p>
</li>
<li><p>这个算法会导致 STW，即使是号称不会STW的CMS(新的垃圾回收器)，在枚举根节点的时候也是会停顿的。</p>
</li>
</ul>
<h2 id="2-2-详细说说-GC-Roots"><a href="#2-2-详细说说-GC-Roots" class="headerlink" title="2.2 详细说说 GC Roots"></a>2.2 详细说说 GC Roots</h2><p>GC Roots 中包含一下内容：</p>
<ul>
<li><p>虚拟机栈中引用的对象，比如方法参数和局部变量</p>
</li>
<li><p>本地方法栈中 JNI(本地方法) 中引用的对象</p>
</li>
<li><p>方法区中，类的静态属性引用的对象</p>
</li>
<li><p>方法区中，常量引用的对象</p>
</li>
<li><p>被同步锁 synchronized 所持有的对象</p>
</li>
<li><p>JVM内部的引用，比如基本数据类型的 Class，各种异常等常驻对象</p>
</li>
<li><p>除了这些以外，根据用户所选用的垃圾收集器和和内存区域不同，还可能有其他的对象临时加入roots，举个例子就是 分代收集和局部回收。就是说，你要收集堆中年轻代的数据，那么年轻代外面，老年代的数据也可能被认为是roots。</p>
</li>
<li><p>可以这么认为，如果一个指针指向堆中的一个对象，但是这个指针不在堆中，那么他就可能是 root，那么根据上面所说的分代回收，我认为可以这么理解，指针指向了一个待回收区域但是指针不在这个区域，对于这个区域来说，这个指针就是 root。当然，这个区域一般都是堆，毕竟只有 堆 和 方法区有垃圾收集，而且方法区一般不收集。</p>
</li>
</ul>
<p>我觉得可以这么理解，如果GC区域不同，那么GC Roots 也就不确定，GC Roots归根到底就是除了这个被回收区域以外有可能用到这个区域中对象的地方，就是GC Roots，比如我们要收集堆，那么堆中的对象大多被栈指向，所以栈在这里就是堆的GC Roots，那么如果我们要回收年轻代，那么老年代也有可能是GC Roots。</p>
<h2 id="2-3-对象的-finalize机制"><a href="#2-3-对象的-finalize机制" class="headerlink" title="2.3 对象的 finalize机制"></a>2.3 对象的 finalize机制</h2><p>对象Object内有一个方法：finalize() 方法，这个方法是对象被GC的时候，释放之前，会调用这么一个方法，有那么点类似于析构函数，我们最好不要手动去调用他，最好让JVM去调用他。</p>
<p>就是因为finalize的存在，导致一个对象在虚拟机中存在三种状态：</p>
<ul>
<li><p>可触及的：GC Roots 连接的对象，肯定是存活的</p>
</li>
<li><p>可复活的：对象的所有引用都被释放，但是对象可能在 finalize方法中复活</p>
</li>
<li><p>不可触及的：对象的finalize方法被调用，且对象没有复活，那么这个对象就是不可触及的，一个不可触及的对象肯定不能复活，因为一个对象的finalize方法只能调用一次。</p>
</li>
</ul>
<p>只有不可触及的对象，才会被回收。</p>
<h2 id="2-4-总结标记过程"><a href="#2-4-总结标记过程" class="headerlink" title="2.4 总结标记过程"></a>2.4 总结标记过程</h2><p>就因为有finalize方法的存在，gc不能仅仅通过引用链来判断是否回收，总共需要两次标记：</p>
<ul>
<li><p>如果对象到GC Roots 之间没有引用链，进行第一次标记</p>
</li>
<li><p>进行筛选，判断该对象的finalize方法有没有必要执行：</p>
<ul>
<li><p>如果对象没有重写 finalize 方法或者 finalize方法已经被调用过了，则被判定位不可触及对象</p>
</li>
<li><p>如果对象重写了finalize方法，且还未执行过，则会把这个对象插入F-Queue 中，一个被虚拟机自动创建的，低优先级的线程 Finalizer，挨个触发队列里面的finalize方法。</p>
</li>
<li><p>finalize方法是对象最后逃离死亡的机会，稍后GC会对 F-Queue里面的对象进行第二次标记，如果调用finalize，方法里面和引用链中任何一个对象建立了联系，那么这个对象就被移出“即将回收集合”。之后，如果对象再次没有引用的情况，这时finalize方法不会调用，finalize方法只执行一次，然后对象直接变成不可触及。</p>
</li>
</ul>
</li>
</ul>
<h2 id="省略"><a href="#省略" class="headerlink" title="省略"></a>省略</h2><p>中间差了一堆东西，有堆相关工具的使用，以后有需要看 P144 - P146</p>
<h1 id="3-GC-清理阶段"><a href="#3-GC-清理阶段" class="headerlink" title="3. GC -清理阶段"></a>3. GC -清理阶段</h1><p>成功区分出存活对象和死亡对象后，JVM要进行下一步，也就是清理垃圾，释放内存，给下面的对象腾地方</p>
<p>具体算法下面三个：</p>
<ul>
<li><p>复制算法 Copying</p>
</li>
<li><p>标记-清除 算法 Mark-Sweep</p>
</li>
<li><p>标记-压缩 算法 Mark-Compact</p>
</li>
</ul>
<h2 id="3-1-标记清除算法"><a href="#3-1-标记清除算法" class="headerlink" title="3.1 标记清除算法"></a>3.1 标记清除算法</h2><p>标记清除是一个比较低级，常见的垃圾回收算法，第一次被用在 Lisp语言上(Lisp：世界上第一个有GC的语言)。</p>
<h3 id="3-1-1-执行过程"><a href="#3-1-1-执行过程" class="headerlink" title="3.1.1 执行过程"></a>3.1.1 执行过程</h3><p>当内存满了以后，就会停止整个程序(包括用户线程，这个停止就叫 Stop The World，也就是我们说的 STW)，然后进行下面两件事：</p>
<ul>
<li><p>Collector进行标记，从GCRoots 开始遍历可达对象(很显然就是我们前面说的可达性分析算法)，在对象头header中标记这是个可达对象，被引用对象，注意，标记的不是垃圾，没被标记的才是垃圾。</p>
</li>
<li><p>Collector进行清理，遍历对象，检查对象头的可达标记，如果没有，则被回收。</p>
</li>
</ul>
<h3 id="3-1-2-缺点"><a href="#3-1-2-缺点" class="headerlink" title="3.1.2 缺点"></a>3.1.2 缺点</h3><ul>
<li><p>效率不高，主要原因就是需要遍历，怎么遍历的？递归</p>
</li>
<li><p>在GC的时候需要停止整个程序，用户体验不好</p>
</li>
<li><p>清理出来的内存不是连续的，所以同时还需要维护一个内存空闲列表，我们之前说对象内存分配的时候 Chapter07-23 下说过。</p>
</li>
</ul>
<h3 id="3-1-3-注-清除到底指的啥"><a href="#3-1-3-注-清除到底指的啥" class="headerlink" title="3.1.3 注:清除到底指的啥"></a>3.1.3 注:清除到底指的啥</h3><p>清除指的不是说直接这块内存上的东西就清空了，并非。</p>
<p>垃圾还会留着，但是内存地址会写到空闲列表中，如果再次分配对象，新对象会覆盖垃圾对象。</p>
<h2 id="3-2-复制算法"><a href="#3-2-复制算法" class="headerlink" title="3.2 复制算法"></a>3.2 复制算法</h2><p>为了解决标记清除算法低效的问题，提出的复制算法，这个算法同理 堆中年轻代的GC。</p>
<p>思路：</p>
<p>将内存分为两半，一半空着，另一半放数据，当数据区进行垃圾回收时，同理先进行可达性分析，但是，在分析的同时，如果发现对象是可达的，就会把对象复制到另一半内存中，不是复制内存地址，而是整个对象拷贝(拷贝肯定是规整的拷贝)。然后可达性分析完成，数据也就全部复制到另一半，就说明当前这块内存已经没有有用数据了，全都是垃圾，所以直接清理这一半内存即可。然后下一次GC，把对象全都复制到这里即可。</p>
<h3 id="3-2-1-优点"><a href="#3-2-1-优点" class="headerlink" title="3.2.1 优点"></a>3.2.1 优点</h3><ul>
<li><p>简单，快速</p>
</li>
<li><p>复制以后内存连续，不会出现内存碎片</p>
</li>
</ul>
<h3 id="3-2-2-缺点"><a href="#3-2-2-缺点" class="headerlink" title="3.2.2 缺点"></a>3.2.2 缺点</h3><ul>
<li>需要两倍大的内存空间</li>
</ul>
<h3 id="3-2-3-注意"><a href="#3-2-3-注意" class="headerlink" title="3.2.3 注意"></a>3.2.3 注意</h3><p>如果空间的存活对象多，那一次直接全盘复制一轮，垃圾没几个，就会导致效率过低。</p>
<p>这个算法的应用场景最好是存活对象不太多的时候。垃圾多，复制的少，就会效率高。所以这就解释了为啥新生代采用类似这个算法来GC，原因就是新生代的对象大多数朝生暮死。</p>
<h2 id="3-3-标记-压缩-整理-算法"><a href="#3-3-标记-压缩-整理-算法" class="headerlink" title="3.3 标记-压缩(整理) 算法"></a>3.3 标记-压缩(整理) 算法</h2><h3 id="3-3-1-背景"><a href="#3-3-1-背景" class="headerlink" title="3.3.1 背景"></a>3.3.1 背景</h3><p>复制算法适用于存活对象少，垃圾多的地方，比如新生代，所以新生代采用复制算法，但是老年代普遍对象比较大，岁数大，复制算法不再适用，所以基于老年代，就需要其他的垃圾收集算法。</p>
<p>标记清除算法可以用在老年代，但是效率底下，会产生内存碎片，所以JVM在次基础上，退出了 标记压缩算法。</p>
<h3 id="3-3-2-执行过程"><a href="#3-3-2-执行过程" class="headerlink" title="3.3.2 执行过程"></a>3.3.2 执行过程</h3><p>第一阶段和标记清除算法一样，也是需要进行遍历标记。</p>
<p>然后，将所有存活对象按顺序压缩到内存的一端，然后这一端以外的对象全部清除。</p>
<h3 id="3-3-3-优点"><a href="#3-3-3-优点" class="headerlink" title="3.3.3 优点"></a>3.3.3 优点</h3><ul>
<li><p>解决了标记清除算法中 内存碎片的问题</p>
</li>
<li><p>解决了复制算法中内存双倍的问题</p>
</li>
</ul>
<h3 id="3-3-4-缺点"><a href="#3-3-4-缺点" class="headerlink" title="3.3.4 缺点"></a>3.3.4 缺点</h3><ul>
<li><p>效率低于复制算法</p>
</li>
<li><p>移动数据时，指针的指向需要修改</p>
</li>
<li><p>移动过程中 STW</p>
</li>
</ul>
<h1 id="4-垃圾收集拓展"><a href="#4-垃圾收集拓展" class="headerlink" title="4. 垃圾收集拓展"></a>4. 垃圾收集拓展</h1><p>拓展两个东西：</p>
<ul>
<li><p>增量收集算法</p>
</li>
<li><p>分区算法</p>
</li>
</ul>
<p>这两个算法都是为了提高垃圾收集效率，降低STW。</p>
<h2 id="4-1-增量收集算法"><a href="#4-1-增量收集算法" class="headerlink" title="4.1 增量收集算法"></a>4.1 增量收集算法</h2><p>我们之前看三种垃圾收集算法，有个共同的特点，就是STW时间长，垃圾攒的太多了，一次收集有点费劲，所以出现了增量收集算法。</p>
<p>思想如下：</p>
<p>弄一个GC线程，一个用户线程，咱们也别等到他内存沾满了GC，咱们直接 用户线程和GC线程交替执行，这样就会节省GC时间，减短STW时间，特别好。</p>
<p>然而问题就是：切换线程也很消耗资源。</p>
<h2 id="4-2-分区算法"><a href="#4-2-分区算法" class="headerlink" title="4.2 分区算法"></a>4.2 分区算法</h2><p>众所周知，堆空间越大，收集的区域越大，收集就越费劲，所以我们干脆把堆分成n多不同小区域，分开收集，这样就可以降低消耗时间，降低STW。</p>
<p>分代算法把对象分为了年轻代和老年代，分区算法就是把整个堆分成了若干小区域。</p>
<p>每个区域独立分配，独立回收，好处就是可以控制一次收集多少个区域。</p>
<p>缺点：可能会导致GC 频繁，线程切换频率提高，降低吞吐量。</p>
<h1 id="5-垃圾回收的相关概念"><a href="#5-垃圾回收的相关概念" class="headerlink" title="5. 垃圾回收的相关概念"></a>5. 垃圾回收的相关概念</h1><ul>
<li><p>System.gc() 的理解</p>
</li>
<li><p>内存溢出与泄露</p>
</li>
<li><p>Stop The World</p>
</li>
<li><p>垃圾回收的并行与并发</p>
</li>
<li><p>安全点与安全区域：只有在安全点才能停止用户线程</p>
</li>
</ul>
<h2 id="5-1-System-gc"><a href="#5-1-System-gc" class="headerlink" title="5.1 System.gc()"></a>5.1 System.gc()</h2><blockquote>
<p>本地方法，System.gc() 调用 Runtime.getRuntime().gc()</p>
</blockquote>
<p>我们可以通过 System.gc() 和 Runtime.getRuntime().gc() 来显式调用 FullGC(对整个堆进行回收)。</p>
<p>但是同时，JVM附带一个免责声明，JVM不保证你调用gc() 就一定能执行GC。</p>
<p>一般情况下，GC应该是自动进行的，不应该是我们手动进行，否则就太麻烦了，有一种应用场景是我们要写一个性能基准，我们手动调用gc。</p>
<p>所以说，我们可以认为 System.gc() 是提醒JVM进行垃圾收集，至于JVM干不干活？不知道。</p>
<p>详细请看：pri.TestSystemGC 和 pri.LocalVarGC</p>
<h2 id="5-2-内存溢出-Out-Of-Memory"><a href="#5-2-内存溢出-Out-Of-Memory" class="headerlink" title="5.2 内存溢出(Out Of Memory)"></a>5.2 内存溢出(Out Of Memory)</h2><p>首先，什么叫内存溢出：java给的解释是，内存不够了，而且gc完了也不够，那就内存溢出</p>
<p>为什么会内存溢出：</p>
<ul>
<li><p>堆空间大小设置的不够</p>
</li>
<li><p>大对象太多而且不能回收，最后就会沾满。jdk7中会抛出：java.lang.OutOfMemory: PermGen space; jdk8中则会抛出：java.lang.OutOfMemory: Metaspace</p>
</li>
</ul>
<p>这里可以看出，再抛出 OOM 之前，肯定要触发一次GC，去尽可能腾出空间</p>
<ul>
<li>比如：他会尝试去回收软引用指向的对象</li>
</ul>
<p>但是，也并非任何情况下都会进行GC，如果我们要分配一个超大的对象，JVM判断整个堆压根就不够用，GC没有意义，就不会GC，直接抛出OOM。</p>
<h2 id="5-3-内存泄露-Memory-Leak"><a href="#5-3-内存泄露-Memory-Leak" class="headerlink" title="5.3 内存泄露(Memory Leak)"></a>5.3 内存泄露(Memory Leak)</h2><p>总的来说，就是一个对象，程序不会再用到他了，但是GC又不能把它回收，这就很恶心，这就是内存泄露.</p>
<p>实际情况是，我们的一些代码习惯不好，导致一些对象有了特别长的生命周期，最终导致 OOM，这个也可以理解成<strong>宽泛意义上的内存泄露。</strong></p>
<p>尽管发生内存泄露不会立马导致程序崩溃，但是会逐步侵蚀内存，最终有可能导致内存溢出。</p>
<blockquote>
<p>注意：这里说的所有内存不是真实内存，而是虚拟机内存，虚拟机内存取决于物理内存。</p>
</blockquote>
<p>尤其注意：要举内存泄露的例子，不要举循环引用。循环引用是不是内存泄露？是，但是Java不会发生这种情况，因为Java没有采用引用计数算法。</p>
<p>具体举几个例子：</p>
<ul>
<li><p>单例模式的某些对象，因为是单例，所以可能生命周期特别长，然后单例里面引用了外部的一些生命周期短的对象，用完了不释放</p>
</li>
<li><p>各种流，比如 socket，io 等东西，用完了不close</p>
</li>
<li><p>看弹幕说有ThreadLocal？</p>
</li>
</ul>
<h2 id="5-4-并发和并行"><a href="#5-4-并发和并行" class="headerlink" title="5.4 并发和并行"></a>5.4 并发和并行</h2><p>并发：就是单核CPU，来回切换时间片，来达到宏观并行，看似同时操作，实际频繁切换。同一个时间段上同时发生。</p>
<p>并行：多核CPU，每个CPU都在干活，好多任务同时进行，就是并行。同一个时间点上同时发生</p>
<h2 id="5-5-垃圾回收的并发与并行"><a href="#5-5-垃圾回收的并发与并行" class="headerlink" title="5.5 垃圾回收的并发与并行"></a>5.5 垃圾回收的并发与并行</h2><p>并行(Parallel)的垃圾回收器：</p>
<p><strong>多条垃圾回收线程并行工作</strong>，但是用户线程仍然停止，比如：ParNew，Parallel Scavenge，Parallel Old</p>
<p>串行(Serial) 的垃圾回收器：</p>
<p>与并行的对应，只有一个垃圾回收线程工作，同样STW</p>
<p>并发(Concurrent)的垃圾回收器：</p>
<p>回收线程和用户线程同时进行，但是不一定是并行的。得看你CPU，单核CPU那就是靠线程切换来达到并发效果，多核那就是GC和用户在两个CPU上。这样看起来不会暂停用户线程(只要是GC，就必定需要暂停用户线程)。</p>
<p>比如G1,CMS。</p>
<h2 id="5-6-安全点-Safe-Point"><a href="#5-6-安全点-Safe-Point" class="headerlink" title="5.6 安全点 Safe Point"></a>5.6 安全点 Safe Point</h2><p>并非任何时间都可以停下来GC，只有在特定的时间点才会进行GC，STW，那么这个时间点就是 sp。</p>
<p>sp的选择挺重要的，如果sp过少，那么gc次数少，如果sp多，那么经常gc就会导致性能下降。大多数指令的执行时间都比较短。那么选择sp的一个标准就是 “是否具有让程序长时间执行的特征”。选择一个执行时间长的指令作为sp，比如 方法调用 循环跳转 异常跳转。</p>
<p>所以，如果保证所有线程都走到了安全点？两种办法：</p>
<ul>
<li><p>抢先式中断：先让所有线程停下来，然后让没有到达安全点的线程继续跑到安全点。然后这种方法已经不用了</p>
</li>
<li><p>主动式中断：设置一个中断标志，线程跑到安全点主动轮询这个标志，如果标志是true，说明JVM现在要GC，那么线程停止。</p>
</li>
</ul>
<h2 id="5-7-安全区域-Safe-Region"><a href="#5-7-安全区域-Safe-Region" class="headerlink" title="5.7 安全区域 Safe Region"></a>5.7 安全区域 Safe Region</h2><p>安全点确保了正在执行的线程可以停止进行GC，如果一个线程sleep了，他没法运行，咋办，这时候引入安全区域。</p>
<p>在一个区域内，引用不会发生改变，就说明在这个区域内任何地方都是安全的，那么就可以进行GC。这个区域就是sr。sr可以看作是sp的扩展。</p>
<h1 id="6-四种引用"><a href="#6-四种引用" class="headerlink" title="6. 四种引用"></a>6. 四种引用</h1><p>我们希望有这么一类对象，当我们内存不够的时候，触发GC，然后GC完了还是不够，那么JVM就会根据引用的不同，自动抛弃一些对象来腾地方。那么这里就涉及到了四种引用：强 软 弱 虚。四种引用的强度依次递减。</p>
<p>涉及到的对象：</p>
<p>父类：java.lang.ref.Reference 这是个抽象类</p>
<p>实现：WeakReference(弱), SoftReference(软), PhantomReference(虚)</p>
<h2 id="6-1-概括的说一下四种引用："><a href="#6-1-概括的说一下四种引用：" class="headerlink" title="6.1 概括的说一下四种引用："></a>6.1 概括的说一下四种引用：</h2><ul>
<li><p>强引用 StrongReference：最传统的引用方式，代码中最普遍存在的引用赋值，Object o &#x3D; new Object() 这种引用关系，只要引用关系还在，任何情况下GC都不能释放对象。</p>
</li>
<li><p>软引用 SoftReference：在系统要内存溢出之前，会把这些引用指向的对象进行二次回收，如果还是不够，才会抛出OOM</p>
</li>
<li><p>弱引用 WeakReference：被弱引用关联的对象只能活到下一次GC，下一次GC无论内存够不够，都会回收</p>
</li>
<li><p>虚引用 PhantomReference：一个对象是否存在虚引用，完全不会影响他的生存时间，我们也无法通过虚引用获取实例，设置虚引用的<strong>唯一目的就是他关联的对象被收集了以后得到一个系统通知</strong>。</p>
</li>
</ul>
<h2 id="6-2-强引用"><a href="#6-2-强引用" class="headerlink" title="6.2 强引用"></a>6.2 强引用</h2><p>这种引用在程序中最常见，我们直接通过new直接创建一个对象，然后直接把这个对象赋值给一个变量，那么就构成了强引用。</p>
<p>强引用是可触及的(还有指向的时候，我们手动置为null不算)，GC 永远不会回收他。</p>
<p>对于一个普通的对象，只要对象超过了作用域，或者我们手动把变量变为null，则对象会被GC。</p>
<p>相对的，我们把软 弱 虚 表示为：软可触及，弱可触及，虚可触及。他们都是在一定情景下可以被回收，只有强可达不可能被回收。</p>
<p>所以强引用是造成内存泄漏的主要原因.</p>
<h2 id="6-3-软引用-Soft-Reference"><a href="#6-3-软引用-Soft-Reference" class="headerlink" title="6.3 软引用 Soft Reference"></a>6.3 软引用 Soft Reference</h2><p>软引用用来描述一些虽然存活，但是不重要的对象，如果要发生内存泄漏，GC会先回收所有的软引用指向的对象，如果内存还是不够，则会抛出OOM异常。一句话概括：内存不足即回收。</p>
<p>软引用使用场景：高速缓存，如果还有内存，则会使用缓存，提高速度，如果内存没了，就会清除缓存，免得因为缓存而导致内存溢出。</p>
<p>虚拟机在某一时刻决定清理软可达的对象时，就会清理软引用。我们也可以把软引用放入一个队列，依次清理。</p>
<p>类似弱引用，区别就是JVM迫不得已才会回收软科大对象，弱引用是直接就回收了。</p>
<h2 id="6-4-弱引用-Weak-Reference"><a href="#6-4-弱引用-Weak-Reference" class="headerlink" title="6.4 弱引用 Weak Reference"></a>6.4 弱引用 Weak Reference</h2><p>只被弱引用关联的对象只能活到下一次GC，无论下一次GC是否有空间，弱引用关联的对象都会被回收。一句话概括：发现即回收。</p>
<p>但是，由于GC线程的优先级比较低，所以可能不能马上发现弱引用，所以弱引用可能也能存活很长时间。</p>
<p>这个东西同理和软引用一样，我们也可以弄一个队列，把弱引用放入队列中进行处理。</p>
<p>弱引用和软引用适合做缓存，如果内存不够了就释放内存，内存够就放缓存。</p>
<h2 id="6-5-虚引用-Phantom-Reference"><a href="#6-5-虚引用-Phantom-Reference" class="headerlink" title="6.5 虚引用 Phantom Reference"></a>6.5 虚引用 Phantom Reference</h2><p>这东西，完全不决定对象的生命周期，有跟没有一个样，甚至我们没法像前两种引用一样去get。</p>
<p>这东西唯一的作用，就是对象被回收的时候我们会收到一个系统通知。</p>
<p>同时这个引用在创建的时候必须传入一个回收队列。</p>
<p>因为，系统回收一个对象如果发现这个对象有一个虚引用，就会回收后把这个虚引用放入引用队列，来进行通知。</p>
<h2 id="6-6-代码"><a href="#6-6-代码" class="headerlink" title="6.6 代码"></a>6.6 代码</h2><p>上面说的十分抽象，这里给一段代码看看：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对于强 软 弱 引用 代码如下：</span></span><br><span class="line"><span class="comment"> * 软和弱引用好歹可以通过get得到他们指向的对象，我们gc以后通过get去获取对象看看情况，</span></span><br><span class="line"><span class="comment"> * 但是对于虚引用那就是另外一种情况了。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="comment">// 强引用，除非null才回收</span></span><br><span class="line">        <span class="type">User</span> <span class="variable">u1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 软引用，内存不足及回收</span></span><br><span class="line">        SoftReference&lt;User&gt; u2 = <span class="keyword">new</span> <span class="title class_">SoftReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 弱引用，发现及回收</span></span><br><span class="line">        WeakReference&lt;User&gt; u3 = <span class="keyword">new</span> <span class="title class_">SoftReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>());</span><br><span class="line"></span><br><span class="line">        System.gc();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// u1 还在，u2 看情况，如果内存满了就没了，u3 八成是没了</span></span><br><span class="line">        u1.get();</span><br><span class="line">        u2.get();</span><br><span class="line">        u3.get();</span><br><span class="line">    &#125;    </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面仅仅是强软弱引用的情况，对于虚引用，那得下面专门说了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//package pri;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.ref.PhantomReference;</span><br><span class="line"><span class="keyword">import</span> java.lang.ref.ReferenceQueue;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PhantomReferenceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> PhantomReferenceTest obj;</span><br><span class="line">    <span class="keyword">static</span> ReferenceQueue&lt;PhantomReferenceTest&gt; queue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 这个线程用于监听ReferenceQueue</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">CheckReferenceQueue</span> <span class="keyword">extends</span> <span class="title class_">Thread</span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(queue != <span class="literal">null</span>)&#123;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 前面我们说到了第二次gc会把obj对象彻底清理掉，因为finlize已经执行过了</span></span><br><span class="line">                    <span class="comment">// 所以虚引用指向的对象被回收时，是怎么个流程？</span></span><br><span class="line">                    <span class="comment">// 我们创建虚引用的时候传入了一个队列，回收时，这个队列就会接收到这个虚引用，</span></span><br><span class="line">                    <span class="comment">// 但是注意，虚引用和软弱引用不一样，虚引用压根就没法get到他指向的那个对象</span></span><br><span class="line">                    <span class="comment">// 所以这里其实仅仅就是通知一下这个队列：ok，现在有一个虚引用指向的对象被我gc回收了，</span></span><br><span class="line">                    <span class="comment">// 虚引用就是充当一个信号的作用</span></span><br><span class="line"></span><br><span class="line">                    PhantomReference&lt;PhantomReferenceTest&gt; objt = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">try</span>&#123;</span><br><span class="line">                        <span class="comment">// 从引用队列中得到虚引用，如果得到了，说明gc的时候obj被回收了，</span></span><br><span class="line">                        <span class="comment">// 因为只有真正被回收，才会把虚引用传给队列。</span></span><br><span class="line">                        objt = (PhantomReference&lt;PhantomReferenceTest&gt;) queue.remove();</span><br><span class="line"></span><br><span class="line">                        System.out.println(<span class="string">&quot;objt=&quot;</span> + objt);</span><br><span class="line">                    &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 最后判断一下，虚引用不为null，说明回收成功,然后回到108行</span></span><br><span class="line">                    <span class="keyword">if</span>(objt != <span class="literal">null</span>)&#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;objt != null,队列中可以得到虚引用，证明回收成功&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">finalize</span><span class="params">()</span> <span class="keyword">throws</span> Throwable&#123;</span><br><span class="line">        <span class="built_in">super</span>.finalize();</span><br><span class="line">        System.out.println(<span class="string">&quot;finlize start&quot;</span>);</span><br><span class="line">        obj = <span class="built_in">this</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;重新给obj赋值为this，finlize中把obj救活了&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 首先创建一个自己的强引用</span></span><br><span class="line">        obj = <span class="keyword">new</span> <span class="title class_">PhantomReferenceTest</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建引用队列，这个玩意待会儿会接收gc信息</span></span><br><span class="line">        queue = <span class="keyword">new</span> <span class="title class_">ReferenceQueue</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个监听ReferenceQueue的线程，同时设置为守护线程，也就是这个线程不会随着main线程的结束而结束</span></span><br><span class="line">        <span class="type">CheckReferenceQueue</span> <span class="variable">checkReferenceQueue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CheckReferenceQueue</span>();</span><br><span class="line">        checkReferenceQueue.setDaemon(<span class="literal">true</span>);</span><br><span class="line">        checkReferenceQueue.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 给obj添加虚引用，创建虚引用的同时需要指定引用队列</span></span><br><span class="line">        PhantomReference&lt;PhantomReferenceTest&gt; ref = <span class="keyword">new</span> <span class="title class_">PhantomReference</span>&lt;&gt;(obj, queue);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">// 很好，我们先试试虚引用能不能像软弱引用一样get，发现不行，也就是说虚引用仅仅就充当一个信号的作用</span></span><br><span class="line">            System.out.println(ref.get());</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;第一次GC&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 我们进行第一轮gc，我们给强引用置空，这个时候虚引用指向的这个对象就没有强引用，</span></span><br><span class="line">            <span class="comment">// 按理说会直接回收掉</span></span><br><span class="line">            obj = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">            System.gc();</span><br><span class="line"></span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 但是我们发现这个时候obj居然不为空，居然还是this，这是为啥？</span></span><br><span class="line">            <span class="comment">// 因为我们上面重写了finlize方法，这个方法里面复活了obj，让obj重新回到了可触及的状态</span></span><br><span class="line">            <span class="comment">// 所以第一轮gc并没有清理掉obj</span></span><br><span class="line">            <span class="keyword">if</span>(obj == <span class="literal">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj == null&quot;</span>);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj != null, finlize生效使obj复活&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;第二次GC&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 很好，我们开始进行第二轮gc，再一次清除强引用指向并调用gc开始清理</span></span><br><span class="line">            obj = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">            System.gc();</span><br><span class="line"></span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ok，这个时候先不要着急看这里，回到上面的第11行，我们从第十一行接着分析。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 行了，上面的队列刘晨我们走完了，最后这里收个尾，最后判断一下obj是不是null</span></span><br><span class="line">            <span class="comment">// 是的话，ok，回收成功</span></span><br><span class="line">            System.out.println(<span class="string">&quot;obj == null?  &quot;</span> + (obj == <span class="literal">null</span>));</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo部署</title>
    <url>/2022/05/22/hexo%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>整个博客使用Hexo搭建，需要电脑上有 node + git 环境，如果没有，请移步下面的教程：</p>
<p><a href="https://www.bilibili.com/video/BV1q4411i7gL">hugo博客搭建</a></p>
<span id="more"></span>

<h1 id="1-Github-Page"><a href="#1-Github-Page" class="headerlink" title="1. Github Page"></a>1. Github Page</h1><p>干嘛的？就是github会给你一个域名，比如 xxx.github.io，这个域名你可以用来部署一些静态页面，步骤也很简单，只要仓库里面是静态页面的文件就可以了。有了这个我们就可以搭建个人博客。</p>
<p><strong><font color='red'>步骤如下：</font></strong></p>
<p>在github创建仓库，仓库名必须是 xxxx.github.io，而且这个xxx，最好是你的用户名，必须遵从这个规范。创建完以后，只要你这个仓库里面有静态页面的东西，那 page 就会生效。可以选择用READMD初始化一下仓库，然后在仓库的 settings 里面，找到 Pages，会发现里面给你提供了一个可访问的网址，说明page已经生效。</p>
<p>如果settings-page里面没有那个网址，说明空仓库，没关系，待会就有了。</p>
<h1 id="2-Hexo"><a href="#2-Hexo" class="headerlink" title="2. Hexo"></a>2. Hexo</h1><p>我们这里选择Hexo来搭建仓库，这里提供一个视频，可以跟着视频搭：</p>
<p><a href="https://www.bilibili.com/video/BV1Yb411a7ty">Hexo搭建教程</a></p>
<h2 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h2><p>所以这个hexo是个什么原理？其实很简单。我们在博客项目下编写md文档，然后hexo会帮我们自动把md文档转化为html，然后连同hexo这个网站一起，打包，发到你配置的git仓库实现自动部署。</p>
<p>所以这也是我之前的一个错误理解，我以为hexo是一个后端服务，需要把他部署在服务器上，github page 帮我们跑这个服务器。其实不该是这么用的，而是hexo安装在我们本地，我们在博客里面写好文章，然后通过命令让hexo帮我们打包发送到git，然后git帮我们部署打包好的静态页面。</p>
<p>当然啦，如果你和我一样弱智的话，也可以把hexo当后端服务跑，hexo提供了一个本机预览的功能，有点类似Vue 的 npm run serve，你大可以找个服务器然后 <code>nohup hexo s &amp;</code>。</p>
<h2 id="2-2-安装流程"><a href="#2-2-安装流程" class="headerlink" title="2.2 安装流程"></a>2.2 安装流程</h2><blockquote>
<p>这里必须要有 node.js 环境，没有的话去装 hugo，同时必须要有git</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 hexo</span></span><br><span class="line">npm install hexo-cli -g</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化 hexo 项目，你自己找一个目录，然后在里面执行这条命令</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注：这里强烈建议配置一下 github 加速，因为这一步要从github拉东西，太慢的话可能会报错</span></span><br><span class="line">hexo init blog</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等待初始化结束，本地启动hexo</span></span><br><span class="line">hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>

<p>然后，正常情况下，会提示这么一句：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>

<p>如果没有这句，那么不出意外地话应该是出意外了，把错误信息百度一下看看 :)</p>
<p>OK，到这里算是安装完了，但是我们还需要配置一下这个玩意。</p>
<h2 id="2-3-配置基本信息"><a href="#2-3-配置基本信息" class="headerlink" title="2.3 配置基本信息"></a>2.3 配置基本信息</h2><p>博客根目录下有个 _config.yml 文件，打开他，改几个地方：</p>
<h3 id="2-3-1-配置博客基本信息"><a href="#2-3-1-配置博客基本信息" class="headerlink" title="2.3.1 配置博客基本信息"></a>2.3.1 配置博客基本信息</h3><p>配置文件中会找到这么几行：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">博客网站的题目</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">&#x27;博客小标题&#x27;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;描述信息&#x27;</span></span><br><span class="line"><span class="attr">keywords:</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">用户名</span></span><br><span class="line"><span class="comment"># 配置语言-简中</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-Hans</span></span><br><span class="line"><span class="comment"># 时区</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-配置仓库"><a href="#2-3-2-配置仓库" class="headerlink" title="2.3.2 配置仓库"></a>2.3.2 配置仓库</h3><p>往后找，找到这么几行：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="comment"># 这里写你的git仓库地址</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">http://xxxxx@github.com/user_name/user_name.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-小坑"><a href="#2-3-3-小坑" class="headerlink" title="2.3.3 小坑"></a>2.3.3 小坑</h3><p>如果这里你配置的是github的仓库地址，那可能需要麻烦点，这里直接写 <a href="https://github.com/xxx/xxx.github.io.git">https://github.com/xxx/xxx.github.io.git</a> 的话，push 的时候会让你输入用户名密码，然后，很可能告诉你现在已经不支持密码验证了，要你配置token。</p>
<p>我这里就不展开说了，百度一下如何获取github的token，然后把这个地址写成 <code>https://your_token@github.com//xxx/xxx.github.io.git</code> 即可。</p>
<h2 id="2-4-安装主题"><a href="#2-4-安装主题" class="headerlink" title="2.4 安装主题"></a>2.4 安装主题</h2><p>我这里选择使用 NexT主题，同样的，在博客项目中执行如下命令，切记必须是博客根目录，就是有 node_modules 那个目录下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">克隆主题源码到 博客的themes 目录下</span></span><br><span class="line">git clone https://github.com/theme-next/hexo-theme-next.git themes/next</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装一个包，不安装的话可能会乱码</span></span><br><span class="line">npm install hexo-renderer-swig</span><br></pre></td></tr></table></figure>

<p>然后配置根目录下的 _config.yml 文件，找到 theme，修改为: <code>theme: next</code> 即可，然后执行命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo g</span><br></pre></td></tr></table></figure>

<p>访问 localhost:4000 看看效果。希望没有乱码。</p>
<h2 id="2-5-Tags-amp-Categories-amp-About"><a href="#2-5-Tags-amp-Categories-amp-About" class="headerlink" title="2.5 Tags &amp; Categories &amp; About"></a>2.5 Tags &amp; Categories &amp; About</h2><p>我们的博客里面的文章得有分类和标签吧？还得有个关于页面吧？怎么配置呢？</p>
<p>在博客根目录下执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page about</span><br><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>

<p>然后，进入source目录，会发现里面有了三个目录，分别是 categories  tags  about。我们挨个改：</p>
<p>首先是进入 categories 目录，编辑 index.md，固定写法，其实就是在date下面，线上面，加一个 <code>type: &quot;categories&quot;</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">title: Categories</span><br><span class="line">date: 2022-05-21 11:43:02</span><br><span class="line">type: &quot;categories&quot;</span><br><span class="line">-----------------------</span><br></pre></td></tr></table></figure>

<p>同理Tags，编辑里面的 index.md ，在date 下面，线上面，加一个 <code>type: &quot;tags&quot;</code> 即可。</p>
<p>同理about，编辑index.md，里面写上你想写的东西就行了。</p>
<p>然后，这三个页面以后都不要管了。</p>
<h2 id="2-6-主题配置"><a href="#2-6-主题配置" class="headerlink" title="2.6 主题配置"></a>2.6 主题配置</h2><p>这可就麻烦了，比如 配置头像，配置github，配置主题的主题，配置搜索功能 等等。这里给个博客自己看吧：</p>
<p><a href="https://blog.csdn.net/weixin_42665200/article/details/104633560">NexT配置</a></p>
<h1 id="3-部署"><a href="#3-部署" class="headerlink" title="3. 部署"></a>3. 部署</h1><p>这个倒是出奇的简单，直接 hexo d 即可。这一步他就会把项目打包，然后传给github，然后github就会给你部署你的静态页面。</p>
<p>当然啦，只要是支持git page 的git网站应该都行，比如gitee，但是gitee申请page挺麻烦的，还得实名认证，不想琢磨。</p>
]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾收集器</title>
    <url>/2022/06/06/garbage-collectors/</url>
    <content><![CDATA[<p>上一章说了主要的垃圾回收的各种基础理论，比如各种的垃圾回收算法，GCRoots 啥的，这一章我们就深入目前主流的各种垃圾回收器，看看他们是如何进行垃圾回收的。</p>
<span id="more"></span>

<h1 id="1-垃圾回收器概述"><a href="#1-垃圾回收器概述" class="headerlink" title="1. 垃圾回收器概述"></a>1. 垃圾回收器概述</h1><p>垃圾回收器，众所周知就是用来进行垃圾回收的一个东西。下面是一些概念：</p>
<ul>
<li><p>垃圾回收器没有在JVM规范中做过多的规定，可以由不同的厂商的JVM来实现。</p>
</li>
<li><p>由于JDK告诉迭代，所以垃圾回收器已经有了很多版本。</p>
</li>
<li><p>从不同的角度看，可以把GC分为不同的类型。</p>
</li>
</ul>
<h1 id="2-垃圾回收器分类"><a href="#2-垃圾回收器分类" class="headerlink" title="2. 垃圾回收器分类"></a>2. 垃圾回收器分类</h1><ul>
<li><p>按照线程数分，可以分为 <strong>串行</strong>垃圾回收器和<strong>并行</strong>垃圾回收器，只有一个垃圾回收线程就是串行，一堆线程回收就是并行。当然，不管线程有几个，得会发生STW。那么具体指的就是只有一个CPU的时候，那就是用串行垃圾回收器，多个CPU那就是并行。</p>
<ul>
<li><p>只有一个单CPU，那就用串行垃圾回收器，如果并发的执行一堆垃圾回收线程效果反而不好。具体应用在 Client模式下的JVM中。</p>
</li>
<li><p>并发性能好的CPU，也可以使用并行的垃圾回收。</p>
</li>
</ul>
</li>
<li><p>按照工作模式来分，那就分为&#x3D;&#x3D;并发&#x3D;&#x3D;式垃圾回收和&#x3D;&#x3D;独占&#x3D;&#x3D;式垃圾回收。</p>
<ul>
<li><p>并发的执行用户线程和垃圾回收线程，让STW没那么明显</p>
</li>
<li><p>独占的垃圾回收器一旦运行，就暂停所有的用户线程。直接STW。</p>
</li>
</ul>
</li>
<li><p>按照碎片处理方式分，分为&#x3D;&#x3D;压缩式&#x3D;&#x3D;垃圾回收器和&#x3D;&#x3D;非压缩式&#x3D;&#x3D;垃圾回收器。</p>
<ul>
<li><p>垃圾回收完成后，整理内存碎片，前面说过，标记-压缩算法，指针碰撞</p>
</li>
<li><p>没有上面那步，空闲列表。</p>
</li>
</ul>
</li>
<li><p>按照工作的内存区分，分为<strong>年轻代</strong>垃圾回收和<strong>老年代</strong>垃圾回收。</p>
</li>
</ul>
<h1 id="3-垃圾回收器的评估性能指标"><a href="#3-垃圾回收器的评估性能指标" class="headerlink" title="3. 垃圾回收器的评估性能指标"></a>3. 垃圾回收器的评估性能指标</h1><p>大致分为以下指标：</p>
<ul>
<li><p>吞吐量：运行用户代码和程序总运行时间的比例。</p>
</li>
<li><p>垃圾收集开销：吞吐量的补数，收集时间和总运行时间的比例</p>
</li>
<li><p>暂停时间：垃圾收集时，暂停用户线程的时间</p>
</li>
<li><p>收集频率：相对于应用程序的执行，收集操作发生的频率。</p>
</li>
<li><p>内存占用：Java堆区所占内存大小</p>
</li>
<li><p>快速：一个对象从诞生到回收的时间。对象就用了就赶紧清理，让他活得时间短一点。</p>
</li>
</ul>
<p>前面三个重点关注，但是上面三个指标不可能全部满足，所以三者构成一个 “不可能三角”，随着硬件逐步发展，现在最多可以同时满足2个。</p>
<p>下面会详细说说上面三个重要指标：</p>
<h2 id="3-1-吞吐量"><a href="#3-1-吞吐量" class="headerlink" title="3.1 吞吐量"></a>3.1 吞吐量</h2><ul>
<li><p>就是CPU执行用户代码的时间 &#x2F; 程序执行的总时间。</p>
</li>
<li><p>高吞吐量的程序有更多的时间基准，快速响应就不要考虑了。</p>
</li>
<li><p>吞吐量优先那就有可能是(只是可能，谁知道实际情况)，减少GC频率，每次时间长一点，但是总GC时间短。</p>
</li>
</ul>
<h2 id="3-2-暂停时间"><a href="#3-2-暂停时间" class="headerlink" title="3.2 暂停时间"></a>3.2 暂停时间</h2><ul>
<li><p>暂停时间：一个时间段内让程序暂停，让GC进行。</p>
</li>
<li><p>注意这个东西是每次的，不是总的STW时间。</p>
</li>
<li><p>如果是暂停时间优先，那就是增加GC频率，然后每次GC时间短。</p>
</li>
</ul>
<p>上面两种指标，是互斥的，如果追求高吞吐量，那么就需要降低GC频率，导致每次GC的时间较长。如果暂停时间优先，则GC频率高，每次是时间短，但是加在一起可能时间长，吞吐量低。</p>
<p>目前的标准：在最大吞吐量优先的情况下，降低停顿时间。</p>
<h1 id="4-垃圾收集器的发展历史"><a href="#4-垃圾收集器的发展历史" class="headerlink" title="4. 垃圾收集器的发展历史"></a>4. 垃圾收集器的发展历史</h1><p><img src="/../images/gc/GCorProcess.png" alt="history"></p>
<p>上面这张图中，有一个分水岭，就是2018年的G1收集器发布，算上这个，在jdk11发布之前，总共是有7种垃圾回收器，这7种是最经典的垃圾回收器，必须要知道，分别是：</p>
<ul>
<li><p>串行回收器：Serial，Serial Old</p>
</li>
<li><p>并行回收器：ParNew，Parallel Scavenge，Parallel Old</p>
</li>
<li><p>并发回收器：CMS，G1</p>
</li>
</ul>
<h1 id="5-7款垃圾收集器和垃圾分代之间的关系"><a href="#5-7款垃圾收集器和垃圾分代之间的关系" class="headerlink" title="5. 7款垃圾收集器和垃圾分代之间的关系"></a>5. 7款垃圾收集器和垃圾分代之间的关系</h1><ul>
<li><p>新生代GC：Serial； ParNew； Parallel Scavenge</p>
</li>
<li><p>老年代GC：Serial Old；Parallel Old；CMS</p>
</li>
<li><p>整堆：G1</p>
</li>
</ul>
<p>然后每个GC之间为了给整堆进行GC，各自会有配合，如下图：</p>
<p><img src="/../images/gc/GCGernection.png" alt="gcors"></p>
<p>我们来解释一下这个图：</p>
<p>jdk8之前，两条红色虚线看成实线，也就是说，jdk8之前，Serial GC 可以和 CMS 和 Serial Old 搭配进行整堆回收，ParNew 可以和 CMS 和 Serial Old 进行搭配，以此类推。然后为啥 CMS和Serial Old 之间还有联系？这是一个后备方案，如果CMS回收失败，就会启用 Serial Old。</p>
<p>所以红线是什么意思？jdk8中，取消了两条红线，也就是红线对应的两种组合取消了，但是你要非要用，也行，就相当于 @Deprecated。jdk9 中，彻底 Remove了，压根就不让你使了。</p>
<p>绿色的线是啥？jdk14中，Deprecated 了 Parallel Scavenge 和 Serial Old 的组合，仅仅是弃用，还没有移除。</p>
<p>CMS有个青色的框，啥意思？jdk14中，删除了 CMS，注意是删除。</p>
<h2 id="5-1-为什么使用多种垃圾回收器"><a href="#5-1-为什么使用多种垃圾回收器" class="headerlink" title="5.1 为什么使用多种垃圾回收器"></a>5.1 为什么使用多种垃圾回收器</h2><p>因为应用场景不同，所以不同的垃圾回收器效果不一样。</p>
<h2 id="5-2-相应参数"><a href="#5-2-相应参数" class="headerlink" title="5.2 相应参数"></a>5.2 相应参数</h2><ul>
<li><p>查看默认的垃圾收集器：-XX:+PrintCommandLineFlags</p>
</li>
<li><p>命令行方式查看：jinfo -flag 参数 进程id ;这个参数可以看上面那条命令的结果，他给你打印好多JVM参数，比如什么 useParallelGC 这种的</p>
</li>
</ul>
<hr>
<p>上面提到了目前为止有7种经典的垃圾回收器，下面我们会挨个介绍:</p>
<h1 id="6-Serial回收器"><a href="#6-Serial回收器" class="headerlink" title="6. Serial回收器"></a>6. Serial回收器</h1><blockquote>
<p>经典的串行回收器</p>
</blockquote>
<p>serial 回收器 可以说是最基本的最老的垃圾回收器，jdk1.3之前回收年轻的唯一选择。因为他是串行的，所以他是Client模式下的垃圾回收器。</p>
<p>Serial 采用 <strong>复制算法</strong>，串行回收 和 STW机制来对内存进行回收。</p>
<p>除了 Serial回收年轻代，还有Serial Old 回收老年代，在上面那张图中我们可以看到，Serial 和 Serial Old 搭配进行回收。Serial Old 和Serial 也是串行然后STW，区别就是老年代的垃圾特性，我们之前说过，决定了老年代不适合采用复制算法。所以Serial Old 收集器采用 标记-压缩算法。</p>
<p>Serial Old 在client模式下是回收老年代的垃圾回收器，在server模式下 Serial Old 也能用，主要就是用来搭配 新生代收集器 Parallel Scavenge 进行整堆收集以及充当CMS的备用收集器，如果CMS回收失败，则采用Serial Old。在前面那张图中体现了。</p>
<p>具体的收集过程如下：</p>
<p><img src="/../images/gc/SerialGC.png" alt="serial_gc"></p>
<p>看图，可以明确的看出来，这个GC是串行的。同时发生STW。单线程的意思就是：</p>
<ul>
<li><p>只是用一个CPU或者说只使用一个垃圾收集线程进行GC</p>
</li>
<li><p>垃圾回收时，只能由垃圾回收线程，所有用户线程必须停止。</p>
</li>
</ul>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ul>
<li><p>简单而高效，在单个CPU的情况下，这玩意专心进行GC，不和其他线程交互，没有额外开销。所以高效。</p>
</li>
<li><p>在桌面应用中，内存一般不高，所以一次GC消耗几百毫秒，也还行。</p>
</li>
<li><p>可以使用 -XX:+useSerialGC 来启用Serial GC，让年轻代和老年代都是用串行垃圾回收器。这个参数就等价于设置年轻代GC为Serial 老年代用 Serial Old。这个东西，采用哪种垃圾回收器就是 -XX:+useGCName；+代表启用，use 使用 然后是 GC名。</p>
</li>
</ul>
<h1 id="7-ParNew-回收器"><a href="#7-ParNew-回收器" class="headerlink" title="7. ParNew 回收器"></a>7. ParNew 回收器</h1><blockquote>
<p>并行回收器</p>
</blockquote>
<p>如果说Serial是单线程的年轻代垃圾收集器，所以 ParNew就是Serial的多线程版本，Par 就是 Parallel 的缩写，New是只能处理新生代。ParNew 除了使用并行回收外，基本和 Serial 没有区别，都是回收年轻代，使用复制算法，采用STW机制。</p>
<p>ParNew是JVM在server模式下的默认年轻代垃圾回收器。</p>
<p>具体流程如下：</p>
<p><img src="/../images/gc/ParNew.png" alt="parnew_gc"></p>
<ul>
<li><p>ParNew 收集新生代，回收频繁，并且使用并行方式，比较高效。</p>
</li>
<li><p>对于老年代，仍然使用串行方式，回收次数少(CPU并行需要切换线程，这里使用串行可以节省资源)。</p>
</li>
</ul>
<p>虽然说ParNew是并行回收，但是我们不能说ParNew效率比Serial高。</p>
<ul>
<li><p>在多核情况下，ParNew的确比Serial效率高，因为多个核可以一起GC，效率高</p>
</li>
<li><p>但是在单核下，ParNew需要这个CPU不停的进行线程调度，所以效率反倒比Serial差。</p>
</li>
</ul>
<p>除了 Serial，ParNew GC 可以和CMS搭配使用。</p>
<h2 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h2><ul>
<li><p>通过选项：-XX:+useParNewGC 来开启ParNew。代表年轻代使用ParNew，不影响老年代。</p>
</li>
<li><p>使用选项：-XX:ParallelGCThreads 限制GC线程数，默认开启和CPU线程数相同的数目。</p>
</li>
</ul>
<p>但是在jdk9以后如果我们指定 ParNew，那就不太好了，他就会给你警告说 ParNew 已经 Deprecated 了，不建议使用。</p>
<h1 id="8-Parallel-Scavenge"><a href="#8-Parallel-Scavenge" class="headerlink" title="8.Parallel Scavenge"></a>8.Parallel Scavenge</h1><blockquote>
<p>吞吐量优先</p>
</blockquote>
<p>ParNew用于收集年轻代以外，Parallel Scavenge 也是使用复制算法，STW，并行回收。所以为啥ParNew有了以后还有ParallelScavenge？</p>
<p>就已经告诉你了，Parallel Scavenge(以后就叫Parallel) 是吞吐量优先。Parallel 的目标是达到一个可控制的吞吐量，所以Parallel 也叫 吞吐量优先垃圾收集器。</p>
<p>自适应调节也是 Parallel 和 ParNew 的一个区别。(啥叫自适应调节？就是在运行的时候可以根据内存情况进行调整)</p>
<p>高吞吐量优先可以高效率的利用CPU时间，尽快完成程序的运算任务。适合&#x3D;&#x3D;后台运算的任务不需要太多交互 的任务&#x3D;&#x3D;，因此常用在服务器环境中使用。</p>
<p>Parallel 在 jdk1.6 中添加了 Parallel Old 用来回收老年代，来替换Serial Old。</p>
<p>Parallel Old 收集器采用&#x3D;&#x3D;标记压缩算法&#x3D;&#x3D;，并行回收，使用STW。</p>
<p>具体流程如下：</p>
<p><img src="/../images/gc/Parallel.png" alt="ParallelSca"></p>
<p>上图中，年轻代用 Parallel Scavenge 回收，老年代用 Parallel Old 回收，两者都是并行的。</p>
<h2 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h2><ul>
<li><p>开启ParallelScavenge：-XX:+useParallelGC 手动指定年轻代使用Parallel来进行回收。(JDK9中开启Parallel会自动开启 Parallel Old)</p>
</li>
<li><p>开启ParallelOld：-XX:+useParallelOldGC 手动指定老年代使用ParallelOld进行回收。(JDK8 中默认使用Parallel和ParallelOld)</p>
</li>
</ul>
<p>上面这两个参数是互相激活的，只要开启一个，就会开启另一个。</p>
<ul>
<li><p>指定Parallel 并行线程数：-XX:ParallelGCThreads</p>
<ul>
<li><p>一般来说，最好是 CPU数目&#x3D;&#x3D;线程数目</p>
</li>
<li><p>细节上的区别：当CPU &lt;&#x3D; 8；则线程数 &#x3D;&#x3D; CPU数</p>
</li>
<li><p>当CPU&gt;8；则线程数&#x3D;3 + ( (5 * cpu) &#x2F; 8)</p>
</li>
</ul>
</li>
<li><p>指定垃圾收集最大 STW时间：-XX:MaxGCPauseMillis</p>
<ul>
<li><p>不是绝对的，只会尽可能地靠近这个时间，他会调整一些JVM参数。</p>
</li>
<li><p>对于用户来说肯定是STW越低越好，但是对于服务器来说还是吞吐量更重要，所以这个参数慎用。</p>
</li>
</ul>
</li>
<li><p>指定垃圾收集时间和总时间的占比：-XX:GCTimeRatio,用于衡量吞吐量。</p>
<ul>
<li>取值范围0-100，默认是99，也就是GC时间占总时间的1%；</li>
</ul>
</li>
</ul>
<p>上面两个参数互斥，吞吐量和STW时间不可兼得。</p>
<ul>
<li><p>指定Parallel采用自适用机制：-XX:+useAdaptiveSizePolicy，默认是开启的。</p>
<ul>
<li><p>在这种模式下，年轻代和老年代的大小比例会自动调整已达到 堆大小 吞吐量 暂停时间 之间的平衡。</p>
</li>
<li><p>手动调整比较费劲的情况下，应该使用这个模式。</p>
</li>
</ul>
</li>
</ul>
<h1 id="9-CMS"><a href="#9-CMS" class="headerlink" title="9. CMS"></a>9. CMS</h1><blockquote>
<p>低延迟</p>
</blockquote>
<h2 id="9-1-概述"><a href="#9-1-概述" class="headerlink" title="9.1 概述"></a>9.1 概述</h2><p>jdk1.5 的时候，推出的垃圾收集器，全称是 Concurrent-Mark-Sweep ：并发的垃圾清除收集器。这个收集器是HotSpot虚拟机推出的第一个并发的垃圾收集器，宏观上他和用户线程一起工作，降低STW时间。</p>
<p>CMS的关注点是尽可能低的STW时间，STW时间越低，就越适合与用户交互的程序。低延迟可以提高用户体验。</p>
<blockquote>
<p>很多Java程序部署在服务器上，我们很关注服务器的响应速度，降低系统停顿时间，所以CMS挺适合服务器程序</p>
</blockquote>
<p>CMS采用标记-清除算法，并且也会STW,仅仅是STW时间短了而已。</p>
<p>然而，CMS作为老年代的垃圾收集器，他没法和 Parallel Scavenge 收集器协调工作，所以在jdk1.5以后，CMS作为老年代收集器的时候，年轻代只能选择 ParNew 或者 Serial 中的一个。</p>
<p>在G1出现之前，CMS还是应用非常广泛的，直到现在，一些地方还在使用CMS。</p>
<p>具体流程如下：</p>
<p><img src="/../images/gc/CMS.png" alt="cms"></p>
<p>核心的流程就是中间四步：</p>
<ul>
<li><p>初始标记 Initial-Mark：这个阶段程序中的所有工作线程都会停止进入STW状态，然后进行初始标记，仅仅标记出、<strong>GCRoots能够直接到达的对象</strong>，一旦标记完成就会马上恢复前面暂停的线程。因为和GCRoots直接关联的对象比较少，所以这个过程非常快。</p>
</li>
<li><p>并发标记 Concurrent-Mark：<strong>从GCRoots直接关联的对象开始遍历整个对象图</strong> 的过程，这个过程比较慢，但是不需要暂停用户线程，他可以和用户线程并发执行。</p>
</li>
<li><p>重新标记 Remark：修正的过程，前面并发标记的时候因为用户线程还在运行导致标记有一些偏差，这个阶段就是为了修正这些标记偏差，这个过程比初始标记的时间长一些，但远比并发标记时间短。</p>
<blockquote>
<p>注意这个修正修正的是啥？在并发阶段没法确定是不是垃圾的东西，这里重新确定垃圾。注意，是并发标记的时候已经怀疑是垃圾了，然后这里重新进行一个判断处理。</p>
</blockquote>
</li>
<li><p>并发清理 Concurrent-Sweep：清除死亡对象，释放内存空间，由于存活对象不需要移动，所以这个阶段也可以和用户线程并发进行。</p>
</li>
</ul>
<h2 id="9-2-总结CMS"><a href="#9-2-总结CMS" class="headerlink" title="9.2 总结CMS"></a>9.2 总结CMS</h2><p>尽管CMS并发标记，但是在初始标记和重新标记阶段还是会发生STW，但是时间很短。所以说任何的GC都不可能完全消除STW，只能尽可能地减少这个时间。</p>
<p>由于并发标记阶段和并发清理阶段都是并发的，不需要停顿工作，所以整体来看CMS是低停顿的。</p>
<p>由于在清理阶段用户线程没有停顿，这个时候用户线程还是会产生对象消耗内存，所以不能说老年代满了才收集垃圾，而是当老年代的空间达到一个阈值的时候，CMS就会开始工作，确保在清理过程中还能正常的往堆中放东西。如果清理阶段CMS预留的内存不够了，就会出现一次&#x3D;&#x3D;Concurrent Mode Failure&#x3D;&#x3D;失败，这个时候 Serial Old 作为备用GC就会开始工作，这个时候停顿时间就会变长了。</p>
<p>为啥CMS不用标记-压缩算法？</p>
<p>因为在清理阶段用户线程还在执行，这个时候你压缩内存，修改对象的内存地址，就会导致用户线程找不到对象。</p>
<h2 id="9-3-CMS的优缺点："><a href="#9-3-CMS的优缺点：" class="headerlink" title="9.3 CMS的优缺点："></a>9.3 CMS的优缺点：</h2><p>优点：延迟低 并发收集</p>
<p>缺点：</p>
<ul>
<li><p>会产生内存碎片，可能导致清理后没有足够的大块的内存，无法放置大对象，被迫出发 FullGC。</p>
</li>
<li><p>CMS收集器对CPU资源比较敏感，他在并发阶段虽然不会导致用户线程停止，但是他会消耗CPU资源，让系统的吞吐量降低。</p>
</li>
<li><p>CMS无法处理浮动垃圾，啥是浮动垃圾，我们在并发标记阶段怀疑是垃圾的东西，在重新标记阶段重新判断。但是有些东西在并发标记阶段压根没有被怀疑，但是在并发过程中他变成垃圾了，这个时候重新标记阶段就没还有办法进行处理。这部分，在并发过程中变成垃圾的垃圾，就称为 &#x3D;&#x3D;浮动垃圾&#x3D;&#x3D;。只能在下一次GC中清理。</p>
</li>
</ul>
<h2 id="9-4-CMS相关参数"><a href="#9-4-CMS相关参数" class="headerlink" title="9.4 CMS相关参数"></a>9.4 CMS相关参数</h2><ul>
<li><p>指定JVM使用CMS：-XX:+useConMarkSweepGC,打开这个以后会自动开启 -XX:+useParNewGC,也就是 ParNew + CMS + Serial Old 的堆回收组合。</p>
</li>
<li><p>指定堆使用率阈值，达到则GC：-XX:CMSInitiatingOccupanyFraction</p>
<ul>
<li><p>jdk5 中默认是 68%，堆使用率达到 68%则进行回收。jdk6以后默认是 92%。</p>
</li>
<li><p>如果内存增长比较慢，可以设置大阈值，这样可以降低回收次数，提高效率。如果内存增长快，则应该缩小阈值，避免在清理过程中内存不足导致Concurrent Mark Failure，触发 FullGC，降低效率。</p>
</li>
</ul>
</li>
<li><p>指定进行FullGC之后对内存进行整理，避免内存碎片产生：-XX:+useCMSCompactAtFullCollection.这样停顿时间更长了。</p>
</li>
<li><p>指定多少次 FullGC以后对内存空间进行整理：-XX:CMSFullGCsBeforeCompaction</p>
</li>
<li><p>指定 CMS 线程数目：-XX:ParallelCMSThreads</p>
<ul>
<li>默认的线程数：（ParallelGCThreads + 3） &#x2F; 4；这个 ParallelGCThreads 默认就是 cpu个数。</li>
</ul>
</li>
</ul>
<h2 id="9-5-小结"><a href="#9-5-小结" class="headerlink" title="9.5 小结"></a>9.5 小结</h2><p>Serial Parallel CMS 有啥不一样？</p>
<ul>
<li><p>如果要最小化地使用内存和并行开销，选择 Serial GC</p>
</li>
<li><p>最大化应用的吞吐量，选择 Parallel Scavenge</p>
</li>
<li><p>最小化中断时间或停顿时间，选择 CMS (CMS+ParNew)</p>
</li>
</ul>
<h2 id="9-6-CMS的后续"><a href="#9-6-CMS的后续" class="headerlink" title="9.6 CMS的后续"></a>9.6 CMS的后续</h2><ul>
<li><p>jdk9中，CMS被标记为 Deprecated，如果用参数启用CMS，会被警告，说明CMS还在。</p>
</li>
<li><p>jdk14中，彻底删除CMS，通过参数设置会告诉你CMS已经没了，采用默认垃圾回收器。</p>
</li>
</ul>
<h1 id="10-G1-垃圾收集器"><a href="#10-G1-垃圾收集器" class="headerlink" title="10. G1 垃圾收集器"></a>10. G1 垃圾收集器</h1><blockquote>
<p>区域化分代式的垃圾回收</p>
</blockquote>
<h2 id="10-1-起源"><a href="#10-1-起源" class="headerlink" title="10.1 起源"></a>10.1 起源</h2><p>前面已经有了很多的垃圾回收器了，为啥又发布了G1.</p>
<p>原因就是，现在的项目越来越大，没有GC程序就不能正常运行，而会导致STW的GC又跟不上实际需求，所以才会对GC进行不断的优化，G1 就在 jdk7 update4 以后出来了，是目前收集技术的前沿作品 : )</p>
<p>同时，为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间，同时兼顾良好的吞吐量量。</p>
<p>官方给G1的定位就是：在延迟可控的情况下获得尽可能高的吞吐量。所以才担当起全功能收集器的重任。</p>
<h2 id="10-2-为啥叫-Garage-First"><a href="#10-2-为啥叫-Garage-First" class="headerlink" title="10.2 为啥叫 Garage First"></a>10.2 为啥叫 Garage First</h2><ul>
<li><p>G1是一个并行的垃圾回收器，他把堆内存分成不同的区region(物理上不连续),使用不同的region来表示 eden survivor1 survivor2 和 old</p>
</li>
<li><p>G1 GC 有计划的避免在Java整个堆中进行垃圾回收。G1 跟踪各个 Region 来记录每个区的价值(回收获得的空间大小和时间消耗情况)，在后台维护一个优先队列，每次根据允许的回收时间，优先回收价值最大的区。</p>
</li>
<li><p>所以为啥叫first，因为回收价值大的垃圾优先，就是 first。</p>
</li>
</ul>
<p>G1 是一款面向服务端应用的GC，及高概率在满足低延迟的同时维持高吞吐量。</p>
<p>jdk1.7以后，移除了 Experiment 的标志，jdk1.9以后作为默认的垃圾收集器，取代了 CMS和 Parallel + Parallel Old，Orcale 官方叫他 全功能的垃圾收集器。</p>
<p>jdk8中可以通过: -XX:+useG1GC 来开启 G1.</p>
<h2 id="10-3-G1-回收器的优势特点"><a href="#10-3-G1-回收器的优势特点" class="headerlink" title="10.3 G1 回收器的优势特点"></a>10.3 G1 回收器的优势特点</h2><h3 id="10-3-1-并行和并发"><a href="#10-3-1-并行和并发" class="headerlink" title="10.3.1 并行和并发"></a>10.3.1 并行和并发</h3><ul>
<li><p>并行：G1在回收期间，可以有多个GC线程同时进行收集，有效利用多核算力，提高效率。此时 用户线程 STW</p>
</li>
<li><p>并发：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时进行，因此一般情况下，不会在回收阶段完成阻塞应用程序。</p>
</li>
</ul>
<h3 id="10-3-2-分代收集"><a href="#10-3-2-分代收集" class="headerlink" title="10.3.2 分代收集"></a>10.3.2 分代收集</h3><ul>
<li><p>G1 依旧是分代回收，堆依然分为 年轻代和老年代，年轻代还是 eden 和 两个幸存者，但是G1不要求这些区连续，也不再规定这些去的大小和数量。</p>
</li>
<li><p>G1 将堆分为若干个区域Region，这些区域既可以存放老年代，也可以存放年轻代，都是逻辑上的。</p>
</li>
<li><p>G1 同时兼顾老年代和年轻代，和其他的不一样，其他的仅仅是收集年轻代或老年代。</p>
<p>以前的分代，快和块之间都是挨着的，这回不是了，是下图这样的：</p>
<p><img src="/../images/gc/G1Region.png"></p>
<p>每个块region 的角色可以变化，比如 Eden 区，某一个Eden区被回收了，那这个Eden就可能变成Survivor</p>
</li>
</ul>
<h3 id="10-3-3-空间整理"><a href="#10-3-3-空间整理" class="headerlink" title="10.3.3 空间整理"></a>10.3.3 空间整理</h3><ul>
<li><p>CMS 可以指定在 FullGC后进行碎片整理，</p>
</li>
<li><p>G1把空间划分为一个个的region，内存的回收一Region为基本单位，region之间是复制算法，整体可以看作 标记-压缩算法(Region摆放到一起)。两种算法都可以避免产生过多的碎片。有利于程序长时间运行，不会无法分配大对象。堆大情况下G1的优势更大。</p>
</li>
<li><p>可预测的停顿时间模型(软实时)</p>
<p>这是G1相对CMS的另一个优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者指定在一个M毫秒的时间片内，消耗在垃圾收集上的时间不超过N毫秒。</p>
<ul>
<li><p>由于分区的原因，G1可以选取部分区域进行回收，这样缩小了回收范围，对于全局停顿的发生也能有一个较好的控制。</p>
</li>
<li><p>G1跟踪各个Region中垃圾堆积的价值，维护一个优先列表，可以在有限时间内收集高价值的region，保证了在一定时间内G1可以获取尽可能高的收集效率。</p>
</li>
<li><p>相对于CMS，G1未必能做到CMS最优的停顿时间，但是G1的最差停顿时间要比G1好很多。</p>
</li>
<li><p>何为软实时？实时，那就是我们给定10ms，他就在10ms内完成收集。那软实时的意思就是他尽可能地在10ms内完成，可能有偏差。</p>
</li>
</ul>
</li>
</ul>
<h2 id="10-4-G1的缺点"><a href="#10-4-G1的缺点" class="headerlink" title="10.4 G1的缺点"></a>10.4 G1的缺点</h2><p>相对于CMS，G1运行时的内存占用，和程序运行时的额外执行负载都比CMS高。</p>
<p>小内存下，CMS更好，大内存自然是G1更好，平衡点是 6-8G内存。</p>
<h2 id="10-5-G1相关参数"><a href="#10-5-G1相关参数" class="headerlink" title="10.5 G1相关参数"></a>10.5 G1相关参数</h2><ul>
<li><p>指定采用G1为收集器：-XX:+useG1GC,jdk9以后这个就是默认的了。</p>
</li>
<li><p>指定每个Region的大小：-XX:G1HeapRegionSize 必须是 2的次方，范围是1-32，目的是为了让堆分出大约2048个region。默认是堆的1&#x2F;2000；</p>
</li>
<li><p>指定期望的最大GC停顿时间，G1不保证能达到：-XX:MaxGCPauseMillis,默认是200ms，如果你设置的比较低，那G1每回收集的region数目就会少，如果内存增长快的话那就有可能导致堆空间占满，最终出发FullGC，反倒时间变长了。</p>
</li>
<li><p>指定并行时的GC线程数：-XX:ParallelGCThread,最多设置为8</p>
</li>
<li><p>指定并发标记线程数：-XX:ConcGCThreads,设置并行垃圾回收线程的数目，默认是 cpu的1&#x2F;4</p>
</li>
<li><p>指定出发垃圾回收的堆阈值：-XX:IniliatingHeapOccupancyPercent,超过这个值就会触发GC，默认是45.</p>
</li>
</ul>
<h2 id="10-6-适用场景"><a href="#10-6-适用场景" class="headerlink" title="10.6 适用场景"></a>10.6 适用场景</h2><ul>
<li><p>服务器环境，有大内存和多核CPU，</p>
</li>
<li><p>最主要的应用是需要低延迟，有大堆 的应用程序、</p>
</li>
<li><p>用来替换掉jdk1.5 的CMS，在下面情况中，G1的效果比CMS好：</p>
<ul>
<li><p>超过50% 的java堆被活动数据占用</p>
</li>
<li><p>对象分配频率或者年代提升频率变化很大。</p>
</li>
<li><p>GC停顿时间过长。</p>
</li>
</ul>
</li>
</ul>
<h2 id="10-7-分区Region：化整为零"><a href="#10-7-分区Region：化整为零" class="headerlink" title="10.7 分区Region：化整为零"></a>10.7 分区Region：化整为零</h2><p>G1把内存分为了大约 2048个大小相同的region，region大小取决于堆空间，范围是 1m - 32m，是2的次方数。所有的region大小相同，且整个JVM运行期间不会改变。</p>
<p>虽然还有年轻代老年代的区分，但是这些区在物理上不再要求连续，物理上不隔离了，每个分区其实都是一部分的region集合，通过对region进行动态分配，从而实现各个区的逻辑连续。</p>
<p>一个region在他存活期间只能扮演一个角色，年轻代或者老年代。如果G1把这个region回收了，比如一个region本来是eden，然后一回收，这个region里面的东西直接进入另一个survivor 的region，那当前这个eden的region整个就空了。然后就会维护一个空闲列表，表明这个region空的，然后下一次内存分配，可能就把他取出来当老年代了。</p>
<p>G1中，除了young old ，还有一个区：Humongous,H区。这个区用来存放大对象(必须是1.5 region以上的，叫大对象)。因为壁板情况下，大对象都是默认直接分配老年代的，但是如果是短命的大对象，那就不太好了。所以划分出来H区。&#x3D;&#x3D;如果一个H区装不下，那G1就会寻找连续的H区来存储&#x3D;&#x3D;，为了能找到连续的H区，有的时候不得不出发FullGC。G1把H区当作老年代的一部分看待。</p>
<h1 id="11-G1的回收流程"><a href="#11-G1的回收流程" class="headerlink" title="11. G1的回收流程"></a>11. G1的回收流程</h1><p>主要包括下面3个环节：</p>
<ul>
<li><p>年轻代回收 Young GC</p>
</li>
<li><p>老年代并发标记 Concurrent Marking</p>
</li>
<li><p>混合回收 Mix GC</p>
</li>
</ul>
<p>没完，如果情况特殊，单线程，独占式，高强度的FullGC还是会存在的，和CMS一样，提供一个后备保障。</p>
<h2 id="11-1-环节概述"><a href="#11-1-环节概述" class="headerlink" title="11.1 环节概述"></a>11.1 环节概述</h2><p>上面三个回收环节大致说一下：</p>
<h3 id="11-1-1-年轻代GC概述"><a href="#11-1-1-年轻代GC概述" class="headerlink" title="11.1.1 年轻代GC概述"></a>11.1.1 年轻代GC概述</h3><p>年轻代分配内存，当Eden区快满了的时候会触发一个 &#x3D;&#x3D;并发&#x3D;&#x3D;的&#x3D;&#x3D;独占&#x3D;&#x3D;的垃圾回收，在回收期间，G1暂停所有工作线程，启动多线程的垃圾回收器进行回收。把对象移动到 survivor 或者 old，或者俩都涉及。</p>
<h3 id="11-1-2-老年代并发标记概述"><a href="#11-1-2-老年代并发标记概述" class="headerlink" title="11.1.2 老年代并发标记概述"></a>11.1.2 老年代并发标记概述</h3><p>当老年代的占用率达到默认值(45%) 或者是我们指定的值时，出发并发标记。</p>
<h3 id="11-1-3-混合回收概述"><a href="#11-1-3-混合回收概述" class="headerlink" title="11.1.3 混合回收概述"></a>11.1.3 混合回收概述</h3><p>标记完成后，马上进行混合回收，G1移动老年代的存活对象到新的区(Region)，这些新区构成新的老年代。和别的收集器不同，G1不需要回收整个老年代，而是老年代中的一部分region。在回收老年的同时，年轻代的region也会被回收。所以叫混合回收。</p>
<h2 id="11-2-记忆集-Remembered-Set"><a href="#11-2-记忆集-Remembered-Set" class="headerlink" title="11.2 记忆集 Remembered Set"></a>11.2 记忆集 Remembered Set</h2><p>G1 在判断垃圾的时候就比较复杂，不像其他的垃圾回收器，虽然也有同类问题，但是因为G1的内存模型，导致G1更加麻烦。</p>
<p>首先就是一个对象可能被不同区域引用，比如一个老年代的对象可能引用了其他的年轻代对象，也就是一个对象在一个region上，另一个region也可能引用这个对象。所以说我们判断一个对象是否是垃圾，难道需要遍历所有的region去判断么？同时难道我们收集年轻代的时候，我们也要遍历整个老年代么？那么问题就来了，我们说过G1的应用场景是大内存多核CPU，在大内存情况下遍历所有region显然不合适，会降低MinorGC效率。</p>
<p>对于上面的问题，解决方案如下：</p>
<ul>
<li><p>无论是 G1还是其他的分代收集器，JVM都是采用 remembered set （以后简称为 RSet）来扫描全局。</p>
</li>
<li><p>每个region 都有一个 remember set。</p>
</li>
<li><p>每个Reference 类型数据写操作时，都会产生一个 Write Barrier暂停中断操作。</p>
</li>
<li><p>然后检查【将要写入的引用指向的对象】是否和Reference不在一个region，</p>
</li>
<li><p>如果Reference和指向对象不在一个region，通过CardTable把相关引用信息记录到引用指向对象的region对应的remembered set 中。</p>
</li>
<li><p>当垃圾收集时，在GCRoots的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会遗漏。</p>
</li>
</ul>
<p>以上说的，简直不是人话，来翻译一下：</p>
<ul>
<li><p>每个region都有个 rset，所谓rset，就是一个列表，或者什么其他的数据结构；这个表只干一件事，就是记录当前region中的哪些对象被其他region引用了。注意是其他region引用当前region对象。</p>
</li>
<li><p>Write Barrier 写屏障，就是你写入一个对象的时候，暂停一下，系统检查一下你写入的这个对象和你修改的引用是否在同一个region下。</p>
</li>
<li><p>如果不在同一个region，就通过CardTable在rset中记录。简单说，CardTable就记录了对象和其他region的引用，然后CardTable整体写到rset中。</p>
</li>
<li><p>在进行GC时，我们不是需要遍历GCRoots么，我们这个时候把当前你要收集的Region，的rset，也加入GCRoots中，遍历GCRoots也顺便遍历rset中记录的其他region，这样就不需要扫描全堆了。</p>
</li>
</ul>
<h2 id="11-3-G1回收具体流程一：年轻代"><a href="#11-3-G1回收具体流程一：年轻代" class="headerlink" title="11.3 G1回收具体流程一：年轻代"></a>11.3 G1回收具体流程一：年轻代</h2><h3 id="11-3-1-第一步：扫描根"><a href="#11-3-1-第一步：扫描根" class="headerlink" title="11.3.1 第一步：扫描根"></a>11.3.1 第一步：扫描根</h3><p>根是指的static 变量指向的对象，正在执行的方法调用链上的局部变量等。根引用连同RSet记录的外部引用作为扫描存活对象的入口。这里切记肯定是要处理记忆集，尤其是年轻代，反倒是混合回收可能不需要记忆集，因为混合回收的时候年轻代老年代都要回收。</p>
<h3 id="11-3-2-第二步：更新RSet"><a href="#11-3-2-第二步：更新RSet" class="headerlink" title="11.3.2 第二步：更新RSet"></a>11.3.2 第二步：更新RSet</h3><p>处理Dirty Card Queue中的card，更新RSet。此阶段完成后Rset可以准确的反应老年代堆所在的内存分段中对象的引用。简单说，老年代Region的引用指向了其他region的对象。</p>
<p>不是人话，简单说，RSet一开始并没有写好，而是在这一步从 Dirty Card Queue 中获取card，加入 RSet。</p>
<p>JVM会在 Object o &#x3D; object; 执行前后进行一些特殊的操作，在 Queue 中保存一个card，然后在这一步集中把card取出来，然后更新RSet。</p>
<p>为啥这里不再 Object o &#x3D; object; 的时候就更新RSet？原因就是，更新RSet需要线程同步，开小会很大，所以在赋值的时候暂时不处理RSet。</p>
<h3 id="11-3-3-第三步：处理RSet"><a href="#11-3-3-第三步：处理RSet" class="headerlink" title="11.3.3 第三步：处理RSet"></a>11.3.3 第三步：处理RSet</h3><p>识别RSet中保存的老年代对象 中指向的年轻代对象。这些被老年代指向的年轻代对象就是存活对象。</p>
<h3 id="11-3-4-第四步：复制对象"><a href="#11-3-4-第四步：复制对象" class="headerlink" title="11.3.4 第四步：复制对象"></a>11.3.4 第四步：复制对象</h3><p>此阶段对象树被遍历，Eden区内存中存活对象全部被拷贝到 survivor区中空的内存分段。如果存活对象没有达到年龄阈值无法提升，则年龄计数器+1，达到则提升到老年代。如果survivor区空间不够，则直接提升到老年代。</p>
<h3 id="11-3-5-第五步：处理引用"><a href="#11-3-5-第五步：处理引用" class="headerlink" title="11.3.5 第五步：处理引用"></a>11.3.5 第五步：处理引用</h3><p>处理 Soft Weak Phantom Final JNIWeak等引用，最终eden区内存清空，GC线程停止，而目标内存中的对象都是连续的，在复制阶段就进行了排列，避免产生内存碎片。</p>
<h2 id="11-4-G1回收具体流程二：并发标记过程"><a href="#11-4-G1回收具体流程二：并发标记过程" class="headerlink" title="11.4 G1回收具体流程二：并发标记过程"></a>11.4 G1回收具体流程二：并发标记过程</h2><h3 id="11-4-1-初始标记阶段"><a href="#11-4-1-初始标记阶段" class="headerlink" title="11.4.1 初始标记阶段"></a>11.4.1 初始标记阶段</h3><p>标记从GCRoots直接可达的对象，注意是直接可达，这个过程触发STW。并且触发一次 Young GC。</p>
<p>这个过程和 CMS一样。</p>
<h3 id="11-4-2-根区域扫描-Root-region-scanning"><a href="#11-4-2-根区域扫描-Root-region-scanning" class="headerlink" title="11.4.2 根区域扫描 Root region scanning"></a>11.4.2 根区域扫描 Root region scanning</h3><p>G1 GC 扫描survivor区直接可达的老年代区域对象，并标记被引用的对象。这一过程必须在Young GC 之前完成。</p>
<p>不说人话，survivor区中的引用指向的老年代对象。</p>
<h3 id="11-4-3-并发标记-concurrent-marking"><a href="#11-4-3-并发标记-concurrent-marking" class="headerlink" title="11.4.3 并发标记 concurrent marking"></a>11.4.3 并发标记 concurrent marking</h3><p>在整个堆中进行并发标记(和应用程序线程并发执行)，此过程可能被Young GC 中断。如果发现一个region里面全是垃圾，那就不用标记了，直接回收。同时，并发标记阶段会计算每个区域的对象活性。</p>
<h3 id="11-4-4-再次标记-Remark"><a href="#11-4-4-再次标记-Remark" class="headerlink" title="11.4.4 再次标记 Remark"></a>11.4.4 再次标记 Remark</h3><p>类似CMS的修正。由于应用程序没有停止，所以需要修正上次并发标记的结果。G1采用snapshot-at-the-beginning(SATB)算法进行修正，比CMS更快。</p>
<h3 id="11-4-5-独占清理-Clean-Up"><a href="#11-4-5-独占清理-Clean-Up" class="headerlink" title="11.4.5 独占清理 Clean Up"></a>11.4.5 独占清理 Clean Up</h3><p>计算各个区域的内存对象和GC回收比例，并进行排序，识别可以回收的区域，为下个阶段做铺垫。整个过程STW的。</p>
<h3 id="11-4-6-并行清理阶段"><a href="#11-4-6-并行清理阶段" class="headerlink" title="11.4.6 并行清理阶段"></a>11.4.6 并行清理阶段</h3><p>识别并清理完全空闲的区域</p>
<h2 id="11-5-G1回收具体流程三：混合回收"><a href="#11-5-G1回收具体流程三：混合回收" class="headerlink" title="11.5 G1回收具体流程三：混合回收"></a>11.5 G1回收具体流程三：混合回收</h2><p>当越来越多的对象晋升到老年代 old region 时，为了避免内存被消尽，虚拟机会触发一个混合垃圾收集器，也就是 MixedGC，这个算法并不是一个Old GC，除了除了回收整个 Young Region，还会回收一部分的 Old GC。这里需要注意，是一部分老年代，而不是全部的老年代。可以选择哪些 Old Region 进行回收，从而可以对垃圾回收的耗时时间进行控制。也要注意的是 Mixed GC 并不是 FullGC。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>Java期末考试</title>
    <url>/2022/06/07/java-exam/</url>
    <content><![CDATA[<p>Java期末考试瞎指导。</p>
<span id="more"></span>

<h1 id="1-Java-概述"><a href="#1-Java-概述" class="headerlink" title="1. Java 概述"></a>1. Java 概述</h1><p>好像没啥会考的，主要就是主方法，记住就行了。</p>
<h1 id="2-基本数据类型和数组"><a href="#2-基本数据类型和数组" class="headerlink" title="2. 基本数据类型和数组"></a>2. 基本数据类型和数组</h1><p>八种基本数据类型 byte  char  short  int  long  float  double  boolean，大致有俩小知识点：</p>
<ul>
<li>精度丢失问题：高精度往低精度转化会丢东西</li>
<li>类型转化：这个又分强制类型转化和自动类型转化<ul>
<li>强制类型转化很简单：<code>long l = 1L; int i = (int)l;</code></li>
<li>自动类型转化：就是两个精度不一样的数据类型放在一起运算，会自动把低精度值转化为高精度值</li>
</ul>
</li>
</ul>
<p>单独的数组可能会考个小题，问你下面哪种创建数组的方式不对，这个记住三种创建数组的方式就行了：</p>
<ul>
<li>动态赋值 <code>int[] a = new int[数组长度];</code></li>
<li>静态赋值 <code>int[] a = new int[]&#123;...数组元素&#125;;</code></li>
<li>简化静态 <code>int[] a = &#123;...数组元素&#125;;</code></li>
</ul>
<p>然后数组的循环赋值，循环取值，<code>array.length</code> 得到数组长度应该都不用说了。</p>
<h1 id="3-运算符、表达式、语句"><a href="#3-运算符、表达式、语句" class="headerlink" title="3. 运算符、表达式、语句"></a>3. 运算符、表达式、语句</h1><p>运算符就是大致就是 + - * &#x2F; % 这种的，然后逻辑运算符就是与或非 &amp;&amp; || ! 这仨，没啥说的。</p>
<p>还有一些不咋常用的运算符比如三目，移位，位运算，不是很常用，了解就行了。</p>
<p>至于运算符的各种性质比如 结合性 运算符优先级等等，这种东西说实话没啥用，考的可能性有，撑死了一道小题，尤其优先级这个，我觉得智商100以上的人都会给算式加括号，实际情况不会去研究优先级这种东西。所以这个稍微看看就行了，不是重点。</p>
<p>语句，以及流程控制，这个东西和C++可以说一模一样：</p>
<ul>
<li>判断：<code>if()&#123;...&#125;</code>、<code>if()&#123;...&#125;else&#123;...&#125;</code>、<code>if()&#123;...&#125;else if()&#123;...&#125;else.&#123;..&#125;</code></li>
<li>循环：<code>for(..;..;..)&#123;...&#125;</code>、<code>while()&#123;...&#125;</code>、<code>do&#123;...&#125;while()</code></li>
<li>break、continue：用于终止循环和跳过剩余步骤继续下一轮循环，这个python和C++也都有</li>
</ul>
<p>剩下的什么变量命名规范，还有剩下的一些小知识点，我觉得都是码代码的基础规范了，不说了。</p>
<h1 id="4-类和对象"><a href="#4-类和对象" class="headerlink" title="4. 类和对象"></a>4. 类和对象</h1><p>这章那就太重要了，可以这么说，100分的卷80分都和这章有联系，要么直接考这章，要么考后面的继承和接口，属于是间接的考这章的东西。</p>
<h2 id="4-1-如何写类和对象"><a href="#4-1-如何写类和对象" class="headerlink" title="4.1 如何写类和对象"></a>4.1 如何写类和对象</h2><p>和C++差不多，大致思路一样，就是语法变了而已。</p>
<p>这里面包含了第四章的1-6，比较简单，可以说是后面所有东西的基础。</p>
<h2 id="4-2-方法"><a href="#4-2-方法" class="headerlink" title="4.2 方法"></a>4.2 方法</h2><p>这里分了两种方法：实例方法和静态方法。</p>
<ul>
<li>实例方法：只有创建对象以后，通过对象才能访问</li>
<li>静态方法：用static修饰，可以直接通过类名访问</li>
</ul>
<h2 id="4-3-方法重载"><a href="#4-3-方法重载" class="headerlink" title="4.3 方法重载"></a>4.3 方法重载</h2><p>简单说就是类里面的几个方法，方法名相同但是参数列表不同，比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo</span>&#123;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">sum</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c, <span class="type">int</span> d)</span>&#123; <span class="keyword">return</span> a + b + c + e; &#125;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">sum</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c)</span>&#123; <span class="keyword">return</span> sum(a, b, c, <span class="number">0</span>); &#125;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">sum</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123; <span class="keyword">return</span> sum(a, b, <span class="number">0</span>, <span class="number">0</span>); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>很简单的概念，记住就行了，大部分情况下不会没事干重载一个方法，考试的时候方法重载多半要和构造方法联动，到时候就是一个类好几个构造方法的重载，然后构造方法里面还有各种的this，问你创建完这个对象以后输出是啥。</p>
<h2 id="4-4-构造方法"><a href="#4-4-构造方法" class="headerlink" title="4.4 构造方法"></a>4.4 构造方法</h2><p>创建对象时给成员赋值的方法：</p>
<ul>
<li>方法名和类名相同，且没有返回值</li>
<li>构造方法也能重载</li>
<li>构造方法大致分为两类：无参构造和带参构造。区别就是有无入参</li>
<li>一个类至少有一个构造方法，如果不写，编译器会给你自动补一个无参构造</li>
<li>注意上面这条，只有不写构造的时候才会补，但凡写了构造，都不会给你补无参了</li>
</ul>
<h2 id="4-5-this关键字"><a href="#4-5-this关键字" class="headerlink" title="4.5 this关键字"></a>4.5 this关键字</h2><p>这个就比较重要了，可能会在这里出 除了 编程题以外的任何题型，比如选择题，再比如程序结果分析，给你一段代码里面套一堆this，问你最终输出啥。</p>
<p>同时这个this会和第五章的super联动，如果到时候出的题恶心的话，可能两个类相互继承，然后子类又是this又是super的，不好分析反正。</p>
<p>this有两种意思：</p>
<ul>
<li><code>this(...看情况有没有参数)</code>：指的是调用当前类的某一个构造方法，且<font color='red'>如果要写这个，必须写在构造器的第一行</font>，根据this() 的传参确定是哪一个构造方法的重载。</li>
<li><code>this.xxxx</code>：指的是当前类的某一个成员，为了避免方法的参数名和成员名重名。</li>
</ul>
<h2 id="4-6-访问控制"><a href="#4-6-访问控制" class="headerlink" title="4.6 访问控制"></a>4.6 访问控制</h2><p>其实就是三个访问修饰符：</p>
<ul>
<li>private：私有，类外不可访问</li>
<li>protected：受保护，同包下类外可以直接访问好像，这个不怎么用</li>
<li>public：公有，类外随便访问</li>
</ul>
<p>这里需要把握好一件事：<font color='red'>所有的访问控制都是相对于其他类对本类的访问，类内部随便访问类自身成员和方法，访问控制是用来限制类外对类的修改。</font>。</p>
<h2 id="4-7-包和Import"><a href="#4-7-包和Import" class="headerlink" title="4.7 包和Import"></a>4.7 包和Import</h2><p>这俩东西我天天用，但是问我这是啥我还真不好解释，包自己看吧，import我说一句：</p>
<p>import后面跟着的是你类的全限定命名，什么意思，就是说你有一个类，在 cn.heuet包下，有个类叫User，那你导入的时候就得写 <code>import cn.heuet.User</code>。这个cn.heuet.User 就是User这个类的全限定命名，就是把包名带上就行了。</p>
<h2 id="4-8-剩下的"><a href="#4-8-剩下的" class="headerlink" title="4.8 剩下的"></a>4.8 剩下的</h2><p>什么对象组合，就是类里面的成员是另一个类，什么对象数组，就是和基本数据类型差不多 <code>User[] users = new User[10];</code> 就是这个。</p>
<p>包装类提一句，就是把基础数据类型封装成了一个类，仅此而已，这个类里面包含了一些这个类型的一些属性。自己看书吧，这个不是很重要，包装类主要用在泛型上，但是你们学的似乎泛型不是重点，所以连带着包装类没那么重要。</p>
<h2 id="4-9-考题"><a href="#4-9-考题" class="headerlink" title="4.9 考题"></a>4.9 考题</h2><p>我觉得这一章的考题，大部分，应该都不会很难，难题主要集中在下一章。但是有另类，也就是 4.3-4.5。这几部分出题的话有可能会比较恶心。</p>
<p>可能会出程序分析题，就是给你一段代码，问你执行结果是啥，各种构造方法重载+this关键字，比如可能会出下面这种题：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> a;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getA</span><span class="params">()</span>&#123; <span class="keyword">return</span> <span class="built_in">this</span>.a; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">A</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.a = <span class="number">10</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;a1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">A</span><span class="params">(<span class="type">int</span> a)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>();</span><br><span class="line">        <span class="built_in">this</span>.a = a;</span><br><span class="line">        System.out.println(<span class="string">&quot;a2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">A</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>(a &gt; b ? a : b);</span><br><span class="line">        System.out.println(<span class="string">&quot;a3&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">A</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">A</span>(<span class="number">10</span>, <span class="number">30</span>);</span><br><span class="line">System.out.println(a.getA());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 问：程序输出啥？</span></span><br><span class="line"><span class="comment">// a1</span></span><br><span class="line"><span class="comment">// a2</span></span><br><span class="line"><span class="comment">// a3</span></span><br><span class="line"><span class="comment">// 30</span></span><br></pre></td></tr></table></figure>

<p>反正我觉得这章的主要考点，额，都可能会提到点，各种小知识点，比如还有static，100%会考，但是我觉得难点就是这个构造重载+this。剩下的不是很难了。</p>
<h1 id="5-继承、接口、泛型"><a href="#5-继承、接口、泛型" class="headerlink" title="5. 继承、接口、泛型"></a>5. 继承、接口、泛型</h1><h2 id="5-1-继承"><a href="#5-1-继承" class="headerlink" title="5.1 继承"></a>5.1 继承</h2><p>这章的超级重点，真的是超级重点，往后什么接口，什么泛型，哪怕是上转型对象，也不如继承重要。为啥，继承的某些特性确实比较恶心，特别容易出程序分析题，甚至可以这么说，到时候程序分析题假如有5个，很有可能3个题，都是分析继承。</p>
<p>大致是什么题型呢？就是给你好几个类，最可能是两个类继承，如果老师不当人的话也有可能出现三个类以上互相继承，继承一大堆私有公有，然后同时需要考虑子父类的构造方法执行顺序。然后三个类磨磨唧唧给你继承完了，随便给你创建一个对象，问你打印啥东西，然后问你哪个成员的值是多少。这种题可以说就是整张卷子的难度天花板，极难分析而且极易出错。</p>
<p>题目知识点：</p>
<ul>
<li>构造方法重载</li>
<li>this关键字</li>
<li>super关键字</li>
<li>继承</li>
<li>方法重写</li>
<li>子类对象和父类对象成员冲突</li>
</ul>
<p>差不多一道这种程序分析题，少说上面这些东西融合个3 4个知识点，比如A类继承了B类，然后调用了B类的某个super，然后覆盖了某个B类的成员，再通过super.xxx去访问这个成员，然后调用两个B类的公开方法去操作B类的私有成员，巨麻烦巨绕。</p>
<p>我这里建议啊：碰见这种题，有条件直接敲一遍跑一遍，别自己分析，费力不讨好的。</p>
<p>这章的知识点挺多的我就不说了，看书吧，看不懂来问就行。看的重点就集中在继承这一块，就是this、super、重写、成员覆盖 等等。</p>
<h2 id="5-2-接口"><a href="#5-2-接口" class="headerlink" title="5.2 接口"></a>5.2 接口</h2><p>后面的接口，反倒不是很难，你们这本书基于jdk1.6，1.6的时候接口比较死板，就是一个类实现一个接口，然后必须实现这个接口里面的所有方法，就这么简单。</p>
<p>然后需要注意的就是：Java中类是单继承，但是可以多实现接口，这个记住了，可能考小题。</p>
<h2 id="5-3-上转型对象"><a href="#5-3-上转型对象" class="headerlink" title="5.3 上转型对象"></a>5.3 上转型对象</h2><p>这个不太好解释了，就是一个类，继承或者实现了另外一个东西，然后创建对象的时候就是 父类&#x2F;接口引用指向子类&#x2F;实现类对象。额，看代码吧：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">extends</span> <span class="title class_">A</span>&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这就是上转型</span></span><br><span class="line"><span class="type">A</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">B</span>();</span><br></pre></td></tr></table></figure>

<p>前面A a，就是创建了一个父类的引用，后面真正创建了子类对象，然后A a &#x3D; new B(); 的意义就是 父类引用指向子类对象。</p>
<p>这个分为两个：一个是接口的上转型，或者叫接口回调；另一个是子类的上转型，就是父类引用指向子类对象。</p>
<p>前一个可以说不重要，但是后面这个，子类上转型为父类，就又可以和继承联动出一些让人想吐的题了。比如上面说的，3 4 个类来回继承，各种super this，好不容易继承完了，给你创建对象的时候给你来个上转型，哎，难度又高了，更不会了。</p>
<h2 id="5-4-剩下的东西"><a href="#5-4-剩下的东西" class="headerlink" title="5.4 剩下的东西"></a>5.4 剩下的东西</h2><p>比如各种奇葩的类，匿名类，内部类，异常类，泛型类，以及泛型，这些东西可以说不重要，多半不会考的，考了也是小题，不会是重点。</p>
<p>但是我还是提一句啊，异常这个东西，其实是特别重要的，奈何她讲的不行，考试也不是重点。咱们学的里面，接口回调+异常+泛型，这三个东西都是那种实际上相当重要但是她不给好好讲的。</p>
<h2 id="5-5-考题"><a href="#5-5-考题" class="headerlink" title="5.5 考题"></a>5.5 考题</h2><p>继承+重载+this+super+成员覆盖+方法重写+子类上转型，就这几个东西，会出一些难度极高的题。</p>
<p>反正我当年碰见这种程序分析题，看不懂，直接敲了一遍。比如可能会有这种：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> a;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getA</span><span class="params">()</span>&#123; <span class="keyword">return</span> <span class="built_in">this</span>.a; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setA</span><span class="params">(<span class="type">int</span> a)</span>&#123; <span class="built_in">this</span>.a = a; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">A</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.a = <span class="number">10</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;a1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">A</span><span class="params">(<span class="type">int</span> a)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>();</span><br><span class="line">        <span class="built_in">this</span>.a = a;</span><br><span class="line">        System.out.println(<span class="string">&quot;a2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">extends</span> <span class="title class_">A</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> b;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getB</span><span class="params">()</span> &#123; <span class="keyword">return</span> b; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setB</span><span class="params">(<span class="type">int</span> b)</span> &#123; <span class="built_in">this</span>.b = b; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">B</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.b = <span class="number">100</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;b1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">B</span><span class="params">(<span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>(b);</span><br><span class="line">        <span class="built_in">this</span>.b = b;</span><br><span class="line">        System.out.println(<span class="string">&quot;b2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">C</span> <span class="keyword">extends</span> <span class="title class_">B</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> b;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setB</span><span class="params">(<span class="type">int</span> b)</span>&#123; <span class="built_in">this</span>.b = b; <span class="built_in">super</span>.setB(b / <span class="number">10</span>); &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getB</span><span class="params">()</span>&#123; <span class="keyword">return</span> <span class="built_in">this</span>.b; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSuperB</span><span class="params">()</span>&#123; <span class="keyword">return</span> <span class="built_in">super</span>.getB(); &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">C</span><span class="params">(<span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>(b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">C</span> <span class="variable">c</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">C</span>(<span class="number">2022</span>);</span><br><span class="line">        System.out.println(c.getB());</span><br><span class="line">        System.out.println(c.getA());</span><br><span class="line">        c.setB(<span class="number">100000</span>);</span><br><span class="line">        System.out.println(c.getB());</span><br><span class="line">        System.out.println(c.getA());</span><br><span class="line">        System.out.println(c.getSuperB());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后问你输出是啥</span></span><br><span class="line">a1</span><br><span class="line">a2</span><br><span class="line">b2</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">2022</span></span><br><span class="line"><span class="number">100000</span></span><br><span class="line"><span class="number">2022</span></span><br><span class="line"><span class="number">10000</span></span><br></pre></td></tr></table></figure>

<p>这题我瞎写的啊，真正考试那题八成比我这个复杂点，我这个考虑了半天也没把上转型考虑进去，考试的时候这种题，咋也得用上转型恶心人。</p>
<h1 id="6-7-字符串系列和集合系列"><a href="#6-7-字符串系列和集合系列" class="headerlink" title="6. 7. 字符串系列和集合系列"></a>6. 7. 字符串系列和集合系列</h1><p>这俩东西，是面试的高频问题，对的，面试的高频问题，一遍面试一上来问你字符串的东西，然后面试会问你集合类的源码，比如ArrayList内部是否线程安全。话说回来，考试好像不是很重要。</p>
<p>字符串有个小知识点：就是字符串判断相等的问题，这个考试很有可能会考。</p>
<p>我这里就大致一说吧：字符串如果是 <code>String s1 = &quot;hello world&quot;;</code> 这种直接赋值，我们叫他字面量赋值，这个时候他就是指向了一块字符串内存，这个时候另一个字符串<code>String s2 = &quot;hello world&quot;;</code> s2 就也会指向这块内存。就是这种字面量赋值的方式，只要两个字符串内容相等，那么两个字符串 <code>s1 == s2 且 s1.equals(s2) == true</code>。</p>
<p>如果不是字面量赋值，比如这样 <code>String s1 = new String(&quot;hello world&quot;);</code> 那这就是一个对象，不会直接指向这个helloworld 的内存，这个时候另一个字符串 <code>String s2 = new String(&quot;hello world&quot;);</code> 即便内容相等，但是两个对象也不相等，这个时候 <code>s1 != s2 但 s1.equals(s2) == true</code> 。</p>
<p>看不懂的话看看书吧，这个地方要深究的话可以一路给你讲到JVM虚拟机讲到底层，那就费劲了。</p>
<p>剩下的各种字符串衍生类比如StringBuffer、StringToken啥的，还有什么Scanner这些的，似乎不重要，考的话也是考小题，然后正则表达式，我记得当年我们考过填空？还是选择，忘了。正则倒是有可能会考，但不是重点。</p>
<p>然后就是各种集合，这个集合一般会伴随泛型，但是既然泛型没咋讲，那我估计集合也不太会考，考的话也是考小题。对于考试来说数组就够用了，什么LinkedList什么TreeMap，学算法才可能用呢。</p>
<h1 id="8-线程"><a href="#8-线程" class="headerlink" title="8. 线程"></a>8. 线程</h1><p>如何创建线程啥的，考的可能性不大，至少不会让你们自己写线程，线程这个东西，我找了一个30多小时的课专门学的，挺难的，我觉得没啥必要重点看。</p>
<p>但是，如果我没猜错，这应该是你们第一次接触多线程，第一次听说线程通讯和线程状态，所以说概念题倒是很有可能考，我们当年考了一道简答题，就是直接问 线程有哪些状态，这些状态如何切换。</p>
<p>所以线程多看看概念我觉得就差不多了，如何创建线程，如何开始线程，甚至还有线程通讯，各种sleep各种notify，没啥必要花时间看我觉得。</p>
<h1 id="9-总结一下"><a href="#9-总结一下" class="headerlink" title="9. 总结一下"></a>9. 总结一下</h1><p>呐，复习吧，就紧着第四章和第五章复习，第五章呢，就紧着继承那块复习，我大胆预测一下啊，就继承那块，少说占个20分以上，而且出的题都是大题。剩下的小知识点就会出一些小题，比如可能会考你 面向对象的三个特征（封装继承多态）这类的小概念。</p>
<p>编程题反倒不会太难，因为继承那块的东西让你们写说实在的多少有点难为你们了，所以最后考的，应该就是让你们设计个类，然后写写方法，但是也不会太简单，C++的时候和Python考试编程题充其量就是让你写个水仙花数，打印个质数，Java就绝不会这么简单了。Java的编程题可能会多少和实践有点联系，比如让你用类实现个登录这种的。</p>
<p>嗯，说难不难说简单不简单的。</p>
]]></content>
  </entry>
  <entry>
    <title>JVM-方法区</title>
    <url>/2022/05/30/jvm-methodarea/</url>
    <content><![CDATA[<p>JVM方法区，主要用于储存各种类的元信息，也就是我们常说的Class类摸版，这里详细说一下方法区的内存分布和垃圾回收问题。同时这里也不会只讲方法区，因为讲完方法区以后我们就可以深入的去研究一个对象是如何被创建的，所以后面还会和堆空间结合起来说。</p>
<span id="more"></span>

<h1 id="1-方法区"><a href="#1-方法区" class="headerlink" title="1. 方法区"></a>1. 方法区</h1><h2 id="1-1-明确几个概念"><a href="#1-1-明确几个概念" class="headerlink" title="1.1 明确几个概念"></a>1.1 明确几个概念</h2><ul>
<li><p>方法区虽然之前说过算是 堆的一部分，但是一般情况下是要分开的。</p>
</li>
<li><p>方法去看作是JVM独立的一部分。</p>
</li>
<li><p>HotSpot 虚拟机的方法区还有一个别名：Non-Heap 非堆。</p>
</li>
<li><p>方法区会自己收缩扩大</p>
</li>
</ul>
<h2 id="1-2-方法区的基本理解"><a href="#1-2-方法区的基本理解" class="headerlink" title="1.2 方法区的基本理解"></a>1.2 方法区的基本理解</h2><ul>
<li><p>方法区和堆类似，都是线程共享的。</p>
</li>
<li><p>方法区在JVM启动时被创建，和heap一样他的物理内存可以不连续。</p>
</li>
<li><p>方法区的大小和heap一样，可固定 可 伸缩</p>
</li>
<li><p>方法区的大小决定了系统能加载多少个类，如果类过于多，也会抛出 OutOfMemoryError</p>
<ul>
<li>比如加载过多 jar 包，或者 tomcat部署过多服务，比如 30 - 50 个。</li>
</ul>
</li>
<li><p>关闭JVM会释放这部分内存。</p>
</li>
</ul>
<h2 id="1-3-HotSpot-虚拟机-方法区演进"><a href="#1-3-HotSpot-虚拟机-方法区演进" class="headerlink" title="1.3 HotSpot 虚拟机 方法区演进"></a>1.3 HotSpot 虚拟机 方法区演进</h2><ul>
<li><p>JDK7 中，将方法区称为永久代，JDK8以后用元空间取代了永久代</p>
<blockquote>
<p>JVM虚拟机规范中说：将类的原信息存储到本地堆中，这块区域称为元空间</p>
</blockquote>
</li>
<li><p>确切来说永久代和方法区并不等价，仅针对 HotSpot 虚拟机而言，他并没有规定如何实现方法区。</p>
</li>
<li><p>可以这么理解，方法区就是一个接口，永久代和元空间用于存储类的原信息，是方法区的实现。</p>
</li>
</ul>
<h2 id="1-4-hotSpot-设置-方法区大小"><a href="#1-4-hotSpot-设置-方法区大小" class="headerlink" title="1.4 hotSpot 设置 方法区大小"></a>1.4 hotSpot 设置 方法区大小</h2><ul>
<li><p>JDK7 之前：</p>
<ul>
<li><p>-XX:PermSize&#x3D;100m 设置初始大小 默认 20.75m</p>
</li>
<li><p>-XX:MaxPermSize&#x3D;200m 设置最大值 默认 32位机器 64m，64位机器 86m</p>
</li>
</ul>
</li>
<li><p>JDK8 以后：</p>
<ul>
<li><p>-XX:MetaspaceSize&#x3D;100m 设置初始大小 默认 21m</p>
</li>
<li><p>-XX:MaxMetaspaceSize&#x3D;200m 设置最大值 默认没有最大，最大就是你的真实内存</p>
</li>
</ul>
</li>
</ul>
<p>二者的区别：</p>
<ul>
<li><p>元空间和永久代不同，元空间会耗尽你所有的内存，直到你的内存崩了，他会给你抛出 OOM异常。</p>
</li>
<li><p>-XX:MetaspaceSize 设置初始大小。对于一个64位的机器来说，默认是21m空间，那么这个21m就是一个高水位线，一旦元空间的东西超过了21m，就会触发FullGC来清理不用的类(类加载器死亡了)，然后这个高水位线会重置。如果清理的不多，同时在最大空间以内，他就会稍微提高这个高水位线，如果清理的过多，就会降低这个高水位线。</p>
</li>
<li><p>根据上面所说的，如果初始值比较低，那么就会频繁触发 FullGC，为了提高性能，建议吧这个初始值调高。</p>
</li>
</ul>
<h1 id="2-方法区内部结构"><a href="#2-方法区内部结构" class="headerlink" title="2. 方法区内部结构"></a>2. 方法区内部结构</h1><h2 id="2-1-方法区主要存储对象"><a href="#2-1-方法区主要存储对象" class="headerlink" title="2.1 方法区主要存储对象"></a>2.1 方法区主要存储对象</h2><ul>
<li><p>类型信息</p>
<ul>
<li><p>全限定命名</p>
</li>
<li><p>直接父类的全限定命名</p>
</li>
<li><p>类的访问修饰符</p>
</li>
<li><p>实现的直接接口的有序列表</p>
</li>
</ul>
</li>
<li><p>域信息(Field 其实就是字段，或者属性):</p>
<ul>
<li><p>JVM必须在方法去中保存所有字段的相关信息和声明顺序</p>
</li>
<li><p>域的相关信息包括：名称 类型 访问修饰符</p>
</li>
</ul>
</li>
<li><p>方法</p>
<ul>
<li><p>JVM必须在方法去中保存下面的信息，同时也会保存声明顺序：</p>
</li>
<li><p>方法名称</p>
</li>
<li><p>方法返回值类型</p>
</li>
<li><p>参数的数量与类型(按顺序)</p>
</li>
<li><p>访问修饰符</p>
</li>
<li><p>方法的字节码 操作数栈 局部变量表及大小(abstract native 方法除外)</p>
</li>
<li><p>异常表(abstract native 除外)</p>
<ul>
<li>包括 每个异常处理的开始位置，结束位置，代码处理在PC寄存器中的偏移地址，被捕获的异常类的常量池索引</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2-2-全局常量"><a href="#2-2-全局常量" class="headerlink" title="2.2 全局常量"></a>2.2 全局常量</h2><p>就是 static final，用 final 修饰的 static 成员。</p>
<p>这个东西在编译的时候就已经为他分配了值。直接反编译，就可以看到.</p>
<h1 id="3-常量池-和-运行时常量池"><a href="#3-常量池-和-运行时常量池" class="headerlink" title="3. 常量池 和 运行时常量池"></a>3. 常量池 和 运行时常量池</h1><p>一个有效的字节码文件里面包含了类的信息 字段 方法 接口等，以外，还包括一个东西，就是常量池：Constant Pool。常量池里面包括：字面量 类型，字段，方法的引用。</p>
<p>看图： </p>
<p><img src="/images/runtime/ConstantPool.png" alt="method_area"></p>
<p>这图领会精神，因为我也看不懂.</p>
<h2 id="3-1-为什么引入-常量池"><a href="#3-1-为什么引入-常量池" class="headerlink" title="3.1 为什么引入 常量池"></a>3.1 为什么引入 常量池</h2><p>Java 一个类编译后生成字节码文件。而Java字节码通常需要数据支持，而这些数据大到无法存到 字节码文件中，所以引入常量池，在动态链接阶段 会用到运行时常量池。</p>
<p>比如我们写一个最简单的HelloWorld 程序，这个程序就用到了 Object,System,PrintStream等一系列的类。这些类很显然不能全都装在字节码里面，所以就以常量池的形式存储。</p>
<p>比如我们随便反编译一个类，得到 Constant Pool，都是一大堆 #… 这种东西，然后我们跟着他的 # 一路往下追，才能找到他到底是个啥。</p>
<h2 id="3-2-常量池里面都存啥？"><a href="#3-2-常量池里面都存啥？" class="headerlink" title="3.2 常量池里面都存啥？"></a>3.2 常量池里面都存啥？</h2><ul>
<li><p>数量值</p>
</li>
<li><p>字符串值</p>
</li>
<li><p>类引用</p>
</li>
<li><p>字段引用</p>
</li>
<li><p>方法引用</p>
</li>
</ul>
<p>举个例子：</p>
<p><code>Object object = new Object();</code></p>
<p>他在 字节码中会被表示成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:new #2</span><br><span class="line">1:dup </span><br><span class="line">2:invokespecial #3</span><br></pre></td></tr></table></figure>

<p>这里的#2 和#3就是常量池中的东西，new 后面这个#2，指向的就是常量池中用于表示Object这个类的字符串常量，注意是字符串常量，#3 就指向了常量池的Object的<init>O 方法，然后在类加载的链接阶段就会将这些字符串常量转化为运行时常量池，然后#2也会指向真实的内存地址。</p>
<p>总的来说：常量池就可以理解成一张表，JVM根据这张表，去找到要执行的类名 方法 参数 字面量等。</p>
<h2 id="3-3-运行时常量池"><a href="#3-3-运行时常量池" class="headerlink" title="3.3 运行时常量池"></a>3.3 运行时常量池</h2><p>这里明确一下，运行时常量池和字节码中的常量池表不一样。</p>
<ul>
<li><p>运行时常量池 是 方法区的一部分</p>
</li>
<li><p>常量池表是字节码文件的一部分，用于存储编译期生成的各种字面量和引用，这部分内容将在类加载后放到方法区的运行时常量池中。</p>
</li>
<li><p>加载类和接口到虚拟机后就会生成对应的运行时常量池</p>
</li>
<li><p>JVM为每一个已经加载的类型(类或者接口)都维护一个运行时常量池，池中的数据向数组像一样，可以通过索引访问。</p>
</li>
<li><p>运行时常量池中包含多种不同的常量，包括编译期间就已经明确的字面量，也包括运行时解析后才能得到的方法或字段引用，此时已经不再是常量池那种符号地址了，而是真实地址</p>
</li>
<li><p>运行时常量池对比常量池的一个特点：具备动态性</p>
</li>
<li><p>运行时常量池类似其他语言的符号表，但是内容更丰富。</p>
</li>
<li><p>在构造类型的运行时常量池的时候，如果方法区的空间不够了，就会抛出 OutOfMemoryError</p>
</li>
</ul>
<h1 id="4-JVM方法区的演进"><a href="#4-JVM方法区的演进" class="headerlink" title="4. JVM方法区的演进"></a>4. JVM方法区的演进</h1><ul>
<li><p>首先 HotSpot 虚拟机才有永久代</p>
</li>
<li><p>HotSpot虚拟机的演进：</p>
<ul>
<li><p>JDK6以前，有永久代，静态变量存放在永久代上</p>
</li>
<li><p>JDK7还有永久代，但是 字符串常量池，静态变量从永久代移除，放到了堆上</p>
</li>
<li><p>JDK8以后，取消永久代，而是元空间，类型信息 字段 方法 常量保存在元空间，但是 静态变量和字符串常量池还在堆上。</p>
</li>
</ul>
</li>
<li><p>以前有永久代的时候，所有内存都放在JVM的内存上，到了元空间，变成了本地内存。</p>
</li>
</ul>
<h2 id="4-1元空间为何要取代永久代"><a href="#4-1元空间为何要取代永久代" class="headerlink" title="4.1元空间为何要取代永久代"></a>4.1元空间为何要取代永久代</h2><ul>
<li><p>JDK8以后，永久代没了，原先存在永久代中的数据被存到了一个和堆不连续的本地内存上， 这块地方就是元空间。</p>
</li>
<li><p>因为类的元数据放在本地内存，所以元空间的上线就是真实内存max</p>
</li>
</ul>
<h2 id="4-2-好处"><a href="#4-2-好处" class="headerlink" title="4.2 好处"></a>4.2 好处</h2><ul>
<li><p>方法区的大小很难确定，如果功能过多，加载的雷多，很可能出现OOM错误。</p>
</li>
<li><p>对永久代调优很困难，就是 FullGC，去判断哪些是垃圾特别麻烦，所以 尽量少去GC，就需要更大的方法区空间。</p>
</li>
</ul>
<h2 id="4-3-StringTable-调整"><a href="#4-3-StringTable-调整" class="headerlink" title="4.3 StringTable 调整"></a>4.3 StringTable 调整</h2><p>首先说一下啥是StringTable，StringTable 就是字符串常量池，JVM中有一个专门储存字符串的地方，因为字符串大量使用，所以干脆给你做成一个单独的常量池。这个东西在后面我们说到字符串的时候还会详细说，这里先了解一下。</p>
<p>JDK7以前，StringTable在永久代，而JDK7以后，把StringTable扔到了堆中，为哈？</p>
<p>如果放在方法区，那就会涉及FullGC，而FullGC只有在永久代满了的时候才会触发， GC不频繁，而StringTable 经常用，看法中大量的String被创建，所以放在永久代里面 效率底下，所以放在堆中。</p>
<h2 id="4-4-静态成员放在哪里"><a href="#4-4-静态成员放在哪里" class="headerlink" title="4.4 静态成员放在哪里"></a>4.4 静态成员放在哪里</h2><p>就是说我们有一个静态成员，比如 <code>private static UserUtils uu = new UserUtils();</code> ，那么这个UserUtils 到底在哪？</p>
<p>明确一下，只要是new出来的东西，就肯定是放在堆中的，没有例外。不同的是这个 static uu 放到哪了。</p>
<p>JDK7 以后，这个引用也会放在堆中，而JDK6以前，这个引用同样放在方法区。</p>
<h1 id="5-元空间GC"><a href="#5-元空间GC" class="headerlink" title="5. 元空间GC"></a>5. 元空间GC</h1><blockquote>
<p>方法区的具体实现部分可以不涉及GC ——Java虚拟机规范</p>
</blockquote>
<p>首先明确，方法去中有GC，但是方法区的GC很难让人满意。</p>
<p>方法区的垃圾回收主要回收常量池和类型信息。</p>
<h2 id="如何垃圾回收"><a href="#如何垃圾回收" class="headerlink" title="如何垃圾回收"></a>如何垃圾回收</h2><ul>
<li><p>常量相对简单，然而他没讲</p>
</li>
<li><p>如何判断类型不再使用：</p>
<ul>
<li><p>该类的所有对象都被回收，且不存在子类对象</p>
</li>
<li><p>加载该类的类加载器被回收，这个除非是精心设计的可以可替换类加载的场景，比如 JSP OSGI 等，否则很难达成。</p>
</li>
<li><p>类的Class 在任何地方都没有被引用，任何地方都不能通过反射区访问这个类。</p>
</li>
</ul>
</li>
<li><p>Java 虚拟机只有满足了上述三个条件才会允许回收这个类，但也仅仅是允许， 并不是说就想对象一样，一定可以被回收。</p>
</li>
<li><p>在大量使用反射 动态代理 CGlib等字节码框架，动态生成</p>
</li>
</ul>
<p>这里只是大致说一句GC，GC后面会专门说的。</p>
<h1 id="6-创建对象流程"><a href="#6-创建对象流程" class="headerlink" title="6. 创建对象流程"></a>6. 创建对象流程</h1><p>学了方法区，我们就得详细说说一个对象是如何被创建的了，这里就会把方法区和堆空间结合起来说了。所以这部分内容比较综合。</p>
<h2 id="6-1-创建方式"><a href="#6-1-创建方式" class="headerlink" title="6.1 创建方式"></a>6.1 创建方式</h2><p>首先，创建对象的方式：</p>
<ul>
<li><p>new 对象</p>
<blockquote>
<p>包括单例设计模式里面的 getInstance 那种在内部调用 new 的</p>
</blockquote>
</li>
<li><p>Class.newInstance() 反射创建对象</p>
<blockquote>
<p>条件比较苛刻，首先必须有无参构造，其次构造函数必须是 public</p>
</blockquote>
</li>
<li><p>Constructor的 newInstance(args) 调用构造函数</p>
<blockquote>
<p>可以调用任意构造函数，不用担心权限</p>
</blockquote>
</li>
<li><p>Clone，需要类 实现 Cloneable 接口，实现 clone 方法</p>
</li>
<li><p>反序列化，通过 ObjectSteam</p>
</li>
<li><p>第三方库 Objenesis</p>
</li>
</ul>
<h2 id="6-2-字节码角度看对象创建"><a href="#6-2-字节码角度看对象创建" class="headerlink" title="6.2 字节码角度看对象创建"></a>6.2 字节码角度看对象创建</h2><p>我们写一个代码，main 方法里面仅仅创建一个 Object 对象，然后反编译，看看 得到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0: new           #2   // class java/lang/Object  </span><br><span class="line">3: dup  </span><br><span class="line">4: invokespecial #1   // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V  </span><br><span class="line">7: astore_1  </span><br><span class="line">8: return</span><br></pre></td></tr></table></figure>

<p>首先我们看第一条指令 new，它里面涉及到的东西：</p>
<ul>
<li><p>加载 Object，将 Object 放到方法区，当然这个过程可能早就做了</p>
</li>
<li><p>在堆中给Object 分配空间，此时内存占用大小已经可以通过数据类型确定下来了，然后 给成员变量进行初始化，给他一个初值。</p>
</li>
</ul>
<p>第二步 dump 复制操作：</p>
<ul>
<li>因为这个对象在 main 方法中执行，所以引用在操作数栈里面， 然后他吧引用复制了一份，一份用来赋值，一个用来调用方法。</li>
</ul>
<blockquote>
<p>为啥是在操作数栈？因为此时对象还没有创建完，创建完之后 指令 7 才会存储到 局部变量表中。</p>
</blockquote>
<p>第三步 invokespecial 调用 <init> 方法，也就是构造函数。</p>
<p>第四步 astore 将对象存储到 局表。</p>
<h2 id="6-3-具体的创建流程"><a href="#6-3-具体的创建流程" class="headerlink" title="6.3 具体的创建流程"></a>6.3 具体的创建流程</h2><p>一个对象创建出来，new 出来，大致需要经历六个步骤：</p>
<h3 id="6-3-1-判断对象对应的类是否加载-链接-初始化"><a href="#6-3-1-判断对象对应的类是否加载-链接-初始化" class="headerlink" title="6.3.1 判断对象对应的类是否加载 链接 初始化"></a>6.3.1 判断对象对应的类是否加载 链接 初始化</h3><p>很显然这三步是反射的时候学过的，然后一开始类加载也学过一些， 可以看chapter02回忆一下。下面具体说：</p>
<p>虚拟机遇到一条new指令，首先根据这个指令的参数去metaspace 也就是方法区里面定位这个类的符号引用，并且检查这个符号引用对应的类是否完成了 加载 链接 初始化。 也就是查找类型元信息。如果找不到，则会在双亲委派模式下调用 ClassLoader 来加载Class文件， 如果找不到，则抛出 ClassNotFoundException。</p>
<p>如果找到了，则加载类，方法区中生成 Class对象。</p>
<h3 id="6-3-2-为对象分配内存"><a href="#6-3-2-为对象分配内存" class="headerlink" title="6.3.2 为对象分配内存"></a>6.3.2 为对象分配内存</h3><p>计算对象占用空间大小，这个根据类的成员类型很容易可以计算出来，如果是引用数据类型，那就分配 引用空间即可，也就是 4 字节，然后为对象分配空间。</p>
<p>如何分配空间又是个问题，这里区分内存规整和不规整：</p>
<ul>
<li><p>内存规整，则采用指针碰撞来为对象分配内存。</p>
<p>这tm是啥？简单说，就是如果内存规整，一条内存，用过的连续在一端，没用过的在另一端， 区分的特别明显，那么这条内存在用过的和没用过的中间有个指针用来划分区域。 在这种情况下分配内存，指针只需要向空的那一端移动和对象一样的大小即可。</p>
<p>如果垃圾收集器采用的是 Serial ParNew 这种基于标记压缩算法的，虚拟机使用这种内存分配方式。</p>
<p>一般使用带有 Compact(整理)过程的收集器时，使用指针碰撞。</p>
</li>
<li><p>内存不规整，虚拟机就需要维护一个列表，也就是空闲列表。</p>
<p>那么啥叫空闲列表？内存不规整，使用过的和没用过的相互交错，就需要一个列表用来 标记那些内存是没用过的，那些使用过的。</p>
<p>分配内存的时候，查询列表，找到一块能放得下的地方，吧对象放进去， 然后更新空闲列表。</p>
</li>
<li><p>总的来说，采用那种方法是由Java堆是否规整决定的，堆规整与否又是由所采用的垃圾收集器 是否有压缩算法决定。</p>
</li>
</ul>
<h3 id="6-3-3-处理并发安全问题"><a href="#6-3-3-处理并发安全问题" class="headerlink" title="6.3.3 处理并发安全问题"></a>6.3.3 处理并发安全问题</h3><ul>
<li><p>采用CAS 失败重试，区域枷锁 保证更新的原子性</p>
</li>
<li><p>给每个线程预留一块 TLBA ，通过 -XX:+&#x2F;-useTLBA 来控制， jdk8默认开启。</p>
</li>
</ul>
<h3 id="6-3-4-初始化分配到的空间"><a href="#6-3-4-初始化分配到的空间" class="headerlink" title="6.3.4 初始化分配到的空间"></a>6.3.4 初始化分配到的空间</h3><p>简单地说就是给每个成员一个默认值，保证一个对象不赋值就可以直接使用。</p>
<h3 id="6-3-5-设置对象的对象头"><a href="#6-3-5-设置对象的对象头" class="headerlink" title="6.3.5 设置对象的对象头"></a>6.3.5 设置对象的对象头</h3><p>将对象的所属类(也就是累的元信息) 和 对象的 HashCode 和 对象的 GC信息，锁信息存储到对象头中，这个过程的具体设置方式取决于JVM。</p>
<h3 id="6-3-6-调用-init-方法"><a href="#6-3-6-调用-init-方法" class="headerlink" title="6.3.6 调用 init 方法"></a>6.3.6 调用 init 方法</h3><p>init 方法并不是构造方法，而是给对象进行完整的赋值，比如 成员的赋值，实例代码块里面对于成员的赋值，构造函数里面给成员的赋值，都在init 方法里面，不是单纯的构造函数。</p>
<h2 id="6-4-总结"><a href="#6-4-总结" class="headerlink" title="6.4 总结"></a>6.4 总结</h2><p>看这条代码</p>
<p>Object o &#x3D; new Object();</p>
<p>其实 new 就是一个指令，告诉JVM 要去加载 Object，然后Object() 就是调用构造器，完整的创建一个对象出来，应该是吧上面的6部全都执行完才算是创建完了，就一个new，可以说仅仅是有了个对象的大体模型，但是细节还不完善。</p>
<h1 id="7-对象的内存分布"><a href="#7-对象的内存分布" class="headerlink" title="7. 对象的内存分布"></a>7. 对象的内存分布</h1><p>对象的内存分布主要分为：</p>
<ul>
<li><p>对象头 header</p>
</li>
<li><p>实例数据 instance data</p>
</li>
<li><p>对齐填充</p>
</li>
</ul>
<p>下面会挨个说。</p>
<h2 id="7-1-对象头"><a href="#7-1-对象头" class="headerlink" title="7.1 对象头"></a>7.1 对象头</h2><p>对象头里面包含两部分：</p>
<ul>
<li><p>运行时元数据 Mark Word（32bit），里面记录了以下内容：</p>
<ul>
<li><p>哈希值</p>
</li>
<li><p>GC分代年龄，就是堆里面的年龄计数器记录的那个东西</p>
</li>
<li><p>锁状态标志</p>
</li>
<li><p>线程持有的锁</p>
</li>
<li><p>偏向线程id</p>
</li>
<li><p>偏向时间戳</p>
</li>
</ul>
</li>
<li><p>类型指针 Klass Word（32bit）</p>
<p>指向了方法区里面的Class，也就是类型元信息。确定对象所属类型</p>
<p>方法 Object.getClass() 就是体现了这个，就是我们以前说的，对象可以找到 它对应的Class。</p>
</li>
<li><p>特殊情况： 如果存的是数组，那么还会保存数组长度信息（32bit）。</p>
</li>
</ul>
<p>这块内容在Java并发编程的时候也会说的，到时候可以再加深一下印象。</p>
<h2 id="7-2-实例数据"><a href="#7-2-实例数据" class="headerlink" title="7.2 实例数据"></a>7.2 实例数据</h2><p>他是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段 (包括继承的和本身的)</p>
<p>存放规则：</p>
<ul>
<li><p>相同宽度的字段总是被分配在一起。</p>
</li>
<li><p>父类中定义的变量会出现在子类之前</p>
</li>
<li><p>如果 CompactFields 参数为 true，子类的窄变量可以插入到父类的变量之间。</p>
</li>
</ul>
<h2 id="7-3-图解过程"><a href="#7-3-图解过程" class="headerlink" title="7.3 图解过程"></a>7.3 图解过程</h2><p>我们现在有一个Customer对象，这个对象里面还包含了一个Account对象，那么这个Customer对象的内存分布如何？</p>
<p>具体情况如下：</p>
<p><img src="/images/runtime/NewObjectProcess.png"></p>
<p>看图就行了，我觉得这个图还是挺清楚的。</p>
<h1 id="8-对象的访问定位"><a href="#8-对象的访问定位" class="headerlink" title="8. 对象的访问定位"></a>8. 对象的访问定位</h1><p>简单地说，JVM是如何通过栈帧中的引用访问到对象实例的？</p>
<p>懂得来说，都是一个流程：</p>
<p>栈帧中的引用指向堆区，堆区再通过元数据指针指向方法区。</p>
<p>具体的流程有两个：</p>
<h2 id="8-1-句柄访问"><a href="#8-1-句柄访问" class="headerlink" title="8.1 句柄访问"></a>8.1 句柄访问</h2><p>就是说堆中我们再专门弄出一个空间，专门用来放类型指针，栈的引用先指向了句柄，然后句柄再指向实例数据和类型数据。</p>
<p><img src="/images/runtime/%E5%8F%A5%E6%9F%84%E8%AE%BF%E9%97%AE.png"></p>
<h2 id="8-2-直接指针"><a href="#8-2-直接指针" class="headerlink" title="8.2 直接指针"></a>8.2 直接指针</h2><p>这个就很好理解了，就是堆中的对象里面还有个对象头指向了类型数据，HotSpot虚拟机就是使用这种办法。</p>
<p><img src="/images/runtime/%E7%9B%B4%E6%8E%A5%E6%8C%87%E9%92%88.png"></p>
<p>这个就是栈帧里面的引用直接指向堆中的对象实体，实体里面有一个指针指向方法区的类型元信息。</p>
<p>Hotspot 虚拟机就用的是直接访问，看24那张图，可以看出来是直接访问。</p>
<h1 id="9-直接内存"><a href="#9-直接内存" class="headerlink" title="9. 直接内存"></a>9. 直接内存</h1><p>jdk8中的元空间不再是 jvm的虚拟内存，而是直接内存，所以这里我们看看什么是直接内存。</p>
<h2 id="9-1-直接内存概念"><a href="#9-1-直接内存概念" class="headerlink" title="9.1 直接内存概念"></a>9.1 直接内存概念</h2><ul>
<li><p>直接内存不是虚拟机运行时内存的一部分，也不是java虚拟机规范中定义的内存区域</p>
</li>
<li><p>直接内存是堆外，直接向系统申请的内存</p>
</li>
<li><p>来源于 NIO，通过存在堆中的 DirectByteBuffer操作native内存。</p>
</li>
<li><p>通常，访问直接内存的效率要高于java堆，读写速度快。</p>
<ul>
<li><p>由于处于性能考虑，读写频繁的场合可能用到直接内存。</p>
</li>
<li><p>java 的NIO 库允许Java程序直接使用内存，用于数据缓冲区。</p>
</li>
</ul>
</li>
</ul>
<h2 id="9-2-NIO-和-IO-的比较"><a href="#9-2-NIO-和-IO-的比较" class="headerlink" title="9.2 NIO 和 IO 的比较"></a>9.2 NIO 和 IO 的比较</h2><ul>
<li><p>IO：文件输入输出</p>
<p>基础工具：byte[] &#x2F; char[] 用于传输</p>
<p>基础的类：Stream</p>
</li>
<li><p>NIO(New IO &#x2F; Non-Blocking IO)</p>
<p>基础工具：Buffer</p>
<p>基础的类：Channel</p>
</li>
</ul>
<p>不使用 NIO ，JVM进行IO的流程如下：</p>
<p><img src="/images/runtime/non-direct-memory.png"></p>
<p>使用NIO，JVM进行IO流程</p>
<p><img src="/images/runtime/NIOProcess.png"></p>
<p>额，咱也不懂这玩意有啥用，反正先写在这里。</p>
<h1 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h1><p>啊，总算是整理完了，这一章东西可谓是奇多，不光是讲方法区，同时还讲了堆和方法区之间是如何配合的，这两部分如何协同才能创建出一个对象来。需要慢慢消化。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM-堆</title>
    <url>/2022/05/28/jvm-heap/</url>
    <content><![CDATA[<p>很好，上一章讲了栈，这里开始看看堆是怎么一个情况。</p>
<blockquote>
<p>首先要说的一点是，整个这一章，都是关于堆的，在网课里面堆讲了30集，着实离谱，而且东西奇多，所以笔记也会多到离谱</p>
</blockquote>
<span id="more"></span>

<h1 id="1-堆的概述"><a href="#1-堆的概述" class="headerlink" title="1. 堆的概述"></a>1. 堆的概述</h1><ul>
<li><p>一个JVM实例只存在一个堆内存，堆也是 Java内存管理的核心区域</p>
<blockquote>
<p>一个进程对应一个JVM实例，JVM实例只有一个Runtime，Runtime里面只有堆和方法区是线程公用，所以说的直白了，一个进程只有一个堆</p>
</blockquote>
</li>
<li><p>JVM启动时堆的大小已经确定</p>
</li>
<li><p>堆的大小可以调节</p>
</li>
<li><p>Java虚拟机规范中规定，堆可以处于物理不连续的内存上，但是逻辑上应视为连续。</p>
<blockquote>
<p>如何证明堆是进程唯一的？需要用到一个工具，在 java.bin 目录下，jvisualvm，这个东西可以看到目前的java进程信息，(需要安装一个插件，VisualGC，工具里面就能安装).然后进入 visualGC</p>
</blockquote>
</li>
<li><p>即使整个线程共用一个堆，对内部还是有线程私有的缓冲区，最典型的就是 ThreadLocal，Buffer，TLAB Allocation，很好，目前我都不知道啥意思。</p>
</li>
<li><p>几乎所有的对象实例都分配在堆上，注意是几乎，不是所有，随着 JVM 的更新，JVM会进行逃逸检测，栈上也可以村对象了。</p>
</li>
<li><p>数组和对象可能永远不会存在栈上，栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。</p>
<blockquote>
<p>官网中JVM规范说的是所有，所以引出了下一条</p>
</blockquote>
</li>
<li><p>方法结束后，堆中的对象不会马上被删除，仅仅在垃圾收集的时候才会被删除。</p>
<blockquote>
<p>这里解释一下什么意思，一个方法，方法里面有引用，指向堆中的实例，当方法执行完成后，栈帧出栈，这时候引用就没了，就不在指向堆了，这个时候听不会马上GC，因为影响效率，他会在堆满了的时候去进行垃圾收集。</p>
</blockquote>
<blockquote>
<p>这里老师的原话是：出栈后引用为空，很好现在回来看，显然是栈帧出栈，局部变量表停止指向</p>
</blockquote>
</li>
<li><p>堆是GC作用的重点区域。</p>
</li>
</ul>
<h1 id="2-堆空间内存细分"><a href="#2-堆空间内存细分" class="headerlink" title="2. 堆空间内存细分"></a>2. 堆空间内存细分</h1><p>现代垃圾收集器大部分都是基于分带收集论涉及，对空间细分为：</p>
<ul>
<li><p>java7 包括之前的JVM 堆内存逻辑上分为 3部分：新生区 + 养老区 + 永久区</p>
<ul>
<li><p>Young Generation Space -&gt; 新生区 Young&#x2F;New</p>
<blockquote>
<p>又被划分为 Eden 区 和 Survivor 区</p>
</blockquote>
</li>
<li><p>Tenure Generation space -&gt; 养老区 Old&#x2F;Tenure</p>
</li>
<li><p>Permanent Space -&gt; 永久区 Perm</p>
</li>
</ul>
</li>
<li><p>java8 以后堆内存逻辑上分为3部分：新生区 + 养老区 + 元空间</p>
<ul>
<li><p>Young Generation Space 新生区 Young&#x2F;New</p>
<blockquote>
<p>同理分为 Eden Survivor</p>
</blockquote>
</li>
<li><p>Tenure Generation Space 养老区 Old&#x2F;Tenure</p>
</li>
<li><p>Meta Space 元空间 Meta</p>
</li>
</ul>
</li>
</ul>
<p>需要注意的是，永久代和元空间其实并不属于 堆，而是属于方法区，所以在这里不细说永久代。 如何证明堆包括元空间和养老代？还是昨天那个工具：Jvisualvm，里面的 visualGC， 里面 三块，enden survivor tenure 加起来 就是你设置的 堆的大小。</p>
<p>在Java 中分别叫 PSYoungGen&#x3D;新生区 ParOldGen&#x3D;养老区 MetaGen&#x2F;PSPermGen&#x3D;元空间&#x2F;永久区</p>
<h1 id="3-设置堆空间大小"><a href="#3-设置堆空间大小" class="headerlink" title="3. 设置堆空间大小"></a>3. 设置堆空间大小</h1><ul>
<li><p>堆的大小在JVM启动的时候就已经设定好了，可以通过 -Xmx 和 -Xms 来设置</p>
<ul>
<li><p>-Xms 用来表示堆区的初始内存，等价于： -XX:InitialHeapSize</p>
</li>
<li><p>-Xmx 用来表示堆区的最大内存，等价于：-XX:MaxHeapSize</p>
<blockquote>
<p>-X 是 JVM 参数，ms &#x3D; memory start</p>
</blockquote>
</li>
</ul>
</li>
<li><p>一旦堆区的内存大小超过 -Xmx，就会跑出 OutOfMemoryError异常。</p>
</li>
<li><p>通常会将-Xms 和 -Xmx配置相同的值，目的就是为了能够在Java垃圾回收机制清理完堆区后 不需要重新分割计算堆区的大小，从而提供性能。</p>
</li>
<li><p>默认情况下，初始内存大小：物理电脑内存大小 &#x2F; 64,最大内存：物理电脑内存大小 &#x2F; 4</p>
</li>
</ul>
<h1 id="4-堆的年轻代和老年代"><a href="#4-堆的年轻代和老年代" class="headerlink" title="4. 堆的年轻代和老年代"></a>4. 堆的年轻代和老年代</h1><p>别说话，看图： </p>
<p><img src="/../images/runtime/HeapOldGenAndYoungGen.png" alt="heap"></p>
<p>存储在JVM中的Java对象可以分为两类：</p>
<ul>
<li><p>生命周期比较短的瞬时对象，创建消亡都非常迅速</p>
</li>
<li><p>生命周期比较长，极端情况下和JVM的声明周期一样长</p>
</li>
</ul>
<p>创建出来的对象先放在 年轻代的Eden 区，进行一轮垃圾回收之后，如果是垃圾了，就直接回收了， 如果不是垃圾，说明对象幸存，则放到 survivor0 或者 survivor1 中。</p>
<blockquote>
<p>survivor 也叫 from &#x2F; to 区</p>
</blockquote>
<h2 id="内存占比"><a href="#内存占比" class="headerlink" title="内存占比"></a>内存占比</h2><p>默认情况下，年轻代和老年代占比 1:2，也就是年轻代占堆的1&#x2F;3，老年代占堆的 2&#x2F;3.能不能手动调整？可以，启动时添加JVM参数：<code>-XX:NewRatio=n</code> 设置年轻代和老年代占比 1:n。当然默认情况下是 <code>-XX:NewRatio=2</code>。但是这个数一般不建议改，除非你确定项目中有很多老对象。</p>
<p>HotSpot虚拟机中，伊甸园区和幸存者区占比为 8:1:1。同理可以通过启动参数 <code>-XX:survivorRatio=n</code> 来调整。但是需要说一下，其实启动后占比是6:1:1，而不是8:1:1，你要是真想让他8:1:1符合规范，那你设置一下好了。</p>
<p>几乎所有对象首先都是在Eden区创建，除非这个对象太大了直接放到OldGen，而且大部分对象的销毁都是放在Eden中，有研究表明 80%的对象都是朝生暮死，生命周期很短。如果我们嫌不够的话，可以使用参数 <code>-Xmn</code> 来调整新生代大小.</p>
<h1 id="5-创建对象的大体流程"><a href="#5-创建对象的大体流程" class="headerlink" title="5. 创建对象的大体流程"></a>5. 创建对象的大体流程</h1><p>前文说道，创建对象一般发生在新生代，那么新生代具体发生了什么，让我们来详细说一说，注意，这里并没有提到类加载器，仅仅是在对重给对象分配内存流程。后面还会详细说一个对象创建具体的流程。</p>
<h2 id="5-1-流程"><a href="#5-1-流程" class="headerlink" title="5.1 流程"></a>5.1 流程</h2><ol>
<li><p>在Eden区分配空间，大部分情况都是吧对象分配在eden区，上文也说过，除非这个对象特别大</p>
</li>
<li><p>当Eden区满了的时候，出发年轻代的垃圾回收机制，叫 YGC(YoungGC) 或者叫 MinorGC，Eden中已经没有了引用的对象将会被回收，剩下的对象，将会进入 survivor0 或者 survivor1，这里我们先假设 survivor0 和 survivor1 都是空的，再假设 Eden中没有被回收的对象进入了 survivor0.这个时候 survivor0 就叫to区，同时进入 survivor0 的对象有一个年龄计数器，用来记录幸存次数，从 0 变成 1。</p>
</li>
<li><p>继续创建对象，放在 Eden中，当Eden再一次满了，再次触发 YGC，这回Eden中的幸存对象将会进入空的那个 survivor，这里空的是 survivor1，年龄计数器变为1，同时 survivor0 中的对象也进行YGC，s0中的幸存者也会进入s1，那么这个时候，s1就叫to区，s0就叫from 区，s区的垃圾回收是 Eden 回收，他也顺带回收一下，如果 s区满了，再说。</p>
</li>
<li><p>一直进行这个 Eden + from &#x3D;&gt; to 的过程，同时对象的年龄计数器累加。</p>
</li>
<li><p>当一个对象的年龄计数器值达到临界的时候，默认是15，那么就会认为这个对象的生命周期很长，就会把它放入 老年代。这个过程叫提升 ：Promotion</p>
</li>
</ol>
<h2 id="5-2-总结"><a href="#5-2-总结" class="headerlink" title="5.2 总结"></a>5.2 总结</h2><ul>
<li><p>针对 s区，复制之后有交换，谁空谁是to</p>
</li>
<li><p>关于垃圾回收，频繁在 新生代回收，很少在老年代回收，几乎不再永生代(Meta) 回收。</p>
</li>
<li><p>再出发 YGC 的时候，Eden区肯定是被清空了</p>
</li>
</ul>
<h2 id="5-3-特殊情况"><a href="#5-3-特殊情况" class="headerlink" title="5.3 特殊情况"></a>5.3 特殊情况</h2><p>看图：</p>
<p><img src="/../images/runtime/MemoryHandleSpecialCase.png" alt="heap_memory"></p>
<p>解释一下： 正常流程肯定能看懂，说一点特殊情况：</p>
<ul>
<li><p>Eden 放不下了，可能是 Eden 满了，触发 YGC，然后Eden 还是放不下，这个时候Eden肯定是 空了，说明 对象大小超过了 Eden大小，则直接放入 老年代。</p>
</li>
<li><p>上面这种情况，如果 老年代也放不下，触发 FGC，还放不下，那完了，抛出 OOM错误。</p>
</li>
<li><p>触发YGC的时候，如果 s区放不下，就直接进入老年代。</p>
</li>
</ul>
<h1 id="6-堆垃圾回收"><a href="#6-堆垃圾回收" class="headerlink" title="6. 堆垃圾回收"></a>6. 堆垃圾回收</h1><p>大体来看，Heap 中的 GC 分为 3种：</p>
<ul>
<li><p>Young GC &#x2F; MinorGC</p>
</li>
<li><p>Full GC</p>
</li>
<li><p>Old GC &#x2F; Major GC</p>
</li>
</ul>
<p>根据 HotSpot 虚拟机，按照收集区域又分为两种：部分收集和整堆收集</p>
<ul>
<li><p>部分收集：不是完整收集整个Java 堆的收集，其中又分为：</p>
<ul>
<li><p>新生代收集 MinorGC&#x2F;YoungGC: 只收集年轻代的垃圾收集</p>
</li>
<li><p>老年代收集 MajorGC&#x2F;OldGC： 只收集老年代</p>
<ul>
<li><p>目前只有CMS GC会有单独收集老年代的行为</p>
</li>
<li><p>很多时候 MajorGC 会和 FullGC 混合使用，需要具体分辨是老年代回收还是整堆回收</p>
</li>
</ul>
</li>
<li><p>混合回收器 Mixed GC：收集整个新生代和部分老年代的垃圾</p>
<ul>
<li>只有G1 GC 有这种行为</li>
</ul>
</li>
</ul>
</li>
<li><p>整堆收集：收集整个 Java 堆 和 方法区 的垃圾，注意，还包括方法区。</p>
</li>
</ul>
<p>下面说一下各个内存部分的垃圾回收触发机制：</p>
<h2 id="6-1-年轻代触发机制"><a href="#6-1-年轻代触发机制" class="headerlink" title="6.1 年轻代触发机制"></a>6.1 年轻代触发机制</h2><ul>
<li><p>年轻代空间不足，就会触发minor gc,这里说的空间不足指的是eden空间不足，survivor 满了不会触发 minor gc，只会发生提升。每次回收都会清空年轻代内存。</p>
</li>
<li><p>Java 对象大多数申明周期很短，所以minor gc 发生的特别频繁。</p>
</li>
<li><p>minor gc 会触发STW，也就是暂停用户线程，等垃圾回收结束，才会恢复用户线程</p>
</li>
</ul>
<h2 id="6-2-老年代回收："><a href="#6-2-老年代回收：" class="headerlink" title="6.2 老年代回收："></a>6.2 老年代回收：</h2><ul>
<li><p>发生在老年代的垃圾回收，当对象从老年代消失了，我们就认为 major gc 或者 full gc 发生了，</p>
</li>
<li><p>发生一次 major gc，一般来说，伴随着至少一次的minor gc，不是绝对的，以后再说。</p>
<ul>
<li>也就是当老年代空间不足时，西安出发一次 minor gc，如果空间还不足，触发 major gc</li>
</ul>
</li>
<li><p>major gc 一般比 minor gc 慢10倍以上，stw 时间更长。</p>
</li>
<li><p>如果major gc后空间还是不够，抛出 OOM 异常。</p>
</li>
</ul>
<h2 id="6-3-FullGC-触发机制："><a href="#6-3-FullGC-触发机制：" class="headerlink" title="6.3 FullGC 触发机制："></a>6.3 FullGC 触发机制：</h2><ul>
<li><p>调用 System.gc() 时</p>
</li>
<li><p>老年代空间不足</p>
</li>
<li><p>方法区空间不足</p>
</li>
<li><p>通过 minor gc 后进入老年代的平均大小大于老年代的可用内存</p>
</li>
<li><p>eden from 的对象往 to 区复制，to区空间不够，提升到老年代，老年代空间也不够，触发 full gc</p>
</li>
<li><p>开发中尽量避免 full gc</p>
</li>
</ul>
<h1 id="7-TLAB"><a href="#7-TLAB" class="headerlink" title="7. TLAB"></a>7. TLAB</h1><p>前文说过TLAB，说是 堆里面有每个线程的私有缓冲区，有 TLAB，ThreadLocal，Buffer，Allocation，其实后面的三个词全都在说 TLAB。</p>
<h2 id="7-1-TLAB是啥"><a href="#7-1-TLAB是啥" class="headerlink" title="7.1 TLAB是啥"></a>7.1 TLAB是啥</h2><p>ThreadLocal Buffer Allocation： 线程私有缓冲区，用于结局线程安全问题。</p>
<h2 id="7-2-为什么要设置TLAB"><a href="#7-2-为什么要设置TLAB" class="headerlink" title="7.2 为什么要设置TLAB"></a>7.2 为什么要设置TLAB</h2><p>堆是整个进程共享的一块区域，如果一大堆线程同事访问堆，会造成县城不安全，如果给数据加锁，那效率就太慢了，所以为了提高效率，加入了线程缓冲区。</p>
<p>JVM给每个线程在 Eden 划分出来一块 TLAB，这种方式解决了线程安全问题，提高了内存分配吞吐量，我们就管这种方式叫“快速分配策略”.</p>
<p>虽然说不是所有对象都可以分配在 TLAB上，但是TLAB确实是JVM分配对象的首选。TLAB非常小，仅仅占到了 Eden的 1%。</p>
<p>如果对象在TLAB分配失败，JVM就会考虑给对象加锁，直接把对象放在Eden中。</p>
<h2 id="7-3-一些参数"><a href="#7-3-一些参数" class="headerlink" title="7.3 一些参数"></a>7.3 一些参数</h2><ul>
<li><p>-XX:useTLAB 是否开启TLAB，默认开启</p>
</li>
<li><p>-XX:TLABWasteTargetPercent 设置TLAB占Eden的百分比。</p>
</li>
</ul>
<h2 id="7-4-对象创建过程"><a href="#7-4-对象创建过程" class="headerlink" title="7.4 对象创建过程"></a>7.4 对象创建过程</h2><p>有了TLAB以后，对象创建流程如下：</p>
<p><img src="/../images/runtime/TLAB.png" alt="tlab"></p>
<h2 id="7-5-剩下的"><a href="#7-5-剩下的" class="headerlink" title="7.5 剩下的"></a>7.5 剩下的</h2><p>p81 没好好看，以后可以补一补。</p>
<h1 id="8-逃逸分析"><a href="#8-逃逸分析" class="headerlink" title="8. 逃逸分析"></a>8. 逃逸分析</h1><p>随着 JIT(编译器) 的发展，逃逸分析技术逐渐成熟，栈上分配，标量替换优化技术 导致技术上有了一点区别，那就是 堆上分配对象不再那么绝对了。</p>
<p>大部分情况下，一个对象在堆上分配空间，但是在某些特殊情况下，这个对象经过了逃逸分析，发现这个方法并没有逃离方法，那么这个对象就有可能在栈上分配空间。</p>
<p>但是提一句，HotSpot虚拟机可是没有逃逸分析里面的部分功能的，比如栈上分配这个，HotSpot就没有。</p>
<h2 id="8-1-逃逸分析概述"><a href="#8-1-逃逸分析概述" class="headerlink" title="8.1 逃逸分析概述"></a>8.1 逃逸分析概述</h2><p>逃逸分析干嘛的？就是用来优化内存分配的，我们前面说对象都要分配到堆上，但是堆上涉及到GC，而栈却不涉及GC，所以可不可以把对象存到栈上，然后方法执行完成直接弹栈，省的GC了。所以这个就是逃逸分析要干的事，分配一个对象，就要看这个对象有没有发生逃逸，如果发生逃逸，也就是这个对象跑出了当前方法作用域，那么发生逃逸，该咋办咋办，如果没有，则可以进行优化。就可以把这个对象放到栈上。</p>
<ul>
<li><p>通过逃逸分析，Java Hotspot 编译器能够分析一个对象的引用从而决定这个对象是否分配到栈上。</p>
</li>
<li><p>逃逸分析的基本行为就是分析对象的作用域：</p>
<ul>
<li><p>一个对象被定义后，如果只在方法中调用，那么没有发生逃逸。</p>
</li>
<li><p>对象被定义后，方法外也引用了它，则发生了逃逸。比如方法中创建的对象最后被return了。</p>
</li>
</ul>
</li>
<li><p>没有发生逃逸，则对象可以分配到栈上，毕竟别的地方不用，方法执行完，栈帧出栈，对象也跟着出栈。</p>
</li>
<li><p>发生逃逸，那就老老实实往堆上分配。</p>
</li>
</ul>
<p>举个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这种情况下，user 对象仅仅在方法内部被调用，则没有逃逸，往栈上分配就行了  </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;  </span><br><span class="line">    <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();  </span><br><span class="line">    user = <span class="literal">null</span>;  </span><br><span class="line">&#125;  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 这种情况，StringBuffer 最终被return，发生了逃逸。  </span></span><br><span class="line"><span class="keyword">public</span> StringBuffer <span class="title function_">getString</span><span class="params">(String a, String b)</span>&#123;  </span><br><span class="line">    <span class="type">StringBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();  </span><br><span class="line">    buffer.append(a);  </span><br><span class="line">    buffer.append(b);  </span><br><span class="line">    <span class="keyword">return</span> buffer;  </span><br><span class="line">&#125;  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 上面的 StringBuffer 改成这种，就不会发生逃逸  </span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getString</span><span class="params">(String a, String b)</span>&#123;  </span><br><span class="line">    <span class="type">StringBuffer</span> <span class="variable">stringBuffer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();  </span><br><span class="line">    stringBuffer.append(a);  </span><br><span class="line">    stringBuffer.append(b);  </span><br><span class="line">    <span class="keyword">return</span> stringBuffer.toString();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>参数如下：</strong></p>
<ul>
<li><p>-XX:-DoEscapeAnalysis 关闭逃逸分析</p>
</li>
<li><p>-XX:+DoEscapeAnalysis 开启逃逸分析</p>
</li>
</ul>
<h2 id="8-2-逃逸分析：代码优化"><a href="#8-2-逃逸分析：代码优化" class="headerlink" title="8.2 逃逸分析：代码优化"></a>8.2 逃逸分析：代码优化</h2><p>总的来说，可以通过逃逸分析干好多事，上面那个，仅仅是一个 栈上分配。</p>
<p>逃逸检测的优化：</p>
<ul>
<li><p>栈上分配</p>
</li>
<li><p>同步省略</p>
</li>
<li><p>分离对象&#x2F;标量替换</p>
</li>
</ul>
<h3 id="8-2-1-栈上分配"><a href="#8-2-1-栈上分配" class="headerlink" title="8.2.1 栈上分配"></a>8.2.1 栈上分配</h3><p>就是前面说的，站上分配对象，如果实体仅仅在方法内部使用没有进入外部，则对象会被分配到栈上。</p>
<h3 id="8-2-2-同步省略"><a href="#8-2-2-同步省略" class="headerlink" title="8.2.2 同步省略"></a>8.2.2 同步省略</h3><p>如果一个对象仅在一个线程中使用，或者说，一个对象只能从一个线程中被访问，那么对于这个对象的操作就不考虑同步。</p>
<ul>
<li><p>线程同步的代价是很高的。</p>
</li>
<li><p>在动态编译同步代码块的时候，如果JIT 检测到一个对象仅仅在一个线程中被访问，而没有发布到其他线程，则运行时 JVM 就会取消对这个对象进行上锁，大大的提高效率，这就叫 锁消除。</p>
</li>
</ul>
<p>举个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;  </span><br><span class="line">    <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();  </span><br><span class="line">    <span class="keyword">synchronized</span>(user)&#123;  </span><br><span class="line">        System.out.println(user);  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 上面这种情况，user 对象仅仅在一个线程中被访问，并没有多个线程共享，所以几遍你给他加了锁，  </span></span><br><span class="line"><span class="comment">// JVM也不会执行，但是废话，这种情况，本来我们就不应该加锁。</span></span><br></pre></td></tr></table></figure>

<h3 id="8-2-3分离对象或标量替换"><a href="#8-2-3分离对象或标量替换" class="headerlink" title="8.2.3分离对象或标量替换"></a>8.2.3分离对象或标量替换</h3><p>有的对象可能不需要作为一个连续的内存结构存入到内存中，而且也可以被访问到。那么这部分对象的部分(甚至全部) 就可以存到 CPU的寄存器中。</p>
<p>用Java 说，就是这个对象不用存在 堆中，那就可以放到 栈 中。这里还需要解释几个概念：</p>
<p><strong>标量</strong></p>
<p>无法被分解成更小的数据，比如基本数据类型。</p>
<p><strong>对应聚合量</strong></p>
<p>还可以被分解的对象就是聚合量，比如我们自己写的类的实例。</p>
<p><strong>标量替换</strong></p>
<p>如果经过逃逸分析，发现你目前的对象没有在方法外面使用，他就会把你的聚合量，分解为几个标量，这个过程就叫标量替换。</p>
<p>说白了，就是吧对象打散了，分配到栈上。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;  </span><br><span class="line">    <span class="type">Point</span> <span class="variable">p</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Point</span>();  </span><br><span class="line">    System.out.println(<span class="string">&quot;Point.x=&quot;</span> + p.x + <span class="string">&quot; Point.y=&quot;</span> + p.y);  </span><br><span class="line">&#125;  </span><br><span class="line">​  </span><br><span class="line"><span class="comment">// 最终这个东西会被优化成  </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;  </span><br><span class="line">    <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">1</span>;  </span><br><span class="line">    <span class="type">int</span> <span class="variable">y</span> <span class="operator">=</span> <span class="number">2</span>;  </span><br><span class="line">    System.out.println(<span class="string">&quot;Point.x=&quot;</span> + x + <span class="string">&quot; Point.y=&quot;</span> + y);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>-XX:+EliminateAllocation 开启标量替换，默认就是开启的。</p>
<h2 id="8-3-总结"><a href="#8-3-总结" class="headerlink" title="8.3 总结"></a>8.3 总结</h2><p>大体说几点：</p>
<ul>
<li><p>逃逸分析并不成熟</p>
</li>
<li><p>逃逸分析本身也消耗性能，如果分析了半天，结果发现都逃逸了，那完犊子了</p>
</li>
<li><p>Oracle HotSpot 并没有栈上分配，所以肯定对象都在堆上</p>
</li>
</ul>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟机栈</title>
    <url>/2022/05/27/jvm-stack/</url>
    <content><![CDATA[<p>虚拟机栈，JVM用于处理方法执行的地方，东西还挺多，而且还听重要.</p>
<span id="more"></span>

<h1 id="1-虚拟机栈概述"><a href="#1-虚拟机栈概述" class="headerlink" title="1. 虚拟机栈概述"></a>1. 虚拟机栈概述</h1><blockquote>
<p>Java Virtual Machine Stack</p>
</blockquote>
<p>首先明确个概念，JVM是基于栈的存储模型(当然还有基于寄存器的)，一般来说java 中 栈里面存放运行时数据，堆 进行存储，比如创建对象，就会放到堆里面，当然这不代表栈不会存数据，一些局部变量也是存在栈里面的。</p>
<h2 id="1-1-虚拟机栈是什么"><a href="#1-1-虚拟机栈是什么" class="headerlink" title="1.1 虚拟机栈是什么"></a>1.1 虚拟机栈是什么</h2><p>每个线程创建时都会创建一个虚拟机栈，里面存储着栈帧(Stack Frame) 对应方法调用，栈帧就是方法调用，方法开始调用栈帧入栈，方法调用结束栈帧出栈。</p>
<p>生命周期和JVM一样。</p>
<h2 id="1-2-作用"><a href="#1-2-作用" class="headerlink" title="1.2 作用"></a>1.2 作用</h2><p>主管程序的运行，保存方法的局部变量，部分结果，并参与方法的调用和返回</p>
<blockquote>
<p>局部变量包括 8 中基本数据类型和 引用数据类型的引用，仅限引用地址，不包括实际的对象，对象在堆中。</p>
</blockquote>
<p>大致说一下，先不说那么细，看图： </p>
<p><img src="/images/runtime/stackFrame.png" alt="stack_frame"></p>
<p>这里定义两个方法，A 和 B，然后两个方法进行入栈操作，绿色的就是 B 方法，那么栈顶的方法就是当前方法，然后B执行完，A就是当前方法。</p>
<p>那么目前，我们可以粗略的将方法，理解为栈帧，当然栈帧里面还细分一堆东西，我们现在先不说了。</p>
<h2 id="1-4-栈的优点"><a href="#1-4-栈的优点" class="headerlink" title="1.4 栈的优点"></a>1.4 栈的优点</h2><ul>
<li><p>有效的存储方式，访问速度仅次于程序计数器</p>
</li>
<li><p>JVM 对栈的操作只有两个</p>
<ul>
<li><p>方法执行，入栈</p>
</li>
<li><p>执行完，出栈</p>
</li>
</ul>
</li>
<li><p>不存在垃圾回收</p>
<blockquote>
<p>栈不存在 GC 但是存在 OOM (out of memory 内存溢出),PC寄存器俩都没有</p>
</blockquote>
</li>
</ul>
<h2 id="1-5-栈可能出现的问题"><a href="#1-5-栈可能出现的问题" class="headerlink" title="1.5 栈可能出现的问题"></a>1.5 栈可能出现的问题</h2><p>Java 中，栈的大小可以是动态的或者固定不变的。如果栈的大小固定不变，那么入栈操作可能会因为栈满了而报错， 抛出 StackOverFlowError</p>
<blockquote>
<p>最常见的就是无限递归</p>
</blockquote>
<p>如果栈的大小动态，那么可能进行入栈操作是跟内存要空间，结果内存没了，导致异常 抛出 OutOfMemoryError</p>
<h1 id="2-栈帧概述"><a href="#2-栈帧概述" class="headerlink" title="2. 栈帧概述"></a>2. 栈帧概述</h1><p>何为栈帧，我们上面说，把一个方法的调用理解成栈帧，一个方法在JVM中执行，就是虚拟机栈中压入了这个方法对应的栈帧，方法执行完成后，这个栈帧就会弹栈。同时为了保证方法执行的正确性以及其他的一些什么乱七八糟的东西，栈帧内部还有很多的其他组成部分，我们下面会详细说。</p>
<h2 id="2-1-栈帧的注意事项"><a href="#2-1-栈帧的注意事项" class="headerlink" title="2.1 栈帧的注意事项"></a>2.1 栈帧的注意事项</h2><ul>
<li><p>不同线程之间的栈帧不能相互引用</p>
</li>
<li><p>如果方法调用了其他返回，在方法返回时，当前栈帧会传给前一栈帧执行结果，当前栈帧出栈，让上一个栈帧变为当前。</p>
</li>
<li><p>java中有两个方式返回方法，return 和 throw(没有处理)，两种办法都会弹出栈帧。</p>
</li>
</ul>
<h2 id="2-2-栈帧的具体结构"><a href="#2-2-栈帧的具体结构" class="headerlink" title="2.2 栈帧的具体结构"></a>2.2 栈帧的具体结构</h2><p>分为5部分：</p>
<ul>
<li><p>局部变量表</p>
</li>
<li><p>操作数栈&#x2F;表达式栈</p>
</li>
<li><p>动态链接&#x2F;指向运行时常量池的方法引用</p>
</li>
<li><p>方法返回地址</p>
</li>
<li><p>附加信息</p>
</li>
</ul>
<p>下面我们就会进入这5个部分，详细说说栈帧里面都是些什么鬼。</p>
<h1 id="3-局部变量表"><a href="#3-局部变量表" class="headerlink" title="3. 局部变量表"></a>3. 局部变量表</h1><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h2><ul>
<li><p>也叫本地变量表：</p>
</li>
<li><p>定义一个数字数组，用于存储方法参数，和定义在方法内的局部变量，这些数据类型包括 8种基本数据类型，引用，和返回值类型。</p>
</li>
<li><p>一个线程配套一个虚拟机栈，所以不存在线程安全问题。</p>
</li>
<li><p>这个表的长度一开始就已经固定，且不会发生改变，因为在编译的时候编译器就已经解析出来你这个方法需要多少个临时变量了，表长存在一个 maximum local variables 属性里面。 可以反编译一个class文件找找，code 里面的 locals 也记录了。</p>
</li>
<li><p>只在当前方法中有效，别人想用就得传参了，方法调用结束变量表随之销毁。</p>
</li>
<li><p>方法嵌套次数由虚拟机栈决定，一般来说，栈越大，嵌套越多，如果一个方法的本地数据过多， 会导致栈帧过大，进而占用虚拟机栈的空间变多，导致方法嵌套次数变少。</p>
</li>
</ul>
<p>我们解析一个 class文件，就能在方法里面找到 LocalVariableTable， slot 代表了第几个本地变量，然后 length不解释，signature 就是数据类型， 同时，code 里面的 locals 也记录了 变量表的最大长度。</p>
<h2 id="3-2-解析Class中的方法"><a href="#3-2-解析Class中的方法" class="headerlink" title="3.2 解析Class中的方法"></a>3.2 解析Class中的方法</h2><p>我们解析一个 class文件以后，不说 javap 解析了，就说 jclasslib 解析以后得到的东西。首先我们解析完成后，随便进入一个方法，这里我就以main方法为例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">name: cp_info #30 &lt;main&gt;  </span><br><span class="line">descriptor: cp_info #31 &lt;([Ljava/lang/String:V)&gt;  </span><br><span class="line">Access flags: 0x0009 [public static]</span><br></pre></td></tr></table></figure>

<p>name 就是方法名，告诉你是 main 方法，descriptor 描述，包括 参数类型：LJava…String,L 代表引用，V 代表void 无返回值。Access flags 访问表示，告诉你是 public static。</p>
<p>然后，我们进入 code，byteCode 就是字节码指令, ExceptionTable 就是异常表，没有异常，空。misc 里面就是一些描述，比如 本地变量表的最大长度，还有指令长度，字节码指令0 - 最后那个号。</p>
<p>然后code 里面还有一个 LineNumberTable,里面记录Java 代码和 字节码指令的行号映射关系，lineNumber 表示 Java 行数，startPC 代表字节码指令行数，两个上述一一对应。</p>
<p>LineNumberTable如下：</p>
<p><img src="/images/runtime/line_number_table.png" alt="line_number_table"></p>
<p>然后重点看看本地变量表，局部变量表如下：</p>
<p><img src="/images/runtime/local_var_table.png" alt="local_var_table"></p>
<p>你方法里面有几个局部变量，他就有几行+1，几个字段+1(一般情况是，为啥？实例方法局部变量表中的第一位是 this)：</p>
<ul>
<li><p>name名字： 想必是局部变量的名称</p>
</li>
<li><p>descriptor 描述符： 就是类型，同理L是引用，</p>
</li>
<li><p>startPC起始PC： 是你这个局部变量的作用域的起始位置，是一个 字节码行号， 根据 lineNumber 表找到对应java 的行数，其实就是你java声明了这个局部变量的下一行。</p>
</li>
<li><p>index 序号： 就是索引</p>
</li>
<li><p>length长度： 不是说你这个变量多长，而是作用域长度，结合上面的 startPC， 比如 misc 里面记录的字节码长度是16，就代表你总共有16条指令， 然后已定义了一个变量，从 字节码的 第8行开始，然后到第15(0开始)失效， 那么你的这个 length 就是 8，从第8行开始，在往后的8行内生效。</p>
</li>
</ul>
<h2 id="3-3-槽-Slot"><a href="#3-3-槽-Slot" class="headerlink" title="3.3 槽 Slot"></a>3.3 槽 Slot</h2><p>本地变量表中，会将数据存放到 槽中。</p>
<ul>
<li><p>JVM 会给每一个 slot 分配一个索引，根据这个索引可以访问到局部变量表中的局部变量值。</p>
</li>
<li><p>当一个实例方法被调用时，他的方法参数和局部变量会按顺序复制到每一个 slot 上。</p>
</li>
<li><p>32 bit 的数据占用一个 slot，64bit 的占用两个，64的只有 long 和 double，包括引用都是 32bit的。</p>
</li>
<li><p>如果要访问一个 64bit的数据，只需要访问这个数据的第一个slot的索引即可。</p>
</li>
<li><p>如果当前栈帧被构造方法或者实例方法创建，则 对象 this 会被存到 index 位 0 的栈帧上，其余的按顺序。</p>
</li>
</ul>
<h2 id="3-4-静态变量和局部变量的对比"><a href="#3-4-静态变量和局部变量的对比" class="headerlink" title="3.4 静态变量和局部变量的对比"></a>3.4 静态变量和局部变量的对比</h2><ul>
<li><p>局部变量表初始化完以后，才会按顺序定义局部变量的空间</p>
</li>
<li><p>静态变量有两次机会赋值，第一次是链接阶段的准备阶段，讲静态变量初始化位零值，第二次是 初始化阶段，赋值为我们定义的值。</p>
</li>
<li><p>局部变量没有初始化，他必须我们自己定义初始值，否则不能用。</p>
</li>
</ul>
<h2 id="3-5-补充说明"><a href="#3-5-补充说明" class="headerlink" title="3.5 补充说明"></a>3.5 补充说明</h2><ul>
<li><p>这部分和GC有很大联系的就是局部变量表，方法执行时，通过这东西完成参数传递。</p>
</li>
<li><p>局部变量表中的变量也是GC中重要的根节点，只要是被局部变量表中直接或间接引用的对象都不会被回收。</p>
</li>
</ul>
<h1 id="4-操作数栈"><a href="#4-操作数栈" class="headerlink" title="4. 操作数栈"></a>4. 操作数栈</h1><h2 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4.1 概述"></a>4.1 概述</h2><p>操作数栈，字面意思，就是用于方法内代码执行做运算的。细节如下：</p>
<ul>
<li><p>每一个栈帧除了局部变量表外，还有操作数栈，后进先出。</p>
</li>
<li><p>根据指令的不同，进行 push 和 pop 的操作，也只能进行这两个操作</p>
<ul>
<li><p>某些字节码指令让操作数入栈，然后其他的指令让操作数出栈求和，再重新入栈。</p>
</li>
<li><p>比如 赋值 求和 交换等操作。</p>
</li>
</ul>
</li>
<li><p>主要用于保存计算的中间结果，同时作为计算过程中变量临时的存储空间</p>
</li>
<li><p>操作数栈就是JVM执行引擎的一个工作区，随着方法执行被创建，刚创建时是空的(空 !&#x3D; 没创建)</p>
</li>
<li><p>每个操作数栈都有一个明确的深度来进行存储，也是在编译的时候就已经定义好的， 在code 里面的 max_stack 里面定义，或者 javap 里面 方法的stack 参数</p>
</li>
<li><p>栈里面的每一个元素都可以是任意java类型，32bit的数据占1个栈深度，64bit占2个站深度。</p>
</li>
<li><p>如果被调用的方法有返回值，那么返回值也会入栈，同时PC寄存器更新下一条指令。</p>
</li>
<li><p>栈里面的元素和字节码指令的数据类型必须严格匹配，编译器在编译期间会进行验证。</p>
</li>
<li><p>我们所说的 Java解释引擎是基于栈的，这里的栈 就是 操作数栈。</p>
</li>
</ul>
<h2 id="4-2-具体流程分析"><a href="#4-2-具体流程分析" class="headerlink" title="4.2 具体流程分析"></a>4.2 具体流程分析</h2><p>我们找一段代码来具体分析分析操作数栈到底是干啥的，直接看图：</p>
<p><img src="/images/runtime/operateStack.png" alt="ops_stack"></p>
<p>我们逐条看指令，</p>
<ol>
<li><p>首先进行了 bipush 操作，push 15，将 15 存入操作数栈</p>
</li>
<li><p>执行 istore_1 也就是弹栈得到15后存入局部变量表的1位置(复习一下，0位置存this)</p>
</li>
<li><p>bipush 8，将8存入操作数栈</p>
</li>
<li><p>执行 istore_2 弹栈得8 存入 局部变量表的 2位置</p>
</li>
<li><p>iload_1 这里读取 表中1位置的数据，放入 操作数栈 进行入栈操作</p>
</li>
<li><p>iload_2 读取 表中2位置的数据，入栈</p>
</li>
<li><p>iadd 将两个操作数弹栈，相加，得到结果重新入栈</p>
</li>
<li><p>istore_3 将得到的数据 存储到 局部变量表 3 位置</p>
</li>
<li><p>返回</p>
</li>
</ol>
<p>在这个过程中，这个栈只需要 2 深度，所以可以看到，code 里面的 stack &#x3D;&#x3D; 2.</p>
<p>顺带说一句，这里我们可以看到什么 bipush，sipush，意思就是：b(yte) -&gt; i(nt) 和 s(hort) -&gt; i(nt)</p>
<p>有一种特殊的情况，方法 A return int，然后 方法B 里面调用 A 并用i接收返回值。</p>
<p>首先在方法A里面最后会进行 ireturn，也就是把返回值结果返回，然后在B方法里面，在 调用A方法接受参数的位置，会进行 aload_0他会得到返回值并入栈。</p>
<h1 id="5-动态链接"><a href="#5-动态链接" class="headerlink" title="5. 动态链接"></a>5. 动态链接</h1><blockquote>
<p>或者叫 指向运行时常量池的方法引用</p>
</blockquote>
<p>先说一下符号链接</p>
<ul>
<li>java源文件被编译到class文件里面的时候，所有的变量和方法引用都作为符号引用保存在class常量池中</li>
</ul>
<p>这话简直不是人话，我来给翻译一下：</p>
<p>我们先解析一个class文件，这个原本的Java文件里面有个a方法和b方法，b方法里面调用了a，所以字节码里面方法B有这么一句：</p>
<p><code>1: invokevirtual #6 // Method methodA:()V</code></p>
<p>这就意思是调用了 方法#6，当然注释告诉我其实就是 methodA，然后我们去常量池 里面找 #6 是个啥，然后找半天，不停地指向别的符号，最后指向了 methodA 和 ()V，methodA 就是方法名，()V 就是无参，返回 void 磨磨唧唧不停地指向别的东西。</p>
<p>同时，体现出，所有的东西，都存在常量池中，比如我们输出的 String，也存在 常量池中。</p>
<p>所以：</p>
<p>运行时，将常量池加载到方法区内形成运行时常量池，然后每个栈帧都包含一个 指向运行时常量池中 该栈帧所属方法的引用，那么这个引用，就是动态链接，可以支持该方法实现动态链接。</p>
<p>下面解释一下啥是常量池：</p>
<blockquote>
<p>说的还是不是人话，我这里再解释一下：我们解析一个Class文件会发现里面有个constant pool常量池，这里面包含什么？字符串字面值，各种需要用到的类等等等等。然后下面的代码比如 String st &#x3D; “123”，这个123就会存到常量池中，并不会直接在代码中体现。</p>
<p>JVM读取class的时候，就会去读这个常量池，也就是可以提前知道这个类里面要用到哪些其他的类，以及有用到哪些常量值，然后JVM就会把这个常量池读到运行时数据区，比如常量池中有 System.out 这个类，JVM就会提前把这个类加载到方法区中。总而言之，JVM会读取常量池从而形成运行时常量池。</p>
<p>然后，class文件中，代码会指向常量池中的某些元素，比如 invokevirtual #6，就是指向了#6常量，但是JVM读了以后你不能还指向#6了，因为已经有了运行时常量池，常量池中的元素已经有了具体的内存体现了，那你还指向#6干啥，这时就会让代码直接指向运行时常量池。这一步，也就对应了类加载中的 链接-解析 阶段。</p>
</blockquote>
<p>既然知道了啥是常量池，那么我们再看看这个动态链接，其实就很好理解了，字节码文件中，方法名，方法返回值，方法入参类型，这些都是存在常量池中的东西。那么栈帧应该知道自己这个方法对应到运行时常量池中的是哪个，动态链接就是干这个的。</p>
<h2 id="为何需要常量池"><a href="#为何需要常量池" class="headerlink" title="为何需要常量池"></a>为何需要常量池</h2><p>我们加载一个类，比如我们就写一个类里面有一个主方法，就一个输出，他加载到内存里面就需要加载 比如 父类Object，各种数据类型，System对象，PrintWriter对象，等等。</p>
<p>如果这些东西全都存在 class里面，就很浪费，所以弄一个常量池，把常用的东西放进去，需要的时候直接引用过来就行了。</p>
<h1 id="6-方法调用"><a href="#6-方法调用" class="headerlink" title="6. 方法调用"></a>6. 方法调用</h1><blockquote>
<p>从 JVM 角度看java 方法如何被调用</p>
</blockquote>
<p>上面刚说过，在类加载的时候，会把符号引用转化为直接引用，而这个转化过程是在编译期间完成的还是在运行期间完成的，这个还是有区别的。</p>
<h2 id="6-1-静态链接"><a href="#6-1-静态链接" class="headerlink" title="6.1 静态链接"></a>6.1 静态链接</h2><p>一个字节码文件被加载到 JVM 内部时，如果被调用的目标方法在编译期间可知，且运行期间保持不变，那么这个时候 符号 -&gt; 直接 的转化，就叫静态链接。</p>
<blockquote>
<p>简单说，编译期间转化，就叫静态链接</p>
</blockquote>
<h2 id="6-2-动态链接"><a href="#6-2-动态链接" class="headerlink" title="6.2 动态链接"></a>6.2 动态链接</h2><p>对应的，如果在编译期间无法确定，比如接口回调，需要在运行时转换，则成为动态链接。</p>
<blockquote>
<p>同理，运行期间绑定，动态链接</p>
</blockquote>
<h2 id="6-3-绑定"><a href="#6-3-绑定" class="headerlink" title="6.3 绑定"></a>6.3 绑定</h2><p>什么叫绑定？一个字段，方法，类的符号引用替换成直接引用的过程，只发生一次。同时这里还区分早期绑定和晚期绑定：</p>
<ul>
<li><p>早期绑定：对应静态链接，目标方法在编译期间可知且运行时不变，可以明确被调用的方法是哪一个，使用静态链接的方式进行符号到直接的转化，叫早期绑定</p>
</li>
<li><p>晚期绑定：不确定目标方法，使用动态链接进行转换，就叫晚期绑定</p>
</li>
</ul>
<h2 id="6-4-虚方法和非虚方法"><a href="#6-4-虚方法和非虚方法" class="headerlink" title="6.4 虚方法和非虚方法"></a>6.4 虚方法和非虚方法</h2><p>非虚方法对应 静态链接和早期绑定，在编译期间就确定方法的具体版本。如下都属于非虚方法：</p>
<ul>
<li><p>静态方法</p>
</li>
<li><p>私有方法</p>
</li>
<li><p>final 修饰的方法</p>
</li>
<li><p>实例构造器</p>
</li>
<li><p>父类方法</p>
</li>
</ul>
<p>其他的都属于虚方法。</p>
<h2 id="6-5-虚拟机中调用方法的指令"><a href="#6-5-虚拟机中调用方法的指令" class="headerlink" title="6.5 虚拟机中调用方法的指令"></a>6.5 虚拟机中调用方法的指令</h2><h3 id="6-5-1-调用指令"><a href="#6-5-1-调用指令" class="headerlink" title="6.5.1 调用指令"></a>6.5.1 调用指令</h3><ul>
<li><p>invokeStatic 调用非虚方法</p>
</li>
<li><p>invokeSpecial 调用 <init> 构造方法，私有方法，父类方法</p>
</li>
</ul>
<p>前面两个都属于调用非虚方法</p>
<ul>
<li><p>invokeVirtual 调用虚方法</p>
<blockquote>
<p>但是不代表 invokeVirtual 调用的都是虚方法，特别的，调用final方法，也是 invokeVirtual</p>
</blockquote>
</li>
<li><p>invokeInterface 调用接口方法</p>
</li>
</ul>
<p>还有一个特殊的，调用Lambda 的指令</p>
<ul>
<li>invokeDynamic</li>
</ul>
<p>java7 开始才引入了 invokeDynamic 这个东西，为了体现 java 的 动态类型语言特性。但是 java7 没法直接生成 invokeDynamic 指令，知道 java8 出现了 lambda 表达式，java8 才能直接生成 invokeDynamic 指令。</p>
<h3 id="6-5-2-动态类型语言-和-静态类型语言"><a href="#6-5-2-动态类型语言-和-静态类型语言" class="headerlink" title="6.5.2 动态类型语言 和 静态类型语言"></a>6.5.2 动态类型语言 和 静态类型语言</h3><p>简单说，静态类型语言在编译期间会对数据类型进行检查，动态类型语言会在运行时进行类型检查，变量本身没有类型，变量值才有类型。</p>
<h1 id="7-方法返回值地址"><a href="#7-方法返回值地址" class="headerlink" title="7. 方法返回值地址"></a>7. 方法返回值地址</h1><p>所谓 方法返回值地址，这里我给举个例子：</p>
<p>我们调用 方法 A，方法 A 里面我们有调用了 方法 B，在虚拟机栈的角度，A 入栈，然后B入栈，现在，方法 B 执行完成，那么就需要回到 方法 A 中 调用 B 的那个地方，继续往下执行，方法 B 的返回值，需要给到 方法 A 调用 B 的那一行代码，这就需要方法返回值地址</p>
<p>方法返回值地址里面存储了 PC寄存器中的值，也就是记录了调用方法的位置的下一行代码，然后方法执行完成，将返回值放入操作数栈，然后根据方法返回值地址，回到方法调用的位置，继续执行。</p>
<h2 id="7-1-方法退出的两种情况"><a href="#7-1-方法退出的两种情况" class="headerlink" title="7.1 方法退出的两种情况"></a>7.1 方法退出的两种情况</h2><ul>
<li><p>正常退出，调用者 PC寄存器的值作为返回地址，调用该方法指令的下一条指令地址。</p>
</li>
<li><p>出现未处理异常，非正常退出，返回地址需要异常表来确定，栈帧不保存这部分信息</p>
</li>
</ul>
<p>所以，方法返回值地址仅针对方法正常推退出的情况。</p>
<h2 id="7-2-返回指令："><a href="#7-2-返回指令：" class="headerlink" title="7.2 返回指令："></a>7.2 返回指令：</h2><p>函数返回指令如下：</p>
<ul>
<li><p>ireturn -&gt; intReturn 返回 byte short int boolean char</p>
</li>
<li><p>lreturn -&gt; longReturn 返回 long</p>
</li>
<li><p>freturn -&gt; floatReturn 返回 float</p>
</li>
<li><p>dreturn -&gt; doubleReturn 返回 double</p>
</li>
<li><p>areturn -&gt; 不知道 返回 引用</p>
</li>
<li><p>return -&gt; void 方法无返回值</p>
</li>
</ul>
<h2 id="7-3-异常表"><a href="#7-3-异常表" class="headerlink" title="7.3 异常表"></a>7.3 异常表</h2><p>如果方法存在异常，则会有一个异常表进行处理，在方法里面，需要 javap</p>
<p>结构如下：</p>
<table>
<thead>
<tr>
<th>from</th>
<th>to</th>
<th>target</th>
<th>type</th>
</tr>
</thead>
<tbody><tr>
<td>6</td>
<td>8</td>
<td>11</td>
<td>java&#x2F;io&#x2F;IOException</td>
</tr>
</tbody></table>
<p>意思如下：</p>
<p>从 6 到 8 行 如果出现异常IOException，交给 11 处理，其实也就是 try catch 代码块里面的东西。</p>
<h1 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h1><p>很好，栈总算是说完了。下面就是牛逼的堆了。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>微信小程序-页面跳转</title>
    <url>/2022/05/22/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BD%AC/</url>
    <content><![CDATA[<blockquote>
<p>create by 陈HL_pthef on 2022&#x2F;05&#x2F;22</p>
</blockquote>
<p>自从宣布开始做课设到现在，各种问题层出不穷，尤其页面跳转这个问题仍旧困扰着很多人。那在这里就详细说说 这个微信小程序到底如何实现页面跳转。</p>
<p><strong><font color="red">注意：</font></strong></p>
<p><strong>下面的内容不要深究原因，不要深究原因，不要深究原因</strong>，跟着做就可以了。</p>
<span id="more"></span>

<h2 id="1-页面"><a href="#1-页面" class="headerlink" title="1. 页面"></a>1. 页面</h2><p>想要页面跳转肯定先得有页面，所以如何创建页面呢？我这里用一个新的微信小程序模板：<br><img src="http://49.232.218.190/p1.png" alt="weixin_app"></p>
<p>首先，我们右键pages，那个红色的图标，右键他，然后选择新建文件夹，起一个合适的名字，我这里就叫 tempPage 。创建完以后如下所示：</p>
<p><img src="http://49.232.218.190/p2.png" alt="new_dir"></p>
<p>然后，我们右键你新建的这个文件夹，选择新建Page，要求你起个Page名称，我这里强烈建议：<strong><font color='red'>Page名称和文件夹名称保持一致</font></strong>。新建以后，就会出现4个文件，如下图：</p>
<p><img src="http://49.232.218.190/p3.png" alt="new_page"></p>
<p>呐，看好了，Page名和文件夹名一致。</p>
<p>而且，新建的这个文件夹，和文件夹里面这个和文件夹同名的Page，他们的名称必须<br><strong><font color='red'>全是英文！！！</font></strong>，这一点特别重要，否则待会跳转直接喜提 not found 异常。</p>
<p>然后我们在这个新页面上写点东西，打开 xxx.wxml 这个文件（xxx就是你Page的名），随你写点啥，我这里就写：</p>
<p><img src="http://49.232.218.190/p4.png" alt="temp_page_content"></p>
<p>很好，到这里，新页面准备完成，下一步我们需要实现从index.wxml 页面跳转到你的这个新页面。</p>
<h2 id="2-跳转"><a href="#2-跳转" class="headerlink" title="2. 跳转"></a>2. 跳转</h2><p>首先要想跳转，你得有个触发跳转的东西对吧，这里统一使用按钮也就是button，当然可以是别的，比如图片，view，啥的，都可以，但这里我就用button举例子了。所以我们的目标就是，在页面上放一个按钮，我们一点他，页面就会跳转到新页面。</p>
<p>第一步就是创建按钮，在 index.wxml 文件里面写一个button。</p>
<p><img src="http://49.232.218.190/p5.png" alt="button"></p>
<p>我这里的 index.wxml 啥也没有，你们的肯定有东西，根据你们的情况，把这个button放到合适的地方。同时可以看到左边 button 也显示出来了。</p>
<p>然后我们给这个button 绑定一个事件，在button标签里面写如下内容：</p>
<p><img src="http://49.232.218.190/p6.png" alt="button_bind"></p>
<p>其实就里面加了一个bindtap，bindtap后面跟着的那个东西，名字还真不能随便起，有如下规则：</p>
<ul>
<li>只能出现英文字母，数字和下划线（减号下面那个符号，我劝你别用）</li>
<li>数字不能开头</li>
</ul>
<p>我这里就叫jump了，你那叫啥都行，比如 toPage，toMyPage，甚至abc，都可以，但是决不能是 123, 1bc 甚至各种emoji，肯定报错。</p>
<p>然后，我们去这个页面对应的js文件下，因为我这个button是在index页面下写的，所以当前页面的js文件也就是index.js，在这个文件里加这么一段：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 我这里叫jump，你那还真不一定叫jump</span></span><br><span class="line"><span class="comment">// 你上面bindtap后面起的啥名，这里就写啥</span></span><br><span class="line"><span class="title function_">jump</span>(<span class="params"></span>)&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同理，我这里的url 写的是 ../tempPage/tempPage</span></span><br><span class="line">    <span class="comment">// 你那里不一定，这里应该写 ../你新页面的文件夹名/Page名</span></span><br><span class="line">    <span class="comment">// 而且特别注意，这里前里两个点一定不能丢。</span></span><br><span class="line">    <span class="comment">// 而且最后面的Page，没有后缀，不是 tempPage.js </span></span><br><span class="line">    <span class="comment">// 也不是 tempPage.wxml，就是tempPage</span></span><br><span class="line">    wx.<span class="title function_">navigateTo</span>(&#123;</span><br><span class="line">        <span class="attr">url</span>: <span class="string">&quot;../tempPage/tempPage&quot;</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>

<p>现在js文件的整体效果如下：</p>
<p><img src="http://49.232.218.190/p7.png" alt="js"></p>
<p>也就是这段代码，至少写在Page里面，你别写到Page外面了。</p>
<p>写完以后，保存，然后点击那个按钮，如果不出意外的话应该是可以跳转了。</p>
<h2 id="3-意外"><a href="#3-意外" class="headerlink" title="3. 意外"></a>3. 意外</h2><p>如果没跳转，看看是不是如下原因：</p>
<ul>
<li>跳转后页面一片大白：卡了，重启一下程序，或者看看你的新页面是不是就没写东西，那肯定白</li>
<li>页面白还有一种情况，那就是你把跳转页面的js文件里的东西都删了，切记切记：<strong><font color="red">新Page的js文件里的东西已经是最简形式，千万不要删任何东西</font></strong>。否则恭喜你喜提大白屏.</li>
<li>点击按钮没有反应：<ul>
<li>查看 bindtap 后面那个名字和代码里面那个名字是否一致，我的都叫jump</li>
<li>卡了，重启</li>
</ul>
</li>
<li>跳转后告诉你 not found：这个原因就多了，归根到底就是微信没找到页面<ul>
<li>检查跳转路径：必须是 <code>../跳转页面所在文件夹名/跳转页面名</code>，且页面名没有任何后缀</li>
<li>检查页面路径，两个页面是否都在文件夹里面包着，然后这个文件夹都在红色的pages下。只有满足这个要求，上面的跳转路径才能生效。</li>
<li>别是用了中文吧？？！！</li>
</ul>
</li>
</ul>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>我这里是用了 index页面往别的页面跳转做示范，但是实际做课设的时候真不一定就是从index页面跳，可能是你自己的A页面往你自己的B页面跳，咋办？？照猫画虎呗。</p>
<p>现在你要从A页面跳到B页面：</p>
<ul>
<li>首先确认两件事：<ul>
<li>AB两页面是否都在文件夹里面，文件夹是否都在 pages 下，也就是说两文件夹同层</li>
<li>Ab两页面的文件夹和页面名是否有中文，确认没有</li>
</ul>
</li>
<li>在A页面中写一个button，并照猫画虎写个bindtap，后面的名字按规范起</li>
<li>在A页面的js文件中，插入上述那段代码，名字必须和你的bindtap一致，url改成<code>../B页面的所在文件夹名称/B页面名称(切记没有后缀)</code></li>
<li>完成</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>01-机组基本概念</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-01-%E6%9C%BA%E7%BB%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>三部分：计算机发展、计算机硬件、计算机的性能指标</p>
<span id="more"></span>

<h1 id="1-计算机发展历史"><a href="#1-计算机发展历史" class="headerlink" title="1. 计算机发展历史"></a>1. 计算机发展历史</h1><p>不重要，看图就行了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702084446.png" alt="image.png"></p>
<h1 id="2-硬件基本组成"><a href="#2-硬件基本组成" class="headerlink" title="2. 硬件基本组成"></a>2. 硬件基本组成</h1><h2 id="2-1-冯诺依曼机"><a href="#2-1-冯诺依曼机" class="headerlink" title="2.1 冯诺依曼机"></a>2.1 冯诺依曼机</h2><p>最早期的计算机需要手动接线来完成指令，冯诺依曼提出了主存储器，将所有指令先存放在存储器中，然后处理机在执行。基于这个理念就出来了冯诺依曼机。结构如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702085344.png" alt="image.png"></p>
<p>数据通过 IO 设备进入运算器，存储程序将其存储到存储器，执行指令时，控制器读取指令，指挥运算器运算。</p>
<p>冯诺依曼机五个特点：</p>
<ol>
<li>计算机由五大部件组成</li>
<li>指令和数据以同等地位存储在存储器，可按地址寻址</li>
<li>指令和数据用二进制表示</li>
<li>指令由操作码和地址码组成</li>
<li>有存储程序，数据通过 IO 设备进入运算器，存储程序将数据存到存储器</li>
<li>运算器是核心</li>
</ol>
<h2 id="2-2-现代计算机结构"><a href="#2-2-现代计算机结构" class="headerlink" title="2.2 现代计算机结构"></a>2.2 现代计算机结构</h2><p>如果以运算器和核心的话会很低效，所以现代计算器多<strong>以存储器为核心</strong>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702090105.png" alt="image.png"></p>
<p>其中控制器和运算器联系十分紧密，所以现代多将两个部分整合成一个芯片，也就是 CPU：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702090323.png" alt="image.png"></p>
<p>这里的主存其实就是内存，辅存指的就是外存。</p>
<h2 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702090634.png" alt="image.png"></p>
<h1 id="3-硬件工作原理"><a href="#3-硬件工作原理" class="headerlink" title="3. 硬件工作原理"></a>3. 硬件工作原理</h1><p>看看主机内部的三个元件如何相互协调工作</p>
<h2 id="3-1-主存储器"><a href="#3-1-主存储器" class="headerlink" title="3.1 主存储器"></a>3.1 主存储器</h2><p>主存储器里面首先有两个寄存器：MAR 地址寄存器和 MDR 数据寄存器。MAR 储存地址，MDR 储存数据。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702091234.png" alt="image.png"></p>
<p>CPU 想要跟主存取数据，首先会将物理地址写入 MAR，然后主存就会拿着MAR里面的地址去找数据，然后将数据写入 MDR，CPU再来 MDR 拿数据。也就是说 MAR 和 MDR 是直接和 CPU 交互的元件。</p>
<p>主存储体就是存数据的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702091421.png" alt="image.png"></p>
<p>存储单元由存储元组成，存储元就是一个电容，可以存放一个 bit ，一堆存储元组成存储单元，存储单元就可以存放一串二进制代码。</p>
<p>存储字（word）：存储单元里面存的二进制代码的组合，也就是一个存储单元存放的数据</p>
<p>存储字长：二进制代码的位数。</p>
<p>所以说，MAR 的位数直接反映了存储单元的个数，MDR 的位数&#x3D;存储字长。比如 MAR 是4位，则主存中只有 2^8 个存储单元，MDR 16 位，则存储单元可以存放 16 bit 也就是两字节。</p>
<h2 id="3-2-运算器"><a href="#3-2-运算器" class="headerlink" title="3.2 运算器"></a>3.2 运算器</h2><p>直接看图的了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702092105.png" alt="image.png"></p>
<p>需要注意的是：ACC 本身就是一个寄存器，用来存操作数，或者说计算结果，根据下面那个表我们也可以看出来，加法运算时，ACC 会存储被加数，X 存储操作数也就是加数，然后 ALU 计算 ACC 和 X 的值得到结果，将结果存储到 ACC 中。剩下的 MQ 也是这个道理。</p>
<h2 id="3-3-控制器"><a href="#3-3-控制器" class="headerlink" title="3.3 控制器"></a>3.3 控制器</h2><p>这个玩意通过控制总线协调各个部件进行工作：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702092454.png" alt="image.png"></p>
<p>其中 CU 是里面最核心的东西，他才是负责协调控制的那个部件。</p>
<p>想要完成一条指令，首先要根据 PC 取出一条指令，然后将指令放到 IR 中分析指令，最后让 CU 去执行指令。PC 和 IR 都是用于取指。</p>
<h2 id="3-4-计算机工作过程"><a href="#3-4-计算机工作过程" class="headerlink" title="3.4 计算机工作过程"></a>3.4 计算机工作过程</h2><p>写一段代码：<code>int a = 2, b = 3, c = 1; int y = a * b + c;</code>，这个进程在主存中就会变成这样：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702092908.png" alt="image.png"></p>
<p>具体的工程流程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702093154.png" alt="image.png"></p>
<h2 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702093534.png" alt="image.png"></p>
<h1 id="4-计算机系统层次结构"><a href="#4-计算机系统层次结构" class="headerlink" title="4. 计算机系统层次结构"></a>4. 计算机系统层次结构</h1><p>首先CPU他要执行指令，所以会有一个传统机器 M1，使用机器语言执行二进制机器指令。根据我们之前说的，执行一条指令其实还要干很多事，比如从主存拿东西啥的，这一些列事儿可以称作微指令，所以传统机器M1下面还有一个微指令机器 M0。</p>
<p>在这俩之上就是软件部分了，从下到上分别有操作系统，汇编语言机器，高级语言机器，不多说了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702094239.png" alt="image.png"></p>
<h1 id="5-计算机性能指标"><a href="#5-计算机性能指标" class="headerlink" title="5. 计算机性能指标"></a>5. 计算机性能指标</h1><h2 id="5-1-存储器的性能指标"><a href="#5-1-存储器的性能指标" class="headerlink" title="5.1 存储器的性能指标"></a>5.1 存储器的性能指标</h2><p>前面已经说过了，MAR 指明存储单元有多少个，MDR 指明存储字长，这俩放到一起就可以推出内存大小。</p>
<p>比如 MAR 有32位，MDR 有8位，则内存&#x3D; 2^32 x 8bit &#x3D; 4GB。</p>
<h2 id="5-2-CPU-性能指标"><a href="#5-2-CPU-性能指标" class="headerlink" title="5.2 CPU 性能指标"></a>5.2 CPU 性能指标</h2><p>CPU 主频：CPU 里面写的什么 2.9GHz 这种，可以理解成CPU执行指令的节奏。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702095319.png" alt="image.png"></p>
<p>CPI：执行一条指令要花费的时钟周期数，比如两个 CPU 都执行乘法指令，CPU 内部的结构不同，执行时间就可能不同，就会导致 CPI 不同。这个指标一般看的是平均，因为影响 CPI 的因素太多了。</p>
<p>有了 CPI 和 CPU 时钟周期，我们就可以大致推算执行一条指令所需要的时间：也就是 CPI x 时钟周期。</p>
<p>IPS：每秒执行多少条指令，IPS&#x3D;主频&#x2F;平均CPI</p>
<p>FLOPS：每秒执行多少次浮点运算。注意这个和前面的 IPS 前面可能会加单位，比如 TFLOPS，GFLOPS，这里的 K、M、G、T 可就不是 2 的幂了，而是 10^3、10^6、10^9、10^12，也就是千、百万、十亿、万亿。</p>
<p>一般数量单位会以10这种来描述，也包括主频，2.9GHz 就是说每秒钟震荡 2.9 * 10^9 次。</p>
<h2 id="5-3-系统整体性能指标"><a href="#5-3-系统整体性能指标" class="headerlink" title="5.3 系统整体性能指标"></a>5.3 系统整体性能指标</h2><p><strong>数据通路带宽</strong></p>
<p>数据总线一次所能并行传送信息的位数。其实就是一次能传输多少位的数据，如果内存MDR 是16位，数据总线带宽是8位，则内存往CPU发送数据得发送两次。</p>
<p><strong>吞吐量</strong></p>
<p>系统单位时间内处理请求的数量。这个比较宽泛，取决于数据多快输入主存，CPU多快取指令，等等，这些步骤大部分都关系到主存，因此吞吐量主要取决于主存的存取周期。</p>
<p><strong>响应时间</strong></p>
<p>用户向计算机发送一个请求，到系统对请求作出响应并获得他需要的结果的等待时间。通常包括CPU运行时间和等待时间。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>02-数据的表示和运算</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-02-%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<p>数据的表示与运算。</p>
<span id="more"></span>

<h1 id="1-数据表示"><a href="#1-数据表示" class="headerlink" title="1. 数据表示"></a>1. 数据表示</h1><h2 id="1-1-进制转换"><a href="#1-1-进制转换" class="headerlink" title="1.1 进制转换"></a>1.1 进制转换</h2><p>首先说一个概念：<strong>基数</strong>。每个数码位所用到的不同的符号的个数，比如 10 进制可以用到 0-9 十个不同的符号，基数就是10。8进制用到 0-7 八个不同的符号，基数就是8。</p>
<p>一个 R 进制数：abc.d 换算成10进制就是 a x R^2 + b x R^1 + c x R^0 + d x R^-1。</p>
<p>R 进制加法的话只需要 逢 R 进 1 即可。</p>
<h2 id="1-2-二进制转八、十六进制"><a href="#1-2-二进制转八、十六进制" class="headerlink" title="1.2 二进制转八、十六进制"></a>1.2 二进制转八、十六进制</h2><p>二进制到八进制：把二进制三个分一组，然后每组直接转10进制数即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1111000010.01101 -&gt;</span><br><span class="line">00+1 111 000 010 . 011 01+0</span><br><span class="line">  1   7   0   2  .  3   2 </span><br></pre></td></tr></table></figure>

<p>二进制到16进制：二进制数四个分一组，然后每组转10进制然后16进制表示即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1111000010.01101 -&gt;</span><br><span class="line">00+11 1100 0010 . 0110 10+00</span><br><span class="line">  3     C    2  .   6   8   </span><br></pre></td></tr></table></figure>

<p>反过来 八进制、十六进制 转 二进制就是反过来，将每个数分为 3个一组、4个一组的二进制数即可。</p>
<p>符号记一下：</p>
<p>二进制：111010101<font color='red'>B</font></p>
<p>八进制：（1625）8</p>
<p>十六进制：（1625）16; 1625<font color='red'>H</font>; <font color='red'>0x</font>1625;</p>
<p>十进制：（1625）10；1625<font color='red'>D</font></p>
<h2 id="1-3-十进制转R进制"><a href="#1-3-十进制转R进制" class="headerlink" title="1.3 十进制转R进制"></a>1.3 十进制转R进制</h2><p>整数部分10进制转R进制：短除到0，然后从下往上顺即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703105308.png" alt="image.png"></p>
<p>小数部分10进制转R进制：一直乘R，直到乘到1或者开始循环为止，每次乘积大于1，提出来1然后小数部分继续乘。然后从上往下取，上面是小数部分的高位。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703105633.png" alt="image.png"></p>
<p>或者拼凑一下，根据二进制表去尝试凑10进制数：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703105846.png" alt="image.png"></p>
<p>比如 260.75，就是 256 + 4 . 0.5 + 0.25，也就是100000100.11。</p>
<h2 id="1-4-真值和机器数"><a href="#1-4-真值和机器数" class="headerlink" title="1.4 真值和机器数"></a>1.4 真值和机器数</h2><p>真值：我们能识别的数字，符合我们习惯的。</p>
<p>机器数：这个数字存储到计算机中啥样的，比如正负号怎么表示，就是机器数。</p>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703110206.png" alt="image.png"></p>
<p>注意有的时候十进制数不能准确转化为二进制数，比如0.3.</p>
<h1 id="2-BCD-码"><a href="#2-BCD-码" class="headerlink" title="2. BCD 码"></a>2. BCD 码</h1><p>二进制数符合计算机习惯，十进制数符合我们的习惯，如果按照我们之前说的转换方法实际非常麻烦，BCD 码就是为了解决进制转换麻烦的问题。</p>
<p>解决办法其实就是二进制到八进制和十六进制的方法，让每一位十进制数都对应一组bit位，这样的话可能造成冗余，但是转换起来比较简单。</p>
<h2 id="2-1-8421-码"><a href="#2-1-8421-码" class="headerlink" title="2.1 8421 码"></a>2.1 8421 码</h2><p>用 4个 bit 来表示一个10进制数，4bit就有16种状态，也就是会有6种状态冗余。映射关系：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703110744.png" alt="image.png"></p>
<p>比如我们要表示 985，那就是 1001 1000 0101。就是简单的按位转换。</p>
<p><strong>加法操作</strong></p>
<p>比如我们要计算 1 + 3，那就是简单的 0001 + 0011 &#x3D; 0100. 结果没问题。如果是 5 + 8，那就问题大了，5 + 8 &#x3D; 0101 + 1000 &#x3D; 1101，这个数字不在映射区间内，咋办？</p>
<p>这个时候就需要修正一下，给这个数字 + 6 强迫他进位，进位以后剩下的，就是3，进走的就是1，结果就是 13：</p>
<p>1101 + 0110（6）&#x3D; 10011 &#x3D; 0001 ｜ 0011，后四位正好是3，前面0001就是进位的1。</p>
<p>8421 种四个bit的权值不变，分别是 8 4 2 1，所以这种也叫有权码。</p>
<h2 id="2-2-余3码"><a href="#2-2-余3码" class="headerlink" title="2.2 余3码"></a>2.2 余3码</h2><p>就是在 8421 码的基础上，给每个数字都加3（0011），咱也不知道这是为啥，反正就是加了三。</p>
<h2 id="2-3-2421-码"><a href="#2-3-2421-码" class="headerlink" title="2.3 2421 码"></a>2.3 2421 码</h2><p>也是在 8421 基础上改的，他修改了4个bit的权值，分别是 2 4 2 1，修改后映射关系如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703111812.png" alt="image.png"></p>
<p>这样做是为了让 0-4 这五个数第一位都是0，5-9 第一位都是1。</p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703112000.png" alt="image.png"></p>
<h1 id="3-无符号整数表示与运算"><a href="#3-无符号整数表示与运算" class="headerlink" title="3. 无符号整数表示与运算"></a>3. 无符号整数表示与运算</h1><p>无符号数，也就是“自然数”，0 1 2 3 4 这种的。比如 C 语言里面的 <code>unsigned short a = 10; </code> 这就是声明了一个无符号短整型数。</p>
<h2 id="3-1-无符号数的表示"><a href="#3-1-无符号数的表示" class="headerlink" title="3.1 无符号数的表示"></a>3.1 无符号数的表示</h2><p>一般一台电脑有机器字长限制，计算机的通用寄存器只能存8bit，那么无符号整数的上限也就是 8bit 了。ALU 最多也就只能进行8位运算。</p>
<p>其实很简单，就是将无符号真值转换成二进制数然后填到 8bit 寄存器中，需要注意的是，如果真值过大，可能出现数据溢出的情况，如 256 对应二进制为 100000000，放不到 8bit 里面，只能保留后面的00000000.</p>
<p>特点：</p>
<ul>
<li>全部二进制位都是数值位，没有符号位，第i位的位权是 2^(i-1)</li>
<li>n bit 无符号整数表示范围是 0 - 2^n - 1，超出则溢出</li>
<li>可以表示最小的数是全0，最大的数是全1.</li>
</ul>
<h2 id="3-2-无符号数的加减法"><a href="#3-2-无符号数的加减法" class="headerlink" title="3.2 无符号数的加减法"></a>3.2 无符号数的加减法</h2><p>很简单，就是正常的二进制加法，不说了。计算机如何进行无符号整数的减法？并不是像人一样给他列竖式计算，而是将减法转变为加法，为啥？因为加法电路便宜。</p>
<p>A：99 &#x3D; 1100011；B：9 &#x3D; 1001，我们要计算 A - B 咋办？</p>
<ul>
<li>被减数不变，减数全部按位取反，末位 + 1</li>
<li>减法变加法，从最低位开始，按位相加，并往高位进位</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">B = 00001001 </span><br><span class="line">按位取反：</span><br><span class="line">B = 11110110 </span><br><span class="line">然后末位加一：</span><br><span class="line">B = 11110111</span><br><span class="line"></span><br><span class="line">然后 A + B = </span><br><span class="line">    01100011</span><br><span class="line">+   11110111</span><br><span class="line">=  101011010</span><br><span class="line"></span><br><span class="line">最高位1溢出，保留后面的 01011010 = 90</span><br></pre></td></tr></table></figure>

<h1 id="4-带符号整数"><a href="#4-带符号整数" class="headerlink" title="4. 带符号整数"></a>4. 带符号整数</h1><p>这种就是计算机里面的整数，比如 -2，-1，C 语言里面的就是 <code>int,short</code> 。同理，往后还按机器字长8bit来看。</p>
<p>这玩意有三种表示法：原码、反码、补码。三种方式都可以表示带符号整数。</p>
<h2 id="4-1-原码"><a href="#4-1-原码" class="headerlink" title="4.1 原码"></a>4.1 原码</h2><h3 id="4-1-1-原码表示"><a href="#4-1-1-原码表示" class="headerlink" title="4.1.1 原码表示"></a>4.1.1 原码表示</h3><p>很简单，bit里面最高位表示正符号，用 0 表示正，用 1 表示负，剩余的位数表示数值的真值绝对值。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703121515.png" alt="image.png"></p>
<p>机器字长为n+1 的话，数值范围就是 -(2^n - 1) - 2^n - 1。同时，真值0有两种形式：+0 和 -0，对应的就是最开头的符号位不同，剩下的位数都是0.</p>
<p>如果给明了机器字长为8bit的话，x &#x3D; -19 就可以写作 [x]原 &#x3D; 1,0010011，用逗号分隔符号位。没有指明机器字长的话，也可以写作 [x]原 &#x3D; 1,10011，补的0可以省略了。</p>
<h3 id="4-1-2-原码的计算"><a href="#4-1-2-原码的计算" class="headerlink" title="4.1.2 原码的计算"></a>4.1.2 原码的计算</h3><p>直接说，不太好算，比如两个数 +10 和 -9，两个数的符号位分别是 0 和 1，如果直接按照上面的运算规则的话结果就是错的，因为<strong>符号位不能参与运算</strong>。</p>
<p>如何让符号位也可以参与运算？这就提出了补码。</p>
<h2 id="4-2-补码"><a href="#4-2-补码" class="headerlink" title="4.2 补码"></a>4.2 补码</h2><h3 id="4-2-1-原、反、补-转换"><a href="#4-2-1-原、反、补-转换" class="headerlink" title="4.2.1 原、反、补 转换"></a>4.2.1 原、反、补 转换</h3><p>原码到补码还有一个中间态，就是反码，转变规则如图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703122316.png" alt="image.png"></p>
<p>注：</p>
<ul>
<li>负数的情况下，原码、反码、补码 的最高位，全都表示的是符号</li>
<li>还是负数的情况下，原码和反码可以按照规则相互转换，但是补码不能通过 + 1 的方式转回反码了，需要末位-1 才对，但是二进制减法有点麻烦，所以不用这种办法进行转换，而是补码直接转回原码，然后再转反码。</li>
</ul>
<h3 id="4-2-2-原码、补码-转换"><a href="#4-2-2-原码、补码-转换" class="headerlink" title="4.2.2 原码、补码 转换"></a>4.2.2 原码、补码 转换</h3><p>直接看图就行了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703122826.png" alt="image.png"></p>
<p>这种方法取反的时候可不包含第一个1，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[x]原 = 1,1100100 从右往左找到第一个 1 ：</span><br><span class="line"></span><br><span class="line">[x]原 = 1,1100 1 00 然后不包括自己，左边的数值位取反：</span><br><span class="line"></span><br><span class="line">[x]原 = 1,0011 1 00 就变成了补码</span><br></pre></td></tr></table></figure>

<p>但是实际上对于计算机而言，补码转原码还是一样的流程，数值位取反以后末位+1.</p>
<h3 id="4-2-3-补码的加法"><a href="#4-2-3-补码的加法" class="headerlink" title="4.2.3 补码的加法"></a>4.2.3 补码的加法</h3><p>补码可以把符号位直接当作数值位来计算，然后按位相加，向更高位进位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703124907.png" alt="image.png"></p>
<p>最后按位相加以后向更高位进了个 1，然后舍去，保留最后8bit，得到0.如果是两个负数计算，同理：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703125106.png" alt="image.png"></p>
<p>最后将结果从补码转回原码，从右往左找到第一个1，然后左边的数值位取反，得到 10100110，也就是 -38.</p>
<h3 id="4-2-4-补码的减法"><a href="#4-2-4-补码的减法" class="headerlink" title="4.2.4 补码的减法"></a>4.2.4 补码的减法</h3><p>同理，减法电路比较贵，所以尽可能用加法处理，一个补码减去一个补码，就可以理解成一个补码加上一个补码的负数：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703125453.png" alt="image.png"></p>
<p>补码转成负数也有简单的方法，从右往左找到第一个1，然后这个1左边的所有位包括符号位，全部取反即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703125834.png" alt="image.png"></p>
<p>最后的计算结果首位是0，是个整数，所以原反补一样，故结果是38.</p>
<h2 id="4-3-总结"><a href="#4-3-总结" class="headerlink" title="4.3 总结"></a>4.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703125948.png" alt="image.png"></p>
<h2 id="4-4-三种码的比较"><a href="#4-4-三种码的比较" class="headerlink" title="4.4 三种码的比较"></a>4.4 三种码的比较</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703144600.png" alt="image.png"></p>
<h2 id="4-5-移码"><a href="#4-5-移码" class="headerlink" title="4.5 移码"></a>4.5 移码</h2><p>很简单，在补码的基础上，符号位取反。这种玩意儿只能表示整数。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703144809.png" alt="image.png"></p>
<p>对比：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703145002.png" alt="image.png"></p>
<p>8比特机器数从全0到全1对应的四种码：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703145052.png" alt="image.png"></p>
<h1 id="5-定点小数"><a href="#5-定点小数" class="headerlink" title="5. 定点小数"></a>5. 定点小数</h1><p>啥叫定点？就是说默认小数点的位置，前面的整数可以理解为定点整数，小数点默认隐藏在最后，定点小数就是小数点默认隐藏在符号位和数值位之间。</p>
<p>定点小数可以用原码、反码、补码表示，但是不能用移码表示。</p>
<h2 id="5-1-定点小数原码"><a href="#5-1-定点小数原码" class="headerlink" title="5.1 定点小数原码"></a>5.1 定点小数原码</h2><p>和之前几乎一毛一样，只是每一个bit的位权变了，从之前的 2^i 变成了现在的 2^(-i) 而已。符号位仍旧是 0 &#x3D; 正，1 &#x3D; 负。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703145515.png" alt="image.png"></p>
<h2 id="5-2-定点小数补码"><a href="#5-2-定点小数补码" class="headerlink" title="5.2 定点小数补码"></a>5.2 定点小数补码</h2><p>和之前也是一模一样，仍旧是整数不变，负数先变成反码（除符号位以外全部取反）然后再变成补码（反码+1），当然之前那种简便方法也能用。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703145916.png" alt="image.png"></p>
<h2 id="5-3-定点小数计算"><a href="#5-3-定点小数计算" class="headerlink" title="5.3 定点小数计算"></a>5.3 定点小数计算</h2><p>还是一模一样，两个定点小数做加减运算，需要先将定点小数转为补码，然后用补码运算。</p>
<p>定点小数补码加法：从最低位开始，按位相加（符号位参与运算），并往高位进位；定点小数补码减法：被减数不变，减数全部位按位取反、末位+1，减法变加法；然后按位相加，进位。</p>
<h2 id="5-4-定点小数VS定点整数"><a href="#5-4-定点小数VS定点整数" class="headerlink" title="5.4 定点小数VS定点整数"></a>5.4 定点小数VS定点整数</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703150454.png" alt="image.png"></p>
<p>同时，补位也不一样：</p>
<ul>
<li>定点整数 [x]原 &#x3D; 1,110，补位后 &#x3D; 1,<font color='red'>0000</font>110，得在符号位和数值位之间补0</li>
<li>定点小数 [x]原 &#x3D; 1.110，补位后 &#x3D; 1.110<font color='red'>0000</font>，在数值位后面补0</li>
</ul>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>04-存储系统</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-04-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>存储系统，也就是主存。</p>
<span id="more"></span>

<h1 id="1-存储系统基本概念"><a href="#1-存储系统基本概念" class="headerlink" title="1. 存储系统基本概念"></a>1. 存储系统基本概念</h1><h2 id="1-1-存储器的层次化结构"><a href="#1-1-存储器的层次化结构" class="headerlink" title="1.1 存储器的层次化结构"></a>1.1 存储器的层次化结构</h2><p>越靠近 CPU 的存储器速度越快，容量越小，价格越高。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709103908.png" alt="image.png"></p>
<p>高速缓存 和 内存 都可以和 CPU 交互数据。外存和内存的数据交换一般由 OS 完成，内存和高速缓存的数据交互一般由硬件完成，软件不需要操心。</p>
<h2 id="1-2-存储器的分类"><a href="#1-2-存储器的分类" class="headerlink" title="1.2 存储器的分类"></a>1.2 存储器的分类</h2><p>按照层次分类就是上面这个图，从上到下速度越来越慢。其中 Cache 和 主存可以直接被 CPU 读写。</p>
<p>按照存储介质：</p>
<ul>
<li>半导体存储器：主存、Cache，速度会更快</li>
<li>磁表面存储器：比如磁带、磁盘</li>
<li>光存储器：比如光盘</li>
</ul>
<p>按照存取方式分类：</p>
<ul>
<li>随机存取存储器（RAM）：读写任何一个存储单元所需要的时间都是相同的，类似数组，可以直接访问一个存储地址。</li>
<li>顺序存取存储器（SAM）：比如磁带，想要访问疑问存储单元必须要从头开始找，读取时间取决于存储单元所在位置</li>
<li>直接存取存储器（DAM）：比如磁盘，既有随机存取的特性，也有顺序存取的特性。比如磁头可以移动到相应位置，然后顺着磁片转动的方向顺序读写数据。</li>
<li>相联存储器（Associative Memory）：可以按照内容访问的存储器，可以按照内容检索到存储位置进行读写，比如 “快表”。</li>
</ul>
<p>DAM 的速度介于 RAM 和 SAM 之间，比 SAM 快。SAM 和 DAM 都叫串行访问存储器：读写某个存储单元所需要的时间和存储单元的物理位置有关。</p>
<p>按照数据的可更改性：</p>
<ul>
<li>读写存储器（Read&#x2F;Write）：即可读也可写，比如磁盘、内存、Cache</li>
<li>只读存储器（Read Only，ROM）：只能读不能写，比如蓝光光碟</li>
</ul>
<p>但是实际上 ROM 也可以写，就是麻烦。</p>
<p>按照信息的可保存性：</p>
<ul>
<li><p>易失性存储器：比如主存，断电后数据丢失</p>
</li>
<li><p>非易失性存储器：比如磁盘、光盘，断电后数据不丢失</p>
</li>
<li><p>可破坏性读出：信息读出后数据会被破坏，需要进行重写，比如 DRAM 芯片</p>
</li>
<li><p>非破坏性读出：就是不会破坏，比如磁盘，SRAM 芯片</p>
</li>
</ul>
<h2 id="1-3-存储器性能指标"><a href="#1-3-存储器性能指标" class="headerlink" title="1.3 存储器性能指标"></a>1.3 存储器性能指标</h2><ul>
<li>存储容量：存储字长 x 字长，比如 1M x 8位</li>
<li>单位称为：每位价格 &#x3D; 总成本 &#x2F; 总容量</li>
<li>存储速度：数据传输率 &#x3D; 数据宽度&#x2F;存储周期</li>
</ul>
<p>这个存储周期说一说：存储器存取完以后有一个冷却时间，启动存储到存储完成时存取时间，然后到下一次存取的时间间隔叫恢复时间，这俩时间加到一起叫存取周期。</p>
<ul>
<li>主存带宽：也就数据传输率，每秒从主存进出信息的最大数量，单位是 字&#x2F;秒、字节&#x2F;秒、位&#x2F;秒。</li>
</ul>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709110148.png" alt="image.png"></p>
<h1 id="2-主存储器的基本组成"><a href="#2-主存储器的基本组成" class="headerlink" title="2. 主存储器的基本组成"></a>2. 主存储器的基本组成</h1><h2 id="2-1-基本的半导体元件及原理"><a href="#2-1-基本的半导体元件及原理" class="headerlink" title="2.1 基本的半导体元件及原理"></a>2.1 基本的半导体元件及原理</h2><p>回忆一下内存的组成，内存里面有存储体、MAR、MDR，存储体里面是一大堆的存储单元，每个存储单元是一串存储元构成的。这里说说存储元是咋来的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709110650.png" alt="image.png"></p>
<p>说一下 MOS 管是啥玩意，这个东西是一种开关，当上面给一定的电压以后，下面虚线部分就会被接通。所以叫半导体，高电压时导电，低电压时不导电。</p>
<p>存储数据：</p>
<p>存储元的右边给一个 5V 的电压，MOS 上面也给 5V 的电压，则线路接通，5V 电压就会给到电容，电容的上端 5V，下端接地 0V，则电容充电，可以保存一定的电荷，则可以代表当前存储元存储了二进制 1。</p>
<p>访问数据：</p>
<p>MOS 上面个 5V 电压，线路接通，如果电容里面保存了电荷的话，电容就会放电，存储元右边如果检测到电荷，说明存储元存储了 1，访问到了数据。如果没有电荷，则存储的是 0 。</p>
<p>我们将一片存储元有序排列：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709111200.png" alt="image.png"></p>
<p>给红线一个 5V 的高电压，直接接通一串存储元，然后每个绿线接受电荷，就可以得到这一行存储元存储的数据，这就构成了存储单元。然后一串存储单元就构成了存储体。</p>
<p>一次性可以读出的绿色的数据，就是存储字，这图里一行只有 8 个存储单元，一次只能读入 8 bit 数据，所以存储字长为 8bit。所以说一次访存只能得到一个存储字，就是因为每次给电压只能接通一行存储元。</p>
<p>存储单元长度 &#x3D; 字长。但是编址不一定按照存储单元来编，通常是按照字节编址，一个存储单元里面可能有多个地址。</p>
<h2 id="2-2-存储器芯片的基本原理"><a href="#2-2-存储器芯片的基本原理" class="headerlink" title="2.2 存储器芯片的基本原理"></a>2.2 存储器芯片的基本原理</h2><p>直接上图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709111938.png" alt="image.png"></p>
<p>这张图里有假设有 8 个存储单元，则三位二进制可以表示所有存储单元，故 MAR 为 3位。我们要访问 0 号存储单元，MAR 给出 000，译码器就需要将 MAR 发来的 000 转化为具体的电信号，去接通相应的线路，得到数据，并将其存在 MDR 中。</p>
<p>除此之外，还需要一个控制电路，首先需要控制 MAR，只有当 MAR 电压稳定后才让其接通到译码器，然后当电压稳定后，才认为 MDR 数据无误，才会开启数据总线，将数据从 MDR 发送出去。</p>
<p>还有三个东西：</p>
<ul>
<li>片选线：CS 或者 CE（这俩头上有个横线，这里没法加），头上加横线表示低电平时有效，就是说芯片可用。</li>
<li>写控制线：WE（上划线），该线低电平时表示当前允许写</li>
<li>读控制线：OE（上划线），该线低电平时表示当前允许读</li>
</ul>
<p>WE 和 OE 也可以合二为一，还是 WE（上划线），低电平时允许写，高电平时允许读。</p>
<p>简化的结构如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709112932.png" alt="image.png"></p>
<p>地址线和 MAR 对应，数据线和 MDR 对应。一个内存条上面有多个存储芯片，比如一个 8G 的内存条可能就有 8 个 1G 的存储芯片，假如我们想要访问第二个存储芯片，就可以给第二个芯片的片选线一个低电平，其他的芯片给高电平，就可以实现。</p>
<p>这些线实际对应的就是金属引脚，比如 MAR 是 3 位的话，地址线就是 3 根，金属引脚就是 3 个。</p>
<p>现在告诉你 MAR 有 n 位，则存储单元个数 &#x3D; 2^n。总容量就是 &#x3D; 存储单元个数 x 存储字长。或者也可以说一个存储芯片是 8 x 8 的，就是说存储单元有 8 个，存储字长为 8 bit。同理如果是 8K x 8 位，则总容量就是 2^13 x 8bit 。</p>
<h2 id="2-3-寻址"><a href="#2-3-寻址" class="headerlink" title="2.3 寻址"></a>2.3 寻址</h2><p>现代计算机通常是按字节编址，就是说一个字节一个地址，但是也支持按字、半字寻址。</p>
<p>假如总容量为 1KB，按照一个 Byte 一个地址，则需要 1K 个地址，地址线就是 10 根。按字寻址的话，就是 256 个单元，每个单元 4Byte。按半字寻址，就是 512 个单元，每个单元 2Byte。字寻址就是将字号左移两位就可以得到起始字节地址。半字就是左移1位。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709114155.png" alt="image.png"></p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709114215.png" alt="image.png"></p>
<h1 id="3-DRAM-和-SRAM"><a href="#3-DRAM-和-SRAM" class="headerlink" title="3. DRAM 和 SRAM"></a>3. DRAM 和 SRAM</h1><p>这是两种存储芯片，之前说过 RAM 是随机存储器，DRAM 就是动态 RAM，SRAM 是静态 RAM。DRAM 用于主存、SRAM 用于 Cache。</p>
<p>这俩芯片的对比是一个考点。</p>
<h2 id="3-1-栅极电容-VS-双稳态触发器"><a href="#3-1-栅极电容-VS-双稳态触发器" class="headerlink" title="3.1 栅极电容 VS 双稳态触发器"></a>3.1 栅极电容 VS 双稳态触发器</h2><p>之前我们说的主存储器基本组成，说的就是 DRAM，一般用于主存，DRAM 芯片使用栅极电容存储信息，就是说过的电容存储元。</p>
<p>而 SRAM 使用双稳态触发器存储信息。</p>
<h3 id="3-1-1-栅极电路"><a href="#3-1-1-栅极电路" class="headerlink" title="3.1.1 栅极电路"></a>3.1.1 栅极电路</h3><p>之前说的已经很多了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709115112.png" alt="image.png"></p>
<p>读出1：MOS 接通，电容放电，数据线上产生电流；读出0：相应的，电容里面没有存储电荷，数据线没有产生电流。</p>
<p>这种有个问题，就是接受数据的时候电容就把电荷释放掉了，属于是 <font color='red'>破坏性读出</font>，所以读出后还需要将数据重写，也叫 <font color='red'>再生</font>。读写速度更慢，但是存储元制造成本更低，集成度高，功耗低。</p>
<h3 id="3-1-2-双稳态触发器"><a href="#3-1-2-双稳态触发器" class="headerlink" title="3.1.2 双稳态触发器"></a>3.1.2 双稳态触发器</h3><p>双稳态：储存数据 1 时，A 高 B 底；存储数据 0 时，A 低 B 高。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709115406.png" alt="image.png"></p>
<p>所以这玩意就需要两条数据线，读出时，发现BL低电平，BLX高电平，则 A 低 B 高，读取到了 0。写入时逆着来呗，BL 给一个低电平，BLX 给一个高电平，则写入0。</p>
<p>这种就属于 <font color='red'>非破坏性读出</font>，读出后不需要重写，所以这种玩意而读写速度更快，但是每个存储元制造成本更高，集成度低，功耗大。</p>
<h3 id="3-1-3-二者对比"><a href="#3-1-3-二者对比" class="headerlink" title="3.1.3 二者对比"></a>3.1.3 二者对比</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709120100.png" alt="image.png"></p>
<p>这里又引出一个新问题：啥是刷新。电容里面的电荷即使不管他，也是会慢慢流失的，DRAM 里面的电容只能维持电荷 2ms，所以每隔 2ms，就需要给电容重新充电。</p>
<p>而 SRAM 只要不断电，触发器的状态就不会改变。</p>
<h2 id="3-2-DRAM-的刷新"><a href="#3-2-DRAM-的刷新" class="headerlink" title="3.2 DRAM 的刷新"></a>3.2 DRAM 的刷新</h2><p><strong>刷新周期</strong></p>
<p>前面说了，电容只能撑 2ms，所以一般 2ms 刷新一次。</p>
<p><strong>一次刷新多少存储单元</strong></p>
<p>这个是个啥玩意，一行不就一个存储单元么，咋还一行存储单元？这个就引出了行列地址。假设 MAR 是 20 位，则译码器就的输出端就需要 2^20 根选通线连接存储单元，这个难度就有点大了。</p>
<p>解决办法就是将存储单元二维排列，然后分行地址和列地址。这样每个译码器的地址线就需要 n&#x2F;2 根，输出端的线就会大幅减少。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709121237.png" alt="image.png"></p>
<p>这个算一算就知道了，本来有 2^n 个存储单元，平铺开的话，行列分别是 2^n 开根号，就是 2^(n&#x2F;2)，也就说地址线需要 n&#x2F;2 根。用 MAR 20位举例，拆分后，每个译码器地址线 10 根，输出端控制线就是 1024 根。</p>
<p>这样的话只需要给出行地址，让行地址译码器选中一整行的存储单元刷新就行了。</p>
<p><strong>如何刷新</strong></p>
<p>有硬件支持，读出一行的信息后重新写入，占用一个读写周期。</p>
<p><strong>什么时候刷新</strong></p>
<p>假设 DRAM 内部 128 x 128 个存储单元，读写周期（存取周期）0.5us，2ms 共 2ms &#x2F; 0.5us &#x3D; 4000个周期。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709122400.png" alt="image.png"></p>
<p>首先明确一下，给了读写周期，那么刷新一行时间我们也默认 0.5us，同时之前说过，存取周期 &#x3D; 存取时间 + 恢复时间，这个恢复时间可不等价于这个刷新操作。</p>
<p>第一种方式，2ms 内需要刷新 2000 次，有点过于频繁了。第二种死区有点长。第三种就是将每行的刷新分散到 2ms 内，在 CPU 空闲的时候刷新一下得了。</p>
<p>刷新操作由存储器独立完成，不需要 CPU 控制。</p>
<h2 id="3-3-送行列地址"><a href="#3-3-送行列地址" class="headerlink" title="3.3 送行列地址"></a>3.3 送行列地址</h2><p>最后说一下这个东西，SRAM 和 DRAM 内部都是行列结构，但是 DRAM 容量更大，所以地址线通常也多，为了减少地址线，就提出了 <strong>地址线复用技术</strong>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709123956.png" alt="image.png"></p>
<p>采用这种方法就需要分两次发送行列地址。</p>
<h1 id="4-ROM-芯片"><a href="#4-ROM-芯片" class="headerlink" title="4. ROM 芯片"></a>4. ROM 芯片</h1><p>ROM 是哟中非易失性的芯片，断电后数据不会消失。</p>
<h2 id="4-1-MROM"><a href="#4-1-MROM" class="headerlink" title="4.1 MROM"></a>4.1 MROM</h2><p>Mask Read-Only Memory，掩模式只读存储器。</p>
<p>厂家按照客户的需求，在芯片生产过程中直接写入信息，之后任何人不可重写，可靠性高，灵活性差，生产周期长，只适合批量定制。</p>
<h2 id="4-2-PROM"><a href="#4-2-PROM" class="headerlink" title="4.2 PROM"></a>4.2 PROM</h2><p>Programmable ROM 可编程只读存储器。用户买来以后可以用专门的写入器向其中写入信息，写一次后就不能更改。</p>
<h2 id="4-3-EPROM"><a href="#4-3-EPROM" class="headerlink" title="4.3 EPROM"></a>4.3 EPROM</h2><p>Erasable Programmable ROM，可擦除的可编程只读存储器，允许用户写入，之后也可以用某种方式擦除数据，可以进行多次重写。</p>
<p>这里面又分俩：</p>
<ul>
<li>UVEPROM：紫外线擦除，紫外线照射一会儿就能擦除所有数据</li>
<li>EEPROM：电擦除，擦除特定的字</li>
</ul>
<h2 id="4-4-Flash-Memory"><a href="#4-4-Flash-Memory" class="headerlink" title="4.4 Flash Memory"></a>4.4 Flash Memory</h2><p>闪速存储器，也就是闪存，比如 U盘，SD 卡。在 EEPROM 基础上来的，断电后也可以保存信息，且<font color='red'>可以进行多次快速擦除重写</font>。</p>
<p>因为闪存需要先擦除再写入，所以写的速度会比读更慢。</p>
<p>每个存储元只需要单个 MOS，所以位密度比 RAM 要高，其实就是说相同体积下存储元比 RAM 更多，可以保存更多 bit。</p>
<h2 id="4-5-SSD"><a href="#4-5-SSD" class="headerlink" title="4.5 SSD"></a>4.5 SSD</h2><p>固态硬盘，由控制单元和存储单元（Flash 芯片）构成，与闪存的核心区别就是控制单元不一样，但是存储介质都类似，<font color='red'>可以进行多次快速擦除重写</font>。SSD速度快，功耗低，价格高。</p>
<p>手机的辅存也用的是 Flash 芯片，但是比 SSD 使用的芯片集成度高，功耗低，价格贵。</p>
<h2 id="4-6-计算机内部的-ROM"><a href="#4-6-计算机内部的-ROM" class="headerlink" title="4.6 计算机内部的 ROM"></a>4.6 计算机内部的 ROM</h2><p>学过操作系统的知道，开机时，计算机会首先读取主板上的一块 ROM 芯片，执行“自举装入程序”，引导计算机从辅存中加载操作系统。</p>
<p>虽然说 ROM 在主板上，逻辑上我们认为主存由 ROM 和 RAM 组成，二者会统一编址。</p>
<h2 id="4-7-总结"><a href="#4-7-总结" class="headerlink" title="4.7 总结"></a>4.7 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230709125707.png" alt="image.png"></p>
<h1 id="5-双口-RAM"><a href="#5-双口-RAM" class="headerlink" title="5. 双口 RAM"></a>5. 双口 RAM</h1><p>RAM 存在存取周期，就是说每次存取完后都需要有个恢复时间。如果多核CPU访问 RAM，第一个 CPU 访问完 RAM，这个时候第二个 CPU 也要访问 RAM，是不是就得等 RAM 恢复。如何优化这个东西，就用到了双端口 RAM。</p>
<p>没啥用，这块不考。</p>
<h1 id="6-多模块存储器"><a href="#6-多模块存储器" class="headerlink" title="6. 多模块存储器"></a>6. 多模块存储器</h1><h2 id="6-1-多体并行存储器"><a href="#6-1-多体并行存储器" class="headerlink" title="6.1 多体并行存储器"></a>6.1 多体并行存储器</h2><p>为了扩展内存，可以将多个存储体放到一起，其实就可以理解成多个内存条。如何给这些内存条编址就是个问题。</p>
<h3 id="6-1-1-高位交叉编址"><a href="#6-1-1-高位交叉编址" class="headerlink" title="6.1.1 高位交叉编址"></a>6.1.1 高位交叉编址</h3><p>计算机为了区分不同的存储体，就将内存地址划分为两块：体号、体内地址。体号用于表明要访问哪块存储体，体内地址自然就是存储体内的地址，和 OS 里面的逻辑地址很像。</p>
<p>如果将体号放在逻辑地址的高位，就是这里的高位交叉编址：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710122009.png" alt="image.png"></p>
<p>如果我们将地址转化为十进制，发现 M0 的地址是：<code>0 1 2 3 4 5 6 7</code>，M1 的地址是 <code>8 9 10 ...</code> ，也就是同一块存储体内的地址按顺序排列。</p>
<p>假设一块存储体的存取周期为 T，存取时间为 r，T &#x3D; 4r。则每次访问一个存储体都需要花费 3r 的时间来恢复。如果我们要连续访问 <code>00000, 00001, 00010, 00011, 00100</code> 五个地址，就会导致每次访问完一个地址，存储体都需要花费 3r 的时间恢复，这段时间内不能访问下面一个地址，总花费时间为 5T。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710122341.png" alt="image.png"></p>
<h3 id="6-1-2-低位交叉编址"><a href="#6-1-2-低位交叉编址" class="headerlink" title="6.1.2 低位交叉编址"></a>6.1.2 低位交叉编址</h3><p>和上面对应，逻辑地址的低位是体号，高位是体内地址：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710122449.png" alt="image.png"></p>
<p>同理将地址变为十进制，发现地址 <code>0 1 2 3 </code> 四个连续的逻辑地址被分散到了四个存储体上，逻辑地址横着连续，单个存储体内地址不连续。</p>
<p>这样的好处是，如果我们要访问一块连续的内存，就不需要等待前一块内存所对应的存储体恢复，让前面慢慢恢复，CPU 直接访问下一块存储体即可。</p>
<p>还是 T &#x3D; 4r，连续访问 <code>00000 00001 00010 00011 00100</code> 五个地址，效果如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710122830.png" alt="image.png"></p>
<p>如果访问的内存足够多，宏观上访问一次内存的时间就会趋近 r。效率几乎提升四倍。</p>
<p>为啥要讨论访问连续空间？因为一般来说代码就会放在连续的空间内。也就是 OS 中说的局部性原理。</p>
<p>这种存取方式就叫 <font color='red'>流水线</font>，CPU 的操作很快，但是访问内存很慢，就安排多个存储体并行的为 CPU 提供服务，宏观上，一个存储周期内，m体交叉存储器可以提供的数据量为单个模块的 m 倍。</p>
<h3 id="6-1-3-存储体数量"><a href="#6-1-3-存储体数量" class="headerlink" title="6.1.3 存储体数量"></a>6.1.3 存储体数量</h3><p>存储周期为 T，存取时间为 r（或者换一种说法，总线传输周期为 r，反正就是 CPU 读写一次内存的时间不可能低于 r），为了让流水线不间断，应该保证模块数 m &gt;&#x3D; T&#x2F;r。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710123424.png" alt="image.png"></p>
<p>最好的情况就是让 m &#x3D; T&#x2F;r，这样可以节省存储体数量，也不会让 CPU 等待。</p>
<p>如何确定地址 x 对应哪个存储体？可以用二进制判断，看最低两位。或者 x 的十进制直接 mod m，也行。</p>
<h3 id="6-1-4-总结"><a href="#6-1-4-总结" class="headerlink" title="6.1.4 总结"></a>6.1.4 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710123919.png" alt="image.png"></p>
<h2 id="6-2-单体多字存储器"><a href="#6-2-单体多字存储器" class="headerlink" title="6.2 单体多字存储器"></a>6.2 单体多字存储器</h2><p>之前不是一行就是一个存储字吗，这回让它一行存 m 个存储字，就是说一次读写可操作的数更多了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710123949.png" alt="image.png"></p>
<p>但是这个有个问题，就是一次只能读出一整行 m 个字，如果我们要访问的几个字不在一行，则需要多次读取，同时访问到的无用数据也会更多。不如多题并行存储器灵活，可以直接在不同的存储体上访问多个字。</p>
<h2 id="6-3-总结"><a href="#6-3-总结" class="headerlink" title="6.3 总结"></a>6.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710124400.png" alt="image.png"></p>
<h1 id="7-内存与-CPU-连接"><a href="#7-内存与-CPU-连接" class="headerlink" title="7. 内存与 CPU 连接"></a>7. 内存与 CPU 连接</h1><p>这一章主要研究这么俩问题：1. 想要扩展主存的字数（容量）咋办——字扩展；2. 数据总线宽度 &gt; 存储芯片字长咋办——位扩展。</p>
<p>之前说主存内有 MDR 和 MAR，但目前的计算机一般不会讲 MDR 和 MAR 放在主存中，而是集成在 CPU 上，CPU 通过地址总线和数据总线连接主存，实现数据的读写。</p>
<h2 id="7-1-存储器芯片的输入输出信号"><a href="#7-1-存储器芯片的输入输出信号" class="headerlink" title="7.1 存储器芯片的输入输出信号"></a>7.1 存储器芯片的输入输出信号</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710155137.png" alt="image.png"></p>
<p>前面说过了，现在的计算机主存里面没有 MAR 和 MDR 了， 所以主要关注一下地址线和数据线。两根线都是 0 - 7 也就是八位，说明主存的字数是 2^8 也就是256，字长是8 bit。</p>
<h2 id="7-2-位扩展"><a href="#7-2-位扩展" class="headerlink" title="7.2 位扩展"></a>7.2 位扩展</h2><p>现在我们有一块 8K x 1 bit 的存储芯片 （注意，一个内存条通常有多个存储芯片，就是内存条上那些黑色的块），我们要把这块芯片和 CPU 连接，咋连？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710155612.png" alt="image.png"></p>
<p>CS 是片选线，指高电平有效，这里给 1 就代表当前芯片工作。WE 指的是 Write Enable，上面没有横线就代表高电平时有效。8K 个也就是 2 ^ 13 个存储单元，就需要 13 根地址线，所以链接到 A0 - A12 上。而存储字长只有 1bit，所以数据线只能连接一根 D0，这就造成了浪费。</p>
<p>如何充分利用 CPU 上面的数据线？可以给他接多个存储芯片：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710155934.png" alt="image.png"></p>
<p>第二块存储芯片的地址线和 A0 - A12 相连，WE 和 CPU 的 WE 相连，CS 也给 1 代表第二块存储芯片工作。这样的话 CPU 给出一个地址，就可以同时选中两块存储芯片上的相同位置的数据，也就是两位，然后将这两位数据分别给 D0 和 D1。</p>
<p>这就实现了位扩展，通过多个存储芯片串联同时选中的方式，将存储字长扩展为 8 bit。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710160253.png" alt="image.png"></p>
<h2 id="7-3-字扩展"><a href="#7-3-字扩展" class="headerlink" title="7.3 字扩展"></a>7.3 字扩展</h2><p>我们又买了一块存储芯片，8K x 8bit，CPU 找就是 A0 - A15，D0 - D7。连接方式很简单，就是将 CPU 的 A0 - A12 链接到芯片上，然后 D0 - D7 全部连接到芯片。</p>
<p>这个时候CPU 的 A13 - A15 地址线还没用上，如何利用这几根线来扩展主存容量？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710160835.png" alt="image.png"></p>
<p>将另一块芯片接到 CPU 上，然后将 A13 和 A14 地址线连接到两块芯片的 CS 片选线上，这样的话如果给出的地址是 <code>01,xxxxxxxxxxxxx</code>，就说明要选中第一块存储芯片，因为 A13 地址线给了一个高电平，激活了第一块芯片。如果给出的地址是 <code>10,xxxxxxxxxxxxx</code>，说明选中第二块芯片。</p>
<p>这种情况下，我们就需要规定最高两位地址不能是全 0 或者 全 1，必须是 10 或者 01 的情况。这种方法叫 <font color='red'>线选法</font>，用线来控制存储芯片。</p>
<p>然而这样的话会导致一个问题就是地址不连续，如何解决？其实上面这个图有优化空间，可以将两块芯片的 CS 都连接到 A13 上，然后 A13 到第二块芯片的线上加一个非门，A13 给 1，第一块芯片接收到 1，第二块芯片经过非门接收到 0。同理 A13 给 0，就会选中第二块芯片，这样地址就连续了。</p>
<p>这个非门可以叫 <strong>1-2 译码器</strong>，就是说一位可以选中两种状态，可以顺着这个思路优化，当时将内存的时候，地址线到内存芯片就有一个译码器，可以将n位地址转到 2^n 个存储单元上。这里也可以加一个译码器，将 n 位地址转到 2^n 个存储芯片上。比如这个 CPU，A15 - A13 三位就可以映射到 8个存储芯片，这种就叫 3-8 译码器。这样地址就可以连续了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710161903.png" alt="image.png"></p>
<p>这是一个 2-4 译码器的实例。几个注意的点：</p>
<ul>
<li>图里面显示地址线是 CPU 到芯片1 再到 芯片2，芯片之间的地址线相连。这个是为了简化，所有的地址线只会来自于 CPU。</li>
<li>我们发现 CS 是一个低电平有效，所以线上面有个空心圆，译码器上也有空心圆，可以理解成非门，需要将信号取反。这就是习惯，低电平有效的电路连接线上加一个圈。</li>
</ul>
<p>这种方法就叫 <font color='red'>译码片选法</font>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710162427.png" alt="image.png"></p>
<h2 id="7-4-字位同时扩展"><a href="#7-4-字位同时扩展" class="headerlink" title="7.4 字位同时扩展"></a>7.4 字位同时扩展</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710162510.png" alt="image.png"></p>
<p>这个看图倒是很好理解，就是将位扩展的那种方式，多个芯片为一组，充分利用 CPU 的地址线。然后每组芯片再进行字扩展，充分利用 CPU 的地址线。</p>
<p>扩展后的主存变成了 64K x 8 bit。同时地址空间从 全0 到 全1，是连续的。</p>
<h2 id="7-5-译码器"><a href="#7-5-译码器" class="headerlink" title="7.5 译码器"></a>7.5 译码器</h2><p>对于不同的片选线 CS ，要选择不同的译码器，高电平有效的CS就要使用输出一个 1 的译码器，低电平有效的 CS 就是用输出一个 0 的译码器，画图的时候也会有区别：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710163046.png" alt="image.png"></p>
<p>译码器上有的时候也有存在 “使能”，类似 CS，用于开启译码器，比如图里面的 EN，就需要一个高电平才能让译码器工作。</p>
<p>有些更复杂的情况，译码器上会有多个 使能，比如三个，<code>G1. G2A(低). G2B(低)</code>，只有在给 <code>100</code> 信号的时候，译码器才会工作，否则的话译码器输出全 1（或者全0，反正就是无效）。</p>
<p>这玩意的功能是 CPU 用来控制片选信号的生效时间。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710163647.png" alt="image.png"></p>
<p>功能就是，CPU 会首先通过 A0 - A15 发出地址，但是电流可能不稳定，MREQ 首先会输出1，所以译码器不工作，输出全0。当 CPU 确定电流稳定后，MREQ 才会发出 0 信号，让译码器开始工作，连接到存储芯片。</p>
<p>上面这个译码器，就是经典的 <font color='red'>74LS138</font> 译码器，结构需要记住。</p>
<p>所以回过头来理解一下存取周期这个东西：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230710163915.png" alt="image.png"></p>
<p>地址线在一个交点位置发出地址，也就是地址有效那条线，但是同一时刻 CS 并没有接通（CS 那块灰色代表高电平，没接通，中间那段平的是低电平，代表 CS 接通），CS 接通的时间和地址发出的时间间隔，就是我们上面说的 MREQ。</p>
<p>然后过了一段时间 Dout 找到了数据开始往出传，也就是数据有效那条线。等到数据稳定以后，CPU就撤销了片选信号，所以 CS 关闭。</p>
<p>等到数据真的接受到了，CPU 撤销地址请求信号。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>03-数据运算</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-03-%E6%95%B0%E6%8D%AE%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<p>数据计算.</p>
<span id="more"></span>

<h1 id="1-奇偶校验"><a href="#1-奇偶校验" class="headerlink" title="1. 奇偶校验"></a>1. 奇偶校验</h1><p>数据传输过程中，如何判断数据的正确性，比如计算机A向计算机B发送消息：00 01 10 11，如果最后的11传输过程中变成了 10 ，计算机B如何发现？</p>
<p>比较简单的就是通过 1 的个数来判断，我们现在就规定发送的每一组数据 1 的个数必须为奇数数，我们就可以给数据添加一位校验位：</p>
<p><code>00 01 10 11 -&gt; 100 001 010 111</code>，给数据的开头加上一个bit位，强制 1 的个数为奇数，如果 11 变成了 10，110中1的个数为偶数，计算机B就能知道数据错误。这个就叫<font color='red'>奇偶校验</font>.</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703162230.png" alt="image.png"></p>
<p>计算机如何实现的奇偶校验？</p>
<p>假如有两个编码：1001101 和 1010111，计算机会通过 异或 运算来得到校验位，如果我们要求这两个数的偶校验的校验位：1 ^ 0 ^ 0 ^ 1 ^ 1 ^ 0 ^ 1 &#x3D; 0，所以偶校验位&#x3D;0；于是 1001101 的偶校验码 &#x3D; 01001101，然后同样使用异或进行奇偶校验，一样的步骤，如果得到 1 说明数据出错。</p>
<h1 id="2-电路基本原理"><a href="#2-电路基本原理" class="headerlink" title="2. 电路基本原理"></a>2. 电路基本原理</h1><h2 id="2-1-回忆-ALU"><a href="#2-1-回忆-ALU" class="headerlink" title="2.1 回忆 ALU"></a>2.1 回忆 ALU</h2><p>之前说过，ALU 算数逻辑单元，就是用于计算的。支持操作：</p>
<ul>
<li>算术运算；加、减、乘、除</li>
<li>逻辑运算：与、或、非、异或等</li>
<li>辅助功能：移位、求补</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703163611.png" alt="image.png"></p>
<p>之前老说的机器字长，其实就是下面的输入的两个操作数，也就是说 ALU 最多只能支持几个bit的数进行运算，最终运算结果之前说会存到 X 寄存器中，所以说 X 寄存器的位数 &#x3D;&#x3D; 输入的操作数的位数，也就等于机器字长。</p>
<h2 id="2-2-最基本的逻辑运算"><a href="#2-2-最基本的逻辑运算" class="headerlink" title="2.2 最基本的逻辑运算"></a>2.2 最基本的逻辑运算</h2><p>就是那几个：与或非、</p>
<p>先看与或非的情况：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703163845.png" alt="image.png"></p>
<p>这里也是分优先级的，与的优先级要高于或的优先级，同时 与或 两种运算符和分配律，结合率等，比如 ：AB + CD 就是 A 和 B，C和D 先与，然后两个结果进行或运算。</p>
<p>再比如：AC + AD，就可以分配率一下：A（C+D），所以电路就有两种设计方法：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703164149.png" alt="image.png"></p>
<p>左边自然就是 AC + AD 的逻辑，右边就是A（C+D）的逻辑。</p>
<p>然后再来看看 与非（与取反，只有全1才为0）、或非（或取反，只有全0才为1）、异或（两个不一样为1）、同或（两个一样为1）：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703164652.png" alt="image.png"></p>
<h2 id="2-3-异或门的应用"><a href="#2-3-异或门的应用" class="headerlink" title="2.3 异或门的应用"></a>2.3 异或门的应用</h2><p>比如之前的奇偶校验就可以用它，一个信息 1001101，求他的偶校验位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703165304.png" alt="image.png"></p>
<h1 id="3-加法器设计"><a href="#3-加法器设计" class="headerlink" title="3. 加法器设计"></a>3. 加法器设计</h1><h2 id="3-1-一位全加器"><a href="#3-1-一位全加器" class="headerlink" title="3.1 一位全加器"></a>3.1 一位全加器</h2><p>就是可以计算一个bit加上一个bit的一种电路，就是一位全加器（Full Adder，FA）：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703165617.png" alt="image.png"></p>
<p>看图我们可以知道，FA 的功能，就是已知两个加数 Ai 和 Bi，还有从低位上来的进位 Ci-1，要求出结果 Si 已经进位 Ci。</p>
<p>Si 简单，已经说了，只要 A B C 有奇数个 1 即可，就用异或，三个数依次异或就得到了 Si。</p>
<p>Ci 分两种情况：1. Ai 和 Bi 两个都是 1，那是肯定进位的，Ci 不用考虑，所以 AiBi。2. Ai 和 Bi 有一个是1，然后 Ci-1 也是1，这样也能进位，所以（Ai 异或 Bi）与 Ci。</p>
<p>最后电路出来长这样：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703170138.png" alt="image.png"></p>
<p>左边就是 FA 的具体实现，右边就是简化版的封装出来的电路元器件。</p>
<h2 id="3-2-串行加法器"><a href="#3-2-串行加法器" class="headerlink" title="3.2 串行加法器"></a>3.2 串行加法器</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703170338.png" alt="image.png"></p>
<p>每次讲两位送入 FA，然后得到 Si 和 Ci，将 Ci 保存到进位位中，提供给下一次操作。如果两个操作数长 N，就要分为 N 次操作，每次一对 bit 进行运算，然后产生 1bit 的和，然后串行的逐位送回寄存器。</p>
<h2 id="3-3-并行加法器"><a href="#3-3-并行加法器" class="headerlink" title="3.3 并行加法器"></a>3.3 并行加法器</h2><p>其实就是将很多的 FA 串起来，但是后面的 FA 依旧需要等待前面的 FA 提供进位数 Ci-1 才能工作，他们仅仅是可以并行的接收操作数 Ai 和 Bi。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703170740.png" alt="image.png"></p>
<p>所以这玩意业绩爱哦串行进位的并行加法器。</p>
<h2 id="3-4-并行进位加法器"><a href="#3-4-并行进位加法器" class="headerlink" title="3.4 并行进位加法器"></a>3.4 并行进位加法器</h2><p>这章并不是很重要，不是重点，听听就行了。</p>
<h2 id="3-5-补码加减运算器"><a href="#3-5-补码加减运算器" class="headerlink" title="3.5 补码加减运算器"></a>3.5 补码加减运算器</h2><h3 id="3-5-1-基本加法器"><a href="#3-5-1-基本加法器" class="headerlink" title="3.5.1 基本加法器"></a>3.5.1 基本加法器</h3><p>加法器里面实现 n bit 数加上 n bit 数，输出结果并输出进位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703214942.png" alt="image.png"></p>
<p>比如 1000 + 0111，前面进位 Cin &#x3D; 1，则：F &#x3D; 0000，Cout 因为进位 &#x3D; 1。最终 Cout 可能被丢弃，只保留 F 。</p>
<p>如果是 8 bit + 8 bit，就可以两个加法器串起来，前面计算4bit，然后将进位信息给第二个加法器，第二个加法器算后面 4bit，然后两个 F 拼接一下即可。</p>
<h3 id="3-5-2-补码加减法器"><a href="#3-5-2-补码加减法器" class="headerlink" title="3.5.2 补码加减法器"></a>3.5.2 补码加减法器</h3><p>这个就牛逼了，我们先回忆一下补码怎么运算：</p>
<ol>
<li>两个补码相加，直接带着符号位直接按位相加</li>
<li>两个补码相减，减数取反（所有位取反末位加一）然后相加</li>
</ol>
<p>然后在上面加法器的基础上，设计这个补码运算器：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703215910.png" alt="image.png"></p>
<p>解释一下这个多路选择器，如果发现是加法，多路选择器会收到0信号，打开右边那条路；发现是减法，接收到1信号，打开左边那条路。</p>
<p>比如，X &#x3D; 1000，Y &#x3D; 0111；两个数相加的话，MUX 走 0 路，0 路会将 Y 直接输送到加法器里面，不做任何处理，同时 MUX 会向 Cin 发送0，也就是末位不做任何处理。</p>
<p>如果是 X - Y 的话，MUX 走 1 路，1 路会经过一个非门，将 Y 所有位取反，然后发送到加法器。同时向 Cin 发送 1 信号，相当于给 Y 的末位+1 取反。</p>
<p>说一下，有符号数的运算，和无符号数的运算，底层都是用这一套电路完成的，但是这就出现了问题：</p>
<h3 id="3-5-3-运算问题"><a href="#3-5-3-运算问题" class="headerlink" title="3.5.3 运算问题"></a>3.5.3 运算问题</h3><p><strong>无符号数运算</strong></p>
<p>比如算一个无符号整数相加，X&#x3D;3，Y&#x3D;4，相加，那就是X和Y直接输入加法器（两个数都是整数，补码&#x3D;原码），Cin&#x3D;0，则最后得到<code>（0011 + 0100） = 0111 = 7D</code>。没毛病</p>
<p>但是如果是 X - Y，那么 X 正常输入，Y 要全部取反，Cin &#x3D; 1，则 <code>（0011 + 1011 + 1）= 1111 = 15D</code>。这可就不对了，归根到底就是因为无符号数压根不能表示负数。</p>
<p><strong>有符号数</strong></p>
<p>这个也是有问题的，X &#x3D; -8，Y &#x3D; 7。X补 &#x3D; 1000，Y补&#x3D;0111，如果是 X + Y，则按位相加，得到 1111 也就是 -1D（1111可是补码，记得转回来）。</p>
<p>但是 X - Y 问题就又有了，X补正常输入，Y补全部取反&#x3D;1000，Cin&#x3D;1，所以 <code>X-Y = (1000 + 1000 + 1) = 10001 = 1D</code>，造成这个的原因是符号位运算得2，进位然后抛弃了，结果剩下符号位&#x3D;0，这不就错了。</p>
<p>这是为啥呀，因为计算机不会管你是有符号数还是无符号数，反正就是经过这个电路一通算，但是针对不同的数，进位方式和判断溢出是不一样的。</p>
<h3 id="3-5-4-标志位生成"><a href="#3-5-4-标志位生成" class="headerlink" title="3.5.4 标志位生成"></a>3.5.4 标志位生成</h3><p>用四个标志位来判断计算是否发生了进位或者溢出。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703223606.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230703223322.png" alt="image.png"></p>
<p>四个东西大致说一说：</p>
<p><strong>OF</strong></p>
<p>OF 用来判断有符号数运算是否发生溢出，其实简单说就是看看符号位有没有发生溢出导致结果正负性错误。计算方法不说了，很好理解。</p>
<p><strong>SF</strong></p>
<p>用来表示运算结果的正负，为0表示正，为1表示负。计算方法是取最高位本位和，啥意思，就是上面的一位全加器记得吧，最高位 A + B + Cin 进完位以后留下的那个数，就是 SF。比如 1000 + 1000 &#x3D; 10000。SF 就是第一个0.</p>
<p><strong>ZF</strong></p>
<p>计算结果全0，就是0。</p>
<p><strong>CF</strong></p>
<p>无符号数加减判断是否发生溢出或者借位，溢出好理解，就是两个无符号数相加然后位数不够了；借位就是小数减大数结果为负，但是无符号数不能表示负数，这就发生了借位。判断方法就是最高位的 Cout 异或 Sub（加减控制信号）。</p>
<p>如果是加法，Sub &#x3D; 0，最高位 Cout &#x3D; 1，说明进位了，也就是溢出了。如果是减法，Sub &#x3D; 1，最高位按理说是的进位的（记住就行），但是 Cout 却为 0，就说明发生了借位。</p>
<h1 id="4-移位运算"><a href="#4-移位运算" class="headerlink" title="4. 移位运算"></a>4. 移位运算</h1><p>就是C语言的里面的左移右移<code>2 &lt;&lt; 1</code>。</p>
<h2 id="4-1-算数移位"><a href="#4-1-算数移位" class="headerlink" title="4.1 算数移位"></a>4.1 算数移位</h2><p>通过改变各个数码位和小数点的相对位置，从而改变各个数码位的位权。可用移位运算实现乘法、除法。</p>
<h3 id="4-1-1-原码的算数移位"><a href="#4-1-1-原码的算数移位" class="headerlink" title="4.1.1 原码的算数移位"></a>4.1.1 原码的算数移位</h3><p><strong>整数的移位</strong></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707090535.png" alt="image.png"></p>
<p>左移就是后面的所有数值位往前走一步，所以每一位的位权都会 x 2，所以左移一位 &#x3D; 原数 x 2^1。左移两位就是 x 2^2，左移三位就不一样了，左移三位的话第一个1会移出数值位发生溢出，所以直接舍弃第一个1，变成：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707090759.png" alt="image.png"></p>
<p>右移同理，右移一位所有位权 x 2^(-1)，则 原数 x 2^(-1)，两位同理，三位就不一样了，最右边的1会移出，同理直接舍弃即可。</p>
<p><strong>定点数的移位</strong></p>
<p>这个和上面的规律一模一样，不说了。</p>
<h3 id="4-1-2-补码的算数移位"><a href="#4-1-2-补码的算数移位" class="headerlink" title="4.1.2 补码的算数移位"></a>4.1.2 补码的算数移位</h3><p>这个课就有点恶心了。如果是正数的话，原反补三码合一，和原码的移位规则一毛一样，不解释。负数就不一样了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707091045.png" alt="image.png"></p>
<p>先说反码的移位，反码里面 1 对应原码的 0，所以发生移位时，原码需要补0，反码就需要补1。</p>
<p>反码是原码整个取反，补码是反码末位+1，那么补码有个规律，从右往左数第一个1的右边，和原码保持一致，左边和反码保持一致：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">原码：1，0010 100</span><br><span class="line">反码：1，1101 011</span><br><span class="line">补码：1，1101 100（这三个和原码一样，前面四位和反码一样）</span><br></pre></td></tr></table></figure>
<p>所以，如果补码往右移，则前面的反码部分会有空缺，则补1，如果是往左移，最右边的原码部分会有空缺，则补0：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">补码：1，1101 100</span><br><span class="line"></span><br><span class="line">右移1位：1，11101 10 （前面补1）</span><br><span class="line">左移1位：1，101 1000 （后面补0）</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-总结"><a href="#4-1-3-总结" class="headerlink" title="4.1.3 总结"></a>4.1.3 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707091753.png" alt="image.png"></p>
<p>计算机如何实现 -20 x 7？可以把 7 理解成 2^0 + 2^1 + 2^2，也就是 -20 乘这仨，计算机就会给-20 分别左移1位，左移两位，然后三个数相加即可。</p>
<h2 id="4-2-逻辑移位"><a href="#4-2-逻辑移位" class="headerlink" title="4.2 逻辑移位"></a>4.2 逻辑移位</h2><p>可以看作是无符号数的一种算数移位，有符号数移位的时候符号不会跟着移，这个其实就是没有符号位，所有二进制位一块参与移动然后按规则舍弃补0.</p>
<p>应用场景：比如 RGB 颜色，计算机可以将三个 RGB 整合成一个 int，咋办？三个 3Byte 的空间，R 的值左移16位，跑到最高位，G 的值用另一个 3Byte，左移8位，B 的值用另一个 3Byte，不动。然后三个数相加。</p>
<h2 id="4-3-循环移位"><a href="#4-3-循环移位" class="headerlink" title="4.3 循环移位"></a>4.3 循环移位</h2><p>这个很简单，就是说左移，左边溢出的那一位，补到最后面空的那一位上，这个可以用在进位中，也就是前面说过的 CF：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707092741.png" alt="image.png"></p>
<h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707092807.png" alt="image.png"></p>
<h1 id="5-定点数乘法"><a href="#5-定点数乘法" class="headerlink" title="5. 定点数乘法"></a>5. 定点数乘法</h1><h2 id="5-1-原码一位乘法"><a href="#5-1-原码一位乘法" class="headerlink" title="5.1 原码一位乘法"></a>5.1 原码一位乘法</h2><p>这个东西相当恶心，假设我们要算 [x]原 &#x3D; 1.1101，[x]原 &#x3D; 0.1011，计算两个数相乘。符号倒是十分好确定，只需要两个数的符号位异或即可得到。所以我们就要计算 [x绝对值]原 &#x3D; 0.1101 和 [x绝对值]原 &#x3D; 0.1011 两个数的积。</p>
<h3 id="5-1-1-机器运算"><a href="#5-1-1-机器运算" class="headerlink" title="5.1.1 机器运算"></a>5.1.1 机器运算</h3><p>先回忆一下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230702092105.png" alt="image.png"></p>
<p>计算 0.1101 x 0.1011，根据寄存器功能，我们把两个数放在X和MQ中：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707094805.png" alt="image.png"></p>
<p>第一步，就是计算 0.1101 x 0.0001。具体实现就是，看 MQ 的乘法低位（深色的那个）是1，就直接将 X 中的值加到 ACC 中即可，小数点先不管。这时 MQ 中的乘法低位1已经用完了，所以<font color='red'>将 ACC 和 MQ 整体右移，舍弃 MQ 的低位</font>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707095223.png" alt="image.png"></p>
<p>这么做的目的是，保存乘积最低位的1，也就是从 ACC 右移到 MQ 中的那个红色的1，同时方便下一次错位相加，也就是左边红框里面的加法。然后循环上面的步骤，现在 MQ 中的低位就是 0.1011 的下一个1，同理是将 X 直接加到 ACC 中，这就实现了红框里面的错位相加，然后同理将 ACC 和 MQ 右移，保存乘积的低位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707095524.png" alt="image.png"></p>
<p>这时，MQ 中的低位是0，则 ACC 直接加0，其实就是不动，但是 ACC 和 MQ 还是需要右移一位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707095626.png" alt="image.png"></p>
<p>发现 MQ 低位是1，同理 X 加到 ACC 上，得到：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707095713.png" alt="image.png"></p>
<p>最后 MQ 里面保留的0其实就是符号位，不用管，乘积小数点在0后面，所以得到结果 0.10001111. 最后将符号加上，两个数的符号位异或，得到结果：1.10001111。</p>
<h3 id="5-1-2-题目"><a href="#5-1-2-题目" class="headerlink" title="5.1.2 题目"></a>5.1.2 题目</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707095855.png" alt="image.png"></p>
<p>可以看到和上面几乎一样，中间虚线的位置表示的就是右移舍弃 MQ 并保留 ACC 的部分积，然后左边就是在模拟 ACC 和 X 的相加。</p>
<p>注意这里的符号位用的是双符号位，其实原码乘法不用双符号位，补码采用的，这里是为了统一补码。</p>
<p>如果是整数相乘的话唯一的区别就是小数点位置，小数点位置会在 MQ 的符号位前面。</p>
<h2 id="5-2-补码一位乘法"><a href="#5-2-补码一位乘法" class="headerlink" title="5.2 补码一位乘法"></a>5.2 补码一位乘法</h2><p>原码乘法和补码乘法的区别：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707163757.png" alt="image.png"></p>
<h3 id="5-2-1-乘法器结构"><a href="#5-2-1-乘法器结构" class="headerlink" title="5.2.1 乘法器结构"></a>5.2.1 乘法器结构</h3><p>这个和原码乘法器还有点区别，上面提到了 MQ 里面有一个辅助位，这个辅助位就在 MQ 的最低位后面，所以 MQ 就会多一位，CPU 里面大部分寄存器位数应该是一定的，所以 ACC 和 X 也都会加一位：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707164554.png" alt="image.png"></p>
<p>还有个区别：原码乘法里面，寄存器X和 MQ 存的都是原码的绝对值，这里是直接将补码存入 X 和 MQ，不取绝对值。ACC 和 X 都是双符号位，MQ 是单符号位。</p>
<h3 id="5-2-2-计算流程"><a href="#5-2-2-计算流程" class="headerlink" title="5.2.2 计算流程"></a>5.2.2 计算流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707164750.png" alt="image.png"></p>
<p>解释一下：</p>
<p>第一次，辅助位 - 最低位，就是那俩小下划线后面减前面得-1，根据上面的图，应该将 X 取负（也就是 [-x]补）加到 ACC 上，然后右移。这会导致最低位和辅助位同时更新。</p>
<p>第二次，辅助位 - 最低位 &#x3D; 0，则用 0 加到 ACC 上，然后右移。</p>
<p>第三次，辅助位 - 最低位 &#x3D; 1，按照规定，将 X 加到 ACC 上（就是给 ACC 加上 [x]原），然后右移。这里的右移注意：是补码的算数右移，就是说现在 x 的补码是一个负数，算数右移的话左边要补 1 而不是 0 （复习一下，负数补码右移左边补1，左移右边补0）。</p>
<p>第四次，略</p>
<p>最后一次，我们发现 MQ 的最低位变成了 MQ 最开始的符号位 0，原码的话就到此为止了，符号位不参与运算，但是这里符号位同样要运算，这也就是为啥说进行完 n 轮加和之后还要进行一次。最后带着符号位运算一次。但是这次运算完不再右移，ACC 和 MQ 共同构成结果（不包含最低位和辅助位）。</p>
<h1 id="6-定点数除法"><a href="#6-定点数除法" class="headerlink" title="6. 定点数除法"></a>6. 定点数除法</h1><p>这个是定点小数除法，所以规定被除数一定得比除数小，这样商才能是小于1的，如果最后商大于1，定点小数不能表示大于1的部分，就出错了。</p>
<h2 id="6-1-原码除法运算"><a href="#6-1-原码除法运算" class="headerlink" title="6.1 原码除法运算"></a>6.1 原码除法运算</h2><p>两种方法。如何检测最后的商是否大于1 ？用的就是第一次的商，如果是1的话就会停止。</p>
<h3 id="6-1-1-恢复余数法"><a href="#6-1-1-恢复余数法" class="headerlink" title="6.1.1 恢复余数法"></a>6.1.1 恢复余数法</h3><p>机器字长 &#x3D; 5，包括一位符号位，数值位 n &#x3D; 4，x &#x3D; 0.1011，y &#x3D; 0.1101，计算 x &#x2F; y；切记切记，计算除法的时候，符号位通过两个数的符号位异或确定，所以<font color='red'>计算时取的是 x 和 y 的绝对值</font>。</p>
<p>先写出：|x| &#x3D; 0.1011;  |y|&#x3D;0.1101;  [|y|]补 &#x3D; 0.1101; [-|y|]补 &#x3D; 1.0011;</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707225350.png" alt="image.png"></p>
<p>又把 CPU 搬出来了，这回 X 寄存器里面放的是除数也就是 |y|，切记放的是绝对值，ACC 寄存器里面放的是 |x|，MQ 里面放的是商。</p>
<p>计算步骤：</p>
<p>第一步，确定第一位商，CPU 可不会口算，他只会试，假设第一位商 &#x3D; 1，则：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">            1</span><br><span class="line">      |-----------</span><br><span class="line">01101 / 01011</span><br><span class="line">        01101</span><br></pre></td></tr></table></figure>
<p>他就会出现这种情况，然后两个数相减，也就是被除数减除数（x - y），怎么实现减法？此时 ACC 和 X 寄存器里面的数都是绝对值，所以当作无符号数来算，x - y &#x3D; [x]补 + （[-|y|]补），然后一算得到 11110：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707230028.png" alt="image.png"></p>
<p>然后发现 11110 是个负数，说明 ACC 里面的被除数小于 X 里面的除数，商 1 是错的，咋办？把商改回0，然后 ACC 加一个 y 的补码恢复到之前状态。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707230259.png" alt="image.png"></p>
<p>然后将 ACC 和 MQ 整体左移，舍弃ACC最高位，然后 MQ 最后面补 0:</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707230429.png" alt="image.png"></p>
<p>然后重复上面的操作，假设MQ的最低位商1，然后 ACC - X 判断是否大于0，然后发现结果确实是正数，所以商 1 是对的，保留 ACC 里面的数：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707230644.png" alt="image.png"></p>
<p>然后左移，重复上面的操作。直到最后商把 MQ 填满：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707230835.png" alt="image.png"></p>
<p>如果最后商 1 发现不行的话，记得把商还改回 0 。</p>
<p>手算的话：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707231018.png" alt="image.png"></p>
<p>计算步骤就是，啥都甭管一上来就减，如果发现差为负数，那就商 0，然后给它加回去，左移。然后再减。商是每次减完以后确定的。</p>
<h3 id="6-1-2-加减交错法"><a href="#6-1-2-加减交错法" class="headerlink" title="6.1.2 加减交错法"></a>6.1.2 加减交错法</h3><p>就是在上面的基础上优化，前面的先减后加太麻烦了，能不能减完以后即便发现不对，也不往回加了，直接在 ACC 的基础上操作：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707231326.png" alt="image.png"></p>
<p>如果 ACC 减去 X 发现得负数，直接让商 &#x3D; 0，然后直接算 2a + b 去求下一位商，如果 2a + b 是正的，则 商 &#x3D; 1，ACC 更新为 2a + b；如果是负的，那就重复上面的操作。</p>
<p>具体操作就是让减完以后负的 ACC 直接左移一位，然后加上 X：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707231858.png" alt="image.png"></p>
<p>别忘了符号位，和之前一样异或。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707231932.png" alt="image.png"></p>
<h2 id="6-2-补码除法运算-加减交替法"><a href="#6-2-补码除法运算-加减交替法" class="headerlink" title="6.2 补码除法运算-加减交替法"></a>6.2 补码除法运算-加减交替法</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707232957.png" alt="image.png"></p>
<p>大致说一句啊，第一步是用 y补 和 x补 来判断是 x + y 还是 x - y，这里显然是 x + y，因为俩人异号。相加完以后得到余数，然后余数再和除数 y补 比较，发现同号，然后商1，左移 然后减去 y补。商 0 的话又是另一回事了。</p>
<p>然后在最后一步，商的末位恒置为 1，最后的结果就是 10101，余数是 0.0111（余数记得可是双符号位的，MQ 是单符号位）。</p>
<h1 id="7-C语言数据类型转换"><a href="#7-C语言数据类型转换" class="headerlink" title="7. C语言数据类型转换"></a>7. C语言数据类型转换</h1><p>直接看图吧，没啥好说的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230707234130.png" alt="image.png"></p>
<h1 id="8-数据的存储与排列"><a href="#8-数据的存储与排列" class="headerlink" title="8. 数据的存储与排列"></a>8. 数据的存储与排列</h1><h2 id="8-1-大小端模式"><a href="#8-1-大小端模式" class="headerlink" title="8.1 大小端模式"></a>8.1 大小端模式</h2><p>其实很简单，就是一个 int 在内存中如何排列的，比如一个 4 字节的 int：<code>0x 01 23 45 67</code>；转化为二进制就是 <code>0000 0001 0010 0011 0100 0101 0110 0111 B</code>，这个二进制如何在内存中存储。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708105906.png" alt="image.png"></p>
<p>解释一下为啥小端方式更适合处理：计算机读取肯定是从低地址读到高地址部分，比如 CPU 加法的时候，先读取低地址部分，然后相加，然后再读取高地址部分加和，这样更方便。</p>
<h2 id="8-2-边界对齐"><a href="#8-2-边界对齐" class="headerlink" title="8.2 边界对齐"></a>8.2 边界对齐</h2><p>现代计算机通常是用字节编址，一个字节会对应一个地址。同时也支持按字、半字、按字节寻址。假设存储字长为 32 bit，那么一个字就是 32 bit，半字就是 16 bit。每次访存只能读写一个字。</p>
<p>所谓边界对齐，就是说在内存的小端，字节，半字，字必须对齐：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708110735.png" alt="image.png"></p>
<p>第二行是两个半字，那么第一行哪怕没填满也没关系。</p>
<p>如何寻址？</p>
<p>比如我现在要找到 3号字节，那就往后找就行了，没别的。如果我们要找到 2号半字，则 字节1 和 字节2 构成半字0，字节3 和填充位构成半字1，以此类推，最终找到了半字2。</p>
<p>按字寻址的话，我们要找3号字，那第一行就是字0，第二行字1，第三行字2，最终找到了第四行也就是图里面的 字1。</p>
<p>给出了字号或者半字号，如何找到起始字节地址？字的话是给字号左移两位，半字的话就是左移一位。</p>
<p>边界对齐的好处？</p>
<p>比如我们使用 C 语言定义了一个结构体，三个 char，三个 short，一个 int，就会按照图里面的方式存储，存储到第一个 short 的时候，即使第一个字最后的一个字节还有空余，也不会存储 short，而是直接换行将 short 存到一个半字里面。</p>
<p>这样的好处就是如果我们读取一个 short ，只需要一次访存即可。但是如果我们用边界不对齐的方式：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708111523.png" alt="image.png"></p>
<p>读取一个半字就可能需要读取两次内存，第一次读取半字1-1，第二次读取半字1-2。为啥？因为每次访存只能访问一个字，也就是一行。</p>
<h1 id="9-浮点数"><a href="#9-浮点数" class="headerlink" title="9. 浮点数"></a>9. 浮点数</h1><h2 id="9-1-浮点数表示"><a href="#9-1-浮点数表示" class="headerlink" title="9.1 浮点数表示"></a>9.1 浮点数表示</h2><h3 id="9-1-1-浮点数表示"><a href="#9-1-1-浮点数表示" class="headerlink" title="9.1.1 浮点数表示"></a>9.1.1 浮点数表示</h3><p>定点数不能表示太大的数，范围有限，如何让计算机在有限的字节内存储更大的数据就是浮点数的作用。</p>
<p>定点数的意思就是说小数点固定，要么在符号位后面，要么隐藏在最后面；浮点数的意思就小数点可以浮动。原理就是科学计数法。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708112646.png" alt="image.png"></p>
<p>因为计算机是二进制，所以阶码的底通常是2，也有可能是 4 8 这种的；如果是10进制，3.24 * 10^4，意思就是 3.24 的小数点右移4位，或者说3.24 的数值位左移4位。二进制同理，N 就代表 M 的数值位左移 E 位（前提阶符是正的）。</p>
<p>同时，根据阶码和尾数的bit数，可以确定出两个数的范围。</p>
<h3 id="9-1-2-浮点数尾数规格化"><a href="#9-1-2-浮点数尾数规格化" class="headerlink" title="9.1.2 浮点数尾数规格化"></a>9.1.2 浮点数尾数规格化</h3><p>比如现在有个浮点数 <code>0,10;0.01001</code>，这个数有 9 bit，超过了 8bit，会导致最后一位 1 丢失导致精度损失，咋办？</p>
<p>我们发现，这个浮点数的尾数部分的第一位是0，无意义，我们可以将尾数左移一位，那么相应的阶码就该-1，变成 <code>0,01</code>，最后结果不变。</p>
<p>上面这种方法就叫<strong>左规</strong>。</p>
<p>还有一种右规，就是将尾数右移保证最高位有效。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708114555.png" alt="image.png"></p>
<p>比如这个，用双符号位计算，最后发现发生了溢出导致尾数最高位为0，这时就右规一下。</p>
<h3 id="9-1-3-规格化浮点数的特点"><a href="#9-1-3-规格化浮点数的特点" class="headerlink" title="9.1.3 规格化浮点数的特点"></a>9.1.3 规格化浮点数的特点</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708120520.png" alt="image.png"></p>
<p>这里特别强调：如果尾数是负数而且用补码表示，则规定尾数的最高位必须是0，这会导致规格化不同，比如将 <code>0.110;1.1110100</code> 规格化，后面的尾数就不能右规，因为负数补码右移高位要补1，不符合高位&#x3D;0的要求，所以要将尾数左规三位变成 <code>1.0100000</code>，然后阶码对应的-3，变成 <code>0.011;1.0100000</code></p>
<h3 id="9-1-4-总结"><a href="#9-1-4-总结" class="headerlink" title="9.1.4 总结"></a>9.1.4 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708120949.png" alt="image.png"></p>
<h2 id="9-2-IEEE-754"><a href="#9-2-IEEE-754" class="headerlink" title="9.2 IEEE 754"></a>9.2 IEEE 754</h2><h3 id="9-2-1-再说移码"><a href="#9-2-1-再说移码" class="headerlink" title="9.2.1 再说移码"></a>9.2.1 再说移码</h3><p>之前说移码就是在补码的基础上将符号位取反得到，这个定义不准确，移码的定义：移码&#x3D;真值+偏置值。8 bit 数如果将偏置值设置为 <code>2^(n - 1)</code> 也就是 128，就可以达到 移码 &#x3D; 补码符号位取反的效果。</p>
<p>如果我们将偏置值设置为 127 也就是 <code>2^(n-1) - 1</code>，移码就会变成这样：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708160556.png" alt="image.png"></p>
<p>原码的 -127 到 127 就对应了移码的 0 到 254。移码全 1 和 全 0 是两个特殊状态。</p>
<h3 id="9-2-2-IEEE-754-标准"><a href="#9-2-2-IEEE-754-标准" class="headerlink" title="9.2.2 IEEE 754 标准"></a>9.2.2 IEEE 754 标准</h3><p>就是一套计算机处理浮点数的标准，有了这个标准，不同的计算机就可以用浮点数交换数据。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708161539.png" alt="image.png"></p>
<p>区别：</p>
<ul>
<li>没有阶符了，数符提到了最前面</li>
<li>阶码用移码表示</li>
<li>这里千万注意了，前面的普通浮点数 <code>1,011;0.101</code>，尾数部分仅仅是最后面的 101，至于 0. 那可是符号位，也就是数符。IEEE 这个不一样，数符在最前面，所以后面所说的隐藏的 1. ，这个 1. 是真的数值上的 1. ，而不是说负的M。</li>
</ul>
<p>比如这个：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708162056.png" alt="image.png"></p>
<p>我们在转化的时候，前面的阶码要减去偏移量才行，这里 float 的偏移量是 127，可以把阶码转化为十进制，然后用十进制减去 127。</p>
<p>十进制转浮点数：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708162354.png" alt="image.png"></p>
<p>浮点数转十进制：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708162515.png" alt="image.png"></p>
<h3 id="9-2-3-浮点数最值"><a href="#9-2-3-浮点数最值" class="headerlink" title="9.2.3 浮点数最值"></a>9.2.3 浮点数最值</h3><p>普通最值：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708162806.png" alt="image.png"></p>
<p>注：阶码真值 -126，是因为 -127 和 -128 的移码分别是 00000000 和 11111111，这两个数比较特殊，有其他用途。</p>
<p>如果要表示比最小绝对值还要小的数，也是有可能的，就需要使用阶码全0 和 全1 的两种特殊状态。</p>
<p>当阶码E全为0，尾数M不全为0时，表示非规格化小数，表示 <code>+- (0.xxxb)x2^(-126)</code>。这时强制规定尾数M最高位隐含0而不是1。</p>
<p>当阶码E全为0，尾数M全为0，则表示真值 <code>+-0</code>。</p>
<p>当阶码E全为1，尾数M全为0时，表示无穷大 <code>+-∞</code>。</p>
<p>当阶码E全为1，尾数M不全为0时，表示非数值 <code>NaN</code>。比如 0&#x2F;0、∞-∞ 等非法运算就会得出这个。</p>
<h3 id="9-2-4-总结"><a href="#9-2-4-总结" class="headerlink" title="9.2.4 总结"></a>9.2.4 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708163540.png" alt="image.png"></p>
<h2 id="9-3-浮点数运算"><a href="#9-3-浮点数运算" class="headerlink" title="9.3 浮点数运算"></a>9.3 浮点数运算</h2><p>这个如果没有特别说，就不是 IEEE 754 了，毕竟 IEEE 最短都是 32 bit，多麻烦。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708164802.png" alt="image.png"></p>
<p>计算结果不需要舍入：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708194525.png" alt="image.png"></p>
<p>首先，X 和 Y 的二进制表示都是补码形式。然后第二步尾数相减也就是加上 Y 的补码的负数，最后得到 10.110001000，发现符号位变成了 10，说明前面的计算结果发生了溢出。规格化的时候，将其右移，然后前面符号位要补1，因为之前符号位最高位是1，说明是个负数，所以符号位补1。</p>
<p>有舍入的情况：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708195102.png" alt="image.png"></p>
<h2 id="9-4-浮点数强制类型转换"><a href="#9-4-浮点数强制类型转换" class="headerlink" title="9.4 浮点数强制类型转换"></a>9.4 浮点数强制类型转换</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708195245.png" alt="image.png"></p>
<p>说一下为啥 32bit 情况下 long 或者 float 转 double 都不会精度丢失。因为 double 的尾数部分有 53bit，而 long 只有 32bit，所以不会丢失，同理 float。</p>
<p>而 int 转 float 就会精度丢失，因为 int 有 32bit，抛去一个符号位还剩 31 bit。float 尾数部分有 23 位，加上隐藏的 1. 就有 24 bit，float 放不下 int。但是数据不会溢出，float 表示的范围要比 int 大。</p>
<p>但是 float 转 int 就不行了，溢出是没跑了，如果 float 是个小数 0.0001，转为 int 就会转成 0，会损失精度。</p>
<h2 id="9-5-总结"><a href="#9-5-总结" class="headerlink" title="9.5 总结"></a>9.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230708195734.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>06-Cache缓存</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-06-Cache%E7%BC%93%E5%AD%98/</url>
    <content><![CDATA[<p>经过什么双端口 RAM、多模块存储器提升存储器工作效率，速度仍然和 CPU 差距较大。为了解决问题，就设计了一种更告诉的存储单元，这种玩意价格更高，容量很小，但是十分的块。这个就是 Cache。</p>
<span id="more"></span>

<h1 id="1-Cache-基本概念"><a href="#1-Cache-基本概念" class="headerlink" title="1. Cache 基本概念"></a>1. Cache 基本概念</h1><h2 id="1-1-Cache-工作原理"><a href="#1-1-Cache-工作原理" class="headerlink" title="1.1 Cache 工作原理"></a>1.1 Cache 工作原理</h2><p>根据局部性原理，比如我们要进行微信视频聊天，这期间处理视频聊天的指令需要被频繁执行，放在内存中就浪费了。就可以将这部分指令复制到 CPU 的 Cache 种，让 CPU 更高效的获得指令，速度矛盾被缓和。</p>
<p>一般来说，Cache 集成在 CPU 内部，用 SRAM（静态RAM，双稳态触发器实现的那个）实现，速度快，成本高。</p>
<h2 id="1-2-局部性原理"><a href="#1-2-局部性原理" class="headerlink" title="1.2 局部性原理"></a>1.2 局部性原理</h2><p>这个好像 OS 也说过，两个：</p>
<ul>
<li>空间局部性：未来要访问的信息很可能就在附近，比如顺序访问数组</li>
<li>时间局部性：未来要用到的信息很可能现在也在用，比如循环结构</li>
</ul>
<p>这里看一个小例子：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712165221.png" alt="image.png"></p>
<p>这个程序中访问数组是竖着访问的，而不是横着访问。二维数组在内存中会被按行铺开，一维存储，这里按列访问数组就相当于在内存中跳着访问，破坏了空间局部性，所以这种会更慢。</p>
<h2 id="1-3-性能分析"><a href="#1-3-性能分析" class="headerlink" title="1.3 性能分析"></a>1.3 性能分析</h2><p>就是算CPU执行一次操作的平均时间：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712170350.png" alt="image.png"></p>
<h2 id="1-4-主存调入内存"><a href="#1-4-主存调入内存" class="headerlink" title="1.4 主存调入内存"></a>1.4 主存调入内存</h2><p>根据局部性原理，可以将 CPU 目前访问地址的”周围“部分数据存放到 Cache中，如何界定这个 周围？</p>
<p>这个就用到我们之前 OS 学的东西，内存块，相邻的几个数组元素肯定是存在一个内存块中，只需要将内存块调入 Cache 即可。所以 <font color='red'> Cache 和主存之间以 “块” 为单位进行数据交换</font>。</p>
<p>如果主存 4M，每个块 1KB，则总共有 2^12 个块，然后每个块内有 2^10 个地址，内存编址就可以设计成：<code>（块号 12 bit + 块内地址 10 bit）</code>。</p>
<p>有的时候 Cache 的块也会叫 行。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712214844.png" alt="image.png"></p>
<p>现在还有三个问题：</p>
<ul>
<li>内存中的数据会被放到 Cache 的不同位置，如何区分 Cache 与 主存 的数据块对应关系</li>
<li>Cache 很小，如果 Cache 满了咋办？</li>
<li>CPU 修改了 Cache 中的数据副本，如何确保主存中数据母本的一致性？</li>
</ul>
<p>这三个问题在后面会依次学习：Cache和主存映射方式、替换策略、Cache 写策略。</p>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712215221.png" alt="image.png"></p>
<h1 id="2-主存与Cache映射方式"><a href="#2-主存与Cache映射方式" class="headerlink" title="2. 主存与Cache映射方式"></a>2. 主存与Cache映射方式</h1><p>总共三种策略：</p>
<ul>
<li>全相连映：主存块可以放在 Cache 任意位置</li>
<li>直接映射：每个主存块只能放到一个特定的Cache位置，可以通过取余来确定</li>
<li>组相联映射：将 Cache 分成块数相同的几个组，每个主存块可以放到特定组的任意位置，同样可以取余来确定组号</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712215711.png" alt="image.png"></p>
<p>然后展开说说：</p>
<h2 id="2-1-全相联映射"><a href="#2-1-全相联映射" class="headerlink" title="2.1 全相联映射"></a>2.1 全相联映射</h2><p>如何知道 Cache 里面的每一块映射的是哪一块主存？可以给每一块 Cache 添加一个标记，用于标记这个块映射了主存的哪个块，相当于一个字典。还需要一个给每一个Cache 块添加一个有效位，表示该块确实是映射了某一个主存。</p>
<p>比如 Cache 现在映射了 9 8 5 三个地址，则三个 Cache 块的标记为 9 8 5，那剩下的 Cache 块的标记不能为空，则设置为 0，这就出问题了，0 代表这个 Cache 块没有映射，还是映射了主存的 0 地址？这就是有效位的作用。</p>
<p>来看一个例子：</p>
<p>主存地址空间位 256M（2^28）,按字节编址，其数据 Cache 有8个Cache块，每个块 64 Byte。</p>
<p>按照之前说的，Cache 块的大小要和主存块一致，所以主存块位 64Byte也就是 2^6，可以算出主存划分为 2^22 个块，每个块 2^6 大小。</p>
<p>所以给主存编址为 <code>22bit块号 + 6bit块内地址</code>，假设某一块存入了Cache，访存流程如下：</p>
<ul>
<li>根据前22位地址，去 Cache 里面找标记，如果有这个标记且有效位为1，说明 Cache 命中</li>
<li>然后直接拿着后 6 位块内地址去 Cache 内访问即可。</li>
<li>如果没命中就去访问内存</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712220919.png" alt="image.png"></p>
<p>对了，图里面显示， Cache 块会有 22 bit 的标记，也就是每个 Cache 块会记录自己映射了哪个内存块。</p>
<h2 id="2-2-直接映射"><a href="#2-2-直接映射" class="headerlink" title="2.2 直接映射"></a>2.2 直接映射</h2><p>还是上面的例子，将 0 号块的数据存放到 Cache，mod 上 Cache 的块数8得到0，说明 0 号块只能放到 Cache 的0号块上。往后运行要把 8 号主存块存放到 Cache 上，发现也是只能放到 0 号块，则会把 0 号块的内容覆盖。</p>
<p>这就导致 Cache 仍旧需要一个 标记 和 有效位，起码看看当前 Cache 块里面存的还是不是被访问主存里的数据，别已经被替换了。</p>
<p>看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712221742.png" alt="image.png"></p>
<p>这里说一下为啥根据块地址的后三位来确定 Cache 行，因为我们确定主存块到Cache块的方式是给块号 mod 3，也就是 mod 2^3，看二进制的话就会发现这个操作其实就是取块号的最后三位。所以说这个 28 位的主存地址就被看做了：<code>19bit标记 + 3bitCache行号 + 6bit块内地址</code>。同理 Cache 的标记位也被优化成了 19 bit。</p>
<h2 id="2-3-组相联映射"><a href="#2-3-组相联映射" class="headerlink" title="2.3 组相联映射"></a>2.3 组相联映射</h2><p>就是上面两种方式的结合，8块的 Cache 要分成 4 组，还是按照上面的方法，可以通过块号的最后两位确定映射到Cache 的块号，所以 Cache 的标记就是 20 位。然后将一个内存块放到组内的任意位置，打上标记，这样的话组内顺序查找会快一点。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712223701.png" alt="image.png"></p>
<p>其中第二步就是在块内进行顺序查找。</p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712223809.png" alt="image.png"></p>
<h1 id="3-Cache-替换算法"><a href="#3-Cache-替换算法" class="headerlink" title="3. Cache 替换算法"></a>3. Cache 替换算法</h1><p>对于上面的三种映射方式会有不同的替换策略</p>
<ul>
<li>采用全相联映射方式，只有 Cache 满了才需要考虑替换出哪一块数据</li>
<li>直接映射方式，不需要考虑替换，或者说替换非常简单，直接根据取模的结果覆盖即可</li>
<li>组相联映射方式，分组内满了需要考虑替换</li>
</ul>
<p>所谓替换算法，就是作用在 全相联 和 组相联 上。</p>
<p>总共有四种替换算法：随机算法、先进先出算法、近期使用最少、最近不经常使用。</p>
<p>和之前 OS 里面的虚拟内存页面置换算法挺像。</p>
<h2 id="3-1-随机算法-RAND"><a href="#3-1-随机算法-RAND" class="headerlink" title="3.1 随机算法 RAND"></a>3.1 随机算法 RAND</h2><p>若 Cache 满了，随机选择一块替换。</p>
<p>总共设置 4 个Cache块，初始 Cache 为空，采用全相联映射，一次访问 （1，2，3，4，1，2，5，1，2，3，4，5）这些主存：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712224523.png" alt="image.png"></p>
<p>包括这种图，和之前的页面置换也是几乎一模一样的。这种算法实现简单，但是完全不考虑局部性原理，实际效果很不稳定。</p>
<h2 id="3-2-先进先出算法-FIFO"><a href="#3-2-先进先出算法-FIFO" class="headerlink" title="3.2 先进先出算法 FIFO"></a>3.2 先进先出算法 FIFO</h2><p>这种也很简单，替换掉最先被调入的 Cache 块，确定顺序的方法也很简单：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712224740.png" alt="image.png"></p>
<p>是不和页面置换那个一模一样的套路，就是顺着替换。这种也没有考虑局部性原理，最先调入 Cache 的块也有可能被频繁访问。</p>
<p>这里就出现了 <strong>抖动现象</strong>，一个块刚被换出就被换入。</p>
<h2 id="3-3-最近最少使用算法-LRU"><a href="#3-3-最近最少使用算法-LRU" class="headerlink" title="3.3 最近最少使用算法 LRU"></a>3.3 最近最少使用算法 LRU</h2><p>为每个 Cache 块设置一个 “计数器”，用于记录每个 Cache 块已经多久没有被访问过了。当 Cache 满后替换“计数器”最大的。</p>
<p>这个做题有个方法，置换算法里面说过了，比如现在 Cache 中有 1 2 3 4 四个块，然后现在 5 要进来，替换哪个？就把 1 2 3 4 四个数顺着主存访问顺序开始往前数，最后出现的那个数，就是要替换出去的。具体去看置换算法的 LRU。</p>
<p>具体的做法是：</p>
<ul>
<li>访存命中时，命中的 Cache 块 counter 刷成 0，比其低的counter加1，其余不变。比如说 Cache#1 已经2次没被访问过了，然后访问了一次 Cache#1，则 Cache#1 的 counter 变成0，其他 counter &lt; 2 的全都 + 1。这个可以保证 4 个 Cache 块，每个 counter 不会 &gt; 3。</li>
<li>未命中且有空闲块时，新装入的块 counter 为0，其余都加1</li>
<li>要替换时，将 counter 最大的淘汰，装入新块，counter 为 0，其余都 + 1.</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712230032.png" alt="image.png"></p>
<p>有 2^n 个块，只需要 n 位就可以表示 counter。</p>
<p>这种算法基于“局部性原理”，LRU 实际运行效果优秀，Cache 命中率高。如果被频繁访问的主存块数量 &gt; Cache 行的数量，则可能发生抖动。</p>
<h2 id="3-4-最不经常使用算法-LFU"><a href="#3-4-最不经常使用算法-LFU" class="headerlink" title="3.4 最不经常使用算法 LFU"></a>3.4 最不经常使用算法 LFU</h2><p>类似，给每个 Cache 块设置一个 “计数器”，用于几楼每个 Cache 被访问的次数。当 Cache 满了以后替换 “计数器” 最小的。如果 counter 最小的有多个，可以 FIFO，也可以根据行号大小，优先淘汰行号小的。</p>
<p>流程：简单，新块 counter 为 0，以后每被访问一次 counter 就 + 1 即可。然后替换 min counter。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712230805.png" alt="image.png"></p>
<p>counter 位数不固定。</p>
<p>这种算法其实并不好，没有遵循时间局部性原理，比如我们进行视频聊天，处理视频聊天的代码一直被执行，所以 counter 一直累加，等到我们关闭视频聊天，Cache 肯定是不用了，但是因为 counter 已经非常大了，所以不容易被淘汰。所以这个算法效果不如 LRU。</p>
<h2 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712231009.png" alt="image.png"></p>
<h1 id="4-Cache-写策略"><a href="#4-Cache-写策略" class="headerlink" title="4. Cache 写策略"></a>4. Cache 写策略</h1><p>CPU 修改了 Cache 中的数据副本，如何保证 Cache 中的数据和主存中的一致。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712231150.png" alt="image.png"></p>
<p>CPU 读不需要考虑，压根不会导致不一致。</p>
<h2 id="4-1-写命中"><a href="#4-1-写命中" class="headerlink" title="4.1 写命中"></a>4.1 写命中</h2><p>CPU 要对某一个数据进行写操作，然后发现这个数据居然在 Cache 里面，CPU 就会修改 Cache 里的这个数据，所以如何让 Cache 和 主存 一致？</p>
<h3 id="4-1-1-写回法"><a href="#4-1-1-写回法" class="headerlink" title="4.1.1 写回法"></a>4.1.1 写回法</h3><p>Write-Back：当 CPU 对 Cache 写命中时，只修改 Cache 的内容，而不立即写入主存，只有当该块被换出时才写会主存。</p>
<p>换出时如何判断需要回写？给 Cache 的每个块添加一个 脏位，用于记录该块是否被修改，1 &#x3D; 被修改。换出时根据这个脏位来决定是否回写。</p>
<p>这种方法减少了访问次数，但是存在数据不一致的隐患。</p>
<h3 id="4-1-2-全写法"><a href="#4-1-2-全写法" class="headerlink" title="4.1.2 全写法"></a>4.1.2 全写法</h3><p>也叫 写直通法 Write-Through，当 CPU 对 Cache 写命中时，会直接根据地址找到主存，把数据也写回主存，相当于写了两遍，写了 Cache 和 主存。</p>
<p>这个过程肉眼看见的慢，所以提出了 写缓冲 write buffer。</p>
<p>会提供一个 SRAM 实现的 FIFO 队列充当写缓冲，CPU 执行写操作时，除了往 Cache 中写，还会将修改的数据往缓冲区写一份。然后 CPU 就可以干别的去了。会有一个专门的控制电路负责将修改的数据从队列中取出，逐一写回主存。</p>
<p>这种办法写的速度很快，如果操作不频繁，效果挺好。如果写操作频繁，可能会导致写缓冲饱和导致阻塞。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712232309.png" alt="image.png"></p>
<h2 id="4-2-写不命中"><a href="#4-2-写不命中" class="headerlink" title="4.2 写不命中"></a>4.2 写不命中</h2><p>CPU 要写一块地址，发现这个地址没在 Cache 中，不得已去访问内存，这就是写不命中。</p>
<h3 id="4-2-1-写分配法"><a href="#4-2-1-写分配法" class="headerlink" title="4.2.1 写分配法"></a>4.2.1 写分配法</h3><p>write-allocate，写不命中时，先把主存的块调入内存，在 Cache 中修改。<font color='red'>通常搭配写回法使用</font>。</p>
<h3 id="4-2-2-非写分配法"><a href="#4-2-2-非写分配法" class="headerlink" title="4.2.2 非写分配法"></a>4.2.2 非写分配法</h3><p>not-write-allocate，当 CPU 写不命中时，直接把数据写入主存，不调入 Cache，只有 读未命中时才会调入 Cache。</p>
<p>这种通常搭配 全写法使用。</p>
<h2 id="4-3-多级缓存"><a href="#4-3-多级缓存" class="headerlink" title="4.3 多级缓存"></a>4.3 多级缓存</h2><p>这个了解一下就行了。CPU 和 内存之间可能会有多个 Cache，各级 Cache 之间使用 “全写法 + 非写分配法”，Cache 和 主存之间，使用 “写回法 + 写分配法”</p>
<h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712233155.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>05-外存储器</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-05-%E5%A4%96%E5%AD%98%E5%82%A8%E5%99%A8/</url>
    <content><![CDATA[<p>这一章 OS 那里已经讲过大部分了，这里粗略一过.</p>
<span id="more"></span>

<h1 id="1-磁表面存储器"><a href="#1-磁表面存储器" class="headerlink" title="1. 磁表面存储器"></a>1. 磁表面存储器</h1><p>就是将某些磁性材料薄薄的涂在金属铝或者塑料表面作为载磁体来存储信息。磁盘存储器、磁带存储器和磁鼓存储器均属于磁表面存储器。</p>
<p>基本原理如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712160157.png" alt="image.png"></p>
<p>优点：</p>
<ul>
<li>存储容量大，位价格低</li>
<li>记录介质可以重复使用</li>
<li>记录信息可以长期保存而不丢失，甚至可以脱机存档</li>
<li>非破坏性读出，读出时不需要再生</li>
</ul>
<p>缺点：</p>
<ul>
<li>存取速度慢</li>
<li>机械结构复杂</li>
<li>对工作环境要求高</li>
</ul>
<p>这种存储器即可以作为输入设备，也可以作为输出设备。</p>
<h2 id="1-1-磁盘设备的组成"><a href="#1-1-磁盘设备的组成" class="headerlink" title="1.1 磁盘设备的组成"></a>1.1 磁盘设备的组成</h2><p>这块东西在 OS 最后一张学过了。</p>
<p><strong>存储区域</strong></p>
<p>就是三个部分：磁头、柱面、扇区：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712160651.png" alt="image.png"></p>
<p><strong>硬盘存储器</strong></p>
<p>为了让磁头可以动，然后盘片可以转，所以一个硬盘存储器还由 磁盘驱动器、磁盘控制器、盘片组成。</p>
<p>磁盘驱动器：核心部件是磁头组件和盘片组件，温彻斯特盘是一种可以动头固定盘片的硬盘存储器。</p>
<p>磁盘控制器：是硬盘存储器和主机的借口，驻留的标准有 IDE、SCSI、SATA 等。</p>
<h2 id="1-2-磁盘的性能指标"><a href="#1-2-磁盘的性能指标" class="headerlink" title="1.2 磁盘的性能指标"></a>1.2 磁盘的性能指标</h2><p><strong>1. 磁盘的容量</strong></p>
<p>一个磁盘所能存储的字节总数称为磁盘容量。磁盘容量有非格式化容量和格式化容量之分。非格式化容量就是这个磁盘物理上可以存储大小。格式化容量就是说磁盘有些部分会被用作特殊用途，比如顶替坏块等，排除这些部分的容量就是格式化容量。</p>
<p><strong>2. 记录密度</strong></p>
<p>指的是盘片上单位面积记录的二进制信息量，通常以 道密度、位密度、面密度表示。</p>
<ul>
<li>道密度：盘片半径方向上单位长度上的磁道数</li>
<li>位密度：磁道单位长度上能记录的二进制代码位数</li>
<li>面密度：位密度和道密度的乘积</li>
</ul>
<p>OS 里面说过，磁盘上每个扇区的容量都相等，所以说不同磁道的位密度都不一样，越往外越小。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712161720.png" alt="image.png"></p>
<p><strong>3. 平均存取时间</strong></p>
<p>这个在 OS 里面说的已经很详细了。有的时候需要加上磁盘控制器的延迟时间，这个时间在寻道移动磁头之前。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712162025.png" alt="image.png"></p>
<p><strong>4. 数据传输率</strong></p>
<p>磁盘存储器在单位时间内向主机传送数据的字节数，称为数据传输率。</p>
<p>假设磁盘转数 r转&#x2F;秒，每条磁道容量为 N 个字节，则传输率 &#x3D; Dr &#x3D; rN。</p>
<h2 id="1-3-磁盘地址"><a href="#1-3-磁盘地址" class="headerlink" title="1.3 磁盘地址"></a>1.3 磁盘地址</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712162431.png" alt="image.png"></p>
<h2 id="1-4-磁盘工作过程"><a href="#1-4-磁盘工作过程" class="headerlink" title="1.4 磁盘工作过程"></a>1.4 磁盘工作过程</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712162553.png" alt="image.png"></p>
<p>这里说到读写只能是一个 bit 一个 bit 的操作，是串行的，但是我们读的时候最终要把数据连成一串一起发给数据总线，这里就需要一个 <strong>串-并变换电路</strong>，将串行过来的bit整合成并行的数据。</p>
<h2 id="1-5-磁盘阵列"><a href="#1-5-磁盘阵列" class="headerlink" title="1.5 磁盘阵列"></a>1.5 磁盘阵列</h2><p>RAID 廉价冗余磁盘阵列，将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交叉存储、并行访问，具有更好的存储性能、可靠性、安全性。</p>
<p>RAID 总共有 6 种方案，RAID 0 - RAID 5，越往后他的冗余信息占比越少，可靠性和安全性也会更高。</p>
<p>这里介绍前三个：</p>
<h3 id="1-5-1-RAID-0-无冗余无校验"><a href="#1-5-1-RAID-0-无冗余无校验" class="headerlink" title="1.5.1 RAID 0 无冗余无校验"></a>1.5.1 RAID 0 无冗余无校验</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712163521.png" alt="image.png"></p>
<p>这个东西很像我们之前学的主存低位交叉编址，A1 A2 两块连续的数据存储在两块磁盘中，这样的话速度快，访问连续数据无需等待设备恢复。</p>
<p>这种方案没有冗余，所有空间都被用于存储数据，同样也不能校验，如果 A1 的数据发生了跳变，我们就没法知道没法恢复。</p>
<h3 id="1-5-2-镜像磁盘阵列"><a href="#1-5-2-镜像磁盘阵列" class="headerlink" title="1.5.2 镜像磁盘阵列"></a>1.5.2 镜像磁盘阵列</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712163712.png" alt="image.png"></p>
<p>这个很好理解，就是数据一模一样的备份了一份，这样的话可以校验，但是冗余很高。</p>
<h3 id="1-5-3-纠错海明码磁盘阵列"><a href="#1-5-3-纠错海明码磁盘阵列" class="headerlink" title="1.5.3 纠错海明码磁盘阵列"></a>1.5.3 纠错海明码磁盘阵列</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712163321.png" alt="image.png"></p>
<p>A1 - A4 是四个连续的 bit，这种方式将连续的比特存储到不同的磁盘上，然后后面的 3 块磁盘用于存储这4bit数据的海明校验码（3bit）。这3bit校验码可以纠一位的错。就是说如果 Disk 1 损坏了，也可以通过 Disk 4 - 6 的3为校验码恢复 Disk 1 存储的bit。</p>
<h2 id="1-6-总结"><a href="#1-6-总结" class="headerlink" title="1.6 总结"></a>1.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230712163955.png" alt="image.png"></p>
<h1 id="2-SSD-固态硬盘"><a href="#2-SSD-固态硬盘" class="headerlink" title="2. SSD 固态硬盘"></a>2. SSD 固态硬盘</h1><p>去看操作系统最后一章。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>07-存储器</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-07-%E5%AD%98%E5%82%A8%E5%99%A8/</url>
    <content><![CDATA[<p>这一章说的主要是内观管理，和 OS 的内存管理高度一致，详细的去看看 OS 那一章就行了.</p>
<span id="more"></span>

<h1 id="1-页式存储"><a href="#1-页式存储" class="headerlink" title="1. 页式存储"></a>1. 页式存储</h1><p>将一个进程在逻辑上分为若干个大小相等的页面，页面的大小和主存块大小相同。每个页面可以离散的放入不同的主存块中。</p>
<h2 id="1-1-逻辑地址"><a href="#1-1-逻辑地址" class="headerlink" title="1.1 逻辑地址"></a>1.1 逻辑地址</h2><p>一个程序假设 4KB，则2^12字节，所以我们得出这个程序放到内存里面得有 12 位地址。主存一个页是 1KB，就把程序分为 4 个页，一个页 1KB，页内需要 10 位地址，故地址结构为 <code>2bit 页号 + 10bit 页内地址</code>。</p>
<p>然后比如 CPU 要执行一条取数指令 <code>00001 001000001000</code> 前面的 00001 是取数，后面的就是具体的地址，但是这个地址是逻辑地址。如何根据逻辑地址找到真实的物理地址？</p>
<h2 id="1-2-页表"><a href="#1-2-页表" class="headerlink" title="1.2 页表"></a>1.2 页表</h2><p>页表里面记录了 逻辑页号 - 主存块号 的映射关系，CPU 执行指令时，通过页表将逻辑地址转为物理地址。</p>
<p>比如要访问 00 1000001001 这个地址，也就是 #0 页的一个地址，页表中记录了 #0 页对应的主存块是 2 号 也就是 00000010，所以两个一拼接，得到：<code>00000010 1000001001</code> 这个真实的物理地址。</p>
<h2 id="1-3-寻址流程"><a href="#1-3-寻址流程" class="headerlink" title="1.3 寻址流程"></a>1.3 寻址流程</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230713162124.png" alt="image.png"></p>
<p>注意两个点：</p>
<ul>
<li>页表里面的页表项大小是根据主存块的数量决定的，比如这里主存只有 4095 个块，需要 12 位来表示。</li>
<li>这里比 OS 要多的一步就是，找到逻辑地址对应的真实的物理地址后，会去 Cache 里面找一下</li>
</ul>
<h2 id="1-4-快表"><a href="#1-4-快表" class="headerlink" title="1.4 快表"></a>1.4 快表</h2><p>就是页表的一个缓存：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230713162749.png" alt="image.png"></p>
<ul>
<li>快表存储单位是一个表项，而不是像 Cache 那样一个块一个块存</li>
<li>快表是一种相联存储器，就是说可以不根据地址来访问，就像一个 Map 一样，可以根据键来访问值。</li>
<li>快表也会满，所以也需要考虑替换</li>
</ul>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230713163036.png" alt="image.png"></p>
<h1 id="2-虚拟内存"><a href="#2-虚拟内存" class="headerlink" title="2. 虚拟内存"></a>2. 虚拟内存</h1><p>OS 里面讲过了，这里再说一说。就是一个程序启动可能不需要全部的指令，只需要调入必须的几个页即可。所以进程启动时，可以将必须的几个页调入内存，剩下的先放在外存上，等到需要的时候再从外存拿即可。</p>
<p>同时，如果主存满了，可以将这个进程的部分页换出内存。</p>
<p>要实现这个功能需要在页表上进行修改，页表上需要记录一个逻辑页是否被调入了主存，调入到了哪个位置；如果没有调入，需要记录这个逻辑页在外存的位置。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714113556.png" alt="image.png"></p>
<p>这个页表和 OS 里面给出来的还真不太一样，这里添加了这么几个东西：</p>
<ul>
<li>有效位：学 OS 的时候说主存块号可以设为空；但是这里我们通过 主存块号 0 和 有效位 来判断是否调入内存，和 Cache 的有效位是一个道理。</li>
<li>访问位：用来记录这个页最近被访问了几次，用来进行页面替换</li>
<li>脏位：记录这个页在内存中是否发生了修改，看情况写回主存</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714113918.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>09-机器级代码</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-09-%E6%9C%BA%E5%99%A8%E7%BA%A7%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>这一章优点恶心了，主要就是学习汇编语言的一些基础知识，着重关注 x86 汇编语言。</p>
<span id="more"></span>

<p>先说一下啥叫机器级代码，一段C语言程序会被编译器编译成汇编，然后汇编器将其再转为机器语言。其中机器语言和汇编语言，都叫机器级代码。</p>
<p>考试要求：</p>
<ul>
<li>只关注 x86 汇编语言；除非特别说明</li>
<li>给出简单程序的C语言、汇编语言、机器语言表示。能结合 C 语言看懂汇编语言的关键语句，主要是常见指令、选择结构、循环结构、函数调用</li>
<li>汇编语言、机器语言一一对应，能结合汇编语言分析机器语言的指令格式、寻址方式</li>
<li>肯定不会让你写汇编。</li>
</ul>
<h1 id="1-x86-指令基础"><a href="#1-x86-指令基础" class="headerlink" title="1. x86 指令基础"></a>1. x86 指令基础</h1><h2 id="1-1-啥是-x86"><a href="#1-1-啥是-x86" class="headerlink" title="1.1 啥是 x86"></a>1.1 啥是 x86</h2><p>Intel 很早之前出了一款 CPU 叫 8086，这个 CPU 有一系列指令，往后的大部分 CPU 都兼容这个 8086 CPU 的指令，比如什么 80286，80386 这种玩意，都是 86 结尾。所以 8086 CPU 的指令集就是 x86 指令。</p>
<h2 id="1-2-指令格式"><a href="#1-2-指令格式" class="headerlink" title="1.2 指令格式"></a>1.2 指令格式</h2><p>这个之前说过很久了，指令分为操作码和地址码，操作码指明如何处理，地址码指明数据在哪。而数据存放的位置就是三个地方：寄存器、主存、指令立即数。</p>
<p>数据寻址这个东西，就是三个问题：</p>
<ul>
<li>如果数据在寄存器中，指令需要给出寄存器的名字，x86 CPU 里面有哪些寄存器？</li>
<li>如果数据在主存中，如何在指令中指明读写长度</li>
<li>如果数据是一个立即数，如何区分？</li>
</ul>
<p>我们以 mov 指令来举例：<code>mov 目的操作数d, 源操作数s</code>，指的就是将s复制到d所指的位置，可以有如下表达：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715120616.png" alt="image.png"></p>
<p>总结：</p>
<ul>
<li>指令中如果出现 e 开头的东西，就是寄存器</li>
<li>指令中出现一个数字，十进制或者十六进制，那就是立即数</li>
<li>指令中出现中括号，里面是一个十六进制，指的就是主存地址，而前面的 dword ptr 这类标识指的是要从这个主存里面读多少字节，这里就是读双字32bit长度。如果没有写数据长度，默认就是双字。</li>
</ul>
<p>这里的中括号和之前的小括号一个意思，就是根据中括号里面的值去访存取值。</p>
<h2 id="1-3-x86-寄存器"><a href="#1-3-x86-寄存器" class="headerlink" title="1.3 x86 寄存器"></a>1.3 x86 寄存器</h2><p>记住就好：x86 架构中，寄存器都是以 E 开头，指的是 Extend，大小都是 <font color='red'>32bit（两个字）</font>。总共有 8 个寄存器，分为三组：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715121726.png" alt="image.png"></p>
<p>其中 ESI 和 EDI 俩不是很重要，知道是寄存器就行了，EBP 和 ESP 俩就很重要了。EBP 指向的是栈底。</p>
<p>对于上面的四个通用寄存器，大小32bit，但是我们可以灵活的使用，可以只使用低16位，但是寄存器名字得变，去掉字母 E 即可，比如 <code>EAX -&gt; AX, EBX -&gt; BX</code>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715121847.png" alt="image.png"></p>
<p>甚至，我们可以将通用寄存器的低16位划分为两片，一片8位，高8位的空间叫 AH，低8位的空间叫 AL。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715121916.png" alt="image.png"></p>
<p>考试的话最主要的还是 EAX - EDX，后面俩不常见。</p>
<h2 id="1-4-例子"><a href="#1-4-例子" class="headerlink" title="1.4 例子"></a>1.4 例子</h2><p>指令里面的操作数地址可以配合中括号玩很多花活，可以实现寄存器间接寻址，寄存器间接完了还偏移寻址 这种操作：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715122324.png" alt="image.png"></p>
<h1 id="2-常见-x86-汇编指令"><a href="#2-常见-x86-汇编指令" class="headerlink" title="2. 常见 x86 汇编指令"></a>2. 常见 x86 汇编指令</h1><h2 id="2-1-常见运算指令"><a href="#2-1-常见运算指令" class="headerlink" title="2.1 常见运算指令"></a>2.1 常见运算指令</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715125629.png" alt="image.png"></p>
<p>需要着重说的是除法指令：<code>div s 和 idiv s</code>，这俩指令都是一个隐含寻址，s 是除数，在除法之前被除数会提前被安排到 edx 和 eax 两个寄存器中，因为这里需要进行一个位拓展，将 32位 的被除数扩展为 64位，然后 64位 除以 32位，64位 的除数就会放在 edx 和 eax 中。</p>
<p>如果看到了这种指令：<code>add &lt;reg&gt;, &lt;mem&gt;; add &lt;mem&gt;, &lt;con&gt;</code>，mem 指的就是主存，reg 指的是寄存器，con 指的是常量。</p>
<p>x86 规定，一条指令的两个操作数不能同时来自于主存，因为这样两次访存会很慢。同时靠左的操作数不能是常量，因为大部分时候计算结果要存回这里。</p>
<h2 id="2-2-逻辑运算指令"><a href="#2-2-逻辑运算指令" class="headerlink" title="2.2 逻辑运算指令"></a>2.2 逻辑运算指令</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715130017.png" alt="image.png"></p>
<h1 id="3-AT-amp-T-和-Intel-格式"><a href="#3-AT-amp-T-和-Intel-格式" class="headerlink" title="3. AT&amp;T 和 Intel 格式"></a>3. AT&amp;T 和 Intel 格式</h1><p>AT&amp;T 和 Intel 都是 x86 格式，AT&amp;T 是 Unix 和 Linux 常用的，Intel 是 Windows 常用格式。这里来看下两种指令格式的区别：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715152825.png" alt="image.png"></p>
<p>其他的都好理解，最后面这个数据寻址方式：<code>基址 + 变址 x 比例因子 + 偏移量</code> 是干啥的？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715153425.png" alt="image.png"></p>
<p>比如土里创建了一个 Student 结构体，然后有一个结构体数组，每个元素 32B，我们要访问第四个学生信息的变量1，就可以在数组起始地址上往后偏移3 x 32B，找到了数据元素3，然后往里偏移 4B，就找到了变量1.</p>
<h1 id="4-选择语句"><a href="#4-选择语句" class="headerlink" title="4. 选择语句"></a>4. 选择语句</h1><p>这里肯定就涉及到了指令跳转，计算机中指令跳转肯定是要涉及到 PC，在 x86 中，程序计数器 PC 通常叫 IP（Instruction Pointer）。</p>
<h2 id="4-1-无条件跳转指令"><a href="#4-1-无条件跳转指令" class="headerlink" title="4.1 无条件跳转指令"></a>4.1 无条件跳转指令</h2><p>指令：<code>jmp &lt;地址&gt;</code>，指的就是无条件跳转到 &lt;地址&gt;，这个地址可以用常数 <code>jmp 128</code>，代表跳转到 128 地址的指令，也可以用寄存器来指定地址：<code>jmp eax</code>，或者来自主存：<code>jmp [999]</code> 。</p>
<p>众所周知，如果把 JMP 后面的值写死，就会非常不灵活，所以编写汇编时，可以使用锚点：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715154547.png" alt="image.png"></p>
<p>NEXT后面有个冒号就代表他是个锚点，锚点的名字可以自己起。</p>
<p>无条件跳转指令没法直接进行条件判断。</p>
<h2 id="4-2-条件跳转指令"><a href="#4-2-条件跳转指令" class="headerlink" title="4.2 条件跳转指令"></a>4.2 条件跳转指令</h2><p>需要先判断，再跳转：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715154923.png" alt="image.png"></p>
<p>比如我们要实现一个 if，可以这么写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmp eax, ebx</span><br><span class="line">jg next</span><br></pre></td></tr></table></figure>

<p>说的就是，比较 eax 和 ebx 寄存器里面的值，如果 eax &gt; ebx，则跳转到 next: 锚点。</p>
<h2 id="4-3-举例"><a href="#4-3-举例" class="headerlink" title="4.3 举例"></a>4.3 举例</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715155307.png" alt="image.png"></p>
<p>这里的跳转条件取了 a&gt;b 的否命题，来实现 if 部分和 else 部分和程序一致。也可以用 jg 来判断，只是if部分就需要放在后面，jg 后面如果不跳转需要紧跟着 else 部分。</p>
<p>来看道题分析分析：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715155732.png" alt="image.png"></p>
<p>着重看看 12 条指令：<code>jle f1+35h</code>，这里的 f1 可不是一个立即数，注意这是一个函数，函数名叫 f1，通常会将 f1 作为一个标号代表这个函数的起始地址，所以 <code>f1 + 35h</code> 意思是以这个函数的起始地址为基址，往后偏移 35h 。</p>
<p>然后看看图里面，函数的基址是 <code>00401000</code>，往后偏移就是 <code>00401035</code>，往后找，就是第 21 条指令。</p>
<h1 id="5-循环语句"><a href="#5-循环语句" class="headerlink" title="5. 循环语句"></a>5. 循环语句</h1><h2 id="5-1-条件跳转实现循环"><a href="#5-1-条件跳转实现循环" class="headerlink" title="5.1 条件跳转实现循环"></a>5.1 条件跳转实现循环</h2><p>就是用上面的条件跳转指令来实现：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715160535.png" alt="image.png"></p>
<p>这里的 while 循环 和 for 循环是等价的，用 while 可能更好理解一些。需要注意的是：在循环之前（L1: 之前），需要首先进行一次判断（当然得反判断），如果发现条件成立，直接跳过循环到 L2: 即可。</p>
<p>大致需要四个部分组成循环：</p>
<ul>
<li>循环前的初始化，也就是指令的前两句，初始化 result 为 0，初始化 i 为 1</li>
<li>判断是否直接跳过循环，也就是第三四句，切记这里的判断要取否命题</li>
<li>循环主题</li>
<li>是否继续循环，就是 L2: 前面的判断+跳转，如果满足条件，返回循环入口</li>
</ul>
<h2 id="5-2-用loop指令实现循环"><a href="#5-2-用loop指令实现循环" class="headerlink" title="5.2 用loop指令实现循环"></a>5.2 用loop指令实现循环</h2><p>x86 中提供了一种 loop 指令：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715163723.png" alt="image.png"></p>
<p>如果看到了 loopx 这种指令，可以从 C 语言代码倒推。</p>
<h1 id="6-函数调用"><a href="#6-函数调用" class="headerlink" title="6. 函数调用"></a>6. 函数调用</h1><h2 id="6-1-函数调用栈"><a href="#6-1-函数调用栈" class="headerlink" title="6.1 函数调用栈"></a>6.1 函数调用栈</h2><p>这个和 JVM 几乎一个道理，函数调用的时候，会在主存中弄一个函数调用栈，首先执行 main 函数，就会向栈中压入 main 函数的栈桢，然后往后执行 P 函数，同样是压入 P 的栈桢，这时 P 的栈桢就在 main 栈桢上面，如果 P 函数执行完了，就会将 P 的栈桢弹出。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715164204.png" alt="image.png"></p>
<p>栈桢里面保存着函数的局部变量、保存函数调用相关信息。</p>
<h2 id="6-2-Call-amp-Ret-指令"><a href="#6-2-Call-amp-Ret-指令" class="headerlink" title="6.2 Call &amp; Ret 指令"></a>6.2 Call &amp; Ret 指令</h2><p>函数调用指令：<code>call &lt;函数名&gt;</code>，返回指令return: <code>ret</code>。给出以下代码，翻译成汇编指令为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">caller</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="type">int</span> temp1 = <span class="number">125</span>;</span><br><span class="line">	<span class="type">int</span> temp2 = <span class="number">80</span>;</span><br><span class="line">	<span class="type">int</span> sum = add(temp1, temp2);</span><br><span class="line">	<span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715165826.png" alt="image.png"></p>
<p>这个图还解释了调用函数的时候如何让 IP 寄存器（PC）指向被调用函数的位置，以及调用完函数咋回来：</p>
<ul>
<li>在 caller 调用期间调用 add 函数，首先把 IP 旧址放到栈里面，就是栈里面蓝色的那个，放在 caller 栈桢的上面，然后将 IP 设置为函数的起始地址，无条件跳转到add函数，压入栈桢</li>
<li>add 函数执行完弹栈以后，从栈顶找到 IP 旧址，弹栈，恢复 IP 寄存器</li>
</ul>
<p>这里有一个地方前面说过了已经，函数一上来会用函数名设置一个标号，代表的就是这个函数的起始地址，对应的就是add函数里面的 <code>push ebp</code>，后面的 <code>mov eax, [ebp + 12]</code> 代表的就是在add函数内部，偏移 12 个地址。</p>
<h2 id="6-3-如何访问栈桢数据"><a href="#6-3-如何访问栈桢数据" class="headerlink" title="6.3 如何访问栈桢数据"></a>6.3 如何访问栈桢数据</h2><h3 id="6-3-1-函数调用栈在内存中的位置"><a href="#6-3-1-函数调用栈在内存中的位置" class="headerlink" title="6.3.1 函数调用栈在内存中的位置"></a>6.3.1 函数调用栈在内存中的位置</h3><p>32位系统，进程虚拟空间是4GB：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715233251.png" alt="image.png"></p>
<p>这个图的核心意思就是，栈顶处在低地址，栈底处在高地址，所以很多时候栈会倒过来画，符合主存，别不认识。</p>
<p>这个可千万别看反了，我这还是改过来的，注意这里的主存可是上面是高地址，下面是低地址。</p>
<h3 id="6-3-2-EBP-和-ESP"><a href="#6-3-2-EBP-和-ESP" class="headerlink" title="6.3.2 EBP 和 ESP"></a>6.3.2 EBP 和 ESP</h3><p>这俩寄存器之前说的是：</p>
<ul>
<li>EBP：堆栈基地址</li>
<li>ESP：堆栈顶地址</li>
</ul>
<p>这里规范一下，EBP 会指向当前栈桢的底部，ESP 会指向栈桢的顶部，用这俩寄存器来给一个栈桢画范围：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715233958.png" alt="image.png"></p>
<p>注：x86 系统中，默认以 4 字节为栈的操作单位。顺带一提，栈桢大小可不一样。</p>
<p>往后对栈桢内数据的访问，都是基于 EBP 和 ESP 进行的。</p>
<h3 id="6-3-3-Push-amp-Pop-指令"><a href="#6-3-3-Push-amp-Pop-指令" class="headerlink" title="6.3.3 Push &amp; Pop 指令"></a>6.3.3 Push &amp; Pop 指令</h3><p>push 和 pop 指令实现入栈、出栈操作，x86 默认以 4 字节为单位，指令格式如下：</p>
<ul>
<li><code>push &lt;&gt;</code>：先让 esp 减四，也就是往下挪一位（千万注意，栈顶是低地址，所以 esp 往栈顶走可是要做减法的），再将数据压入</li>
<li><code>pop &lt;&gt;</code>：栈顶元素弹栈，将元素写入 &lt;&gt;，再让 esp 加四，就是往上挪一位</li>
</ul>
<p>下面举例：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715234922.png" alt="image.png"></p>
<p>这个画个图看看就行了，这里看看第三个：<code>push [ebp + 8]</code>，就是说，将 ebp 往上两个位置的4字节元素，压入栈，相当于复制了一份，这个 ebp 往上俩位置，很显然就跑到别人栈桢上了。</p>
<p>第五个：<code>pop [ebp + 8]</code> 就是说，弹出栈顶元素，然后 esp + 4，把弹出的元素放入 ebp 网上的两个位置，很好理解吧。</p>
<p>但是这种方式还是有点复杂，这里说一种更简单的：</p>
<h3 id="6-3-4-MOV-指令"><a href="#6-3-4-MOV-指令" class="headerlink" title="6.3.4 MOV 指令"></a>6.3.4 MOV 指令</h3><p>这个指令很简单：<code>mov &lt;a&gt;, &lt;b&gt;</code> 就是将 b 移动到 a，实际上就是一个复制操作，看看例子：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715235516.png" alt="image.png"></p>
<p>第一个：<code>sub esp, 12</code>，给 esp - 12，相当于 esp 往下挪了三格，扩充了当前栈桢，后面 mov 就是疯狂复制，把寄存器里面的数写到栈桢里面，最后一步 <code>add esp, 8</code> 就是 esp + 8 往上挪了两格。</p>
<h3 id="6-3-5-总结"><a href="#6-3-5-总结" class="headerlink" title="6.3.5 总结"></a>6.3.5 总结</h3><p>反正就是让 esp 或者 ebp 来回偏移来找到栈桢里面的元素，然后通过 mov 或者 pop 将元素存到一个位置。</p>
<p>如果用 pop 的话，比如我们想把栈桢里面 ebp - 4 位置的元素存储 eax 寄存器，我们就需要先将 ebp - 4 的元素 push 到栈里，然后 pop 到 eax 中。相比较而言 mov 就简单很多：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715235921.png" alt="image.png"></p>
<h2 id="6-4-如何切换栈桢"><a href="#6-4-如何切换栈桢" class="headerlink" title="6.4 如何切换栈桢"></a>6.4 如何切换栈桢</h2><p>当一个函数 caller 被调用的时候，ebp 和 esp 分别指向栈桢的栈底和栈顶：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715232657.png" alt="image.png"></p>
<p>注：x86 系统中，默认以4字节为栈的操作单位。</p>
<p>然后，caller 内部调用了 add 函数，就会把 add 的栈桢压到栈里面，这个时候 ebp 和 esp 就要移动，指向新栈桢的两端：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715233043.png" alt="image.png"></p>
<h3 id="6-4-1-调用函数时栈桢切换"><a href="#6-4-1-调用函数时栈桢切换" class="headerlink" title="6.4.1 调用函数时栈桢切换"></a>6.4.1 调用函数时栈桢切换</h3><p>首先调用函数时，需要把执行 call 指令：<code>call add</code>，这里 call 的作用是，将 IP 旧值压入到栈中，相当于 push IP，这时 esp 肯定就会 - 4。然后 PC 寄存器指向add函数的起始地址。</p>
<p>执行add函数，函数汇编如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">add:</span><br><span class="line">push ebp</span><br><span class="line">move ebp, esp</span><br><span class="line">mov eax, [ebp + 12]</span><br><span class="line">mov edx, [ebp + 8]</span><br><span class="line">add eax, edx</span><br><span class="line">leave</span><br><span class="line">ret</span><br></pre></td></tr></table></figure>

<p>这段啥意思？首先，将 ebp 的值压入栈，ebp 就是上一个函数的基地址，push 的同时 esp 肯定也会下移，然后 将 esp 复制到 ebp 上，也就是让 ebp 指向当前 esp 指向的位置，最终效果是这样的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716154622.png" alt="image.png"></p>
<p>可以看到，蓝色的 IP 旧值是 call 执行的时候压入的，然后绿色的caller函数基地址是 push ebp 压入的。这样的话，每个函数栈桢的底部，都会存储着上一层函数的基地址，所以 <code>push ebp; mov ebp, esp</code> 这两句指令在函数开始的时候肯定会有（这两个指令也可以精简为 enter，不需要操作数）。</p>
<p>然后我们就可以在执行 add 函数的时候压入一些数据。</p>
<h3 id="6-4-2-调用结束如何返回"><a href="#6-4-2-调用结束如何返回" class="headerlink" title="6.4.2 调用结束如何返回"></a>6.4.2 调用结束如何返回</h3><p>这个很简单，只需要两条指令：<code>mov esp, ebp</code> 和 <code>pop ebp</code> ，即可让栈桢返回caller函数，为啥？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716155420.png" alt="image.png"></p>
<p>看图，第一步 <code>mov esp, ebp</code> 就会实现这个效果，将 ebp 寄存器内的值复制一份给 esp 寄存器，即可实现 esp 和 ebp 都指向 ebp 的位置，显然 ebp 指向的就是 caller 函数的基址。</p>
<p>然后第二步：<code>pop ebp</code> 就是弹栈，将 caller 函数的基址弹出，存入 ebp，同时 esp + 4 往上挪一位，就能让 ebp 重新指回 caller 基址，esp 指回 caller 栈桢顶部。</p>
<p>这两条指令，等价于 <code>leave</code> 指令，效果一样，<code>leave</code> 同样是一个0地址指令。</p>
<p>最后一步，执行 <code>ret</code> 指令，他会从栈桢顶部找到 IP 旧值，将其弹栈并恢复 IP 寄存器。</p>
<h3 id="6-4-3-总结"><a href="#6-4-3-总结" class="headerlink" title="6.4.3 总结"></a>6.4.3 总结</h3><p>记住了，只要不是 main 函数，函数结构一定是这样的，一上来 <code>push ebp</code> 和 <code>mov ebp, esp</code>，或者说直接 <code>enter</code>，然后在结尾 <code>mov esp, ebp</code> 和 <code>pop ebp</code>。最后再来一个 <code>ret</code>。</p>
<h2 id="6-5-栈桢包含信息"><a href="#6-5-栈桢包含信息" class="headerlink" title="6.5 栈桢包含信息"></a>6.5 栈桢包含信息</h2><p>给一段 C 语言程序：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">caller</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="type">int</span> temp1 = <span class="number">125</span>;</span><br><span class="line">	<span class="type">int</span> temp2 = <span class="number">80</span>;</span><br><span class="line">	<span class="type">int</span> sum = add(temp1, temp2);</span><br><span class="line">	<span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看看 caller 栈桢里面包含哪些信息：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716160647.png" alt="image.png"></p>
<p>说明一下：</p>
<ul>
<li>栈桢的顶部肯定是上一个栈桢的基址（ebp 旧值），栈顶肯定是返回地址。</li>
<li>函数的局部变量一般集中存在栈底的位置，且C语言里越靠前的局部变量，越靠近栈顶。所以可以通过 <code>[ebp-4]</code> 、<code>[ebp-8]</code> 这种来访问局部变量。</li>
<li>函数靠近栈顶的位置放着函数调用的入参，同样越先出现的参数，越靠近栈顶，代码里面 temp1 先出现，对应的 x 就更靠近栈顶。这样 add 函数执行时，可以通过 <code>[ebp + 8]</code> 、<code>[ebp + 12]</code> 来拿到入参。</li>
</ul>
<p>然后说一下为啥栈桢里面会有空白区域，因为 gcc 编译器规定，除了当前正在执行的栈桢，栈桢大小必须是 16B 的整数倍。之前说过这个栈的一行是 4B，当前正在执行 add 函数，所以add的栈桢不受限制，可以是一行 4B 也可以是两行 8B。但是如果 add 也要调用一个函数，gcc 一定会把 add 的栈桢凑到 16B 的整数倍。这么一凑可能就有空白区域了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716162006.png" alt="image.png"></p>
<h2 id="6-6-函数传参例子"><a href="#6-6-函数传参例子" class="headerlink" title="6.6 函数传参例子"></a>6.6 函数传参例子</h2><p>还是上面 caller 和 add 函数的例子，我们详细看看汇编代码是如何实现传参和返回值的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716162514.png" alt="image.png"></p>
<p>看 caller 函数：</p>
<ul>
<li>前两步不说，常规代码</li>
<li><code>sub esp, 24</code>，给 esp - 24，让 esp 往下移动了6行，扩展栈桢，这个时候 esp 在 <code>0018</code> 那个位置。</li>
<li><code>mov [ebp-12], 125</code> 和 <code>mov [ebp-8], 80</code>，初始化 temp1 和 temp2，注意这个时候 <code>[ebp-4]</code> 这个位置给空下了，用来以后保存 sum</li>
<li><code>mov eax, [ebp-8]</code> &amp; <code>mov [esp+4], eax</code> 是在拷贝传参，将temp2复制到 eax，再将 eax 复制到 esp+4的位置，也就是 <code>001C</code>。往后的两个 mov 也是一个道理，将 temp1 存到 esp 位置。为啥需要把temp1存到 eax 在放回栈里？因为栈是主存，x86 规定指令的地址码不能都是主存</li>
<li><code>call add</code> 执行 add 函数，esp+4，压入IP旧值，IP指向add函数基址，开始执行 add 函数</li>
</ul>
<p>来看 add 函数：</p>
<ul>
<li>上来两行不说</li>
<li><code>mov eax, [ebp + 12]</code> &amp; <code>mov ebx, [ebp + 8]</code> 将上一个函数 caller 传来的两个参数放入寄存器</li>
<li>执行加法操作，将结果保存到 <code>eax</code> 中</li>
<li><code>leave</code> &amp; <code>ret</code> 不解释了，返回了 caller 函数</li>
</ul>
<p>回到 caller 函数</p>
<ul>
<li><code>mov [ebp - 4], eax</code>，add 函数将返回值存到了 eax中，这里就将 eax 中的值复制到 ebp-4 的位置，相当于接受了 sum 变量</li>
<li><code>mov eax, [ebp - 4]</code>，这个是将 sum 存回 eax，相当于 <code>return sum</code></li>
<li><code>leave</code> &amp; <code>ret</code> 不说了</li>
</ul>
<p>这里使用 eax 来传递函数调用的返回值，如果 caller 函数里面已经用 eax 存放了一些中间结果，咋办？可以在 call 之前，将寄存器中的一些值，压栈保存：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716163827.png" alt="image.png"></p>
<h1 id="6-7-总结"><a href="#6-7-总结" class="headerlink" title="6.7 总结"></a>6.7 总结</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716163910.png" alt="image.png"></p>
<h1 id="7-CISC-amp-RISC"><a href="#7-CISC-amp-RISC" class="headerlink" title="7. CISC &amp; RISC"></a>7. CISC &amp; RISC</h1><p>看两张图就行：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716165731.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716165659.png" alt="image.png"></p>
<p>这里有些新概念：控制方式、流水线。这个下一章就会学。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>08-指令系统</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-08-%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>这里开始研究 CPU，CPU 里面之前说过里面有运算器和控制器，这一章就看看控制器支持的指令如何设计。</p>
<span id="more"></span>

<h1 id="1-指令格式"><a href="#1-指令格式" class="headerlink" title="1. 指令格式"></a>1. 指令格式</h1><h2 id="1-1-指令的定义"><a href="#1-1-指令的定义" class="headerlink" title="1.1 指令的定义"></a>1.1 指令的定义</h2><p>指令是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。</p>
<p>一台计算机的所有指令的集合称为该计算机的指令系统，或者叫指令集。一台计算机只能执行自己的指令系统中的指令，不能执行其他系统的指令。</p>
<p>比如最常见的 x86 架构 和 ARM 架构，就是用两套指令集，所以两种架构下的应用不能直接上对方的架构上运行。</p>
<h2 id="1-2-指令格式"><a href="#1-2-指令格式" class="headerlink" title="1.2 指令格式"></a>1.2 指令格式</h2><p>一条指令就是计算机语言的一个语句，他是一组有意义的二进制代码。一条指令通常包含 <strong>操作吗字段</strong> 和 <strong>地址码字段</strong> 两部分：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714115013.png" alt="image.png"></p>
<p>一条指令可能包含 0、1、2、3、4 个地址吗。根据地址数目不同，可以将指令分为 零地址指令、一地址指令、二地址指令。</p>
<p>如果指令的位数不变的话，后面的地址码越多，寻址能力就越差。</p>
<h3 id="1-2-1-零地址指令"><a href="#1-2-1-零地址指令" class="headerlink" title="1.2.1 零地址指令"></a>1.2.1 零地址指令</h3><p>不需要操作数，只进行一个操作，不需要指明对谁做。</p>
<p>比如：空操作、停机、关中断指令。</p>
<p>有些特殊的指令，比如对于堆栈的操作就可能不指明地址码，比如弹栈操作，默认就是把栈顶的元素弹出。</p>
<h3 id="1-2-2-一地址指令"><a href="#1-2-2-一地址指令" class="headerlink" title="1.2.2 一地址指令"></a>1.2.2 一地址指令</h3><p>格式：<code>OP | A1</code></p>
<p>只需要一个操作数，比如 + 1，- 1，取反，求补码等。类似单目运算。指令含义：<code>OP(A1) -&gt; A1</code>，意思就是，取出 A1 指向的主存的值（如果给一个地址加上括号，一般指的就是取值），进行 OP 操作，然后放回 A1 的主存位置。</p>
<p>需要三次访存，第一次从内存中取出指令，第二次取出 A1 的值，第三次将结果放回 A1.</p>
<p>另一种情况就是需要两个操作数，但是另一个操作数隐含在某个寄存器中，比如 ACC，典型的例子就是乘法操作。指令含义：<code>(ACC)OP(A1) -&gt; ACC</code>，就是从 A1 和 ACC 中取出值，进行 OP 操作，然后将结果写回ACC。</p>
<p>这种需要两次访存，第一次从内存中找到指令，第二次从内存中拿到 A1 的值。</p>
<h3 id="1-2-3-二地址指令"><a href="#1-2-3-二地址指令" class="headerlink" title="1.2.3 二地址指令"></a>1.2.3 二地址指令</h3><p>格式：<code>OP | A1 | A2</code></p>
<p>常用于需要两个操作数的算术运算、逻辑运算相关指令，指令含义：<code>(A1)OP(A2) -&gt; A1</code>，很好理解不解释。</p>
<p>需要四次访存，第一次拿指令，第二次拿 A1，第三次拿 A2，第四次存回 A1</p>
<h3 id="1-2-4-三地址指令"><a href="#1-2-4-三地址指令" class="headerlink" title="1.2.4 三地址指令"></a>1.2.4 三地址指令</h3><p>格式：<code>OP | A1 | A2 | A3(结果)</code></p>
<p>和二地址指令差不多，二地址指令默认运算结果写回 A1，这里是显式的指明结果存放到A3位置。指令含义：<code>(A1)OP(A2) -&gt; A3</code>.</p>
<p>同样是四次访存，不说了。</p>
<h3 id="1-2-5-四地址指令"><a href="#1-2-5-四地址指令" class="headerlink" title="1.2.5 四地址指令"></a>1.2.5 四地址指令</h3><p>格式：<code>OP | A1 | A2 | A3(结果) | A4(下址)</code></p>
<p>和三地址差不多，最终结果也是写回 A3，然后 A4 指向了一下条要执行的指令，会将 PC（程序计数器） 的值改为 A4.</p>
<h2 id="1-3-按指令长度分类"><a href="#1-3-按指令长度分类" class="headerlink" title="1.3 按指令长度分类"></a>1.3 按指令长度分类</h2><p>指令字长：一条指令的总长度（可能会变）</p>
<p>机器字长：CPU 进行一次证书运算所能处理的二进制数据的位数，通常和 ALU 直接相关</p>
<p>存储字长：一个存储单元中二进制妈的位数，通常和 MDR 位数相同</p>
<p>根据指令字长可以分为：半字长指令、单字长指令、双字长指令。指的就是指令长度是机器字长的多少倍。指令字长会影响去指令所需时间。比如机器字长&#x3D;存储字长&#x3D;16bit，则取一条双字长指令需要两次访存。</p>
<p>按字长是否可变又分为两类：定长指令字结构、变长指令字结构。定长指令就是指令的长度都相同，变长自然就是指令长度可能不同。</p>
<h2 id="1-4-按操作吗长度分类"><a href="#1-4-按操作吗长度分类" class="headerlink" title="1.4 按操作吗长度分类"></a>1.4 按操作吗长度分类</h2><ul>
<li>定长操作码：指令系统中所有指令的操作吗长度都相同，如果操作码有n位，则有 2^n 条指令。这种控制器的译码电路设计简单，灵活性较低。</li>
<li>可变长操作码：指令系统中各指令的操作码长度可变。译码电路复杂，但灵活</li>
</ul>
<h2 id="1-5-按操作类型分类"><a href="#1-5-按操作类型分类" class="headerlink" title="1.5 按操作类型分类"></a>1.5 按操作类型分类</h2><p>数据传送，进行主存和CPU之间的数据传送：</p>
<ul>
<li>LOAD：把 <strong>存储器</strong> 的数据放到 <strong>寄存器</strong> 中</li>
<li>STORE：将 <strong>寄存器</strong> 的数据放到 <strong>存储器</strong> 中</li>
</ul>
<p>算术逻辑操作，运算类：</p>
<ul>
<li>算数：加、减、乘、除、加一、减一、补码、浮点运算、十进制运算</li>
<li>逻辑：与、或、非、异或、位操作、位测试、位清除、位求反</li>
</ul>
<p>移位操作，运算类：</p>
<ul>
<li>算术移位、逻辑移位、循环移位</li>
</ul>
<p>转移操作，程序控制类，改变程序执行的顺序：</p>
<ul>
<li>无条件 JMP</li>
<li>条件转移 </li>
<li>调用和返回</li>
<li>陷入Trap 和 陷入指令</li>
</ul>
<p>输入输出操作，输入输出类，进行CPU和IO设备之间的数据传送：</p>
<ul>
<li>CPU 寄存器和IO端口之间的数据传送</li>
</ul>
<h2 id="1-6-总结"><a href="#1-6-总结" class="headerlink" title="1.6 总结"></a>1.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714160324.png" alt="image.png"></p>
<h1 id="2-扩展操作码指令格式"><a href="#2-扩展操作码指令格式" class="headerlink" title="2. 扩展操作码指令格式"></a>2. 扩展操作码指令格式</h1><p>之前我们说过，根据指令的长度可以分为可变长指令和定长指令，根据操作码的长度又可以分为定长操作码和可变长操作码。</p>
<p>这里我们就设计一种扩展操作码指令格式：定长指令字结构+可变长操作码。就是说指令长度固定，但是操作码位数可变，不同地址数的指令使用不同长度的操作码。</p>
<h2 id="2-1-操作码全1扩展"><a href="#2-1-操作码全1扩展" class="headerlink" title="2.1 操作码全1扩展"></a>2.1 操作码全1扩展</h2><p>现规定：指令字长 16 位，每个地址码占 4 位。前 4 位为基本操作码字段 OP，另外3个4位长的地址字段 A1、A2、A3。</p>
<p>根据前面说的，三地址情况下，操作码给我们留了四位，也就是可以设计 2^4 个指令。但是需要把 OP 全为 1 的这个情况留出来，用于扩展，也就是说三地址指令有 15 条。</p>
<p>如果是二地址指令，OP 则有 8 位，通过前四位全 1 来判断，然后后面 4 位设计指令，同样能设计 15 条，留下全 1 作为扩展。</p>
<p>以此类推，如果要设计 0 地址指令，OP 为 16 位，前面 12 位已经是全 1 了，最后四位就可以有 16 个指令了，无需留下扩展。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714161440.png" alt="image.png"></p>
<p>这种方式需要注意：</p>
<ul>
<li>不允许短码是长吗的前缀，也就是短操作码不能与长操作码的前面部分代码相同。例子：3地址指令中，OP 不能和 2地址指令的OP前缀（也就是 1111）相同，否则CPU无法识别该指令是几地址指令。</li>
<li>各指令的操作码一定不能重复。</li>
</ul>
<p>通常情况下，使用频率较高的指令，分配较短的操作码，可以更快识别；对使用频率较低的指令，分配较长的操作码，从而尽可能减少指令译码和分析的时间。</p>
<h2 id="2-2-例题"><a href="#2-2-例题" class="headerlink" title="2.2 例题"></a>2.2 例题</h2><p>指令字长固定为 16 位，设计一套指令系统满足：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714162121.png" alt="image.png"></p>
<p>解释一下：</p>
<p>三地址指令 OP 只有 4 位，要求有 15 条，那就是 0000 - 1110，所以用 1111 作为扩展位。</p>
<p>二地址指令 OP 也有 4 位（不算最高位的 1111），要求有 12 条，对应数字就是从 0 到 11 呗，那就是 <code>0000 - 1011</code>，还剩下四个：<code>1100 1101 1110 1111</code>，四个的最高位都是 <code>11</code>，所以说只需要扩展 <code>11</code> 就超出了二地址OP的范围。</p>
<p>一地址指令 OP 有 6 位（最高位 111111 扩展），要求有 62 条，也就是从 0 - 61，也就是<code>000000 - 111101</code>，扩展 <code>11111</code> 五位即可超出范围，所以向下扩展 5 位。</p>
<p>零地址不说了。</p>
<p>CPU 执行流程：</p>
<p>发现 OP 的前四位不是 1111，则三地址指令，去后面取三个地址码。如果发现前 4 位全为 1，则根据前8位判断指令类型。发现 OP 的前6位全1，则根据前 12 位判断指令类型。如果前 11 位全是1，则零地址指令。</p>
<p>计算指令数目：</p>
<p>假设地址长度为 n，上一层留出 m 种状态，下一层可扩展 m x 2^n 种状态。</p>
<p>啥意思？三地址指令 OP 有 4 位，有 16 状态，只要其中 15 种，则留下了 1 种状态。二地址指令 OP 也是 4 位，则有 1 x 2^4 &#x3D; 16 种状态，但是只留其中 12 种，留下 4 种状态。一地址指令OP仍旧是4位，前面留下 4 种状态，则一地址指令可有 4 x 2^4 &#x3D; 64 种状态。</p>
<p>留出状态是啥意思？比如二地址指令，OP 是 <code>0000 - 1011</code>，扩展出 <code>11</code>，也就是二地址指令把自己的4位OP的最后两位留给了下一层指令。</p>
<h1 id="3-指令寻址"><a href="#3-指令寻址" class="headerlink" title="3. 指令寻址"></a>3. 指令寻址</h1><p>如何确定下一条指令的存放地址。之前说过 PC 会指向下一条要执行的指令地址，下一条指令：<code>(PC) + 1 -&gt; PC</code>.但是这样有问题：</p>
<ul>
<li>如果内存是按照字节编址，而不是存储字编址。一条指令可能占两个字节，PC 不能加1，而是加2.</li>
<li>如果计算机采用变长指令字结构咋办？</li>
</ul>
<h2 id="3-1-顺序寻址"><a href="#3-1-顺序寻址" class="headerlink" title="3.1 顺序寻址"></a>3.1 顺序寻址</h2><p>所有指令都是按顺序放在主存中，只需要对 PC 做手脚即可实现指令寻址。总结就是 <code>(PC) + &quot;1&quot; -&gt; PC</code>。</p>
<h3 id="3-1-1-按字编址-定长指令"><a href="#3-1-1-按字编址-定长指令" class="headerlink" title="3.1.1 按字编址 + 定长指令"></a>3.1.1 按字编址 + 定长指令</h3><p>假设一个指令刚好占一个存储字，主存还是按字编址，则：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714165228.png" alt="image.png"></p>
<p>这种情况最简单，只需要简单的 PC + 1 即可。</p>
<h3 id="3-1-2-按字节编址-定长指令"><a href="#3-1-2-按字节编址-定长指令" class="headerlink" title="3.1.2 按字节编址 + 定长指令"></a>3.1.2 按字节编址 + 定长指令</h3><p>还是上面的例子，存储字长为 2B，一条指令也是 2B，主存按字节编址，那么下一条指令就需要 PC + 2 才能得到：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714165407.png" alt="image.png"></p>
<h3 id="3-1-3-字节编址-可变长指令"><a href="#3-1-3-字节编址-可变长指令" class="headerlink" title="3.1.3 字节编址 + 可变长指令"></a>3.1.3 字节编址 + 可变长指令</h3><p>CPU 会首先读入指令的一部分，判断指令是几地址指令，然后按顺序将后面的部分也读入 CPU，然后让 PC + n，n 就是读入的指令总字节数：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714165540.png" alt="image.png"></p>
<h2 id="3-2-跳跃寻址"><a href="#3-2-跳跃寻址" class="headerlink" title="3.2 跳跃寻址"></a>3.2 跳跃寻址</h2><p>通过转移指令指出PC要指向的值。比如 JMP 指令就是无条件跳转指令，后面跟的地址码就是下一条指令的位置：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714165633.png" alt="image.png"></p>
<h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714165707.png" alt="image.png"></p>
<h1 id="4-数据寻址"><a href="#4-数据寻址" class="headerlink" title="4. 数据寻址"></a>4. 数据寻址</h1><p>运行一条指令时，确定本条指令的地址码指明的真实地址。这个 OS 的第八章内存管理一上来也讲过地址转换，将逻辑地址转为物理地址。</p>
<p>总共有 10 种寻址方式：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714170417.png" alt="image.png"></p>
<p>这个东西是计算机规定好的，所以指令中的地址码可以在前面加上 4bit 的寻址特征，用来表示后面这个地址应该如何寻址。</p>
<p>指令格式如下：<code>OP | 寻址特征 4bit | 形式地址</code>，后面讲的时候默认用的就是一地址指令，多地址指令同样的道理，地址前面加4bit的特征即可。</p>
<p>往后默认 指令字长 &#x3D; 机器字长 &#x3D; 存储字长。操作数为 3。顺便一提：后面出现的什么 (A)，这个括号指的是，根据 A 里面的值，去寻址，也就是 A 指向的那个主存的值。</p>
<h2 id="4-1-直接寻址"><a href="#4-1-直接寻址" class="headerlink" title="4.1 直接寻址"></a>4.1 直接寻址</h2><p>形式地址 A 就是操作数的真实地址 EA，即 EA &#x3D; A：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714170749.png" alt="image.png"></p>
<p>共需要两次访存：取指令、取操作数。</p>
<p>优点：简单，指令执行阶段仅需要访问一次主存，不需要专门计算操作数的地址。</p>
<p>缺点：A 的位数决定了该指令操作数的寻址范围，操作数的地址不易修改。</p>
<h2 id="4-2-间接寻址"><a href="#4-2-间接寻址" class="headerlink" title="4.2 间接寻址"></a>4.2 间接寻址</h2><p>A 不指向操作数的真实地址，而是指向一个一块主存（理解为指针），这个主存指向了操作数的真实地址 EA，A指向内存的值 &#x3D; EA，即 <code>EA = (A)</code>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714171230.png" alt="image.png"></p>
<p>对的，我们甚至可以两次间接寻址，如果 (A) 的第一位是 1，则 (A) 指向下一层指针。分别访存 3 次和 4 次。</p>
<p>优点：扩大寻址范围（有效地址EA 的位数大于形式地址 A 的位数），便于编制程序（用间接寻址可以方便的完成子程序返回）。</p>
<p>缺点：指令执行阶段需多次访存，一次间址需要两次访存，多次寻址需要根据存储字的最高位确定几次访存。</p>
<h2 id="4-3-寄存器寻址"><a href="#4-3-寄存器寻址" class="headerlink" title="4.3 寄存器寻址"></a>4.3 寄存器寻址</h2><p>就是操作数不放在主存里面，放在寄存器中，A指向的是一个寄存器的编号：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714171759.png" alt="image.png"></p>
<h2 id="4-4-寄存器间接寻址"><a href="#4-4-寄存器间接寻址" class="headerlink" title="4.4 寄存器间接寻址"></a>4.4 寄存器间接寻址</h2><p>同样地址码 Ri 指向的是一个寄存器，但是寄存器里面记录的是操作数的主存地址，所以：<code>(Ri) = EA</code>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714231440.png" alt="image.png"></p>
<h2 id="4-5-隐含寻址"><a href="#4-5-隐含寻址" class="headerlink" title="4.5 隐含寻址"></a>4.5 隐含寻址</h2><p>不是明显的给出操作数的地址，而是在指令中隐含着着操作数的地址。这个在之前讲 ALU 的时候就遇到很多，默认另一个操作数是在 ACC 中：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714231609.png" alt="image.png"></p>
<h2 id="4-6-立即寻址"><a href="#4-6-立即寻址" class="headerlink" title="4.6 立即寻址"></a>4.6 立即寻址</h2><p>就是说 A 在这种情况下代表的不是一个地址码，而是操作数本身，直接把操作数存在指令里面：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714231807.png" alt="image.png"></p>
<h2 id="4-7-偏移寻址"><a href="#4-7-偏移寻址" class="headerlink" title="4.7 偏移寻址"></a>4.7 偏移寻址</h2><p>相对寻址、基址寻址、变址寻址 三种方式属于偏移寻址，都是在 A 的基础上偏移一段距离找到操作数地址，不同的就是偏移的起点不一样：</p>
<ul>
<li>基址寻址：以程序的起始存放位置作为“起点”</li>
<li>变址寻址：程序员自己决定从哪里作为“起点”</li>
<li>相对寻址：以程序计数器 PC 所指向的地址作为”起点“</li>
</ul>
<h3 id="4-7-1-基址寻址"><a href="#4-7-1-基址寻址" class="headerlink" title="4.7.1 基址寻址"></a>4.7.1 基址寻址</h3><p>将 CPU 中 <strong>基址寄存器（BR）</strong> 的内容加上指令格式中的形式地址 A，而形成的操作数有效地址，即：<code>EA = (BR) + A</code>。这个就是 OS 里面我们最早说的那种寻址方式（OS里面管它叫重定位寄存器），以程序存放位置的起点为准往后偏移，BR 里面存的就是程序存放位置的起点。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714232909.png" alt="image.png"></p>
<p>注意第二个，有的计算机不会专门设计 BR，会用通用寄存器代替 BR，指令里面就会指明哪个寄存器里面存了基址。</p>
<p>优点：可以扩大寻址范围；便于程序“浮动”，方便实现多到程序并发运行。这个好理解，就是说如果程序装入内存的位置变了，程序的指令不需要更改，只需要更改BR即可。BR的值会存放在PCB中作为进程运行环境。</p>
<p>基址寄存器是面向操作系统的，内容由操作系统或管理程序确定。程序运行过程中，基址寄存器的内容不变，形式地址可变。</p>
<p>汇编语言可以直接操作通用寄存器，但是如果某个寄存器被我们指定为BR，我们也是不能操作的，只要是用于存储基址的东西，只能由操作系统管理。</p>
<h3 id="4-7-2-变址寻址"><a href="#4-7-2-变址寻址" class="headerlink" title="4.7.2 变址寻址"></a>4.7.2 变址寻址</h3><p>有效地址 EA 等于指令字中的形式地址A与 <strong>变址寄存器IX</strong> 的内容相加之和，即：<code>EA = (IX) + A</code>，其中 IX 可为变址寄存器（专用），也可以用通用寄存器代替，这个和基址寻址一样。</p>
<p>他和基址寻址的区别在于：IX 的值由我们自己决定，我们来让他偏移多少位，而 BR 是只能由操作系统管理；同时形式地址 A 被我们看作基地址。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714234237.png" alt="image.png"></p>
<p>如何理解把 A 视作基地址？看下面这个例子：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714234339.png" alt="image.png"></p>
<p>如何实现循环访问数组？着重看 2、3、4 指令：一开始 #2指令让 形式地址7上的操作数和 ACC 里面的数相加，然后存回 ACC，一开始 IX 是0，也就是 #2指令会取到 #7的数据，然后 IX 累加变成 1，然后比较，发现没有满足条件，继续循环。</p>
<p>然后第二轮，#2指令还是要拿形式地址7 的数据，但是 IX 为1，也就是在 #7 的基础上往后偏移移位，也就访问到了 #8 的数据（数组的第二个数），然后往后循环。</p>
<p>所以说 #7 地址在这里可以理解成一个数组的基地址，往后通过 IX 来实现向后偏移访问数组后面的数据。</p>
<p>优点：数组处理过程中，可设定 A 为数组的首地址，不断改变变址寄存器 IX 的内容，便可以很容易形成数组中任意数据的地址，特别<font color='red'>适合编制循环程序</font>.</p>
<h3 id="4-7-3-基址-amp-变址复合寻址"><a href="#4-7-3-基址-amp-变址复合寻址" class="headerlink" title="4.7.3 基址 &amp; 变址复合寻址"></a>4.7.3 基址 &amp; 变址复合寻址</h3><p>这个很好理解，之前的例子里面首地址是0，如果首地址不是0，形式地址A还需要通过 BR 来确定 EA 的值，然后 IX 接着累加实现往后访问。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714235246.png" alt="image.png"></p>
<p>我们可以把各种寻址方式看作是一种函数，输入形式地址，返回物理地址，所以各种寻址方式复合使用很是常见。</p>
<h3 id="4-7-4-相对寻址"><a href="#4-7-4-相对寻址" class="headerlink" title="4.7.4 相对寻址"></a>4.7.4 相对寻址</h3><p>这个很好理解了，就是在 PC 的基础上偏移。把 PC 的内容加上指令格式中的形式地址 A 而形成的操作数有效地址，即：<code>EA = (PC) + A</code>，其中 A 是相对于 PC 的偏移量，可正可负，<font color='red'>补码表示</font>.</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714235643.png" alt="image.png"></p>
<p>这个错误注意了，A 是相对于下一条指令的偏移量，因为指令一被拿出来，PC自动就加一了。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230714235932.png" alt="image.png"></p>
<p>这个例子很好理解， #M+3 指令要跳转回循环开头，需要往回偏移4个指令（为啥是4个，因为执行 M+3 的时候 PC 就已经指向了 M+4 了）。</p>
<p>这种寻址的优点是：操作数的地址不是固定不变的，随着 PC 的变化而变化，并且指令地址之间总是相差一个固定值，因此便于程序浮动（一段代码在程序内部浮动），这种寻址广泛用于跳转指令。</p>
<p>浮动这个在基址寻址里面也说过，基址寻址中的浮动说的是整个进程在内存中浮动，这个说的是一段指令在程序内部浮动。</p>
<h3 id="4-7-5-如何实现判断"><a href="#4-7-5-如何实现判断" class="headerlink" title="4.7.5 如何实现判断"></a>4.7.5 如何实现判断</h3><p>判断：<code>if(a &gt; b) &#123;...&#125; else &#123;...&#125;</code></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715000624.png" alt="image.png"></p>
<h2 id="4-8-堆栈寻址"><a href="#4-8-堆栈寻址" class="headerlink" title="4.8 堆栈寻址"></a>4.8 堆栈寻址</h2><p>堆栈式存储器（或者专用寄存器组）中一块特定的按“先进先出”原则管理的存储器，该区域中被读写单元的地址是用一个特定的寄存器给出的，这个寄存器叫<font color='red'>堆栈指针 SP</font>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715114044.png" alt="image.png"></p>
<p>注意一下：执行弹栈以后SP需要加一指向下一个栈顶元素。入栈的时候 SP - 1 指向上一个空位置，然后将元素放入。</p>
<p>如果堆栈是用寄存器实现的，就是硬堆栈，如果只是在缓存里开辟一块空间，那就是软堆栈：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715114354.png" alt="image.png"></p>
<h2 id="4-9-总结"><a href="#4-9-总结" class="headerlink" title="4.9 总结"></a>4.9 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230715114519.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>11-控制器设计</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-11-%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<p>控制器 CU 设计：硬布线、微程序。</p>
<span id="more"></span>

<h1 id="1-控制器设计-硬布线设计"><a href="#1-控制器设计-硬布线设计" class="headerlink" title="1. 控制器设计-硬布线设计"></a>1. 控制器设计-硬布线设计</h1><h2 id="1-1-回顾"><a href="#1-1-回顾" class="headerlink" title="1.1 回顾"></a>1.1 回顾</h2><p>巨恶心：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718104030.png" alt="image.png"></p>
<p>这张图里面的重点：</p>
<ul>
<li>微操作和微命令：微操作就是之前说的 <code>(PC) -&gt; MAR</code> 这种东西，如何实现这个微操作，CU 应该如何对 PC 和 MAR 发出控制信号，这个就是微命令。</li>
<li><code>FE IND EX INT</code> 四个状态分别对应了之前说过的四个状态寄存器，用来记录当前指令执行到哪个周期了，这个要记住，后面要用</li>
<li>图里面使用了定长机器周期，就是每个周期所需的时钟频率相等，如果占不满，就往后安排微操作。定长的机器周期到底要设计多长，要看可能出现的最大节拍数（通常是以访存所需要的节拍数为准）</li>
</ul>
<p>所以我们的问题就是，CU 如何在已知指令 OP、当前机器周期、节拍信号、机器状态条件 的情况下，确定发出哪些 <strong>微命令</strong>。</p>
<h2 id="1-2-硬布线控制器"><a href="#1-2-硬布线控制器" class="headerlink" title="1.2 硬布线控制器"></a>1.2 硬布线控制器</h2><p>直接看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718105414.png" alt="image.png"></p>
<p>解释一下：</p>
<p>首先，需要把 IR 中的 Op 给 CU 才行，假设 Op 有 n 位，则对应 2^n 种指令，所以操作码译码器的作用就是输入 n 条线，输出 2^n 条线到 CU，用来表示全部指令。比如，n 为 4，输入 0010，则译码器的第 3 根线（#2）就需要给 CU 一个信号，CU 就知道了 Op 是啥了。</p>
<p>CU 还需要通过四个触发器来判断当前指令执行到哪个周期了，所以需要把 FE、IND、EX、INT 四个连到 CU 上，图里面也说了，这四个其实在 CU 内部，只是这里为了符合意思，就这么画了。</p>
<p>然后看左边节拍发生器，假设我们这里是定长机器周期，每个机器周期包含四个节拍，则节拍发生器就会有 <code>T0, T1, T2, T3</code> 四条线连接到 CU。在一个机器周期内，T0 给信号，说明当前处于第一个节拍，T1 给信号，说明在第二个节拍，以此类推，当 T3 给了信号，当前机器周期处在最后一个节拍，周期也就结束了，下一个机器周期又会从 T0 开始给信号。</p>
<p>绿色的不说了。</p>
<p>最先面的红色玩意，每条线都会对应一个微命令也就是微操作，比如让 C1 对应的微操作就是 <code>(PC) -&gt; MAR</code>，则让 C1 连到 <code>PCout</code> 和 <code>MARin</code> 即可。</p>
<p>那么 CU 如何知道什么时候该启动 C1 ？C1 该如何设计？</p>
<p>所有指令的取指周期，T0 节拍下必须要完成 <code>(PC) -&gt; MAR</code>，则 <code>C1 = FE 与(点) T0</code>，也就是说，当节拍处在 T0 且 指令周期是取指（FE &#x3D; 1）的时候，才会让 C1 启动。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718110554.png" alt="image.png"></p>
<p>这个很简单，因为只有在 T0 &amp; FE 的时候才需要 PC 和 MAR 连通，但是比如 <code>M(MAR) -&gt; MDR</code> 这种指令，在多个指令周期内都可能被执行，这个咋设计？</p>
<p>别说话，看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718111002.png" alt="image.png"></p>
<p>稍微解释一点，全部的我也看不懂，看懂一点就得了：</p>
<p>来看逻辑表达式的前面：<code>FE &amp; T1</code>，这就是说，如果当前处于 取指周期且在T1节拍下，则发出该微指令。这个很好理解。FE 的 T0 是 <code>(PC) -&gt; MAR</code>，T1 自然就是顺着 MAR 取指。</p>
<p>在看最后一点：<code>EX &amp; T1 &amp;(ADD | LDA)</code>，就是说，如果当前处于指令执行阶段，而且在 T1 节拍，执行的指令还是 ADD （）或者 LDA（将数据从主存读入 ACC 寄存器）情况下，接通线路执行微操作。</p>
<p>顺着这俩逻辑看看图，图里面的蓝色的线就来自上面的操作码译码器。</p>
<h2 id="1-3-硬布线控制器设计"><a href="#1-3-硬布线控制器设计" class="headerlink" title="1.3 硬布线控制器设计"></a>1.3 硬布线控制器设计</h2><p>这个玩意就是说，已知我们会用到哪些指令，然后我们自己设计一个硬布线控制器，看看每个微操作电路应该怎么弄，如何确定一个微操作的逻辑表达式。</p>
<p>大体分为四个步骤：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718112010.png" alt="image.png"></p>
<p>我们这里为了省事，就假设采用同步控制方式（定长机器周期），几个机器周期有三个节拍。</p>
<h3 id="1-3-1-分析各阶段微操作序列"><a href="#1-3-1-分析各阶段微操作序列" class="headerlink" title="1.3.1 分析各阶段微操作序列"></a>1.3.1 分析各阶段微操作序列</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718112519.png" alt="image.png"></p>
<p>这里首次引入了机器状态寄存器，就是 <code>BAN X</code> 的微操作，写的是：<code>A0 . Ad(IR) + A0(反).(PC) -&gt; PC</code>，意思就是当 A0 也就是符号位为 1（ACC是负数）时，将 IR 里面的地址码送去 PC，或者 A0 是0的时候，就把 PC 送去 PC 也就是不变。</p>
<p>其中标红的 <code>M(MAR) -&gt; MDR</code>，就是各个指令周期都会用到的微操作，设计就会比较复杂。需要考虑不同指令周期和不同指令执行。</p>
<p>我们已经确定了才用定长机器周期的方式，每个机器周期三个节拍，所以第二步略过，直接进入第三步。</p>
<h3 id="1-3-2-安排微操作时序"><a href="#1-3-2-安排微操作时序" class="headerlink" title="1.3.2 安排微操作时序"></a>1.3.2 安排微操作时序</h3><p>安排这个需要三个原则：</p>
<ul>
<li>微操作的先后顺序不能随便更改</li>
<li>被控对象不同的微操作尽量安排在一个节拍内完成</li>
<li>占用时间较短的微操作尽量安排在一个节拍内完成，并允许有先后顺序</li>
</ul>
<p>根据这三个原则，安排一下取指周期的时序：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718152728.png" alt="image.png"></p>
<p>1 和 2 两步被控对象不同，所以可以安排到一个周期内完成，3 和 6 不解释，同样是被控对象不同，看看最后一个 4 和 5，4 和 5 只是 CPU 内部寄存器的流动，CPU 内寄存器数据传输速度非常快，所以可以将两步安排到一个周期内。但是第三步不行，需要访问主存，必须一个时钟周期才能保证微操作的完成。</p>
<p>再看看间址周期：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718153000.png" alt="image.png"></p>
<p>这个很简单，不说了。最后看看执行周期：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718153140.png" alt="image.png"></p>
<h3 id="1-3-3-电路设计"><a href="#1-3-3-电路设计" class="headerlink" title="1.3.3 电路设计"></a>1.3.3 电路设计</h3><p>分为三步：</p>
<ul>
<li>列出操作时间表</li>
<li>写出微操作命令的最简表达式</li>
<li>画出逻辑图</li>
</ul>
<p>首先列出操作时间表，取指周期；</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718153520.png" alt="image.png"></p>
<p>最后两行，I 指的是如果发现指令里面存在形式地址，则 <code>1 -&gt; IND</code>，让 CU 进入间址周期；如果没有间址，则 <code>1 -&gt; EX</code> 直接进入执行阶段。</p>
<p>前面的非访存指令肯定不会用到间址，所以不为1，后面的访存指令可能会进入间址阶段，或者他们的地址码就是直接地址，也不需要进入间址阶段。</p>
<p>再来看看间址周期时间表：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718153846.png" alt="image.png"></p>
<p>最后面的 IND 取反是啥意思？就是说间址周期可能需要进行多次访存，比如他是一个多层的间址，完成这一步只是将第一层间址拼到了 IR 上，所以如果 IND 如果还是 1 的话，下一步就需要循环这个间址周期，知道找到了最终的直接地址，才能将 IND 设为 0，然后 <code>1 -&gt; EX</code>。</p>
<p>最后看看执行周期的操作时间表：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718154331.png" alt="image.png"></p>
<p>那列出这个表有啥用呢？可以根据这些表去找逻辑表达式，比如 <code>M(MAR) -&gt; MDR</code> 这个微操作，把它在表里出现的位置都找出来：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718154513.png" alt="image.png"></p>
<p>看图，这个微操作会在：</p>
<ul>
<li>FE且T1 的时候被执行</li>
<li>IND且T1且指令是 访存指令时执行</li>
<li>EX 且 T1 且指令是 ADD 和 LDA 时执行</li>
</ul>
<p>根据这三个条件，就可以推出下面那个巨长的式子。经过化简，就是下面那个 T1 开头的东西。</p>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718155059.png" alt="image.png"></p>
<h1 id="2-微程序控制器"><a href="#2-微程序控制器" class="headerlink" title="2. 微程序控制器"></a>2. 微程序控制器</h1><h2 id="2-1-设计思路"><a href="#2-1-设计思路" class="headerlink" title="2.1 设计思路"></a>2.1 设计思路</h2><p>之前我们说过，每个指令的机器周期内都会有不同的微操作，微程序的思路就是，按照节拍划分，将一个节拍内完成的所有微操作打包成一个微指令（注意，这叫微指令，而不是微命令，微命令说的是为了实现微操作CU发出的控制信号），然后每个机器周期都会有一串微指令。</p>
<p>然后一个指令执行期间，所有用到的微指令就构成了微程序，CPU 要执行一条指令只需要执行这个指令对应的微程序即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718155926.png" alt="image.png"></p>
<p>所以，我们可以认为，指令就是对一大堆微指令的封装。每一种指令都会对应一个微程序。</p>
<p>然后才用“存储程序”的思想，CPU 出厂前将所有指令的 “微程序”存入“控制器存储器”中。</p>
<p>微指令的基本格式：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718160128.png" alt="image.png"></p>
<p>因为所有微指令都在控制器内部的存储器中，所以需要指明下一条微指令的地址。</p>
<h2 id="2-2-微程序控制器的基本结构"><a href="#2-2-微程序控制器的基本结构" class="headerlink" title="2.2 微程序控制器的基本结构"></a>2.2 微程序控制器的基本结构</h2><p>这个东西和 CPU 执行内存里面的指令很像，指令存放在内存中，微程序存放在 CU 内部的存储器 CM 中。</p>
<p>CM 中存储着各个微程序，微程序里面的微指令顺序存放。</p>
<p>CPU 需要将 PC 中的地址信息给 MAR，MAR 去访存，然后得到指令存到指令后存到 MDR 中。对应微程序，CU 内也有一个 CMAR，这个东西是 MAR 和 PC 功能的结合体。CU 根据 CMAR 找到数据后会存放到 CMDR 中，这个 CMDR 也有 IR 的功能。中间也会经过一个地址译码器。</p>
<p>总体结构如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718161410.png" alt="image.png"></p>
<p>流程就是箭头流程：</p>
<ul>
<li>外界将指令 OP 给微地址形成部件，微地址形成部件根据 OP 找到对应指令的微程序起始地址</li>
<li>经过时序逻辑，将地址交给 CMAR，然后顺着一路在 CM 中找到微程序中的微指令，放到 CMDR 中。</li>
<li>CMDR 根据微指令的操作控制，向外界发出控制信号</li>
</ul>
<h2 id="2-3-微程序控制器的工作原理"><a href="#2-3-微程序控制器的工作原理" class="headerlink" title="2.3 微程序控制器的工作原理"></a>2.3 微程序控制器的工作原理</h2><p>各个指令的取指周期、间址周期、中断周期都相同，所以会共用一份微程序，然后每个指令的执行周期，都会有他们各自的微程序。</p>
<p>上面不是说一个指令对应一个微程序么，怎么这里有说每个周期对应一个微程序，这个是物理上和逻辑上的区别，物理上确实是每个周期都有一个微程序，但是逻辑上，应该认为这些周期加起来才是这个指令的微程序。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718162940.png" alt="image.png"></p>
<p>根据图可以看出来，取指周期、间址周期、中断周期都是一份，下面都是每个指令自己的微程序。</p>
<p>执行周期结束后，这里显示的是返回 #0 位置，等待取指，但是如果这个时候顺序逻辑接收到了中断信号，顺序逻辑会执行中断周期微程序。取指周期同理，如果顺序逻辑发现地址码是一个形式地址，则进入间址周期，如果不是就进入执行周期。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718165230.png" alt="image.png"></p>
<h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718165332.png" alt="image.png"></p>
<h1 id="3-微指令设计"><a href="#3-微指令设计" class="headerlink" title="3. 微指令设计"></a>3. 微指令设计</h1><p>这里探讨的就是微指令的具体格式如何设计，如何 <strong>根据微指令发出相应的微命令</strong>，也就是如何让微程序控制器发出控制信号。</p>
<p>有的微命令可以并行执行，比如 <code>M(MAR) -&gt; MDR; PC + 1 -&gt; PC</code> 这种的，因此一个微指令可以包含多个微命令。</p>
<h2 id="3-1-微指令格式"><a href="#3-1-微指令格式" class="headerlink" title="3.1 微指令格式"></a>3.1 微指令格式</h2><p>首先引入两个概念：</p>
<ul>
<li>相容性微命令：可以并行完成的微命令</li>
<li>互斥性微命令：不允许并行完成的微命令</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718174322.png" alt="image.png"></p>
<p>水平型的微指令就是之前那种，前面有 n 位的操作控制，因为他可以并行的执行一些微命令，所以这个操作控制码可能会比较长，所以编写出来的微程序就会像图里那样比较的胖。</p>
<p>垂直型微指令里面东西多，一条微指令只能定义一个微命令，由操作码字段规定具体功能，所以他写的微程序会比较多，执行慢，显得高。</p>
<p>最后一种混合型不说了。</p>
<p>前面两种重点看看。下面说说水平型的微指令如何设计，<strong>如何用 n 个比特来表示并行的多个微命令</strong>。</p>
<h2 id="3-2-微指令的编码方式"><a href="#3-2-微指令的编码方式" class="headerlink" title="3.2 微指令的编码方式"></a>3.2 微指令的编码方式</h2><p>就是如何让微指令表示一系列的控制信号？讨论的就是水平型微指令的前半部分 操作控制。</p>
<p>前面两种方式考的最多。</p>
<p><strong>1）直接译码方式（直接控制方式）</strong></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718175221.png" alt="image.png"></p>
<p>就是说操作控制的 n 位分别代表 n 中信号，拿到微指令后，只需要激活操作控制码里面为 1 的位对应的信号即可。</p>
<p>比如这里我们假设第一个bit位对应的就是 <code>(PC) -&gt; MAR</code>，最后一个 bit 位表示的是 <code>1 -&gt; R</code>，那我们给出一个微指令 <code>10000000001...</code> 代表的就是并行的执行 <code>(PC) -&gt; MAR; 1 -&gt; R</code>。</p>
<p>优缺点已经给出了。</p>
<p><strong>2）字段直接编码方式</strong></p>
<p>啥意思，就是说我们给操作控制分段，可以并行执行的微命令放到不同的段中，互斥的微命令放到一个段内。且这里引入了译码器，会将段内 n 个比特位译码为最多 （2^n） - 1 种不同的微命令（如果段内全0表示不发出微命令，所以-1）。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718180017.png" alt="image.png"></p>
<p>这种东西为啥可以缩短微指令字长？看个例题：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718180058.png" alt="image.png"></p>
<p>这里互斥的微命令有 5 类，就对应 5 个段，然后根据命令数规划每个段的bit数，最后得到 15，比 33 少多了。</p>
<p><strong>3）字段间接编址方式</strong></p>
<p>这种了解即可：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718180307.png" alt="image.png"></p>
<p>优点就是进一步的缩短微指令字长；缺点很明显，削弱了微指令的并行控制能力。</p>
<h2 id="3-3-微指令的地址形成方式"><a href="#3-3-微指令的地址形成方式" class="headerlink" title="3.3 微指令的地址形成方式"></a>3.3 微指令的地址形成方式</h2><p>就是说，如何确定下一条要执行的微命令的存放地址，6 种方式，其中1 和 3 比较常考：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718180744.png" alt="image.png"></p>
<p>这个玩意它可能出这种题：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718181046.png" alt="image.png"></p>
<p>问了半天其实就是想问 CM 里面总共存了多少条指令。</p>
<h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718181142.png" alt="image.png"></p>
<h1 id="4-微程序控制单元的设计"><a href="#4-微程序控制单元的设计" class="headerlink" title="4. 微程序控制单元的设计"></a>4. 微程序控制单元的设计</h1><p>这个和之前的硬布线控制单元设计基本上一个流程，也是那几步：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718215723.png" alt="image.png"></p>
<p>还以取指周期为例，分析各个阶段的微操作序列：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718220118.png" alt="image.png"></p>
<p>最后一步是 <code>OP(IR) -&gt; 微地址形成部件</code>，就是说将微指令的操作码发送给微地址形成部件，根据 OP 来选择执行哪个微程序。</p>
<p>然后将这些步骤安排到节拍中：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718220350.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>CU 怎么确定微指令 a 的地址？很简单，取指周期的第一个微指令a 就直接把它放在 CM 中的 #0 位置，执行指令时自动去找 #0。</li>
<li>然后怎么继续执行微指令b？很简单，微指令a 中使用下址来指向微指令 b。</li>
<li>使用下址的话，就需要一个 PC + 1 的操作，所以执行完微指令a 以后，需要将下址取出来，放到 CMAR 中供下次取指，这个步骤需要花费一个节拍</li>
<li>最后一步，将指令的 OP 给了微地址形成部件，微地址形成部件会形成该指令对应的执行周期的微程序的存放地址，所以最后要把执行周期的微程序地址放在 CMAR 中（这里假设没有间址周期）</li>
</ul>
<p>还有最后两步：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718221302.png" alt="image.png"></p>
<p>第三步就是前面 3.2 和 3.3 说过的，如何设计微指令。</p>
<p>第四步就是最后设计一堆指令，这个不说了。</p>
<h2 id="扩展：微程序设计分类"><a href="#扩展：微程序设计分类" class="headerlink" title="扩展：微程序设计分类"></a>扩展：微程序设计分类</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718221607.png" alt="image.png"></p>
<h2 id="比较：硬布线和微程序"><a href="#比较：硬布线和微程序" class="headerlink" title="比较：硬布线和微程序"></a>比较：硬布线和微程序</h2><p> <img src="https://gitee.com/pthef/imgrepo/raw/master/20230718221743.png" alt="image.png"></p>
<h2 id="总结：微程序控制器"><a href="#总结：微程序控制器" class="headerlink" title="总结：微程序控制器"></a>总结：微程序控制器</h2><p> <img src="https://gitee.com/pthef/imgrepo/raw/master/20230718221852.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>10-中央处理器</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-10-%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/</url>
    <content><![CDATA[<p>这一章深入 CPU，主要学习以下内容：CPU结构与功能、指令执行过程、数据通路的功能和结构、控制器的功能和原理、流水线。</p>
<span id="more"></span>

<h1 id="1-CPU-结构与功能"><a href="#1-CPU-结构与功能" class="headerlink" title="1. CPU 结构与功能"></a>1. CPU 结构与功能</h1><p>CPU 总共有 5 个功能：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230716213831.png" alt="image.png"></p>
<p>说一下第二个功能，啥叫操作信号？</p>
<p>比如我们要执行一条加法指令，这条信号并不能一次性执行完，将这条指令从主存放到 CPU 的 IR 中，然后控制器会分析指令，发现这个加法指令要从主存中取得操作数，还要放到 ACC 中，这一系列操作就是微指令，这里的操作信号说的就是这个，每个微指令都会有控制信号。</p>
<h2 id="1-1-运算器和控制器的功能"><a href="#1-1-运算器和控制器的功能" class="headerlink" title="1.1 运算器和控制器的功能"></a>1.1 运算器和控制器的功能</h2><p>分开看运算器和控制器的功能：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717121218.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>取指令，自动形成指令地址：这个说的就是 PC + “1” 这个问题</li>
<li>分析指令，产生操作数的有效地址：就是说知道这个指令是干啥的，然后进行一个操作数寻址</li>
<li>执行指令：这里又说到了操作信号，就是说控制器拿到指令后，根据指令发出操作信号来执行微指令</li>
<li>中断：一般来说 CPU 执行完一条指令都需要进行一个中断检查，OS 里面详细说过的</li>
</ul>
<h2 id="1-2-运算器基本结构"><a href="#1-2-运算器基本结构" class="headerlink" title="1.2 运算器基本结构"></a>1.2 运算器基本结构</h2><p>运算器里面有 ALU 算数逻辑单元，然后和 ALU 直接交互的存储器就是<font color='red'>通用寄存器组</font>，比如 AX、BX、CX、DX、SP 等（和上面说过的x86寄存器几乎一样），这些寄存器用于存放操作数和各种地址信息等。SP 是堆栈信息。</p>
<p>AX-DX 这些寄存器还可以划分成两块，比如 AX 的高八位是 AH，低八位是 AL。我们这里把通用寄存器 AX - DX 简称叫 R0 - R3。</p>
<h3 id="1-2-1-专用数据通路"><a href="#1-2-1-专用数据通路" class="headerlink" title="1.2.1 专用数据通路"></a>1.2.1 专用数据通路</h3><p>通用寄存器和 ALU 肯定要连接，寄存器既可以往 A 端输入数据，也可以往 B 端输入数据，所以寄存器和 A B 都有连线，如果寄存器是 16 bit 的话，就需要16根线，这里简化一下，一根线得了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717122117.png" alt="image.png"></p>
<p>每个寄存器都要和 ALU 通讯，所以都要连线，也就有了上面这个图，这个就叫 <font color = 'red'>专用数据通路方式</font>：根据指令执行过程中的数据和地址的流动方向安排连接线路。</p>
<p>这种方式有个问题：每个寄存器都在同时给 ALU 发数据，这种肯定是不行的，咋办？第一种方式，给 A 和 B 两端加一个 MUX 多路选择器，根据控制信号选择一路输入：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717122550.png" alt="image.png"></p>
<p>比如我们要执行 <code>add r0, r1</code> 这个指令，可以给 C1 一个 00 信号，连通 R0，给 C2 一个 01 信号，连通 R1。</p>
<p>或者使用三态门，可以控制每一路是否输出：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717122730.png" alt="image.png"></p>
<p>三态门上面还有个 R0out，可以控制当前线路是否接通。</p>
<p>这种专用数据通路方式性能很高，基本不存在数据冲突，但是结构复杂，硬件量大，不易实现。</p>
<h3 id="1-2-2-单总线方式"><a href="#1-2-2-单总线方式" class="headerlink" title="1.2.2 单总线方式"></a>1.2.2 单总线方式</h3><p>直接看图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717123543.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>输入端暂存寄存器：一方面，暂存一个操作数，比如先把 R0 内容存到寄存器里，然后将 R1 输出，ALU必须两端同时有效，但是单总线只能同时传送一个操作数。有时一条指令要直接从主存读入数据，这个数据就可以放在暂存寄存器里，防止破坏通用寄存器里的值。</li>
<li>移位寄存器：对计算结果进行移位运算。另外 ALU 算完之前是不能输出结果的，必须等到电压稳定后才能输出，所以移位寄存器同时也会暂存计算结果，然后上面连了一个三态门，等到电压稳定后才会连通线路，将结果从移位寄存器里输出回总线，所以也有暂存寄存器的功能。</li>
<li>ACC 累加寄存器：用于暂存 ALU 运算的结果信息，用于实现加法运算，这个在之前的数据计算章节老见。</li>
</ul>
<p>另外 PSW 有点复杂，之前在数据计算章节也说过：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717124118.png" alt="image.png"></p>
<h2 id="1-3-控制器基本结构"><a href="#1-3-控制器基本结构" class="headerlink" title="1.3 控制器基本结构"></a>1.3 控制器基本结构</h2><p>这个可就复杂了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717124500.png" alt="image.png"></p>
<p>解释：</p>
<ul>
<li>PC 能看懂吧，PC 有自增功能，不说了</li>
<li>IR 也很好理解，指令寄存器里面放指令，指令分为 OP 和 地址码 AD</li>
<li>指令译码器：对 OP 进行译码，知道当前指令要干啥，所以 OP 会输入到译码器 ID 中</li>
<li>微操作信号发生器：根据 IR 的内容、PSW 的内容以及时序信号，产生控制整个计算机系统所需的各种控制信号，其结构有组合逻辑性型和存储逻辑型两种</li>
<li>时序系统：用于产生各种时序信号，它们都是由统一时钟 CLOCK 分频得到</li>
<li>后面的 MAR 和 MDR 就不说了</li>
</ul>
<p>来根据这个图理一理执行一条指令到底咋办的，比如要执行一条从内存中取数的指令：</p>
<ol>
<li>PC 指向这条指令，然后通过 PCout 将值输出，去内存中取指令，然后顺着 IRin 将指令输入到 IR 中</li>
<li>IR 将 OP 发送给 ID，ID 一看，是个取内存的指令，然后通过微操作信号发生器开始执行微指令</li>
<li>将 IR 中的 Ad 地址码通过 <code>AdIRout</code> 输出到 CPU 总线上，MARin 接收这个地址码，然后交给地址总线去内存中拿数</li>
<li>内存找到数啦，发送给数据总线，通过 <code>MDRinE</code>  让 MDR 从数据总线拿数，然后通过 <code>MDRout</code> 将数据传输给 CPU 总线，看看下一步咋办。</li>
</ol>
<p>这里注意下 MDR 就行了，MDR 的 IO 线如果后面加 E ，就是和数据总线连着的，没有就是和 CPU 总线相连。</p>
<p>中间的三个部分：指令译码器、微操作信号发生器、时序系统，就是<font color='red'> CU 控制单元</font>.</p>
<h2 id="1-4-CPU-结构"><a href="#1-4-CPU-结构" class="headerlink" title="1.4 CPU 结构"></a>1.4 CPU 结构</h2><p>把上面两张图连在一起就变成了 CPU 的结构：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717155514.png" alt="image.png"></p>
<p>橙色的都是用户可见的：</p>
<ul>
<li>PSW 我们在进行条件跳转的时候会用到，因为前面说过一点，条件跳转的比较就是相减然后通过 PSW 的四个标志位来判断</li>
<li>ACC 老用，做各种运算的时候</li>
<li>PC 在跳转的时候我们也会直接使用</li>
</ul>
<p>剩下的灰色的寄存器我们是感觉不到他们的存在的。</p>
<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717160023.png" alt="image.png"></p>
<h1 id="2-指令执行过程"><a href="#2-指令执行过程" class="headerlink" title="2. 指令执行过程"></a>2. 指令执行过程</h1><h2 id="2-1-指令周期"><a href="#2-1-指令周期" class="headerlink" title="2.1 指令周期"></a>2.1 指令周期</h2><p>就是 CPU 从主存中取出并执行一条指令所需的全部时间。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717160406.png" alt="image.png"></p>
<p>一个指令周期通常用若干个机器周期来表示，机器周期又称为 CPU 周期，意思就是完成一个子工作所需要的时间，比如取指令就花费一个机器周期，然后取出有效地址花费一个机器周期，最后指令执行也花费一个机器周期。</p>
<p>一个机器周期又包含若干个时钟周期，也叫节拍，T周期或者CPU时钟周期，他是CPU 操作的<font color='red'>最基本单位</font>：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717160851.png" alt="image.png"></p>
<p>里面 CLK 的一上一下，就是一个时钟周期，如果一个 CPU 是 3.0GHz 的，就是说一个CPU一秒钟内有 3G 个这种周期。</p>
<p>如果说每个子操作的机器周期相同，就是定长机器周期，如果不一样，就是不定长。对于不同的指令，指令周期可能不同，对于不同的微操作，机器周期也可能不一样。比如下图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717161446.png" alt="image.png"></p>
<p>其中这个间址周期说一下，间接寻址说的就是地址码 Ad 指向一个指针，这个指针才指向了真正的操作数，所以访存拿到真正的操作数这个过程也需要一个机器周期。</p>
<h2 id="2-2-指令周期流程"><a href="#2-2-指令周期流程" class="headerlink" title="2.2 指令周期流程"></a>2.2 指令周期流程</h2><p>如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717161656.png" alt="image.png"></p>
<p>四个周期都有 CPU 的访存，只是目的不一样：</p>
<ul>
<li>取指周期：从主存中取出指令</li>
<li>间址周期：从主存中取出有效地址</li>
<li>执行周期：根据有效地址取出操作数</li>
<li>中断周期：保存程序断点，这个的意思是执行中断处理程序，而不是专指时钟中断然后进程调度</li>
</ul>
<p>CPU 如何知道当前指令正处于什么阶段？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717161928.png" alt="image.png"></p>
<p>通过这四个触发器就行了。</p>
<h2 id="2-3-取指周期-指令周期的数据流"><a href="#2-3-取指周期-指令周期的数据流" class="headerlink" title="2.3 取指周期-指令周期的数据流"></a>2.3 取指周期-指令周期的数据流</h2><p>流程如下：</p>
<ul>
<li>PC 里面记录了要执行指令的地址，将 PC 的值发送给 MAR，计作：<code>(PC) -&gt; MAR</code></li>
<li>CU 发出控制信号，经过控制总线传给主存，这里发送的是读信号，告诉主存要马上要读主存了，计作：<code>1 -&gt; R</code>，这里的 R 指 Read</li>
<li>将 MAR 的内容经过地址总线给主存，主存进行寻址，然后将数据通过数据总线给 MDR，计作：<code>M(MAR) -&gt; MDR</code>，意思是 Memory 里 MAR 指向位置的数据给 MDR</li>
<li>MDR 中的内容（指令）发送给 IR，计作：<code>(MDR) -&gt; IR</code></li>
<li>CU 发送控制信号，形成下一条指令地址，也就是 CU 让 PC + “1”，计作：<code>(PC) + 1 -&gt; PC</code></li>
</ul>
<p>如图所示：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717162647.png" alt="image.png"></p>
<h2 id="2-4-间址周期-指令周期的数据流"><a href="#2-4-间址周期-指令周期的数据流" class="headerlink" title="2.4 间址周期-指令周期的数据流"></a>2.4 间址周期-指令周期的数据流</h2><p>如果指令采用了间接寻址，就是地址码是一个形式地址，指向了主存的指针，就需要进入这个周期：</p>
<ul>
<li>将指令中的形式地址发送给 MAR，计作：<code>Ad(IR) -&gt; MAR</code> 或者 <code>Ad(MDR) -&gt; MAR</code>，MDR 也可以，因为这时刚取指，MDR 保存的还是指令</li>
<li>CU 发出控制信号，启动主存做读操作，计作：<code>1 -&gt; R</code></li>
<li>将 MAR 所指的主存中的内容经过数据总线送给 MDR，计作：<code>M(MAR) -&gt; MDR</code></li>
</ul>
<p>这个时候，MDR 就存放着操作数的有效地址 EA，可以就这么着，待会执行阶段直接把 MDR 中的东西送给 MAR 去取操作数；有的计算机也会将 MDR 中的 EA 给到 IR 中，替换掉 IR 中的形式地址 A，计作：<code>(MDR) -&gt; Ad(IR)</code></p>
<p>流程如图所示：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717163443.png" alt="image.png"></p>
<p>然后就会进入执行周期。执行周期的任务是根据 IR 中的指令字的操作码和操作数通过 ALU 操作产生执行结果。不同的指令执行周期操作不同，因此没有统一的数据流向，这里先不讨论。</p>
<h2 id="2-5-中断周期-指令周期的数据流"><a href="#2-5-中断周期-指令周期的数据流" class="headerlink" title="2.5 中断周期-指令周期的数据流"></a>2.5 中断周期-指令周期的数据流</h2><p>这里暂且理解成时钟中断，暂停当前任务取完成其他任务，为了能够恢复当前任务，需要保存断点。就是执行中断处理程序，注意，这个可不是 OS 里面说的时钟中断进程调度。</p>
<p>会使用堆栈来保存断点，这里 SP 表示栈顶指针，入栈的操作是先修改指针，再放入数据：</p>
<ul>
<li>CU 控制将 SP - 1，修改后的地址送入 MAR，计作：<code>(SP) - 1 -&gt; SP; (SP) -&gt; MAR</code>，这里为啥是 SP - 1 啊，在09机器代码一章说过，计算机内低地址一般是栈顶</li>
<li>CU 发出控制信号，启动主存做写操作，计作：<code>1 -&gt; W</code></li>
<li>将断点（PC 内容）送入 MDR，计作：<code>(PC) -&gt; MDR</code></li>
<li>CU 控制将中断服务程序的入口地址(由向量地址形成部件产生)送入 PC，计作：<code>向量地址 -&gt; PC</code></li>
</ul>
<p>如图所示：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717164428.png" alt="image.png"></p>
<h2 id="2-6-指令执行方案"><a href="#2-6-指令执行方案" class="headerlink" title="2.6 指令执行方案"></a>2.6 指令执行方案</h2><p>一个指令周期通常包含几个时间段（执行步骤），每个步骤完成指令的一部分功能，几个依次执行的步骤完成指令的全部功能。直接看图，懒得写了：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717165011.png" alt="image.png"></p>
<h2 id="2-7-总结"><a href="#2-7-总结" class="headerlink" title="2.7 总结"></a>2.7 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717165030.png" alt="image.png"></p>
<h1 id="3-数据通路-单总线结构"><a href="#3-数据通路-单总线结构" class="headerlink" title="3. 数据通路-单总线结构"></a>3. 数据通路-单总线结构</h1><p>数据的流动大体就是三种方式：寄存器和寄存器、寄存器和主存、寄存器和 ALU。往后就是说说这三种数据传输怎么实现。</p>
<h2 id="3-1-数据通路"><a href="#3-1-数据通路" class="headerlink" title="3.1 数据通路"></a>3.1 数据通路</h2><p>数据通路就是数据在功能部件之间的传送的途径，简单说就是信息从哪里开始，中间经过哪些部件，最后传到哪里。</p>
<p>这些数据通路由 CU 里面的微操作信号发生器控制，他负责建立数据通路，比如之前 CPU 图里面的各种 R0in，R0out，MARin 这种的控制数据流向的都适合微操作信号发生器相连。</p>
<p>数据通路的基本结构：</p>
<ol>
<li>CPU 内部单总线方式：CPU内部总线只有一根，所以同一时间只允许两个部件传输信息</li>
<li>CPU 内部多总线方式：就是内部总线多根呗，比如有三根，就可以支持3组部件同时传递信息</li>
<li>专用数据通路方式：比如 PC 要和 IR 通讯，就会在 PC 和 IR 之间专门连一根线</li>
</ol>
<p>这里我们着重看单总线方式。</p>
<h2 id="3-2-数据传输"><a href="#3-2-数据传输" class="headerlink" title="3.2 数据传输"></a>3.2 数据传输</h2><h3 id="3-2-1-寄存器通讯"><a href="#3-2-1-寄存器通讯" class="headerlink" title="3.2.1 寄存器通讯"></a>3.2.1 寄存器通讯</h3><p>这里用 PC 到 MAR 的数据通讯为例，PC 将数据交给 MAR 的流程为：</p>
<ul>
<li>CU 发送控制信号，打开 PCout 让 PC 的数据发送到总线上：<code>(PC) -&gt; BUS</code></li>
<li>CU 发送控制信号，打开 MARin 让总线上的数据流至 MAR：<code>BUS -&gt; MAR</code></li>
<li>总体的流程就是：<code>(PC) -&gt; BUS -&gt; MAR</code>，PC 上的括号有的时候可以不加</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717215129.png" alt="image.png"></p>
<h3 id="3-2-2-CPU和主存通讯"><a href="#3-2-2-CPU和主存通讯" class="headerlink" title="3.2.2 CPU和主存通讯"></a>3.2.2 CPU和主存通讯</h3><p>然后再来看主存和CPU之间的数据传送：</p>
<ul>
<li>在上面的基础上，MAR 中是 PC 的值指向下一条指令，CU 向主存发出读命令（通过控制总线，这里没画），<code>1 -&gt; R</code></li>
<li>CU 控制 MARout 有效，将MAR中的地址发送到地址总线（也没画）去取指令，然后主存将指令通过数据总线发给 MDR（CU控制MDRInE有效）：<code>MEM(MAR) -&gt; MDR</code></li>
<li>再将MDR数据发送给 IR，这个简单，就是寄存器之间的数据传送，直接发送到CPU内部总线即可：<code>MDR -&gt; BUS -&gt; IR</code></li>
</ul>
<h3 id="3-2-3-寄存器和ALU通讯"><a href="#3-2-3-寄存器和ALU通讯" class="headerlink" title="3.2.3 寄存器和ALU通讯"></a>3.2.3 寄存器和ALU通讯</h3><p>最后看看执行算数或逻辑运算，比如要执行一条加法指令：</p>
<ul>
<li>将 IR 中的地址码发送给 MAR：<code>Ad(IR) -&gt; BUS -&gt; MAR</code>，CU 会依次控制 IRout 和 MARin 有效。</li>
<li>CU 向主存发出读信号：<code>1 -&gt; R</code></li>
<li>访存，并放入 MDR：<code>MEM(MAR) -&gt; 数据总线 -&gt; MDR</code>，CU 会让 MDRinE 有效</li>
<li>将操作数放入 Y 寄存器（就是上面 ALU 结构里面的暂存寄存器）：<code>MDR -&gt; BUS -&gt; Y</code></li>
<li>上面是其中一个加数，另一个加数在 ACC 累加寄存器里，同时接通 ACCout 和 Yout 将两个操作数发送给 ALU：<code>(ACC) + (Y) -&gt; Z</code>，然后CU会告诉 ALU 你要进行加法，结果会被暂存到 Z 寄存器中。</li>
<li>等稳定后，CU 撤销 ACCout 和 ALUin 信号，让 Bus 恢复空闲，然后让 Zout 有效，将结果存回 ACC：<code>Z -&gt; ACC</code></li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717220521.png" alt="image.png"></p>
<h3 id="3-2-4-例题"><a href="#3-2-4-例题" class="headerlink" title="3.2.4 例题"></a>3.2.4 例题</h3><p>取指周期：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717221649.png" alt="image.png"></p>
<p>这里解释一点东西：</p>
<ul>
<li><code>((R0)) + (R1) -&gt; (R0)</code>，这里面每个括号的意思都不一样，左边 R0 的内层括号，指的是取出 R0 的值，是个地址。外层括号说的是，根据这个地址去访存，拿到真正的操作数。R1的括号就是取值。右边 R0 的括号指的是将结算结果会写到 R0 指向的主存里面。</li>
<li><code>(PC) + 1 -&gt; PC</code>，这个可以放在 2 里面，因为取出指令以后就可以加1了，当然也可以后面加个第五步</li>
</ul>
<p>间址周期：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717222249.png" alt="image.png"></p>
<p>再解释一点：</p>
<ul>
<li>我们发现这个间址周期直接把操作数从主存读入到 MDR 里面了，和间接地址一点关系没有，(R0) 其实就是一个直接地址。这个和教材有关系，有的教材认为，间址周期是想办法拿到直接地址，然后将直接地址拼到 IR 上；有的则认为间址周期需要将操作数读入内存。反正横竖都是这么个流程</li>
</ul>
<p>执行周期：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717222932.png" alt="image.png"></p>
<p>为啥最后直接 M(MAR) 了，不是要存回 R0 指向的主存么？很简单，之前已经将 R0 放到 MAR 里面了，而且没有更新，所以直接根据 MAR 访存即可。</p>
<h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p>说一点啊，区分一下内部总线和系统总线：</p>
<ul>
<li>内部总线：CPU 内部总线</li>
<li>系统总线：比如控制总线，数据总线，地址总线这种</li>
</ul>
<p>这一块，什么控制信号，微操作这个，有可能是考大题的。</p>
<h1 id="4-数据通路-专用数据通路"><a href="#4-数据通路-专用数据通路" class="headerlink" title="4. 数据通路-专用数据通路"></a>4. 数据通路-专用数据通路</h1><p>这个其实和单总线流程上差不多，只是各个寄存器之间可能存在通路，这样的话数据传输就可以跳过 CPU 总线。</p>
<p>这里举个例子即可，看看专用数据通路下，取指令如何操作：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717223657.png" alt="image.png"></p>
<p>反正把握好一个方向，取指周期的数据流动一定是：<code>PC -&gt; MAR -&gt; 访存 -&gt; MDR &amp; PC+1 -&gt; IR</code>，在此基础上根据这个图看看控制信号怎么给即可。</p>
<h2 id="4-1-例题"><a href="#4-1-例题" class="headerlink" title="4.1 例题"></a>4.1 例题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717224416.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717224440.png" alt="image.png"></p>
<p>b 和 微操作信号发生器相连，这里推测出他是 IR，毕竟 IR 需要将 OP 发送给微操作发生器。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717224633.png" alt="image.png"></p>
<p>这里可以加两步：<code>(PC) + 1 -&gt; PC</code> 和 <code>Op(IR) -&gt; 发生器</code></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717224843.png" alt="image.png"></p>
<p>取指的是从主存拿一个数过来放到 ACC 中，就是找一条 MDR 到 ALU 到 ACC 的通路，这里可以理解成将操作数读入 MDR，然后发到 ALU 中进行 + 0，然后返回到 ACC。</p>
<p>4 5 6 题连着看：4. 将加数X从主存中读到 ACC 中暂存；5. 将另一个加数Y从主存中读入到 MDR 然后执行 X + Y；6. 将结果写回主存 Z 位置。</p>
<p>第四题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X -&gt; MAR               // 这里 x 是个值，所以不用加括号取值</span><br><span class="line">M(MAR) -&gt; MDR</span><br><span class="line">(MDR) -&gt; ALU -&gt; ACC</span><br></pre></td></tr></table></figure>

<p>第五题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Y -&gt; MAR</span><br><span class="line">M(MAR) -&gt; MDR</span><br><span class="line">(MDR) -&gt; ALU, (ACC) -&gt; ALU</span><br><span class="line">ALU -&gt; ACC</span><br></pre></td></tr></table></figure>

<p>第六题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Z -&gt; MAR</span><br><span class="line">(ACC) -&gt; MDR</span><br><span class="line">(MDR) -&gt; M(MAR)</span><br></pre></td></tr></table></figure>

<h2 id="4-2-总结"><a href="#4-2-总结" class="headerlink" title="4.2 总结"></a>4.2 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230717225626.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>13-总线</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-13-%E6%80%BB%E7%BA%BF/</url>
    <content><![CDATA[<p>前面提到过多次了，什么数据总线，控制总线，地址总线啥啥的，这章就详细看看总线是个什么玩意儿。</p>
<span id="more"></span>

<h1 id="1-总线概述"><a href="#1-总线概述" class="headerlink" title="1. 总线概述"></a>1. 总线概述</h1><p>先看张图：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719163626.png" alt="image.png"></p>
<p>假如说这是一根数据总线，这里说的是一根，其实一个总线里面包含了多根信号线，每根信号线可以发送一个 bit，所以这跟总线可以并行的发送 4bit 数据。</p>
<p>同一时刻只能由一个部件发送数据，但是可以有多个部件接受数据。</p>
<h2 id="1-1-总线定义"><a href="#1-1-总线定义" class="headerlink" title="1.1 总线定义"></a>1.1 总线定义</h2><p>总线是一组能为多个部件 <strong>分时共享</strong> 的公共信息传送线路。有了总线，就可以很方便的在主板上增加硬件，提高 IO 设备和主机之间连接的灵活性。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719164135.png" alt="image.png"></p>
<h2 id="1-2-总线特性"><a href="#1-2-总线特性" class="headerlink" title="1.2 总线特性"></a>1.2 总线特性</h2><p>四个：</p>
<ul>
<li>机械特性：尺寸、形状、管脚数、排列顺序</li>
<li>电气特性：传输方向和有效的电平范围</li>
<li>功能特性：每根传输线的功能（地址、数据、控制）</li>
<li>时间特性：信号的时序关系</li>
</ul>
<p>电气特性说一下，方向指的就是总线的传输防线，比如 CPU 可以通过地址总线给 主存 发送地址，但是主存不能通过这根线根 CPU 通讯。而 MDR 就支持 CPU 和 主存的双向通讯。</p>
<p>电平范围说的是，我们可以规定 0.1 - 0.5v 是低电平，4.8 - 5.2v 是高电平。</p>
<h2 id="1-3-总线分类"><a href="#1-3-总线分类" class="headerlink" title="1.3 总线分类"></a>1.3 总线分类</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719164556.png" alt="image.png"></p>
<h3 id="1-3-1-串行总线和并行总线"><a href="#1-3-1-串行总线和并行总线" class="headerlink" title="1.3.1 串行总线和并行总线"></a>1.3.1 串行总线和并行总线</h3><ul>
<li>串行总线：每次传输只能发送一个 bit 数据，举例就是 USB。</li>
<li>并行总线：一根总线有多个信号线，可以并行的发送多个 bit 位。</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719164937.png" alt="image.png"></p>
<p>因为并行总线内的各个信号线离得近，可能发生干扰，所以数据不能发的特别快，不然容易发生数据跳变。</p>
<p>所以，不能说并行总线的速度一定比串行总线的速度快。</p>
<h3 id="1-3-2-片内、系统、通信"><a href="#1-3-2-片内、系统、通信" class="headerlink" title="1.3.2 片内、系统、通信"></a>1.3.2 片内、系统、通信</h3><p>片内总线：芯片内部的总线。之前的 CPU 内部总线就是属于这个，不说了。</p>
<p>系统总线：计算机系统内各个功能部件（CPU、主存、IO接口）之间相互连接的总线。这里会根据功能再分出三种：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719165510.png" alt="image.png"></p>
<p>通信总线：用于计算机系统之间活着计算机系统与其他系统（比如远程通讯设备、测试设备）之间信息传送的总线，通信总线也叫外部总线。比如网线就是外部总线。</p>
<h3 id="1-3-3-系统总线结构"><a href="#1-3-3-系统总线结构" class="headerlink" title="1.3.3 系统总线结构"></a>1.3.3 系统总线结构</h3><p>这里先提一句，后面会详细讲这个系统总线。</p>
<p><strong>单总线结构</strong></p>
<p>将三种总线：数据、地址、控制 整合成一根大的系统总线，然后让各个部件连接到这个总线上。系统总线会按传送信息的不同细分使用的是里面的哪根线。</p>
<p>各个部件互斥的使用这一根系统总线，而且 虽然总线的速度很快，但是这跟总线还连接着很多 IO 设备，IO 设备和 CPU 主存 之类的数据传输就比较慢了，这就导致总线的性能被浪费。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719170217.png" alt="image.png"></p>
<p><strong>双总线结构</strong></p>
<p>解决了上面 IO 设备速度慢浪费性能的问题，可以将主存总线设计的很快，IO总线设计的慢一点：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719170457.png" alt="image.png"></p>
<p>这里面的通道在 OS 的 IO设备里面讲到过，这里不说了。</p>
<p><strong>三总线结构</strong></p>
<p>三根总线：</p>
<ul>
<li>IO 总线：CPU 和一些慢速的 IO 设备进行连接，比如键盘</li>
<li>主存总线：CPU 和 主存之间交互</li>
<li>DMA 总线：DMA 直接内存访问，用于连接主存和一些比较快的 IO 设备，比如磁盘</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719170817.png" alt="image.png"></p>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719171120.png" alt="image.png"></p>
<h1 id="2-总线性能指标"><a href="#2-总线性能指标" class="headerlink" title="2. 总线性能指标"></a>2. 总线性能指标</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719220244.png" alt="image.png"></p>
<p>好像没啥解释的，说一下第二个时钟周期，里面说现在有的计算机总线时钟周期可能是桥接器提供，啥意思？</p>
<p>就是现在的好多计算机都是四总线设计，根据连接的硬件速度不同总线速度也不同，桥接器就是在各个总线的交叉口上调配各个不同速度总线一起工作。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719220726.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719222411.png" alt="image.png"></p>
<h2 id="2-1-例题"><a href="#2-1-例题" class="headerlink" title="2.1 例题"></a>2.1 例题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719221439.png" alt="image.png"></p>
<p>这里说的地址和数据总线复用其实很好理解，就是同一根线，第一次用它发就是发地址，第二次用它发就是发数据。</p>
<p>第一题说一下，上升沿和下降沿各传送一次数据，说的就是一个时钟周期内，低电平到高电平发一次，高变低再发一次，所以一次时钟周期发送两次数据，得到 <strong>总线周期 &#x3D; 1&#x2F;2 个时钟周期</strong>。</p>
<p>然后总线工作频率 &#x3D; 每秒钟多少个时钟周期（时钟频率）&#x2F; 多少个时钟频率发一次数据（N），这里就得到 66M &#x2F; （1&#x2F;2）也就是 132 MHz。</p>
<p>所以每秒钟总线可以发送 132 M 个数据，乘上数据长度 32 bit，也就得到了带宽。</p>
<p>第二题就注意下什么是猝发就行了。</p>
<h2 id="2-2-总结"><a href="#2-2-总结" class="headerlink" title="2.2 总结"></a>2.2 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719222432.png" alt="image.png"></p>
<h1 id="3-总线仲裁"><a href="#3-总线仲裁" class="headerlink" title="*3. 总线仲裁"></a>*3. 总线仲裁</h1><p>408 不考。</p>
<p>多个部件要请求总线的控制权，如何安排不同的部件什么时候上总线，就是总线仲裁，归根到底就是一种总线调度问题。</p>
<p>有个基本概念：当一个部件上了总线，他就是主设备，然后他可以要求给谁传输数据，这个设备就是从设备，从设备只能被动的从主设备上接受指令和数据。</p>
<h1 id="4-总线的操作和定时"><a href="#4-总线的操作和定时" class="headerlink" title="4. 总线的操作和定时"></a>4. 总线的操作和定时</h1><p>占用总线的一对设备如何进行数据传输。</p>
<h2 id="4-1-总线的四个阶段"><a href="#4-1-总线的四个阶段" class="headerlink" title="4.1 总线的四个阶段"></a>4.1 总线的四个阶段</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719223329.png" alt="image.png"></p>
<p>这个图十分好理解，不说了，下面会按照从上往下的顺序，依次说说这四种总线定时方式。</p>
<h2 id="4-2-同步定时方式"><a href="#4-2-同步定时方式" class="headerlink" title="4.2 同步定时方式"></a>4.2 同步定时方式</h2><p>就是说会有一个东西在旁边数拍子，在每个节拍，主设备和从设备必须完成相应的步骤，最终跟着节奏完成一次设备通信。</p>
<h3 id="4-2-1-读命令流程"><a href="#4-2-1-读命令流程" class="headerlink" title="4.2.1 读命令流程"></a>4.2.1 读命令流程</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719225655.png" alt="image.png"></p>
<p>详细步骤右边都给了，这里看看这个图到底说了个啥：</p>
<ul>
<li>T1 开始前，CPU 通过地址总线给出了地址，这里为啥是从中间往两边分裂，代表的就是地址线的电平即可能是高电平，也可能是低电平。</li>
<li>T1 结束时，CPU 开始发送读命令，T2 开始前电平稳定。这里线条往下的意思就是低电平有效。</li>
<li>T3 开始前，数据开始发送，同样是既可以往高走也可以往低走，高低电平都会发送。</li>
<li>T4 开始前，读命令结束，恢复高电平；在 T4 最后 CPU 撤销地址线的电平</li>
</ul>
<h3 id="4-2-2-优劣势"><a href="#4-2-2-优劣势" class="headerlink" title="4.2.2 优劣势"></a>4.2.2 优劣势</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719230158.png" alt="image.png"></p>
<p>解释下缺点，因为里面有人数拍子，所以每一步都必须按照时间准时完成，如果 CPU 和一个慢速的 IO 设备通讯，从设备跟不上这个节奏，整个就会乱。</p>
<p>同时，每一步卡点完成，没有留出数据校验的时间，所以只有在数据传输安全的情况下才会使用这种（也就是最下面那一行）。</p>
<h2 id="4-3-异步定时方式"><a href="#4-3-异步定时方式" class="headerlink" title="4.3 异步定时方式"></a>4.3 异步定时方式</h2><p>不提供节拍，而是通过握手信号来实现定时控制。</p>
<p>主设备提出交换信息的“请求”信号，经过接口送到从设备；从设备接到主设备的请求后，通过接口向主设备发出 “回答信号”。</p>
<p>根据“请求”和“回答”信号的撤销是否互锁，分为下面三种类型：</p>
<ul>
<li>不互锁方式</li>
<li>半互锁方式</li>
<li>全互锁方式</li>
</ul>
<p>其实特简单，就是是否等到响应再撤销信号的区别：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719230940.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719231038.png" alt="image.png"></p>
<h2 id="4-4-半同步通信"><a href="#4-4-半同步通信" class="headerlink" title="4.4 半同步通信"></a>4.4 半同步通信</h2><p>书上没有，补充的。</p>
<p>就是同步定时的加强版，为了避免某些慢速设备跟不上节奏，就加了一个 “等待”响应信号 wait，如果发现设备跟不上节拍了，就让 wait 向总线控制器发出等待指令，就会等待几个节拍。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719231401.png" alt="image.png"></p>
<h2 id="4-5-分离式通信"><a href="#4-5-分离式通信" class="headerlink" title="4.5 分离式通信"></a>4.5 分离式通信</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719231638.png" alt="image.png"></p>
<h2 id="4-6-总结"><a href="#4-6-总结" class="headerlink" title="4.6 总结"></a>4.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719232433.png" alt="image.png"></p>
<h1 id="5-总线标准"><a href="#5-总线标准" class="headerlink" title="* 5. 总线标准"></a>* 5. 总线标准</h1><p>408 不考。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>12-指令流水线</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-12-%E6%8C%87%E4%BB%A4%E6%B5%81%E6%B0%B4%E7%BA%BF/</url>
    <content><![CDATA[<p>流水线就是说，将指令执行分为多个阶段，每个阶段尽可能使用不同的硬件。当前指令执行完第一阶段后，第一阶段用到的硬件空闲，就可以紧接着指令下一条指令的第一阶段。</p>
<span id="more"></span>

<h1 id="1-指令流水线"><a href="#1-指令流水线" class="headerlink" title="1. 指令流水线"></a>1. 指令流水线</h1><h2 id="1-1-指令流水线的定义"><a href="#1-1-指令流水线的定义" class="headerlink" title="1.1 指令流水线的定义"></a>1.1 指令流水线的定义</h2><p>将一个指令分为多个阶段，每个阶段所用到的硬件可能各不相同，所以说可以在第一条指令执行完第一阶段后，第二条指令就开始执行第一阶段，不必非要等到第一条指令执行完毕。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718222749.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718222830.png" alt="image.png"></p>
<p>这里说一下这个时间是怎么算的，一次重叠的话，第一条指令执行完毕需要 3t，往后每过 2t 就会执行完一条指令，还剩 （n-1）。所以 <code>3t + (n-1) x 2t</code>。下面两次重叠同理。</p>
<h2 id="1-2-流水线的表示方法"><a href="#1-2-流水线的表示方法" class="headerlink" title="1.2 流水线的表示方法"></a>1.2 流水线的表示方法</h2><p>两种图可以表示流水线：</p>
<h3 id="1-2-1-指令执行过程图"><a href="#1-2-1-指令执行过程图" class="headerlink" title="1.2.1 指令执行过程图"></a>1.2.1 指令执行过程图</h3><p>主要用来分析指令执行过程以及影响流水线的因素：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718223246.png" alt="image.png"></p>
<h3 id="1-2-2-时空图"><a href="#1-2-2-时空图" class="headerlink" title="1.2.2 时空图"></a>1.2.2 时空图</h3><p>这个更好玩了，主要用于分析流水线性能：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718223330.png" alt="image.png"></p>
<p>这个图里面一条指令是斜着向上的，代表着一条指令随着时间推移执行哪些阶段。</p>
<h2 id="1-3-流水型的性能指标"><a href="#1-3-流水型的性能指标" class="headerlink" title="1.3 流水型的性能指标"></a>1.3 流水型的性能指标</h2><h3 id="1-3-1-吞吐率-TP"><a href="#1-3-1-吞吐率-TP" class="headerlink" title="1.3.1 吞吐率 TP"></a>1.3.1 吞吐率 TP</h3><p>单位时间内流水线可以完成的任务数量，或者是输出结果的数量。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718223737.png" alt="image.png"></p>
<p>总时间应该会算吧，和之前一样，如果说执行这条指令总共有 k 个阶段，每个阶段 t 时间，则 kt 就是完成一条指令的时间，往后每隔 t 就会完成一条指令，总共 n - 1 条。有了总时间用 n 一除就行了。</p>
<p>这俩时间也好理解，装入时间就是第一条指令从开始到结束的时间；排空指令就是最后一条指令开始到结束的时间。或者这么理解，装入时间，就是让这些硬件逐步开始工作的时间；排空就是这些硬件逐步退出工作的时间。</p>
<p>这里为啥让 t &#x3D; 一个时钟周期，因为我们之前说过，指令的每个阶段都可以对应一个机器周期，每个机器周期内部又有多个时钟周期，这里说的是最理想情况，所以假设每个机器周期只有一个时钟周期。</p>
<h3 id="1-3-2-加速比-S"><a href="#1-3-2-加速比-S" class="headerlink" title="1.3.2 加速比 S"></a>1.3.2 加速比 S</h3><p>就是说使用了流水线完成这些指令要比没用流水线快多少，计算方法也很简单，流水线时间 &#x2F; 串行时间。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718224359.png" alt="image.png"></p>
<h3 id="1-3-3-效率-E"><a href="#1-3-3-效率-E" class="headerlink" title="1.3.3 效率 E"></a>1.3.3 效率 E</h3><p>流水线的设备利用率，这个设备就可以理解成指令执行每个阶段要用到的设备。反映到时空图上就是，从头到尾整个的矩形就是总时间，然后里面占着的地方总面积，就是设备处于忙碌的时间：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718224817.png" alt="image.png"></p>
<p>看图的话就是红色的总面积比上蓝色总面积，红色长拼接一下就是 nt，然后蓝色长就是 (k+n-1)t，俩做个比就行了。</p>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718225017.png" alt="image.png"></p>
<h1 id="2-指令流水线的影响因素"><a href="#2-指令流水线的影响因素" class="headerlink" title="2. 指令流水线的影响因素"></a>2. 指令流水线的影响因素</h1><h2 id="2-1-机器周期的设置"><a href="#2-1-机器周期的设置" class="headerlink" title="2.1 机器周期的设置"></a>2.1 机器周期的设置</h2><p>这里引入一个五短式的指令设计，将指令执行划分为5个阶段：取指、解码、执行、访存、回写。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718225655.png" alt="image.png"></p>
<p>这里每个机器周期的时间可能不同，为了适配流水线，我们这里规定，每个指令的机器周期数相同，且机器周期耗时也相同，这里就让所有的机器周期耗时统一为 100ns。</p>
<p>上面这个五短式的设计，就是经典的 MIPS 架构，是一种 RICS（精简指令集设计）。</p>
<p>还有个问题，比如 ID 阶段只需要 80ns 即可完成，然而我们规定必须耗时 100ns，那剩下的那 20ns，总不能把数据提前传给 EX 阶段的硬件吧。所以图里面每条虚线上都有一些缓冲寄存器。这个东西也叫锁存器，作用就是保存本流水段的执行结果，提供给下一流水段使用。</p>
<p>详细说说里面的每个阶段：</p>
<ul>
<li>IF 和 M 阶段：就是取指和访存阶段，但是需要注意，图里面画的是两个缓存，一个是指令缓存，另一个是数据缓存。这么做的意义就是可以在不同阶段使用不同的硬件。同时因为缓存的命中率很高，所以大多数情况下，数据都是直接来自缓存。如果缓存里面没有则必须去主存里找，就会出现流水线断流的情况。</li>
<li>ID 阶段，这里因为是用 RISC 举例，RISC 规定进入 ALU 的操作数必须来自通用寄存器，所以 ID阶段除了译码，还需要将操作数从通用寄存器放入锁存器 A 和 B，等待指令执行</li>
<li>EX 阶段，上面还有个锁存器 Imm，用来存放立即数，因为有的立即数会在指令中直接给出，所以 Imm 会和 IR 相连。</li>
<li>M 阶段，看图，它可能不需要将数据写回数据缓存，而是直接写回寄存器，所以会有根线连着最后面的锁存器，然后在 WB 阶段返回寄存器。</li>
</ul>
<h2 id="2-2-影响流水线的因素"><a href="#2-2-影响流水线的因素" class="headerlink" title="2.2 影响流水线的因素"></a>2.2 影响流水线的因素</h2><p>总共有三个：结构相关（资源冲突）、数据相关（数据冲突）、控制相关（控制冲突）。</p>
<h3 id="2-2-1-结构相关"><a href="#2-2-1-结构相关" class="headerlink" title="2.2.1 结构相关"></a>2.2.1 结构相关</h3><p>这个就很像 OS 里面的互斥资源，同一时间内，只有一个操作可以访问硬件。官方的话说的是：由于多条指令在同一时刻争用同一资源而形成的冲突，就是结构冲突：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718231452.png" alt="image.png"></p>
<p>图里面画的很清楚了，第一条指令在 M 阶段需要使用主存，而 第四条指令在 IF 阶段就需要使用主存，同一时间访问主存可能导致冲突。同时在 WB 阶段，如果两条指令用的是同一个寄存器，也会导致冲突。</p>
<p>第一个解决办法简单，就是把 Instr3 往后错一位，第二个解决办法：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718231658.png" alt="image.png"></p>
<p>使用多个 Cache，指令用 IM ，数据用 Dm，错开硬件就行了。</p>
<h3 id="2-2-2-数据相关"><a href="#2-2-2-数据相关" class="headerlink" title="2.2.2 数据相关"></a>2.2.2 数据相关</h3><p>这个就类似 OS 的同步问题，在一个程序中，存在必须等前一条指令执行完才能执行后一条指令的情况，则这两条指令数据相关。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718232145.png" alt="image.png"></p>
<p>第一条指令，r2 - r3 回写到 r1，需要在 WB 阶段才能完成，而下面的 2 3 4 条指令在 ID 阶段就要将 r1 的操作数放到锁存器里，就出现了同步问题。</p>
<p>解决办法：可以等，但是等的空闲时间 CPU 在干啥？这个有两种：</p>
<p>通过硬件阻塞（stall）方式，如果发现了硬件阻塞，就用气泡，把第二条后面的指令往后拖：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718232525.png" alt="image.png"></p>
<p>第二种办法，就是通过软件检测两个指令之间有了数据冲突，则编译器在两条指令之间就会插入多个空指令，每个指令也会占用 5 个周期，本质还是延迟冲突指令的执行时间：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718232719.png" alt="image.png"></p>
<p>另一个解决办法是数据旁路技术，根据图我们发现，第二步要的 r1 其实在 第一步的 EX 就已经得到了，我们可以让第一条指令 EX 完以后，直接把计算结果送回 ALU，供第二条指令执行。</p>
<p>第三种办法是编译优化，编译器调整指令顺序来解决同步问题，本质还是延后指令，但是不是空指令，而是执行后面没有同步问题的指令。</p>
<h3 id="2-2-3-控制相关"><a href="#2-2-3-控制相关" class="headerlink" title="2.2.3 控制相关"></a>2.2.3 控制相关</h3><p>流水线遇到转移指令和其他改变 PC 的指令而造成断流时，引起控制相关，还有比如函数调用，函数返回等也会导致这个：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718233613.png" alt="image.png"></p>
<p>比如一上来执行一条跳转指令，要跳转到最后一条指令，这就导致了断流。</p>
<h3 id="2-2-4-总结"><a href="#2-2-4-总结" class="headerlink" title="2.2.4 总结"></a>2.2.4 总结</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718233650.png" alt="image.png"></p>
<h1 id="3-流水线的分类"><a href="#3-流水线的分类" class="headerlink" title="3. 流水线的分类"></a>3. 流水线的分类</h1><p>一点也不想写：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718233946.png" alt="image.png"></p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718234100.png" alt="image.png"></p>
<h1 id="4-流水线多发技术"><a href="#4-流水线多发技术" class="headerlink" title="4. 流水线多发技术"></a>4. 流水线多发技术</h1><h2 id="4-1-超标量技术"><a href="#4-1-超标量技术" class="headerlink" title="4.1 超标量技术"></a>4.1 超标量技术</h2><p>就是在 CPU 内配置多个功能部件，让多条指令并行的执行一个阶段：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718234408.png" alt="image.png"></p>
<p>为啥不能调整指令顺序，因为指令顺序是编译器根据哪些指令可以并发执行而专门设计的，不能随便动。</p>
<h2 id="4-2-超流水技术"><a href="#4-2-超流水技术" class="headerlink" title="4.2 超流水技术"></a>4.2 超流水技术</h2><p>就是说把一个机器周期，再细分成多个节拍，以节拍为单位设计流水线，一个机器周期内一个功能部件可以使用多次：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718234746.png" alt="image.png"></p>
<p>图里为啥叫时钟周期？因为这里说的就是最佳情况，一个机器周期内只有一个时钟周期，理解就行了。</p>
<p>这样的话速度提升三倍。</p>
<h2 id="4-3-超长指令字"><a href="#4-3-超长指令字" class="headerlink" title="4.3 超长指令字"></a>4.3 超长指令字</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718234955.png" alt="image.png"></p>
<p>这个也需要提供多个功能部件，来让一个超长指令并发执行。</p>
<h2 id="8-4-总结"><a href="#8-4-总结" class="headerlink" title="8.4 总结"></a>8.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230718235057.png" alt="image.png"></p>
<h1 id="5-五段式流水线"><a href="#5-五段式流水线" class="headerlink" title="5. 五段式流水线"></a>5. 五段式流水线</h1><p>这里说五个考试中常见的指令：运算类指令、LOAD 指令、STORE 指令、条件转移指令、无条件转移指令。看看这些指令在五短式流水线里面会经历哪些流程。</p>
<h2 id="5-1-运算类指令"><a href="#5-1-运算类指令" class="headerlink" title="5.1 运算类指令"></a>5.1 运算类指令</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719093048.png" alt="image.png"></p>
<ul>
<li>IF 阶段：将指令从 指令缓存中取出，放到 IR 中</li>
<li>ID 阶段：译码，然后将操作数放到相应的锁存器中，如果有立即数的话就从 IR 中将其读入到 Imm 锁存器</li>
<li>EX 阶段：指令指令，将结果存入 EX 段锁存器</li>
<li>M 阶段：因为这是 RISC 指令集，规定运算指令操作数必须来自寄存器，所以这里不需要往主存活着缓冲区回写，所以这个阶段啥也不干。但是这个阶段还是会占用 100ns。</li>
<li>WB 阶段：根据图里的线，ALU 锁存器往下走到最后面的锁存器，然后回写到寄存器里</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719093818.png" alt="image.png"></p>
<p>这种指令不需要访问主存。</p>
<h2 id="5-2-存数指令-LOAD"><a href="#5-2-存数指令-LOAD" class="headerlink" title="5.2 存数指令 LOAD"></a>5.2 存数指令 LOAD</h2><p>RISC 下很重要的两条指令，LOAD 和 STORE，同行来说，RISC 处理器只有 “取数 LOAD” 和 “存数 STORE” 会访问主存，其他指令的操作数都直接来自寄存器。</p>
<p>先说 LOAD，将主存中的数取到寄存器中：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719094048.png" alt="image.png"></p>
<p>这里的 <code>(996 + (Rs)) -&gt; Rd</code>，说的就是一个基址寻址，这个进程的基址可能是放在 Rs 寄存器里，所以给 Rs 寄存器的值往后偏移 996，就得到了 Rd 的物理地址。所以说 LOAD 指令也会执行一个加法。</p>
<p>也可以简写成后面那种，就是直接给一个物理地址，但是通常这个 mem 也是根据上面偏移得到的。</p>
<p>流程：</p>
<ul>
<li>IF ：一样，放到 IR </li>
<li>ID ：将极致寄存器的值放到锁存器 A，将偏移值也就是指令中的立即数放到 Imm</li>
<li>EX ：运算，得到物理地址</li>
<li>M ：从数据 Cache 中取数并放到锁存器</li>
<li>WB ： 将取出的数协会寄存器</li>
</ul>
<p>M 阶段直接写的是数据 Cache，因为数据一般来说很大概率会在缓存中被找到，如果没找到，确实是要访问主存的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719094613.png" alt="image.png"></p>
<h2 id="5-3-存储-STORE"><a href="#5-3-存储-STORE" class="headerlink" title="5.3 存储 STORE"></a>5.3 存储 STORE</h2><p>将寄存器中的值存回主存：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719095017.png" alt="image.png"></p>
<p>流程：</p>
<ul>
<li>IF：同理</li>
<li>ID：将基址 Rd 的值放到锁存器 A 种，将立即数放到 Imm 中，然后我们要把 Rs 中的数存到主存，所以也需要读取 Rs 的值，将其放到 B 锁存器。</li>
<li>EX：运算，将运算结果放到 ALU 的锁存器，然后将 B 里面要存的数放到 Store 搜存器里，涮和下面绿色的线</li>
<li>M：写入数据 Cache</li>
<li>WB ：啥也不干</li>
</ul>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719095217.png" alt="image.png"></p>
<h2 id="5-4-条件转移指令"><a href="#5-4-条件转移指令" class="headerlink" title="5.4 条件转移指令"></a>5.4 条件转移指令</h2><p>这里说两个：beq 和 bne 指令：<code>beq Rs, Rt, #偏移量</code> 和 <code>bne Rs, Rt, #偏移量</code>，这种指令通常采用相对寻址，就是说在 PC 的基础上跳转多少：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719095612.png" alt="image.png"></p>
<p>解释一下这个大长式子，把指令字长就理解成一条指令就行了，如果条件成立，则在当前指令（PC）的下一条指令（+指令字长）的基础上偏移多少个指令，然后将这个数回写 PC，否则正常 PC + 1。通常这个 PC + 1 是在 IF 端结束后自动完成的。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719095834.png" alt="image.png"></p>
<p>需要注意的是 PC 回写发生在 M 段，因为 WB 是回写通用寄存器，PC 可不属于通用寄存器，所以不在 WB 完成。</p>
<p>有的教材会把回写 PC 说成 “WrPC” 段，不属于 M 也不熟 WB，可以安排在 M 段完成。</p>
<h2 id="5-5-无条件跳转指令"><a href="#5-5-无条件跳转指令" class="headerlink" title="5.5 无条件跳转指令"></a>5.5 无条件跳转指令</h2><p>同样是相对寻址，这里就是 <code>jmp #偏移量</code>，功能就是：<code>(PC) + 指令字长 + (偏移量 x 指令字长) -&gt; PC</code>。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719100207.png" alt="image.png"></p>
<p>这里 9.4 和 9.5 两步都是今早修改 PC 的值，原因：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719100317.png" alt="image.png"></p>
<h2 id="5-6-例题"><a href="#5-6-例题" class="headerlink" title="5.6 例题"></a>5.6 例题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230719100729.png" alt="image.png"></p>
<p>这个题就是，我们必须知道这些指令在什么阶段要干啥，才能知道为啥阻塞。</p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>页面防抖</title>
    <url>/2022/10/17/%E9%A1%B5%E9%9D%A2%E9%98%B2%E6%8A%96-md/</url>
    <content><![CDATA[<p>页面防抖是接口幂等性的其中一环，接口幂等性说的是一个接口执行依次和执行多次发生的结果一样，后端保证接口幂等性主要是就是发送请求令牌啥的，前端的话就得考虑如何避免帕金森患者多次点击一个按钮发送多次请求。</p>
<span id="more"></span>

<blockquote>
<p>create by P-F on 2022&#x2F;10&#x2F;17</p>
</blockquote>
<h1 id="1-防抖"><a href="#1-防抖" class="headerlink" title="1. 防抖"></a>1. 防抖</h1><p>前端的某个请求按钮在短时间内多次点击但是只会执行依次就是防抖，比如我以前做过一个线上考试系统，点击创建班级没有做防抖，结果被帕金森患者创建了十多个一样的班级。</p>
<h1 id="2-实现"><a href="#2-实现" class="headerlink" title="2. 实现"></a>2. 实现</h1><p>具体实现就是，给一个按钮设置一个定时器，比如这个按钮在点击以后会在200ms以后才执行，在200ms被再次点击的话就会重置计时器，保证这个按钮是在最后一次点击的200ms以后被执行。至于说用户 200ms 以后有点急了咋办，可以在这期间给这个按钮上锁，直接disabled就行了。</p>
<p>看代码：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建防抖函数</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> debounce = <span class="keyword">function</span>(<span class="params">callback, delay_</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> delay = delay_ || <span class="number">200</span>;</span><br><span class="line">    <span class="keyword">let</span> timer;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> args = <span class="variable language_">arguments</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(timer) &#123;</span><br><span class="line">            <span class="built_in">clearTimeout</span>(timer)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        timer = <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">            callback.<span class="title function_">apply</span>(<span class="variable language_">this</span>, args)</span><br><span class="line">        &#125;, delay)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123;debounce&#125; <span class="keyword">from</span> <span class="string">&quot;...&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 debounce，传入想要实现防抖的方法，即可实现防抖</span></span><br><span class="line"><span class="attr">addUser</span>: <span class="title function_">debounce</span>(<span class="keyword">function</span>(<span class="params">user</span>)&#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(user)</span><br><span class="line">&#125;, <span class="number">500</span>)</span><br></pre></td></tr></table></figure>

<h1 id="3-原理"><a href="#3-原理" class="headerlink" title="3. 原理"></a>3. 原理</h1><p>这玩意有点意思，深究一下为啥调用一个 debounce 就能实现防抖了。</p>
<h2 id="3-1-闭包"><a href="#3-1-闭包" class="headerlink" title="3.1 闭包"></a>3.1 闭包</h2><p>首先，我觉得这个东西用到了一个很有意思的思想：闭包。debounce 作为外层函数创建了一个变量：timer，然后内层函数访问 timer，修改 timer，最后 debounce 返回了内层函数，那么到了最后 debounce 这个外层函数并没有被销毁，而是隐隐的给内层函数提供 timer 这个变量，很有意思。</p>
<h2 id="3-2-结果"><a href="#3-2-结果" class="headerlink" title="3.2 结果"></a>3.2 结果</h2><p>我们调用 <code>addUser: debounce(function(args)&#123;...&#125;, 300)</code> 之后，addUser 最后变成了啥样了？</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="attr">methods</span>: &#123;</span><br><span class="line">        <span class="attr">addUser</span>: <span class="title function_">debounce</span>(<span class="keyword">function</span>(<span class="params">name, age</span>) &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`add user, name=<span class="subst">$&#123;name&#125;</span>, age=<span class="subst">$&#123;age&#125;</span>`</span>)</span><br><span class="line">        &#125;, <span class="number">300</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面是我们想要让 addUser 实现防抖，那就传入我们要防抖的逻辑传入 debounce，然后打印一下 addUser 看看是啥样的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 页面渲染以后 addUser：</span></span><br><span class="line"><span class="attr">addUser</span>: <span class="keyword">function</span> <span class="title function_">_</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> args = <span class="variable language_">arguments</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(timer) &#123;</span><br><span class="line">        <span class="built_in">clearTimeout</span>(timer)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    timer = <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">        callback.<span class="title function_">apply</span>(<span class="variable language_">this</span>, args)</span><br><span class="line">    &#125;, delay)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们会发现，debounce 会生成一个没有形参的函数，然后里面会调用我们传入的 callback。但是有个问题，就是我们调用 addUser 的时候肯定会传入 name 和 age，但是 addUser 又是一个无参方法，咋办，怎么正确的传参？</p>
<p>这个时候就会说道 arguments 对象。</p>
<h2 id="3-3-arguments"><a href="#3-3-arguments" class="headerlink" title="3.3 arguments"></a>3.3 arguments</h2><p>JS 的 function 内部会自动有一个对象：arguments，内部就存储了所有传入的参数，哪怕这个 function 没有形参：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">test</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`args len: <span class="subst">$&#123;<span class="variable language_">arguments</span>.length&#125;</span>`</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">arguments</span>[<span class="number">0</span>] + <span class="variable language_">arguments</span>[<span class="number">1</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">test</span>(<span class="number">10</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>除此之外，我们可以通过 arguments 对象来修改实参：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">test</span>(<span class="params">a, b</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用严格模式，修改不会生效，不加这行的话修改才能生效。</span></span><br><span class="line">    <span class="string">&#x27;use strict&#x27;</span>;</span><br><span class="line">    <span class="variable language_">arguments</span>[<span class="number">0</span>] = <span class="number">100</span></span><br><span class="line">    <span class="variable language_">arguments</span>[<span class="number">1</span>] = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">arguments</span>[<span class="number">0</span>] + <span class="variable language_">arguments</span>[<span class="number">1</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">test</span>(<span class="number">10</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>这里返回的不是 30，而是 300，即便我们传入的是 10 20，但是函数内通过 arguments 对象修改了实参为 100 200。当然这是在费严格模式下，如果在严格模式下，是不能修改实参的。（费严格模式把那行 use strict 注释掉）。</p>
<p>所以在这个防抖函数里面，即时返回的防抖函数没有形参，我们也依旧可以通过 arguments 得到我们调用时传入的实参，然后传给 callback。</p>
<h2 id="3-4-apply-方法"><a href="#3-4-apply-方法" class="headerlink" title="3.4 apply 方法"></a>3.4 apply 方法</h2><p>我们还会发现，调用 callback 的时候并没有直接 <code>callback(arguments)</code>，而是 <code>callback.apply(this, arguments)</code>，这是为啥？这里就需要说说 apply 方法。</p>
<p>apply 方法用于重新指定 function 的 this 指向，当然这是我自己的理解，官方说的是让 function 在别的对象上执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> user = &#123;</span><br><span class="line">    <span class="attr">name</span>: <span class="string">&#x27;jack&#x27;</span>,</span><br><span class="line">    <span class="attr">age</span>: <span class="number">20</span>,</span><br><span class="line"></span><br><span class="line">    <span class="title function_">hello</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`hello, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.name&#125;</span>, i&#x27;m <span class="subst">$&#123;<span class="variable language_">this</span>.age&#125;</span> years old`</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> person = &#123;</span><br><span class="line">    <span class="attr">name</span>: <span class="string">&#x27;Lucy&#x27;</span>,</span><br><span class="line">    <span class="attr">age</span>: <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">user.<span class="property">hello</span>.<span class="title function_">apply</span>(person)</span><br></pre></td></tr></table></figure>

<p>最后执行的结果是 hello, i’m Lucy, i’m 10 years old，我们就会发现，hello 方法里面的 this 居然指向了 person，也就相当于 hello 跑到了 person 对象内被执行了，是不是很神奇。</p>
<p>所以防抖函数里面为啥要用 apply？因为我们传入的 callback 的 this 不是 VueComponent，所以我们需要调用 apply 方法，将 this 修改为 VueComponent，同时还需要用 apply 方法将 arguments 传入。</p>
<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>可以看到，一个小小的防抖就涉及到这么多知识点，就是因为当时看不懂这个防抖，才去补课 this 指向问题的。</p>
]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>运行时数据区概述</title>
    <url>/2022/05/27/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>从这里开始正式进入运行时数据区，运行时数据区是JVM非常核心的一部分，各种内存模型各种垃圾回收都将从这里展开。</p>
<span id="more"></span>

<h1 id="1-运行时数据区"><a href="#1-运行时数据区" class="headerlink" title="1. 运行时数据区"></a>1. 运行时数据区</h1><p>运行时数据区，非常之核心，JVM运行时大部分数据都存在运行时数据区，所以后面大部分的展开，比如各种的字符串，常量池，GC，等等等等一系列的故事都将发生在这里。</p>
<p>首先看一下运行时数据区的图：</p>
<p><img src="/images/runtime/Runtime_data_area.png" alt="runtime"></p>
<p>主要就是包含了：程序计数器、本地方法栈、虚拟机栈、堆、元空间。其中这里先介绍几个简单的，比如程序计数器和本地方法这种的，剩下的虚拟机栈和堆和元空间，都是重点中的重点。</p>
<p>同时扩展一点东西：</p>
<ul>
<li><p>PC寄存器：不涉及 Error 不涉及 GC</p>
</li>
<li><p>虚拟机栈：涉及 Error，比如 StackOverFlowError，不涉及GC，直接弹栈即可。</p>
</li>
<li><p>本地方法栈：涉及 Error，不涉及 GCasd</p>
</li>
<li><p>堆 和 方法区：都涉及 Error 和 GC</p>
</li>
</ul>
<p>这5种东西，一部分是和Java程序共存亡，随着JVM启动而启动，随着JVM销毁而销毁另外的，和线程共存亡。</p>
<p>方法区 和 堆，线程之间公用，剩下的，每一个线程都会有自己独一份的这些东西。</p>
<p>对应的对象就是 Runtime，每一个Java 应用，或者说，一个jvm就对应着一个Runtime对象。</p>
<p>其中，JVM内部还有一些线程：</p>
<ul>
<li><p>虚拟机线程，特别复杂，不说了</p>
</li>
<li><p>周期任务线程，一般用于周期性操作的调度执行</p>
</li>
<li><p>GC线程，支持不同种类的垃圾收集行为</p>
</li>
<li><p>编译线程，将字节码编译成本地代码</p>
</li>
<li><p>信号调度线程，接收信号发给JVM处理</p>
</li>
</ul>
<p>这些东西似乎就没有啥用了，应该不会用到吧。</p>
<h1 id="2-PC寄存器"><a href="#2-PC寄存器" class="headerlink" title="2. PC寄存器"></a>2. PC寄存器</h1><p>所谓PC寄存器，全称 Program Counter Register，也叫程序计数器，主要用于存储下一条要执行的指令的地址。</p>
<p>我们随便写一个程序，然后我们反编译他的 class文件，会看到如下文字：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:bipush   10  </span><br><span class="line">2:istore_1  </span><br><span class="line">3:bipush   20  </span><br><span class="line">4:istore_2</span><br></pre></td></tr></table></figure>

<p>这种的，第一列的数字就是指令地址，第二列以及后面的东西就叫指令，pc寄存器会存储下一条指令的地址，也就是 比如 0 2 这种东西，然后执行引擎会读取pc寄存器里面存储的指令地址所对应的指令，去运行这个指令。</p>
<p>具体流程下图所示：</p>
<p><img src="/images/runtime/pc_register.png" alt="pc_process"></p>
<h2 id="为什幺用PC寄存器"><a href="#为什幺用PC寄存器" class="headerlink" title="为什幺用PC寄存器"></a>为什幺用PC寄存器</h2><p>记录执行位置，并发(CPU轮转)状态下，每个线程都会抢时间片，那么抢到了就会接着执行，这个时候就需要记录当前状态下，该执行那条指令了，PC寄存器就是记录执行状态的。</p>
<p>JVM字节码解释器通过改变PC寄存器的值来记录执行状态。</p>
<h1 id="3-本地方法接口"><a href="#3-本地方法接口" class="headerlink" title="3. 本地方法接口"></a>3. 本地方法接口</h1><p>我们前面一直在说Runtime的事，我们先跳出Runtime，先来看一个东西：本地方法。</p>
<p>首先我们来看一眼JVM的整体结构：</p>
<p><img src="/images/runtime/jvm_structure.jpg" alt="jvm_stu"></p>
<p>看到右下角的两个东西了么：NativeMethodInterface和 NativeMethodLibrary，这两个东西要和 运行时数据区里面的 本地方法栈进行联系，所以我们现看这两块内容。</p>
<h2 id="本地方法"><a href="#本地方法" class="headerlink" title="本地方法"></a>本地方法</h2><h3 id="什么是本地方法"><a href="#什么是本地方法" class="headerlink" title="什么是本地方法"></a>什么是本地方法</h3><p>何为本地方法，Java 调用一个非Java 实现的方法的接口，这个接口就是本地方法，也就是 NativeMethod，(Native 是个关键字);</p>
<p>再简单说，本地方法就是一个Java方法，但是这个方法的具体实现并不是 Java，多数情况下是 C&#x2F;C++。本地接口的作用就是融合不同语言来为Java所用，最主要还是融合 C&#x2F;C++.</p>
<p>需要注意的是，native 方法因为它本身就是 Java 方法，所以Java 方法上有的东西他都有，比如可以进行权限控制，可以使用同步代码，可以抛出异常，可以有static 修饰等。</p>
<h3 id="为什么要用本地方法"><a href="#为什么要用本地方法" class="headerlink" title="为什么要用本地方法"></a>为什么要用本地方法</h3><p>有时Java需要和外部环境交互，比如操作系统，创建 Thread这种的，或者说有些时候需要特别在以效率，就需要用到NativeMethod</p>
<h3 id="和操作系统的交互"><a href="#和操作系统的交互" class="headerlink" title="和操作系统的交互"></a>和操作系统的交互</h3><p>JVM毕竟不是真是的操作系统，他是要依赖于本地环境，这就不可避免的有C代码，同时如果我们关注效率，也需要C，比如 创建线程，这个就是一个本地方法，调用了操作系统的api，去创建线程。</p>
<p>Sun’s Java 的解释器有一部分就是C写的，JVM内部就已经植入了一部分C代码，所以不可避免的需要和C交互。</p>
<h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><p>目前Java已经很少用到Native了，除非是一些底层操作，比如调用打印机这种的，还是需要用到C。</p>
<h1 id="4-本地方法栈"><a href="#4-本地方法栈" class="headerlink" title="4. 本地方法栈"></a>4. 本地方法栈</h1><p>至于本地方法栈，这个东西 简单说，似乎不怎么用。这里涉及到了一些虚拟机栈的知识，后面会说。</p>
<ul>
<li><p>Java虚拟机栈使用管理Java方法的，那么很显然本地方法栈就是用来管理本地方法的。</p>
</li>
<li><p>和虚拟机栈同理，本地方法栈也是线程独有的。</p>
</li>
<li><p>同样可以扩展本地方法栈，同样会抛出 StackOverflowError 和 OutOfMemoryError。</p>
</li>
<li><p>当某个线程调用了一个本地方法后，这个本地方法就会进入一个权限的不受虚拟机限制的世界。他和虚拟机有同样的权限。</p>
<ul>
<li><p>本地方法可以调用本地方法接口来访问虚拟机内部的运行时数据区。</p>
</li>
<li><p>可以直接使用本机处理器中的寄存器。</p>
</li>
<li><p>可以直接分配本地内存</p>
</li>
</ul>
</li>
<li><p>并不是所有的 JVM 都支持本地方法，因为虚拟机规范并没有规定本地方法的实现语言等， 所以如果虚拟机不打算使用本地方法，也就无需本地方法栈</p>
</li>
<li><p>Hotspot JVM中，直接把本地方法栈和虚拟机栈合二为一。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>底层</tag>
      </tags>
  </entry>
  <entry>
    <title>14-输入输出系统</title>
    <url>/2023/07/21/%E6%9C%BA%E7%BB%84-14-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>详细说说 IO 设备如何和主机协调工作，OS 里面也讲过，这里主要是深入内部，看看工作流程.</p>
<span id="more"></span>

<h1 id="1-IO设备概念"><a href="#1-IO设备概念" class="headerlink" title="1. IO设备概念"></a>1. IO设备概念</h1><h2 id="1-1-IO接口"><a href="#1-1-IO接口" class="headerlink" title="1.1 IO接口"></a>1.1 IO接口</h2><p>IO接口又叫 IO控制器，设备控制器，负责协调主机与外部设备之间的数据传输。针对不同的 IO 设备有不同的 IO 控制器，也会制定相应的标准。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720103746.png" alt="image.png"></p>
<p>IO 控制器一般来说是一块芯片，被集成在主板上。</p>
<h2 id="1-2-IO-控制方式简介"><a href="#1-2-IO-控制方式简介" class="headerlink" title="1.2 IO 控制方式简介"></a>1.2 IO 控制方式简介</h2><h3 id="1-2-1-查询与中断"><a href="#1-2-1-查询与中断" class="headerlink" title="1.2.1 查询与中断"></a>1.2.1 查询与中断</h3><p>比如写了一个 C 语言 <code>scanf</code> 一个字符，然后打印，输入字符这个过程如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720104218.png" alt="image.png"></p>
<p>CPU 如何知道键盘已经完成了输入？</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720104255.png" alt="image.png"></p>
<p>这些东西在 OS 里面都说过了。这种方式缺点就是数据必须经过 CPU 的寄存器，需要 CPU 频繁介入。</p>
<p>上面提出了两种 IO 控制方式：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720104654.png" alt="image.png"></p>
<p>两种的缺点都是需要 CPU 高频的介入，为了解决这个问题，提出了 DMA 方式：</p>
<h3 id="1-2-2-DMA-控制方式"><a href="#1-2-2-DMA-控制方式" class="headerlink" title="1.2.2 DMA 控制方式"></a>1.2.2 DMA 控制方式</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720104755.png" alt="image.png"></p>
<p>这些东西在 OS 里面详细说过，这里从机组的角度看看 DMA。上面是一种三总线方式，将高速外设连接到 DMA 接口上（也是一种 IO 接口）。</p>
<p>主存和高速IO设备之间有一条直接数据通路 （DMA总线）。CPU 向 DMA 接口发出 “读&#x2F;写” 命令，并指明主存地址、磁盘地址、读写数据量等参数。</p>
<p>DMA 控制器自动控制磁盘和主存的数据读写，每完成一整块的数据读写，才向 CPU 发出一次中断请求。</p>
<p>这个在 OS 里面说过了，DMA 读硬盘其实也是一个字节一个字节读的，但是 DMA 内部有一个 DR（数据寄存器），会先将读到的数据存入 DR，读完一整块才将其发送到内存。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720105240.png" alt="image.png"></p>
<h3 id="1-2-3-通道控制方式"><a href="#1-2-3-通道控制方式" class="headerlink" title="1.2.3 通道控制方式"></a>1.2.3 通道控制方式</h3><p>上一种方式即便引入了 DMA，CPU 还是需要通过 DMA 和其他 IO 控制器直接和 IO 设备进行交互。所以就引入了通道，通道是具有特殊功能的处理器，能对 IO 设备进行统一管理：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720105534.png" alt="image.png"></p>
<p>控制方式如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720105757.png" alt="image.png"></p>
<h2 id="1-3-IO-系统基本组成"><a href="#1-3-IO-系统基本组成" class="headerlink" title="1.3 IO 系统基本组成"></a>1.3 IO 系统基本组成</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720110037.png" alt="image.png"></p>
<p>IO 硬件部分前面已经说过了，这里就看看 IO 软件就行了。</p>
<h2 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720110139.png" alt="image.png"></p>
<h1 id="2-外部设备"><a href="#2-外部设备" class="headerlink" title="2. 外部设备"></a>2. 外部设备</h1><p>分为三类：输入设备、输出设备（这里涉及到一个考点，VRAM 的计算）、外存储器（涉及到磁盘存取时间的计算，这部分内容在之前存储器里面说过）。</p>
<h2 id="2-1-输入设备"><a href="#2-1-输入设备" class="headerlink" title="2.1 输入设备"></a>2.1 输入设备</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720123433.png" alt="image.png"></p>
<h2 id="2-2-输出设备"><a href="#2-2-输出设备" class="headerlink" title="2.2 输出设备"></a>2.2 输出设备</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720154038.png" alt="image.png"></p>
<p>这里稍微解释下这个 VRAM，就是显存，这个东西说的就是要将画面输出到显示器上，就得先把画面存储到显存内，然后在交给显示器。</p>
<p>所以显存里面至少要存储一桢的画面，一帧画面的大小 &#x3D; 像素点个数 x 每个像素点的大小。像素点个数就是分辨率，像素点大小就是灰度级别。</p>
<p>然后，要保证显示器正常工作，这里假设显示器时 60Hz 的，也就是一秒钟要显示 60 张画面，则显存每秒钟就要传输 60 x 一桢画面大小 的数据，这个就是显存带宽。</p>
<h3 id="2-2-1-显示器"><a href="#2-2-1-显示器" class="headerlink" title="2.2.1 显示器"></a>2.2.1 显示器</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720154653.png" alt="image.png"></p>
<p>后两种看看就行了，CRT 需要说一说。</p>
<p>显示字符的方法以点阵为基础，用一组二位的二进制来表示一个字符，就叫字形码：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720155239.png" alt="image.png"></p>
<p><strong>字符显示器</strong></p>
<p>有了字形码之后，字符显示器如何显示文字：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720155200.png" alt="image.png"></p>
<p>只需要知道我们要显示哪些信息，将其存入显示存储器 RAM 中，然后将内容交给字符发生器，字符发生器里面有个 ROM，ROM 存的就是每个 ACSII 码对应的字形码是啥，字形发生器将字形码交给 CRT 去成像。</p>
<p>还有两种：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720155853.png" alt="image.png"></p>
<p>没啥用，了解就行了</p>
<h3 id="2-2-2-打印机"><a href="#2-2-2-打印机" class="headerlink" title="2.2.2 打印机"></a>2.2.2 打印机</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720155925.png" alt="image.png"></p>
<p>完了按照打印机工作方式还可以分为：</p>
<ul>
<li>串行打印机：一个字一个字打</li>
<li>并行打印机：逐行打印，快</li>
</ul>
<p>再按工作方式还可以分为：</p>
<ul>
<li>针式打印机：就是击打式</li>
<li>喷墨式打印机</li>
<li>激光打印机</li>
</ul>
<h2 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h2><p>就俩考点：VRAM 和 CRT 的字符成像原理</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720160128.png" alt="image.png"></p>
<h1 id="3-IO-接口"><a href="#3-IO-接口" class="headerlink" title="3. IO 接口"></a>3. IO 接口</h1><h2 id="3-1-IO-接口作用"><a href="#3-1-IO-接口作用" class="headerlink" title="3.1 IO 接口作用"></a>3.1 IO 接口作用</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720160444.png" alt="image.png"></p>
<h2 id="3-2-结构和工作原理"><a href="#3-2-结构和工作原理" class="headerlink" title="3.2 结构和工作原理"></a>3.2 结构和工作原理</h2><h3 id="3-2-1-IO-接口结构"><a href="#3-2-1-IO-接口结构" class="headerlink" title="3.2.1 IO 接口结构"></a>3.2.1 IO 接口结构</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720160824.png" alt="image.png"></p>
<p>左边连接的是 IO 空闲，而不是直接连到数据总线、地址总线、控制总线上。而是 IO 总线里面包括左面写的数据线、地址线、控制线。</p>
<p>说一下右边，右边就是实际和 IO 设备相连的地方，比如 USB 接口就在右边，右边可以连接多个同类型的 IO 设备，所以一个 IO 控制逻辑是可以控制多个 IO 设备的。</p>
<p>如何确定要操作哪个设备：可以指定设备的地址；也可以给每个设备都对应一组寄存器，对不同的寄存器操作实现对不同设备的操作。</p>
<p>比如看看下面这个 USB 芯片：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720161013.png" alt="image.png"></p>
<p>芯片左边就是设备侧，可以管理多个 USB 接口，下面用于连接主板上的总线。</p>
<h3 id="3-2-2-IO-接口工作原理"><a href="#3-2-2-IO-接口工作原理" class="headerlink" title="3.2.2 IO 接口工作原理"></a>3.2.2 IO 接口工作原理</h3><p>这里就举例 CPU 要控制打印机打印，分为下面三步：</p>
<ul>
<li>发命令：发送命令字到 IO 控制寄存器，向设备发送命令。不同厂家的 IO 设备可能千差万别，CPU 怎么知道这个设备的命令字是啥，这个就需要驱动程序的协助</li>
<li>读状态：打印机启动，将自己的状态写到状态寄存器中，然后 CPU 读取状态字，获得设备或IO控制器的状态信息。</li>
<li>读&#x2F;写数据：从数据缓冲寄存器发送或读取数据，完成主机与外设的数据交换。</li>
</ul>
<p>CPU 如何知道 IO 设备工作完成？之前说过，CPU 可以通过数据总线轮询状态寄存器，活着 IO 控制逻辑通过控制总线向 CPU 发送中断。</p>
<p>解释上面 IO 控制器结构图中，为啥状态寄存器和控制寄存器合二为一了：</p>
<p>因为这俩使用不冲突，CPU 向寄存器写入指令，IO 控制逻辑取走指令之后寄存器就空了，所以干脆就把状态也写到里面得了。</p>
<h2 id="3-3-IO-端口"><a href="#3-3-IO-端口" class="headerlink" title="3.3 IO 端口"></a>3.3 IO 端口</h2><p>IO 端口其实就是 IO 控制器内部 CPU 可以访问读写的寄存器。CPU 想要控制这些寄存器就需要用到 IO 总线：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720162158.png" alt="image.png"></p>
<p>和左边写的一样，CPU 要访问状态寄存器，就需要通过 IO 总线中的地址线，指明状态寄存器（状态端口）的地址，然后告诉控制线 我要读，最终顺着数据线把状态寄存器里面的值取走。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720162500.png" alt="image.png"></p>
<p>所以如何给这些寄存器编址：</p>
<h3 id="3-3-1-IO-端口编址"><a href="#3-3-1-IO-端口编址" class="headerlink" title="3.3.1 IO 端口编址"></a>3.3.1 IO 端口编址</h3><p>分为两类：统一编址和独立编址。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720163036.png" alt="image.png"></p>
<p>左边是统一编址，将 IO 端口的地址和主存放在一起，我们可以通过访存指令直接操作 IO 端口。</p>
<p>右边是独立编址，IO 端口的地址也是从 0 开始，这样就需要不同的指令来进行访存和访问 IO 端口，比如执行 LOAD 指令，就会去主存中找数据，执行 IN 指令，就会从 IO 端口区找数据。</p>
<h3 id="3-3-2-编址优缺点"><a href="#3-3-2-编址优缺点" class="headerlink" title="3.3.2 编址优缺点"></a>3.3.2 编址优缺点</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720164019.png" alt="image.png"></p>
<h2 id="3-4-分类"><a href="#3-4-分类" class="headerlink" title="3.4 分类"></a>3.4 分类</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720164113.png" alt="image.png"></p>
<p>说一下第一条，里面说 IO 控制器的主机侧数据总是并行传输的，这里不准确，现在的 IO 总线更多的是串行传输。</p>
<h2 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720164229.png" alt="image.png"></p>
<h1 id="4-程序查询方式"><a href="#4-程序查询方式" class="headerlink" title="4. 程序查询方式"></a>4. 程序查询方式</h1><p>从这里开始就深入了解一下前面说过的几种 IO 控制方式。</p>
<h2 id="4-1-流程"><a href="#4-1-流程" class="headerlink" title="4.1 流程"></a>4.1 流程</h2><p>这里模拟一种场景，x86架构下（采用独立编址），用打印机打印三个字符，需要用到的指令是：</p>
<ul>
<li><code>IN Rd, Rs</code>：把 IO 端口 Rs 中的数据输入到 CPU 的 Rd 寄存器</li>
<li><code>OUT Rd, Rs</code>：把 CPU 寄存器 Rs 的数据输出到 IO 端口 Rd 中</li>
</ul>
<p>这里数据都是在 CPU 寄存器中，如果数据在主存中只需要加一条 LOAD 指令即可。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720164829.png" alt="image.png"></p>
<p>顺着图看看详细的流程：</p>
<p>第一步：假设 CPU 借助驱动程序将打印命令 <code>001001110</code> 放到了寄存器 R1 中，CPU 只需要执行 <code>OUT Rn+1, R1</code> 指令，将打印命令从 R1 发送到 IO 设备的状态端口。具体步骤是：CPU 通过地址线告诉 IO 逻辑我要操作 #n+1 ，再通过控制线告诉 IO 逻辑我要写，就可以将命令写入到 控制端口了。</p>
<p>第二步：IO 逻辑接收到了打印命令，将打印命令通过 IO 逻辑右边那根控制线交给打印机，打印机就可以开始启动，启动后，打印机将 Ready 状态交给 IO 逻辑，IO 逻辑将其写入到 状态端口。</p>
<p>第三步：这步和第二步同时的，CPU 完成第一步操作后，就开始轮询状态端口，看打印机啥时候就绪，通过 <code>IN R0, Rn+1</code> 指令就可以将状态字读入到寄存器。</p>
<p>第四步：CPU 开始输出要打印的第一个字符，同样是使用 <code>OUT</code> 指令，通过地址线告诉 IO 逻辑操作 Rn 寄存器也就是数据端口，通过控制线告诉 IO 逻辑我要写，然后通过数据线将第一个字符 “a” 写入到 数据端口。然后 IO 逻辑会拿到这个字符交给打印机开始打印，这期间状态字为 “忙碌”。</p>
<p>然后就是等到打印结束，打印机重新传回 Ready 状态，这期间 CPU 也是一直在轮询，然后重复上述过程，直到打印完三个字符后，打印机返回 Ready 状态或者 Fin 状态，CPU 就知道打印完成了。</p>
<p>最后，CPU 再发送一个“停机”指令，IO逻辑让打印机关闭。</p>
<p>流程图如下：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720170240.png" alt="image.png"></p>
<h2 id="4-2-例题"><a href="#4-2-例题" class="headerlink" title="4.2 例题"></a>4.2 例题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720221600.png" alt="image.png"></p>
<h1 id="5-中断系统"><a href="#5-中断系统" class="headerlink" title="5. 中断系统"></a>5. 中断系统</h1><p>这个是为了下一节 程序中断方式 做准备。</p>
<h2 id="5-1-中断基本概念"><a href="#5-1-中断基本概念" class="headerlink" title="5.1 中断基本概念"></a>5.1 中断基本概念</h2><p>中断就是计算机在执行当前进程的过程中，出现某些急需处理的异常情况或特殊请求，CPU 暂时终止现行进程，而转而去对这些异常情况或特殊请求进行处理，在处理完成后 CPU 又自动回到现行进程的断点处，继续执行。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720222515.png" alt="image.png"></p>
<p>右边就是工作流程，这里稍微解释一下：</p>
<ul>
<li>向 CPU 发出中断请求的叫 中断源</li>
<li>第二步中，响应中断的条件就是 OS 里面说过的 开中断和关中断指令，如果当前 CPU 执行过关中断指令，则 CPU 不会响应中断，直到执行了开中断指令。中断判优就是如果有多个中断信号来了，优先处理哪个</li>
<li>第三步，中断隐指令说的就是将 PC 的值变为中断处理程序的起始地址。</li>
</ul>
<p>CPU 如何知道当前自己处于关中断还是开中断？PSW 里面有个位 IF，这个位 &#x3D; 1，说明处于开中断状态。IF &#x3D; 0，则关中断。</p>
<h2 id="5-2-中断请求分类"><a href="#5-2-中断请求分类" class="headerlink" title="5.2 中断请求分类"></a>5.2 中断请求分类</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720223001.png" alt="image.png"></p>
<p>这个图 OS 里面见过，只是这里加了点东西，引入了 <strong>非屏蔽中断</strong>：就是说，即使 CPU 处在关中断模式下，这种中断来了CPU也必须处理，典型的就是我们按住关机键，这个中断就是非屏蔽中断。</p>
<p>机组我们主要讨论的是来自 IO 设备的外部中断，大部分都是可屏蔽中断。</p>
<h2 id="5-3-中断请求标记"><a href="#5-3-中断请求标记" class="headerlink" title="5.3 中断请求标记"></a>5.3 中断请求标记</h2><p>简单说，每个中断源都设置一个触发器（只能存一个 bit）来记录当前中断源有没有发出中断。我们可以将这些触发器整合到 CPU 内部，也可以分散到各个中断源内。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720225129.png" alt="image.png"></p>
<h2 id="5-4-中断判优"><a href="#5-4-中断判优" class="headerlink" title="5.4 中断判优"></a>5.4 中断判优</h2><p>就是说如果现在有多个中断信号，CPU 应该优先处理哪个？可以用硬件实现，使用硬件排队器，既可以设置在 CPU 中，也可以分散到各个中断源中；软件实现使用查询程序实现的：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720225618.png" alt="image.png"></p>
<p>硬件排队器就是通过一大堆的 非门 和 与非门实现的，看看得了。</p>
<p>如何设置中断的优先级：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720231654.png" alt="image.png"></p>
<p>解释一下：</p>
<ul>
<li>三和四是一个意思，DMA 连接的高速的 IO 设备，比如磁盘啥的。</li>
<li>五，输入设备可能会因为用户手快，第二次输入的字符把第一次输入的字符在寄存器里覆盖了，所以应该优先处理输入设备。输出设备的话只需要把数据放到寄存器里，输出完再放一个就行了</li>
</ul>
<h2 id="5-4-中断处理过程"><a href="#5-4-中断处理过程" class="headerlink" title="5.4 中断处理过程"></a>5.4 中断处理过程</h2><p>CPU 发现中断信号后，首先肯定要保存当前进程的 PC，然后去找中断处理程序的起始地址，这个起始就是 <strong>中断隐指令</strong> 做的事，他并不是一条指令，而是 CPU 要进行中断处理时会自动执行的一系列流程，包括保存 PC、重定向到中断程序 等。</p>
<h3 id="5-4-1-中断隐指令"><a href="#5-4-1-中断隐指令" class="headerlink" title="5.4.1 中断隐指令"></a>5.4.1 中断隐指令</h3><p>必须明确，中断隐指令是一系列的任务，中断隐指令的主要任务：</p>
<ul>
<li>执行关中断，必须要正中断处理期间不被打扰</li>
<li>保存断点，将当前进程的 PC 存入堆栈，或者存入指定单元</li>
<li>引出中断服务程序，是指就是取出中断服务程序的入口地址传送给 PC</li>
</ul>
<p>如何找到中断服务程序的入口，两种办法：软件查询法、硬件向量法。这里主要说说硬件向量法。</p>
<h3 id="5-4-2-硬件向量法"><a href="#5-4-2-硬件向量法" class="headerlink" title="5.4.2 硬件向量法"></a>5.4.2 硬件向量法</h3><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720232604.png" alt="image.png"></p>
<p>就是说主存里面存储这中断服务程序，然后还存着一批储存着中断向量的空间，其地址叫向量地址，这些主存保存了中断服务程序的入口，是一个指向服务程序的指针。</p>
<p>然后，我们将之前的排队器里面的数据交给一个叫 “中断向量地址形成部件” 的玩意，他就会知道你要处理哪个中断源，就会给你形成向量地址（也叫中断类型号），拿着这个地址去主存里面找中断向量，然后直接指令里面的指令就行了。</p>
<p>为啥要使用两级指针？因为服务程序可能被修改。</p>
<h3 id="5-4-3-中断服务程序"><a href="#5-4-3-中断服务程序" class="headerlink" title="5.4.3 中断服务程序"></a>5.4.3 中断服务程序</h3><p>中断服务程序主要任务：</p>
<ul>
<li>保护现场：保存通用寄存器和状态寄存器的内容，以便返回原程序后可以恢复 CPU 环境。可以使用堆栈，也可以是使用特定的存储单元。</li>
<li>中断服务（设备服务）：主体，比如将要打印的字符输入到 IO 控制器的数据端口</li>
<li>恢复现场：通过出栈或者取数指令把之前保存的信息送回寄存器</li>
<li>中断返回：通过中断返回指令回到原程序断点，比如弹出 PC 的值返回</li>
</ul>
<h2 id="5-5-总结"><a href="#5-5-总结" class="headerlink" title="5.5 总结"></a>5.5 总结</h2><p>没啥总结的，没图，说一下，这种方式叫单重中断，中断期间不能响应其他中断，接下来我们说说多重中断。</p>
<h1 id="6-多重中断"><a href="#6-多重中断" class="headerlink" title="6. 多重中断"></a>6. 多重中断</h1><p>之前因为在执行中断服务程序期间 CPU 一直是关中断状态，所以不能响应新的中断，要实现多重中断，就在执行中断服务程序期间开启中断：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720234214.png" alt="image.png"></p>
<p>说几点：</p>
<p>开中断和关中断的顺序：开中断需要等到保存现场结束后才能开启，否则容易发生保存不及时被覆盖的情况。中间的关中断同理，得先关掉中断，然后才能恢复现场。</p>
<p>屏蔽字：比如我们此时在执行 DMA 中断的处理程序，这时新来了一个键盘的中断信号，显然不能放下 DMA 这种优先级高的中断去处理别的。这就需要用到屏蔽字。其实叫 中断屏蔽字，就是说我在处理这个中断的时候，后续的哪些中断可以进来，哪些中断不能响应。</p>
<h2 id="6-1-屏蔽字技术"><a href="#6-1-屏蔽字技术" class="headerlink" title="6.1 屏蔽字技术"></a>6.1 屏蔽字技术</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720235351.png" alt="image.png"></p>
<p>这破玩意看的贼虎，反正记住一点就行了，多重中断下，每个中断源都会有个屏蔽字，加入有 n 个中断源，每个屏蔽字就有 n 位，屏蔽字中第 i 位表示当前中断能否被 第i个中断打断，i &#x3D; 1，不能打断，i &#x3D; 0 能打断。</p>
<h2 id="6-2-例题"><a href="#6-2-例题" class="headerlink" title="6.2 例题"></a>6.2 例题</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720235621.png" alt="image.png"></p>
<p>看里看一下图就知道了，D 优先级比 A 高，如果 A 正在执行中断处理程序，D 发出了中断，则 CPU 就会转而去处理 D，然后看看中断屏蔽字，对于 A 来说，只有 D 的优先级比他高，所以 D 那一位是 0，其他都是 1，代表其他设备不能打断 A 的中断服务程序。</p>
<h2 id="6-3-总结"><a href="#6-3-总结" class="headerlink" title="6.3 总结"></a>6.3 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230720235803.png" alt="image.png"></p>
<h1 id="7-程序中断方式"><a href="#7-程序中断方式" class="headerlink" title="7. 程序中断方式"></a>7. 程序中断方式</h1><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721103804.png" alt="image.png"></p>
<p>例题：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721104156.png" alt="image.png"></p>
<h1 id="8-DMA-方式"><a href="#8-DMA-方式" class="headerlink" title="8. DMA 方式"></a>8. DMA 方式</h1><h2 id="8-1-DMA-控制器"><a href="#8-1-DMA-控制器" class="headerlink" title="8.1 DMA 控制器"></a>8.1 DMA 控制器</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721104605.png" alt="image.png"></p>
<p>原理就是 CPU 告诉DMA 控制器我要读磁盘上的哪块位置，读到主存的哪个位置，然后 DMA 控制器内部就会有两个指针：主存读写指针、外设读写指针。</p>
<p>先把外设读写指针指向的数据读入 DMA 的数据缓冲寄存器，然后通过总线发给主存读写指针指向的位置，然后两个指针都往后移，重复上述过程，直到完成一整块数据的读写。</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721105009.png" alt="image.png"></p>
<h2 id="8-2-DMA-控制器内部结构"><a href="#8-2-DMA-控制器内部结构" class="headerlink" title="8.2 DMA 控制器内部结构"></a>8.2 DMA 控制器内部结构</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721105525.png" alt="image.png"></p>
<p>看着这个图说说流程：</p>
<p>比如我们要从磁盘读数据：</p>
<ul>
<li>DMA 控制器从主存读入一个字，放到数据缓冲寄存器里面，同时，将 DMA 请求触发器设置为 1，代表已经读入一个字了，然后 控制&#x2F;状态逻辑就会将 缓冲寄存器里面的值通过数据总线给主存</li>
<li>主存地址计数器和传送长度计数器，都是字面意思。这里和 状态&#x2F;控制逻辑连着，每传完一个字都会让这俩东西自动 + “1”，来指向下一个位置。</li>
<li>传送长度计数器有长度限制，比如只有 10 bit，只能表示 0 - 1023，我们给他最后 + 1 他就溢出了，然后中断机构就会检测到溢出，代表一个块传送完了，就会向 CPU 发送中断信号。</li>
</ul>
<h2 id="8-3-DMA-传送过程"><a href="#8-3-DMA-传送过程" class="headerlink" title="8.3 DMA 传送过程"></a>8.3 DMA 传送过程</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721110212.png" alt="image.png"></p>
<p>如果按这个图的话，DMA 控制器也是连接到系统总线上的，CPU 只要把系统总线分配给 DMA 控制器，CPU 就肯定不会访问主存，DMA 控制器就可以安静的将数据交给主存。</p>
<p>但是如果使用了之前我们提到过的三总线方式，CPU 和 DMA 接口用 IO 总线连接，DMA 接口和主存用 DMA 总线连接，主存和 CPU 之间有主存总线；这个时候 DMA 想要访问主存，CPU 也有可能要访问主存，且主存不是双端口的，那主存应该先让谁访问？</p>
<h2 id="8-4-DMA-传送方式"><a href="#8-4-DMA-传送方式" class="headerlink" title="8.4 DMA 传送方式"></a>8.4 DMA 传送方式</h2><p>这个就是解决了上面的CPU 和 DMA 如何一起访问主存的问题：</p>
<p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721111147.png" alt="image.png"></p>
<p>解释下第三个，就是说 如果当前 CPU 没有访存，DMA 直接放存就行了。如果 CPU 正在放存，DMA 就稍微等一等。如果 CPU 和 DMA 同时要求放存，DMA 优先，因为DMA里面的数据缓冲有可能被覆盖。</p>
<h2 id="8-5-特点"><a href="#8-5-特点" class="headerlink" title="8.5 特点"></a>8.5 特点</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721111412.png" alt="image.png"></p>
<p>DMA 控制方式下，总线有点混乱，有的时候是 三总线模式，有的时候是单总线，看着题了具体分析就行了。</p>
<h2 id="8-6-总结"><a href="#8-6-总结" class="headerlink" title="8.6 总结"></a>8.6 总结</h2><p><img src="https://gitee.com/pthef/imgrepo/raw/master/20230721111717.png" alt="image.png"></p>
]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
  </entry>
  <entry>
    <title>网站部署</title>
    <url>/2022/10/19/%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>最近写了个小网站，用于给别人的大创项目结项，同时自己也练练技术，本着大学最后一次做应用项目的原因，打算把这个项目做的正式一点，所以开发，部署，dns，备案 一串工作全做了，挺费劲。这里总结一下这次部署网站的流程。</p>
<span id="more"></span>

<blockquote>
<p>create by P-F on 2022&#x2F;10&#x2F;19</p>
</blockquote>
<h1 id="1-开发阶段"><a href="#1-开发阶段" class="headerlink" title="1. 开发阶段"></a>1. 开发阶段</h1><p>开发阶段没什么好说的，前端用的是 Vue+element+axios，后端是 go+beego+mysql+redis+jwt，很正常的技术栈。需要说的是平时调试，平时调试的时候 Vue 项目就是 <code>npm run serve</code> 开8080端口简单启动一下，然后 beego 项目那就是 <code>bee run</code> 开 9090 端口，这个时候就有个问题，两个不同端口之间通讯会跨域，同时我每次打开浏览器还得输入 <code>:8080</code>，很麻烦，所以怎么办呢？</p>
<p>我用本机的 Nginx 做了一下反向代理，直接访问 &#x2F; 转发到 <code>localhost:8080</code>，访问 &#x2F;v1&#x2F;* 就会转发到 <code>localhost:9090</code>，这样前端就直接访问 localhost&#x2F;v1&#x2F;xxx 就可以走 beego 服务，也不用担心跨域。看一下本机 Nginx 的配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> <span class="regexp">~ ^/v1/.*$</span> &#123;</span><br><span class="line">    <span class="attribute">proxy_pass</span> http://localhost:9090;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> / &#123;</span><br><span class="line">    <span class="attribute">proxy_pass</span> http://localhost:8080;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里顺带复习一下 Nginx 的 location 配置：<code>location ~</code> 后面接的是正则，会根据正则来判断是否进入这个 location。</p>
<p>剩下的倒是十分的顺利，因为开发阶段嘛，就在本机，也没有网络的影响，总体感觉十分良好，但是到了真正上线的时候那问题就大了。</p>
<h1 id="2-前端部署"><a href="#2-前端部署" class="headerlink" title="2. 前端部署"></a>2. 前端部署</h1><p>前端的部署，属实非常的坎坷。</p>
<h2 id="2-1-项目拉取"><a href="#2-1-项目拉取" class="headerlink" title="2.1 项目拉取"></a>2.1 项目拉取</h2><p>把前段项目部署到服务器，首先就是如何把项目放到服务器上，之前我的做法是通过 scp 命令直接从本机复制到服务器，但是实在麻烦，所以这回变了。我在服务器上通过 git 把项目源码拉下来，然后修改一些启动参数，再 <code>npm install; npm run build</code> 即可得到 Vue 项目的 dist 包。</p>
<h2 id="2-2-项目部署"><a href="#2-2-项目部署" class="headerlink" title="2.2 项目部署"></a>2.2 项目部署</h2><p>Vue 本质上是一个单页面应用，也就是整个网站本质上就是那个 index.html，但是通过各种 js 啥玩意的可以让这个 index.html 根据不同的 url 显示不同的东西。我第一次部署 Vue 还真就是在服务器上运行 <code>npm run serve</code> 然后就没事了，结果就是关闭终端以后项目也就没了。所以正确姿势就是：将 Vue 打包成 dist，然后配置后端服务器，比如 Nginx，Tomcat，或者自己用 nodejs 自己写一个也行，要实现将找不到对应静态资源的请求全部转发到 vue 生成的 index.html 中。下面就是使用 Nginx 部署 Vue 项目的配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> / &#123;</span><br><span class="line">        <span class="attribute">root</span> /usr/local/www/manyin-tech-frontend/dist;</span><br><span class="line">        <span class="attribute">try_files</span> <span class="variable">$uri</span> <span class="variable">$uri</span>/ <span class="variable">@router</span>;</span><br><span class="line">        <span class="attribute">index</span> index.html;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> <span class="variable">@router</span> &#123;</span><br><span class="line">        <span class="attribute">rewrite</span><span class="regexp"> ^.*$</span> /index.html <span class="literal">last</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体含义就是：首先，访问了 &#x2F; 以后，先去找有没有对应的静态资源，比如前端请求图片你也给他转发到 index.html 这显然不合适，所以首先 <code>try_files @uri @uri/</code> 来判断请求的静态资源是否存在，如果不存在，则转发到 @router 这个location，@router location 再将请求转发给 index.html。</p>
<p>同时配置一下后端的反向代理：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这段在 server 块外面</span></span><br><span class="line">upstream manyin_service &#123;</span><br><span class="line">        server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">9090</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location ~ ^<span class="regexp">/v1/</span>.+$ &#123;</span><br><span class="line">        proxy_pass <span class="attr">http</span>:<span class="comment">//manyin_service;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>OK，到这里算是初步的部署完了，可以通过 IP 地址访问了。</p>
<h2 id="2-3-静态资源优化"><a href="#2-3-静态资源优化" class="headerlink" title="2.3 静态资源优化"></a>2.3 静态资源优化</h2><p>结果一访问发现问题了，页面加载速度特别的慢，可能得一分钟才能把首页加载完，这是为啥？一看浏览器控制台，好家伙，首页三张图片就 20m 多，怪不得慢。那咋办？压缩一下图片。</p>
<p>结果网上找了一圈，要么让我下软件，要么就是在线压缩跟我要钱，好在最后找到一个非常好用的网站，功能还挺多，还能压缩图片：</p>
<p><a href="https://oktools.net/">oktools</a></p>
<p>通过这个网站，把图片的大小降低到了一张 200-300k 的大小，还算是ok。但是图片压缩了以后访问还是略慢，这个时候想到了 Nginx 的 gzip 功能，Nginx 可以将一些静态资源进行 gzip 压缩发送给浏览器，然后浏览器会自动解压，我寻思这样可能可以再加快一点访问速度，于是开始配置 Nginx 的压缩。实测图片不需要压缩，因为根本压不了多少，但是 Vue 打包后一些巨大的 js 文件倒是压缩效果非常不错，可能一个 3 400k 的 js 文件压缩以后就不到100k，css 也可以压缩。下面直接贴配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">gzip</span> <span class="literal">on</span>;</span><br><span class="line"><span class="attribute">gzip_types</span> application/javascript text/css;</span><br><span class="line"><span class="attribute">gzip_vary</span> <span class="literal">on</span>;</span><br><span class="line"><span class="attribute">gzip_disable</span> <span class="string">&quot;MSIE [1-6]\.&quot;</span></span><br><span class="line">gzip_min_length <span class="number">1024</span>;</span><br><span class="line"><span class="attribute">gzip_proxied</span> <span class="literal">off</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>gzip gzip_types gzip_vary 这几个配置比较重要，剩下的似乎不那么要紧，啥意思也忘了，用到的时候再查。</p>
</blockquote>
<p>这块配置放到了 nginx 目录的 conf&#x2F;conf.d 目录下的 gzip.conf 中，这个目录里面就是一些我自己的配置文件，比如上面部署 Vue 的配置我就写在了这个目录的 manyin.conf 文件中，然后在 nginx.conf 文件中 include 就行了。</p>
<p>配置完这些以后就算是差不多了，访问速度反正是说得过去。</p>
<h1 id="3-后端部署"><a href="#3-后端部署" class="headerlink" title="3. 后端部署"></a>3. 后端部署</h1><p>后端倒是部署的方便，为啥？没那么多要求，就是改个启动配置，比如 mysql 的连接，redis 的连接这些的。</p>
<p>整个项目用 go 开发，首先服务器下个 go，直接 <code>yum install -y go</code> 就行了，懒得用源码包安装。然后同理用 git 把后端代码拉取下来，安装项目的依赖包，首先得配置一下代理，否则下载 go 的第三方宝可能会比较慢：<code>go env -w GOPROXY=https://goproxy.cn,direct</code>（忘了是不是这个了，反正是当时配置了代理）。然后就是下载依赖包，好像直接 <code>go mod tidy</code> 就行了。最后一步是 <code>go mod vendor</code> 将依赖包拉到项目目录中，这样项目就可以脱离 gopath 了。</p>
<p>然后 <code>go run main.go</code> 测试一下ok不，ok的话打包：<code>go build</code> 然后设置后台执行：<code>nohup ./go-service &gt; logs.log &amp;</code> 就可以了。</p>
<p>到这里，前后端就算是部署完了，总结一下：后端开放 9090 端口，Nginx 将 &#x2F;v1&#x2F;* 请求转发到 9090 口实现反向代理，同时避免了跨域。Vue 项目部署在 Nginx 上，开启 gzip 帮忙加速。然后就可以愉快的通过 IP 地址访问项目了。</p>
<h1 id="4-域名、DNS、备案"><a href="#4-域名、DNS、备案" class="headerlink" title="4. 域名、DNS、备案"></a>4. 域名、DNS、备案</h1><p>后面的倒是比较的简单吧算是，主要是麻烦，特别的麻烦，但是因为我整个流程是在腾讯云办的，所以跟着腾讯云的文档全程没有问题。</p>
<h2 id="4-1-域名"><a href="#4-1-域名" class="headerlink" title="4.1 域名"></a>4.1 域名</h2><p>首先第一步就是买域名，买完了以后还需要买个 DNS 套餐。我这里用的是腾讯买的域名，买完以后进入腾讯的 DNSPod，给域名添加一个 A 记录（IPv4记录），指向我们从腾讯云买的服务器。然后不出意外一会儿就能通过域名访问了。</p>
<p>但是过一阵子可能再访问会告诉你未通过报备，不让你访问，这就需要进行下一步，报备。</p>
<h2 id="4-2-报备"><a href="#4-2-报备" class="headerlink" title="4.2 报备"></a>4.2 报备</h2><p>这一步其实也简单，跟着腾讯的文档做就可以了。首先第一步是腾讯备案，腾讯会先给把关，通过微信小程序进行备案，然后提供相关材料即可，具体啥材料文档有说的。</p>
<p>对了，备案的时候可能需要把 DNS 的解析关掉。</p>
<p>其实作为我们用户只需要做第一步就行了，就是填上你的报备信息，然后腾讯审核完了就会送给省里去申，这个倒是很慢，我10月3号提交的，10月19号才审核完。</p>
<p>审完了以后会给你一个备案号，把这个备案号贴到网站的底部：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://beian.miit.gov.cn/&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span>冀ICP备xxx号-1<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>就可以了。说是不贴的话要罚款。</p>
<h2 id="4-3-公安备案"><a href="#4-3-公安备案" class="headerlink" title="4.3 公安备案"></a>4.3 公安备案</h2><p>管局备案完了就要去公安备案，也是跟着腾讯的文档就行了，我也是今天刚提交的，不知道结果咋样。顺带一提，腾讯的文档写的是真不错。</p>
<h2 id="4-4-SSL-证书"><a href="#4-4-SSL-证书" class="headerlink" title="4.4 SSL 证书"></a>4.4 SSL 证书</h2><p>腾讯给提供一年的免费 SSL 证书，进入腾讯的 SSL 那个控制台就能看见，申请一个，然后怎么把证书部署到 Nginx，同样有详细的文档，这里就不说了。</p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><p>总结一下奥，域名、DNS、备案、SSL 着一系列操作只需要跟着腾讯的文档就完全没有问题，就死死把握一个流程：购买域名和DNS -&gt; 添加解析记录 -&gt; 提交备案 -&gt; 安装 SSL -&gt; 公安备案 。然后哪个流程不会去腾讯文档查就行了。</p>
]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>部署</tag>
      </tags>
  </entry>
</search>
